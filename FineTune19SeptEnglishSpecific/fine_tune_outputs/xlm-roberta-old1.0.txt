no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/condabin/conda
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/bin/conda
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/bin/conda-env
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/bin/activate
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/bin/deactivate
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/etc/profile.d/conda.sh
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/etc/fish/conf.d/conda.fish
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/shell/condabin/Conda.psm1
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/shell/condabin/conda-hook.ps1
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/lib/python3.10/site-packages/xontrib/conda.xsh
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/etc/profile.d/conda.csh
no change     /home/s27mhusa_hpc/.bashrc
No action taken.
Starting resource monitoring every 30 seconds...
Logs will be stored in: /home/s27mhusa_hpc/Master-Thesis/OutputNewDatasets20thSeptemberFineTuneEnglish/job_monitor_logs_xlm-roberta-old1.0_23420039_20250920_133334
job-finetune-generic-bash-xlm-roberta-old.bash: line 42: iostat: command not found
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Appending key for api.wandb.ai to your netrc file: /home/s27mhusa_hpc/.netrc
wandb: Currently logged in as: murtuzanh (murtuzanh-university-bonn) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
Applying data augmentation...
Original train size: 619, Augmented size: 1238
Map:   0%|          | 0/1238 [00:00<?, ? examples/s]Map:  53%|█████▎    | 650/1238 [00:00<00:00, 5741.23 examples/s]Map: 100%|██████████| 1238/1238 [00:00<00:00, 5459.17 examples/s]Map: 100%|██████████| 1238/1238 [00:00<00:00, 4314.90 examples/s]
Map:   0%|          | 0/155 [00:00<?, ? examples/s]Map: 100%|██████████| 155/155 [00:00<00:00, 904.17 examples/s]
Map:   0%|          | 0/233 [00:00<?, ? examples/s]Map: 100%|██████████| 233/233 [00:00<00:00, 1522.63 examples/s]
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
/home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/fine_tune_xlm_roberta_old.py:275: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[I 2025-09-20 13:33:46,258] A new study created in memory with name: no-name-e54cfbb4-2a64-4cea-9c43-94e2ae4cabfb
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_133347-8ew4gji2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-dream-777
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/8ew4gji2
  0%|          | 0/80 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  1%|▏         | 1/80 [00:03<04:21,  3.31s/it]  2%|▎         | 2/80 [00:05<03:22,  2.59s/it]  4%|▍         | 3/80 [00:07<03:03,  2.38s/it]  5%|▌         | 4/80 [00:09<02:53,  2.28s/it]  6%|▋         | 5/80 [00:11<02:45,  2.20s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.60it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

                                             [A                                              
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A  6%|▋         | 5/80 [00:12<02:45,  2.20s/it]
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  8%|▊         | 6/80 [00:21<05:55,  4.80s/it]  9%|▉         | 7/80 [00:23<04:46,  3.92s/it] 10%|█         | 8/80 [00:25<04:01,  3.35s/it] 11%|█▏        | 9/80 [00:27<03:32,  2.99s/it] 12%|█▎        | 10/80 [00:29<03:07,  2.67s/it]{'eval_loss': 3.0600266456604004, 'eval_precision': 0.0009084302325581395, 'eval_recall': 0.013089005235602094, 'eval_f1': 0.0016989466530750934, 'eval_accuracy': 0.004202819956616052, 'eval_runtime': 1.0368, 'eval_samples_per_second': 149.497, 'eval_steps_per_second': 4.822, 'epoch': 1.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.63it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.31it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.90it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

                                             [A                                               
100%|██████████| 5/5 [00:00<00:00,  6.90it/s][A 12%|█▎        | 10/80 [00:30<03:07,  2.67s/it]
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 14%|█▍        | 11/80 [00:39<05:27,  4.74s/it] 15%|█▌        | 12/80 [00:41<04:31,  3.99s/it] 16%|█▋        | 13/80 [00:43<03:49,  3.43s/it] 18%|█▊        | 14/80 [00:45<03:20,  3.04s/it] 19%|█▉        | 15/80 [00:47<02:56,  2.72s/it]{'eval_loss': 2.0996904373168945, 'eval_precision': 0.00036536353671903543, 'eval_recall': 0.002617801047120419, 'eval_f1': 0.0006412311638345623, 'eval_accuracy': 0.5797180043383948, 'eval_runtime': 1.0218, 'eval_samples_per_second': 151.686, 'eval_steps_per_second': 4.893, 'epoch': 2.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.60it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.27it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 19%|█▉        | 15/80 [00:48<02:56,  2.72s/it]
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 20%|██        | 16/80 [00:57<05:02,  4.73s/it] 21%|██▏       | 17/80 [00:59<04:08,  3.95s/it] 22%|██▎       | 18/80 [01:01<03:30,  3.40s/it] 24%|██▍       | 19/80 [01:03<03:04,  3.02s/it] 25%|██▌       | 20/80 [01:05<02:42,  2.71s/it]{'eval_loss': 0.5178698897361755, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9267895878524945, 'eval_runtime': 1.0175, 'eval_samples_per_second': 152.329, 'eval_steps_per_second': 4.914, 'epoch': 3.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.56it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.25it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.24it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 25%|██▌       | 20/80 [01:06<02:42,  2.71s/it]
100%|██████████| 5/5 [00:00<00:00,  6.24it/s][A
                                             [A                                                25%|██▌       | 20/80 [01:13<02:42,  2.71s/it] 25%|██▌       | 20/80 [01:13<03:41,  3.69s/it]
[I 2025-09-20 13:35:02,339] Trial 0 finished with value: 0.9276030368763557 and parameters: {'learning_rate': 7.773437893873395e-06, 'num_train_epochs': 16, 'per_device_train_batch_size': 16, 'weight_decay': 0.05947373546837456, 'warmup_ratio': 0.05380735626699773, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.9276030368763557.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▅██
wandb:                 eval/f1 █▄▁▁
wandb:               eval/loss █▅▁▁
wandb:          eval/precision █▄▁▁
wandb:             eval/recall █▂▁▁
wandb:            eval/runtime ▄▂▁█
wandb: eval/samples_per_second ▅▇█▁
wandb:   eval/steps_per_second ▅▇█▁
wandb:             train/epoch ▁▃▆██
wandb:       train/global_step ▁▃▆██
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.9276
wandb:                  eval/f1 0
wandb:                eval/loss 0.51508
wandb:           eval/precision 0
wandb:              eval/recall 0
wandb:             eval/runtime 1.0657
wandb:  eval/samples_per_second 145.447
wandb:    eval/steps_per_second 4.692
wandb:               total_flos 1149797729470464.0
wandb:              train/epoch 4
wandb:        train/global_step 20
wandb:               train_loss 1.98936
wandb:            train_runtime 74.4125
wandb: train_samples_per_second 266.192
wandb:   train_steps_per_second 1.075
wandb: 
wandb: 🚀 View run balmy-dream-777 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/8ew4gji2
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250920_133347-8ew4gji2/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_133505-qxkzclvw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-serenity-778
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/qxkzclvw
{'eval_loss': 0.5150824785232544, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9276030368763557, 'eval_runtime': 1.0657, 'eval_samples_per_second': 145.447, 'eval_steps_per_second': 4.692, 'epoch': 4.0}
{'train_runtime': 74.4125, 'train_samples_per_second': 266.192, 'train_steps_per_second': 1.075, 'train_loss': 1.9893646240234375, 'epoch': 4.0}
  0%|          | 0/360 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/360 [00:01<08:53,  1.49s/it]  1%|          | 2/360 [00:02<08:53,  1.49s/it]  1%|          | 3/360 [00:04<08:47,  1.48s/it]  1%|          | 4/360 [00:05<08:43,  1.47s/it]  1%|▏         | 5/360 [00:07<08:48,  1.49s/it]  2%|▏         | 6/360 [00:08<08:43,  1.48s/it]  2%|▏         | 7/360 [00:10<08:39,  1.47s/it]  2%|▏         | 8/360 [00:11<08:36,  1.47s/it]  2%|▎         | 9/360 [00:13<08:34,  1.47s/it]  3%|▎         | 10/360 [00:14<08:37,  1.48s/it]  3%|▎         | 11/360 [00:16<08:33,  1.47s/it]  3%|▎         | 12/360 [00:17<08:30,  1.47s/it]  4%|▎         | 13/360 [00:19<08:29,  1.47s/it]  4%|▍         | 14/360 [00:20<08:27,  1.47s/it]  4%|▍         | 15/360 [00:22<08:31,  1.48s/it]  4%|▍         | 16/360 [00:23<08:27,  1.48s/it]  5%|▍         | 17/360 [00:25<08:24,  1.47s/it]  5%|▌         | 18/360 [00:26<08:22,  1.47s/it]  5%|▌         | 19/360 [00:27<08:19,  1.47s/it]  6%|▌         | 20/360 [00:28<07:14,  1.28s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.53it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A  6%|▌         | 20/360 [00:29<07:14,  1.28s/it]
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  6%|▌         | 21/360 [00:37<19:35,  3.47s/it]  6%|▌         | 22/360 [00:38<16:10,  2.87s/it]  6%|▋         | 23/360 [00:40<13:46,  2.45s/it]  7%|▋         | 24/360 [00:41<12:09,  2.17s/it]  7%|▋         | 25/360 [00:43<10:56,  1.96s/it]  7%|▋         | 26/360 [00:44<10:04,  1.81s/it]  8%|▊         | 27/360 [00:46<09:28,  1.71s/it]  8%|▊         | 28/360 [00:47<09:02,  1.63s/it]  8%|▊         | 29/360 [00:49<08:49,  1.60s/it]  8%|▊         | 30/360 [00:50<08:34,  1.56s/it]  9%|▊         | 31/360 [00:52<08:23,  1.53s/it]  9%|▉         | 32/360 [00:53<08:14,  1.51s/it]  9%|▉         | 33/360 [00:55<08:09,  1.50s/it]  9%|▉         | 34/360 [00:56<08:09,  1.50s/it] 10%|▉         | 35/360 [00:58<08:03,  1.49s/it] 10%|█         | 36/360 [00:59<07:59,  1.48s/it] 10%|█         | 37/360 [01:00<07:56,  1.47s/it] 11%|█         | 38/360 [01:02<07:53,  1.47s/it] 11%|█         | 39/360 [01:03<07:56,  1.48s/it] 11%|█         | 40/360 [01:04<06:41,  1.26s/it]{'eval_loss': 0.4971942603588104, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9276030368763557, 'eval_runtime': 1.0652, 'eval_samples_per_second': 145.511, 'eval_steps_per_second': 4.694, 'epoch': 1.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.68it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.33it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.91it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 11%|█         | 40/360 [01:05<06:41,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.91it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 11%|█▏        | 41/360 [01:13<17:58,  3.38s/it] 12%|█▏        | 42/360 [01:14<14:52,  2.81s/it] 12%|█▏        | 43/360 [01:16<12:46,  2.42s/it] 12%|█▏        | 44/360 [01:17<11:15,  2.14s/it] 12%|█▎        | 45/360 [01:18<10:10,  1.94s/it] 13%|█▎        | 46/360 [01:20<09:24,  1.80s/it] 13%|█▎        | 47/360 [01:21<08:51,  1.70s/it] 13%|█▎        | 48/360 [01:23<08:34,  1.65s/it] 14%|█▎        | 49/360 [01:24<08:15,  1.59s/it] 14%|█▍        | 50/360 [01:26<08:03,  1.56s/it] 14%|█▍        | 51/360 [01:27<07:54,  1.54s/it] 14%|█▍        | 52/360 [01:29<07:47,  1.52s/it] 15%|█▍        | 53/360 [01:30<07:46,  1.52s/it] 15%|█▌        | 54/360 [01:32<07:41,  1.51s/it] 15%|█▌        | 55/360 [01:33<07:37,  1.50s/it] 16%|█▌        | 56/360 [01:35<07:33,  1.49s/it] 16%|█▌        | 57/360 [01:36<07:29,  1.48s/it] 16%|█▌        | 58/360 [01:38<07:32,  1.50s/it] 16%|█▋        | 59/360 [01:39<07:27,  1.49s/it] 17%|█▋        | 60/360 [01:40<06:16,  1.26s/it]{'eval_loss': 0.2961970567703247, 'eval_precision': 0.487012987012987, 'eval_recall': 0.19633507853403143, 'eval_f1': 0.27985074626865675, 'eval_accuracy': 0.9372288503253796, 'eval_runtime': 1.0111, 'eval_samples_per_second': 153.295, 'eval_steps_per_second': 4.945, 'epoch': 2.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.56it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.26it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 17%|█▋        | 60/360 [01:41<06:16,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 17%|█▋        | 61/360 [01:49<17:09,  3.44s/it] 17%|█▋        | 62/360 [01:50<14:14,  2.87s/it] 18%|█▊        | 63/360 [01:51<12:06,  2.44s/it] 18%|█▊        | 64/360 [01:53<10:36,  2.15s/it] 18%|█▊        | 65/360 [01:54<09:34,  1.95s/it] 18%|█▊        | 66/360 [01:56<08:49,  1.80s/it] 19%|█▊        | 67/360 [01:57<08:22,  1.72s/it] 19%|█▉        | 68/360 [01:59<07:58,  1.64s/it] 19%|█▉        | 69/360 [02:00<07:41,  1.59s/it] 19%|█▉        | 70/360 [02:02<07:28,  1.55s/it] 20%|█▉        | 71/360 [02:03<07:20,  1.52s/it] 20%|██        | 72/360 [02:05<07:18,  1.52s/it] 20%|██        | 73/360 [02:06<07:11,  1.50s/it] 21%|██        | 74/360 [02:08<07:06,  1.49s/it] 21%|██        | 75/360 [02:09<07:03,  1.49s/it] 21%|██        | 76/360 [02:11<07:00,  1.48s/it] 21%|██▏       | 77/360 [02:12<07:02,  1.49s/it] 22%|██▏       | 78/360 [02:14<06:58,  1.48s/it] 22%|██▏       | 79/360 [02:15<06:55,  1.48s/it] 22%|██▏       | 80/360 [02:16<05:50,  1.25s/it]{'eval_loss': 0.18884898722171783, 'eval_precision': 0.5400593471810089, 'eval_recall': 0.47643979057591623, 'eval_f1': 0.506258692628651, 'eval_accuracy': 0.954853579175705, 'eval_runtime': 1.0154, 'eval_samples_per_second': 152.647, 'eval_steps_per_second': 4.924, 'epoch': 3.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.61it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.29it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A                                                
                                             [A 22%|██▏       | 80/360 [02:17<05:50,  1.25s/it]
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 22%|██▎       | 81/360 [02:24<16:01,  3.45s/it] 23%|██▎       | 82/360 [02:26<13:13,  2.85s/it] 23%|██▎       | 83/360 [02:27<11:15,  2.44s/it] 23%|██▎       | 84/360 [02:29<09:53,  2.15s/it] 24%|██▎       | 85/360 [02:30<08:54,  1.94s/it] 24%|██▍       | 86/360 [02:32<08:18,  1.82s/it] 24%|██▍       | 87/360 [02:33<07:48,  1.72s/it] 24%|██▍       | 88/360 [02:35<07:26,  1.64s/it] 25%|██▍       | 89/360 [02:36<07:11,  1.59s/it] 25%|██▌       | 90/360 [02:38<06:59,  1.55s/it] 25%|██▌       | 91/360 [02:39<06:55,  1.54s/it] 26%|██▌       | 92/360 [02:41<06:48,  1.52s/it] 26%|██▌       | 93/360 [02:42<06:43,  1.51s/it] 26%|██▌       | 94/360 [02:44<06:38,  1.50s/it] 26%|██▋       | 95/360 [02:45<06:35,  1.49s/it] 27%|██▋       | 96/360 [02:47<06:36,  1.50s/it] 27%|██▋       | 97/360 [02:48<06:32,  1.49s/it] 27%|██▋       | 98/360 [02:50<06:29,  1.49s/it] 28%|██▊       | 99/360 [02:51<06:26,  1.48s/it] 28%|██▊       | 100/360 [02:52<05:26,  1.26s/it]{'eval_loss': 0.13783147931098938, 'eval_precision': 0.5919811320754716, 'eval_recall': 0.6570680628272252, 'eval_f1': 0.6228287841191067, 'eval_accuracy': 0.9627169197396963, 'eval_runtime': 1.0144, 'eval_samples_per_second': 152.803, 'eval_steps_per_second': 4.929, 'epoch': 4.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.57it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.31it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.28it/s][A                                                 
                                             [A 28%|██▊       | 100/360 [02:53<05:26,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.28it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 28%|██▊       | 101/360 [03:00<15:04,  3.49s/it] 28%|██▊       | 102/360 [03:02<12:24,  2.88s/it] 29%|██▊       | 103/360 [03:03<10:31,  2.46s/it] 29%|██▉       | 104/360 [03:05<09:13,  2.16s/it] 29%|██▉       | 105/360 [03:06<08:22,  1.97s/it] 29%|██▉       | 106/360 [03:08<07:42,  1.82s/it] 30%|██▉       | 107/360 [03:09<07:13,  1.71s/it] 30%|███       | 108/360 [03:11<06:52,  1.64s/it] 30%|███       | 109/360 [03:12<06:38,  1.59s/it] 31%|███       | 110/360 [03:14<06:32,  1.57s/it] 31%|███       | 111/360 [03:15<06:23,  1.54s/it] 31%|███       | 112/360 [03:17<06:16,  1.52s/it] 31%|███▏      | 113/360 [03:18<06:11,  1.50s/it] 32%|███▏      | 114/360 [03:20<06:07,  1.49s/it] 32%|███▏      | 115/360 [03:21<06:08,  1.51s/it] 32%|███▏      | 116/360 [03:23<06:04,  1.50s/it] 32%|███▎      | 117/360 [03:24<06:01,  1.49s/it] 33%|███▎      | 118/360 [03:26<05:58,  1.48s/it] 33%|███▎      | 119/360 [03:27<05:55,  1.48s/it] 33%|███▎      | 120/360 [03:28<05:03,  1.27s/it]{'eval_loss': 0.12043830752372742, 'eval_precision': 0.6373873873873874, 'eval_recall': 0.7408376963350786, 'eval_f1': 0.6852300242130751, 'eval_accuracy': 0.9677331887201736, 'eval_runtime': 1.0632, 'eval_samples_per_second': 145.79, 'eval_steps_per_second': 4.703, 'epoch': 5.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.54it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.28it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.92it/s][A                                                 
                                             [A 33%|███▎      | 120/360 [03:29<05:03,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.92it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 34%|███▎      | 121/360 [03:36<13:29,  3.39s/it] 34%|███▍      | 122/360 [03:38<11:09,  2.81s/it] 34%|███▍      | 123/360 [03:39<09:30,  2.41s/it] 34%|███▍      | 124/360 [03:41<08:25,  2.14s/it] 35%|███▍      | 125/360 [03:42<07:36,  1.94s/it] 35%|███▌      | 126/360 [03:44<07:01,  1.80s/it] 35%|███▌      | 127/360 [03:45<06:36,  1.70s/it] 36%|███▌      | 128/360 [03:47<06:19,  1.64s/it] 36%|███▌      | 129/360 [03:48<06:10,  1.61s/it] 36%|███▌      | 130/360 [03:50<06:00,  1.57s/it] 36%|███▋      | 131/360 [03:51<05:53,  1.54s/it] 37%|███▋      | 132/360 [03:53<05:47,  1.52s/it] 37%|███▋      | 133/360 [03:54<05:42,  1.51s/it] 37%|███▋      | 134/360 [03:56<05:43,  1.52s/it] 38%|███▊      | 135/360 [03:57<05:39,  1.51s/it] 38%|███▊      | 136/360 [03:59<05:35,  1.50s/it] 38%|███▊      | 137/360 [04:00<05:32,  1.49s/it] 38%|███▊      | 138/360 [04:01<05:29,  1.49s/it] 39%|███▊      | 139/360 [04:03<05:31,  1.50s/it] 39%|███▉      | 140/360 [04:04<04:39,  1.27s/it]{'eval_loss': 0.12251867353916168, 'eval_precision': 0.7153284671532847, 'eval_recall': 0.7696335078534031, 'eval_f1': 0.7414880201765448, 'eval_accuracy': 0.9709869848156182, 'eval_runtime': 1.0094, 'eval_samples_per_second': 153.557, 'eval_steps_per_second': 4.953, 'epoch': 6.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.63it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A                                                 
                                             [A 39%|███▉      | 140/360 [04:05<04:39,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 39%|███▉      | 141/360 [04:12<12:31,  3.43s/it] 39%|███▉      | 142/360 [04:14<10:20,  2.85s/it] 40%|███▉      | 143/360 [04:15<08:52,  2.45s/it] 40%|████      | 144/360 [04:17<07:46,  2.16s/it] 40%|████      | 145/360 [04:18<07:00,  1.96s/it] 41%|████      | 146/360 [04:20<06:27,  1.81s/it] 41%|████      | 147/360 [04:21<06:04,  1.71s/it] 41%|████      | 148/360 [04:23<05:53,  1.67s/it] 41%|████▏     | 149/360 [04:24<05:39,  1.61s/it] 42%|████▏     | 150/360 [04:26<05:29,  1.57s/it] 42%|████▏     | 151/360 [04:27<05:22,  1.54s/it] 42%|████▏     | 152/360 [04:29<05:16,  1.52s/it] 42%|████▎     | 153/360 [04:30<05:16,  1.53s/it] 43%|████▎     | 154/360 [04:32<05:11,  1.51s/it] 43%|████▎     | 155/360 [04:33<05:08,  1.50s/it] 43%|████▎     | 156/360 [04:35<05:05,  1.50s/it] 44%|████▎     | 157/360 [04:36<05:02,  1.49s/it] 44%|████▍     | 158/360 [04:38<05:04,  1.51s/it] 44%|████▍     | 159/360 [04:39<05:00,  1.49s/it] 44%|████▍     | 160/360 [04:40<04:12,  1.26s/it]{'eval_loss': 0.125009223818779, 'eval_precision': 0.7918918918918919, 'eval_recall': 0.7670157068062827, 'eval_f1': 0.7792553191489362, 'eval_accuracy': 0.9755965292841648, 'eval_runtime': 1.0132, 'eval_samples_per_second': 152.986, 'eval_steps_per_second': 4.935, 'epoch': 7.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.60it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.84it/s][A                                                 
                                             [A 44%|████▍     | 160/360 [04:41<04:12,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.84it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 45%|████▍     | 161/360 [04:48<11:28,  3.46s/it] 45%|████▌     | 162/360 [04:50<09:26,  2.86s/it] 45%|████▌     | 163/360 [04:51<08:05,  2.46s/it] 46%|████▌     | 164/360 [04:53<07:05,  2.17s/it] 46%|████▌     | 165/360 [04:54<06:22,  1.96s/it] 46%|████▌     | 166/360 [04:56<05:51,  1.81s/it] 46%|████▋     | 167/360 [04:57<05:30,  1.71s/it] 47%|████▋     | 168/360 [04:59<05:18,  1.66s/it] 47%|████▋     | 169/360 [05:00<05:06,  1.60s/it] 47%|████▋     | 170/360 [05:02<04:57,  1.57s/it] 48%|████▊     | 171/360 [05:03<04:51,  1.54s/it] 48%|████▊     | 172/360 [05:05<04:46,  1.52s/it] 48%|████▊     | 173/360 [05:06<04:45,  1.53s/it] 48%|████▊     | 174/360 [05:08<04:41,  1.51s/it] 49%|████▊     | 175/360 [05:09<04:38,  1.50s/it] 49%|████▉     | 176/360 [05:11<04:34,  1.49s/it] 49%|████▉     | 177/360 [05:12<04:35,  1.50s/it] 49%|████▉     | 178/360 [05:14<04:32,  1.50s/it] 50%|████▉     | 179/360 [05:15<04:29,  1.49s/it] 50%|█████     | 180/360 [05:16<03:46,  1.26s/it]{'eval_loss': 0.11764772236347198, 'eval_precision': 0.7562189054726368, 'eval_recall': 0.7958115183246073, 'eval_f1': 0.7755102040816326, 'eval_accuracy': 0.9739696312364425, 'eval_runtime': 1.0173, 'eval_samples_per_second': 152.365, 'eval_steps_per_second': 4.915, 'epoch': 8.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.54it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.31it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.89it/s][A                                                 
                                             [A 50%|█████     | 180/360 [05:17<03:46,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.89it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 50%|█████     | 181/360 [05:25<10:20,  3.47s/it] 51%|█████     | 182/360 [05:26<08:30,  2.87s/it] 51%|█████     | 183/360 [05:27<07:14,  2.45s/it] 51%|█████     | 184/360 [05:29<06:20,  2.16s/it] 51%|█████▏    | 185/360 [05:30<05:41,  1.95s/it] 52%|█████▏    | 186/360 [05:32<05:18,  1.83s/it] 52%|█████▏    | 187/360 [05:33<04:58,  1.72s/it] 52%|█████▏    | 188/360 [05:35<04:43,  1.65s/it] 52%|█████▎    | 189/360 [05:36<04:32,  1.60s/it] 53%|█████▎    | 190/360 [05:38<04:25,  1.56s/it] 53%|█████▎    | 191/360 [05:39<04:27,  1.58s/it] 53%|█████▎    | 192/360 [05:41<04:20,  1.55s/it] 54%|█████▎    | 193/360 [05:42<04:15,  1.53s/it] 54%|█████▍    | 194/360 [05:44<04:10,  1.51s/it] 54%|█████▍    | 195/360 [05:45<04:08,  1.50s/it] 54%|█████▍    | 196/360 [05:47<04:08,  1.51s/it] 55%|█████▍    | 197/360 [05:48<04:05,  1.51s/it] 55%|█████▌    | 198/360 [05:50<04:02,  1.50s/it] 55%|█████▌    | 199/360 [05:51<03:59,  1.49s/it] 56%|█████▌    | 200/360 [05:52<03:21,  1.26s/it]{'eval_loss': 0.12453460693359375, 'eval_precision': 0.754257907542579, 'eval_recall': 0.8115183246073299, 'eval_f1': 0.7818411097099621, 'eval_accuracy': 0.975732104121475, 'eval_runtime': 1.0128, 'eval_samples_per_second': 153.035, 'eval_steps_per_second': 4.937, 'epoch': 9.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.62it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.31it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A                                                 
                                             [A 56%|█████▌    | 200/360 [05:53<03:21,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 56%|█████▌    | 201/360 [06:01<09:22,  3.54s/it] 56%|█████▌    | 202/360 [06:02<07:41,  2.92s/it] 56%|█████▋    | 203/360 [06:04<06:30,  2.49s/it] 57%|█████▋    | 204/360 [06:05<05:40,  2.18s/it] 57%|█████▋    | 205/360 [06:07<05:08,  1.99s/it] 57%|█████▋    | 206/360 [06:08<04:42,  1.84s/it] 57%|█████▊    | 207/360 [06:10<04:24,  1.73s/it] 58%|█████▊    | 208/360 [06:11<04:10,  1.65s/it] 58%|█████▊    | 209/360 [06:13<04:01,  1.60s/it] 58%|█████▊    | 210/360 [06:14<03:57,  1.58s/it] 59%|█████▊    | 211/360 [06:16<03:51,  1.55s/it] 59%|█████▉    | 212/360 [06:17<03:46,  1.53s/it] 59%|█████▉    | 213/360 [06:19<03:42,  1.51s/it] 59%|█████▉    | 214/360 [06:20<03:39,  1.50s/it] 60%|█████▉    | 215/360 [06:22<03:39,  1.51s/it] 60%|██████    | 216/360 [06:23<03:36,  1.50s/it] 60%|██████    | 217/360 [06:25<03:33,  1.49s/it] 61%|██████    | 218/360 [06:26<03:31,  1.49s/it] 61%|██████    | 219/360 [06:28<03:29,  1.48s/it] 61%|██████    | 220/360 [06:28<02:56,  1.26s/it]{'eval_loss': 0.12807941436767578, 'eval_precision': 0.7892030848329049, 'eval_recall': 0.8036649214659686, 'eval_f1': 0.7963683527885862, 'eval_accuracy': 0.9750542299349241, 'eval_runtime': 1.0125, 'eval_samples_per_second': 153.079, 'eval_steps_per_second': 4.938, 'epoch': 10.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.66it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.49it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.36it/s][A                                                 
                                             [A 61%|██████    | 220/360 [06:30<02:56,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.36it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 61%|██████▏   | 221/360 [06:37<08:11,  3.53s/it] 62%|██████▏   | 222/360 [06:39<06:42,  2.92s/it] 62%|██████▏   | 223/360 [06:40<05:40,  2.48s/it] 62%|██████▏   | 224/360 [06:42<04:56,  2.18s/it] 62%|██████▎   | 225/360 [06:43<04:27,  1.98s/it] 63%|██████▎   | 226/360 [06:45<04:05,  1.83s/it] 63%|██████▎   | 227/360 [06:46<03:49,  1.72s/it] 63%|██████▎   | 228/360 [06:48<03:37,  1.65s/it] 64%|██████▎   | 229/360 [06:49<03:29,  1.60s/it] 64%|██████▍   | 230/360 [06:51<03:24,  1.57s/it] 64%|██████▍   | 231/360 [06:52<03:19,  1.55s/it] 64%|██████▍   | 232/360 [06:54<03:15,  1.52s/it] 65%|██████▍   | 233/360 [06:55<03:11,  1.51s/it] 65%|██████▌   | 234/360 [06:57<03:10,  1.52s/it] 65%|██████▌   | 235/360 [06:58<03:07,  1.50s/it] 66%|██████▌   | 236/360 [07:00<03:05,  1.49s/it] 66%|██████▌   | 237/360 [07:01<03:03,  1.49s/it] 66%|██████▌   | 238/360 [07:02<03:00,  1.48s/it] 66%|██████▋   | 239/360 [07:04<03:03,  1.52s/it] 67%|██████▋   | 240/360 [07:05<02:34,  1.28s/it]{'eval_loss': 0.1345437467098236, 'eval_precision': 0.7493857493857494, 'eval_recall': 0.7984293193717278, 'eval_f1': 0.773130544993663, 'eval_accuracy': 0.973562906724512, 'eval_runtime': 1.072, 'eval_samples_per_second': 144.593, 'eval_steps_per_second': 4.664, 'epoch': 11.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.59it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.32it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.90it/s][A                                                 
                                             [A 67%|██████▋   | 240/360 [07:06<02:34,  1.28s/it]
100%|██████████| 5/5 [00:00<00:00,  6.90it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 67%|██████▋   | 241/360 [07:13<06:50,  3.45s/it] 67%|██████▋   | 242/360 [07:15<05:36,  2.85s/it] 68%|██████▊   | 243/360 [07:16<04:45,  2.44s/it] 68%|██████▊   | 244/360 [07:18<04:11,  2.17s/it] 68%|██████▊   | 245/360 [07:19<03:44,  1.96s/it] 68%|██████▊   | 246/360 [07:21<03:26,  1.81s/it] 69%|██████▊   | 247/360 [07:22<03:13,  1.71s/it] 69%|██████▉   | 248/360 [07:24<03:03,  1.64s/it] 69%|██████▉   | 249/360 [07:25<02:58,  1.61s/it] 69%|██████▉   | 250/360 [07:27<02:52,  1.57s/it] 70%|██████▉   | 251/360 [07:28<02:47,  1.54s/it] 70%|███████   | 252/360 [07:30<02:44,  1.52s/it] 70%|███████   | 253/360 [07:31<02:43,  1.52s/it] 71%|███████   | 254/360 [07:33<02:40,  1.51s/it] 71%|███████   | 255/360 [07:34<02:37,  1.50s/it] 71%|███████   | 256/360 [07:36<02:34,  1.49s/it] 71%|███████▏  | 257/360 [07:37<02:32,  1.48s/it] 72%|███████▏  | 258/360 [07:39<02:32,  1.50s/it] 72%|███████▏  | 259/360 [07:40<02:30,  1.49s/it] 72%|███████▏  | 260/360 [07:41<02:06,  1.26s/it]{'eval_loss': 0.126034215092659, 'eval_precision': 0.7882653061224489, 'eval_recall': 0.8089005235602095, 'eval_f1': 0.7984496124031008, 'eval_accuracy': 0.976409978308026, 'eval_runtime': 1.0107, 'eval_samples_per_second': 153.367, 'eval_steps_per_second': 4.947, 'epoch': 12.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.54it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.31it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A                                                 
                                             [A 72%|███████▏  | 260/360 [07:42<02:06,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 72%|███████▎  | 261/360 [07:49<05:39,  3.43s/it] 73%|███████▎  | 262/360 [07:51<04:38,  2.84s/it] 73%|███████▎  | 263/360 [07:52<03:59,  2.47s/it] 73%|███████▎  | 264/360 [07:54<03:28,  2.17s/it] 74%|███████▎  | 265/360 [07:55<03:06,  1.96s/it] 74%|███████▍  | 266/360 [07:57<02:50,  1.81s/it] 74%|███████▍  | 267/360 [07:58<02:39,  1.71s/it] 74%|███████▍  | 268/360 [08:00<02:32,  1.66s/it] 75%|███████▍  | 269/360 [08:01<02:25,  1.60s/it] 75%|███████▌  | 270/360 [08:03<02:20,  1.56s/it] 75%|███████▌  | 271/360 [08:04<02:16,  1.54s/it] 76%|███████▌  | 272/360 [08:06<02:13,  1.52s/it] 76%|███████▌  | 273/360 [08:07<02:12,  1.52s/it] 76%|███████▌  | 274/360 [08:09<02:09,  1.51s/it] 76%|███████▋  | 275/360 [08:10<02:07,  1.50s/it] 77%|███████▋  | 276/360 [08:12<02:05,  1.49s/it] 77%|███████▋  | 277/360 [08:13<02:02,  1.48s/it] 77%|███████▋  | 278/360 [08:15<02:02,  1.49s/it] 78%|███████▊  | 279/360 [08:16<02:00,  1.49s/it] 78%|███████▊  | 280/360 [08:17<01:40,  1.26s/it]{'eval_loss': 0.13855084776878357, 'eval_precision': 0.7888040712468194, 'eval_recall': 0.8115183246073299, 'eval_f1': 0.8, 'eval_accuracy': 0.9746475054229935, 'eval_runtime': 1.0159, 'eval_samples_per_second': 152.569, 'eval_steps_per_second': 4.922, 'epoch': 13.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.58it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.27it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A                                                 
                                             [A 78%|███████▊  | 280/360 [08:18<01:40,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 78%|███████▊  | 281/360 [08:25<04:27,  3.39s/it] 78%|███████▊  | 282/360 [08:27<03:40,  2.83s/it] 79%|███████▊  | 283/360 [08:28<03:06,  2.42s/it] 79%|███████▉  | 284/360 [08:30<02:42,  2.13s/it] 79%|███████▉  | 285/360 [08:31<02:24,  1.93s/it] 79%|███████▉  | 286/360 [08:33<02:12,  1.79s/it] 80%|███████▉  | 287/360 [08:34<02:04,  1.71s/it] 80%|████████  | 288/360 [08:36<01:57,  1.64s/it] 80%|████████  | 289/360 [08:37<01:52,  1.58s/it] 81%|████████  | 290/360 [08:38<01:48,  1.55s/it] 81%|████████  | 291/360 [08:40<01:45,  1.53s/it] 81%|████████  | 292/360 [08:42<01:45,  1.55s/it] 81%|████████▏ | 293/360 [08:43<01:42,  1.53s/it] 82%|████████▏ | 294/360 [08:44<01:39,  1.51s/it] 82%|████████▏ | 295/360 [08:46<01:37,  1.50s/it] 82%|████████▏ | 296/360 [08:47<01:35,  1.49s/it] 82%|████████▎ | 297/360 [08:49<01:34,  1.50s/it] 83%|████████▎ | 298/360 [08:50<01:32,  1.49s/it] 83%|████████▎ | 299/360 [08:52<01:30,  1.49s/it] 83%|████████▎ | 300/360 [08:53<01:15,  1.26s/it]{'eval_loss': 0.1321992129087448, 'eval_precision': 0.7939698492462312, 'eval_recall': 0.8272251308900523, 'eval_f1': 0.8102564102564103, 'eval_accuracy': 0.9760032537960954, 'eval_runtime': 1.0165, 'eval_samples_per_second': 152.484, 'eval_steps_per_second': 4.919, 'epoch': 14.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.50it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.22it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.81it/s][A                                                 
                                             [A 83%|████████▎ | 300/360 [08:54<01:15,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.81it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 84%|████████▎ | 301/360 [09:01<03:26,  3.49s/it] 84%|████████▍ | 302/360 [09:03<02:47,  2.89s/it] 84%|████████▍ | 303/360 [09:04<02:20,  2.46s/it] 84%|████████▍ | 304/360 [09:06<02:01,  2.17s/it] 85%|████████▍ | 305/360 [09:07<01:47,  1.96s/it] 85%|████████▌ | 306/360 [09:09<01:39,  1.85s/it] 85%|████████▌ | 307/360 [09:10<01:31,  1.73s/it] 86%|████████▌ | 308/360 [09:12<01:26,  1.66s/it] 86%|████████▌ | 309/360 [09:13<01:21,  1.60s/it] 86%|████████▌ | 310/360 [09:15<01:18,  1.56s/it] 86%|████████▋ | 311/360 [09:16<01:16,  1.57s/it] 87%|████████▋ | 312/360 [09:18<01:13,  1.54s/it] 87%|████████▋ | 313/360 [09:19<01:11,  1.52s/it] 87%|████████▋ | 314/360 [09:21<01:09,  1.51s/it] 88%|████████▊ | 315/360 [09:22<01:07,  1.50s/it] 88%|████████▊ | 316/360 [09:24<01:06,  1.52s/it] 88%|████████▊ | 317/360 [09:25<01:04,  1.50s/it] 88%|████████▊ | 318/360 [09:27<01:02,  1.50s/it] 89%|████████▊ | 319/360 [09:28<01:01,  1.49s/it] 89%|████████▉ | 320/360 [09:29<00:50,  1.27s/it]{'eval_loss': 0.14033576846122742, 'eval_precision': 0.7953367875647669, 'eval_recall': 0.8036649214659686, 'eval_f1': 0.7994791666666667, 'eval_accuracy': 0.9754609544468547, 'eval_runtime': 1.0197, 'eval_samples_per_second': 151.999, 'eval_steps_per_second': 4.903, 'epoch': 15.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.40it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.28it/s][A
100%|██████████| 5/5 [00:00<00:00,  5.55it/s][A                                                 
                                             [A 89%|████████▉ | 320/360 [09:30<00:50,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  5.55it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 89%|████████▉ | 321/360 [09:38<02:15,  3.48s/it] 89%|████████▉ | 322/360 [09:39<01:49,  2.87s/it] 90%|████████▉ | 323/360 [09:40<01:30,  2.45s/it] 90%|█████████ | 324/360 [09:42<01:17,  2.16s/it] 90%|█████████ | 325/360 [09:43<01:08,  1.97s/it] 91%|█████████ | 326/360 [09:45<01:01,  1.82s/it] 91%|█████████ | 327/360 [09:46<00:56,  1.72s/it] 91%|█████████ | 328/360 [09:48<00:52,  1.64s/it] 91%|█████████▏| 329/360 [09:49<00:49,  1.59s/it] 92%|█████████▏| 330/360 [09:51<00:47,  1.60s/it] 92%|█████████▏| 331/360 [09:52<00:45,  1.56s/it] 92%|█████████▏| 332/360 [09:54<00:42,  1.53s/it] 92%|█████████▎| 333/360 [09:55<00:40,  1.51s/it] 93%|█████████▎| 334/360 [09:57<00:39,  1.50s/it] 93%|█████████▎| 335/360 [09:58<00:37,  1.51s/it] 93%|█████████▎| 336/360 [10:00<00:35,  1.50s/it] 94%|█████████▎| 337/360 [10:01<00:34,  1.49s/it] 94%|█████████▍| 338/360 [10:03<00:32,  1.49s/it] 94%|█████████▍| 339/360 [10:04<00:31,  1.48s/it] 94%|█████████▍| 340/360 [10:05<00:25,  1.28s/it]{'eval_loss': 0.1379488855600357, 'eval_precision': 0.7819548872180451, 'eval_recall': 0.8167539267015707, 'eval_f1': 0.7989756722151089, 'eval_accuracy': 0.9754609544468547, 'eval_runtime': 1.1323, 'eval_samples_per_second': 136.888, 'eval_steps_per_second': 4.416, 'epoch': 16.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.57it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.33it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A                                                 
                                             [A 94%|█████████▍| 340/360 [10:06<00:25,  1.28s/it]
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A
                                             [A                                                  94%|█████████▍| 340/360 [10:13<00:25,  1.28s/it] 94%|█████████▍| 340/360 [10:13<00:36,  1.80s/it]
[I 2025-09-20 13:45:20,159] Trial 1 finished with value: 3.377708616309642 and parameters: {'learning_rate': 1.8826252057245697e-05, 'num_train_epochs': 18, 'per_device_train_batch_size': 4, 'weight_decay': 0.0005397657111572729, 'warmup_ratio': 0.04596441786172467, 'optimizer': 'Adafactor'}. Best is trial 1 with value: 3.377708616309642.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▂▅▆▇▇███████████
wandb:                 eval/f1 ▁▃▅▆▇▇███████████
wandb:               eval/loss █▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          eval/precision ▁▅▆▆▇▇███████████
wandb:             eval/recall ▁▃▅▇▇█▇██████████
wandb:            eval/runtime ▄▁▁▁▄▁▁▁▁▁▅▁▁▁▂█▁
wandb: eval/samples_per_second ▅███▅██▇██▄███▇▁█
wandb:   eval/steps_per_second ▅███▅█████▄███▇▁█
wandb:             train/epoch ▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇███
wandb:       train/global_step ▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇███
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.97533
wandb:                  eval/f1 0.80051
wandb:                eval/loss 0.13863
wandb:           eval/precision 0.7825
wandb:              eval/recall 0.81937
wandb:             eval/runtime 1.0153
wandb:  eval/samples_per_second 152.657
wandb:    eval/steps_per_second 4.924
wandb:               total_flos 4886640350249472.0
wandb:              train/epoch 17
wandb:        train/global_step 340
wandb:               train_loss 0.18329
wandb:            train_runtime 616.189
wandb: train_samples_per_second 36.164
wandb:   train_steps_per_second 0.584
wandb: 
wandb: 🚀 View run lively-serenity-778 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/qxkzclvw
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250920_133505-qxkzclvw/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_134523-yeg9vkrp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-smoke-779
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/yeg9vkrp
{'eval_loss': 0.13863079249858856, 'eval_precision': 0.7825, 'eval_recall': 0.819371727748691, 'eval_f1': 0.8005115089514067, 'eval_accuracy': 0.9753253796095445, 'eval_runtime': 1.0153, 'eval_samples_per_second': 152.657, 'eval_steps_per_second': 4.924, 'epoch': 17.0}
{'train_runtime': 616.189, 'train_samples_per_second': 36.164, 'train_steps_per_second': 0.584, 'train_loss': 0.1832943411434398, 'epoch': 17.0}
  0%|          | 0/300 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/300 [00:01<07:23,  1.48s/it]  1%|          | 2/300 [00:02<07:25,  1.49s/it]  1%|          | 3/300 [00:04<07:20,  1.48s/it]  1%|▏         | 4/300 [00:05<07:17,  1.48s/it]  2%|▏         | 5/300 [00:07<07:21,  1.50s/it]  2%|▏         | 6/300 [00:08<07:16,  1.49s/it]  2%|▏         | 7/300 [00:10<07:14,  1.48s/it]  3%|▎         | 8/300 [00:11<07:11,  1.48s/it]  3%|▎         | 9/300 [00:13<07:08,  1.47s/it]  3%|▎         | 10/300 [00:14<07:10,  1.49s/it]  4%|▎         | 11/300 [00:16<07:07,  1.48s/it]  4%|▍         | 12/300 [00:17<07:04,  1.47s/it]  4%|▍         | 13/300 [00:19<07:01,  1.47s/it]  5%|▍         | 14/300 [00:20<06:59,  1.47s/it]  5%|▌         | 15/300 [00:22<07:02,  1.48s/it]  5%|▌         | 16/300 [00:23<06:59,  1.48s/it]  6%|▌         | 17/300 [00:25<06:57,  1.48s/it]  6%|▌         | 18/300 [00:26<06:55,  1.47s/it]  6%|▋         | 19/300 [00:28<06:53,  1.47s/it]  7%|▋         | 20/300 [00:28<05:54,  1.26s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00,  9.00it/s][A
 60%|██████    | 3/5 [00:00<00:00,  7.25it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.64it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.39it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A  7%|▋         | 20/300 [00:29<05:54,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.39it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  7%|▋         | 21/300 [00:37<16:11,  3.48s/it]  7%|▋         | 22/300 [00:38<13:19,  2.88s/it]  8%|▊         | 23/300 [00:40<11:19,  2.45s/it]  8%|▊         | 24/300 [00:41<09:59,  2.17s/it]  8%|▊         | 25/300 [00:43<08:58,  1.96s/it]  9%|▊         | 26/300 [00:44<08:15,  1.81s/it]  9%|▉         | 27/300 [00:46<07:45,  1.71s/it]  9%|▉         | 28/300 [00:47<07:24,  1.63s/it] 10%|▉         | 29/300 [00:49<07:19,  1.62s/it] 10%|█         | 30/300 [00:50<07:05,  1.58s/it] 10%|█         | 31/300 [00:52<06:54,  1.54s/it] 11%|█         | 32/300 [00:53<06:46,  1.52s/it] 11%|█         | 33/300 [00:55<06:40,  1.50s/it] 11%|█▏        | 34/300 [00:56<06:41,  1.51s/it] 12%|█▏        | 35/300 [00:58<06:36,  1.50s/it] 12%|█▏        | 36/300 [00:59<06:32,  1.49s/it] 12%|█▏        | 37/300 [01:01<06:28,  1.48s/it] 13%|█▎        | 38/300 [01:02<06:26,  1.47s/it] 13%|█▎        | 39/300 [01:04<06:28,  1.49s/it] 13%|█▎        | 40/300 [01:04<05:27,  1.26s/it]{'eval_loss': 3.0271317958831787, 'eval_precision': 0.0007229351165732876, 'eval_recall': 0.010471204188481676, 'eval_f1': 0.001352493660185968, 'eval_accuracy': 0.003931670281995662, 'eval_runtime': 1.0896, 'eval_samples_per_second': 142.256, 'eval_steps_per_second': 4.589, 'epoch': 1.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.59it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.32it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.95it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 13%|█▎        | 40/300 [01:05<05:27,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.95it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 14%|█▎        | 41/300 [01:13<14:37,  3.39s/it] 14%|█▍        | 42/300 [01:14<12:04,  2.81s/it] 14%|█▍        | 43/300 [01:16<10:22,  2.42s/it] 15%|█▍        | 44/300 [01:17<09:06,  2.14s/it] 15%|█▌        | 45/300 [01:19<08:12,  1.93s/it] 15%|█▌        | 46/300 [01:20<07:35,  1.79s/it] 16%|█▌        | 47/300 [01:22<07:08,  1.69s/it] 16%|█▌        | 48/300 [01:23<06:55,  1.65s/it] 16%|█▋        | 49/300 [01:25<06:39,  1.59s/it] 17%|█▋        | 50/300 [01:26<06:28,  1.55s/it] 17%|█▋        | 51/300 [01:28<06:20,  1.53s/it] 17%|█▋        | 52/300 [01:29<06:14,  1.51s/it] 18%|█▊        | 53/300 [01:31<06:14,  1.52s/it] 18%|█▊        | 54/300 [01:32<06:09,  1.50s/it] 18%|█▊        | 55/300 [01:33<06:04,  1.49s/it] 19%|█▊        | 56/300 [01:35<06:01,  1.48s/it] 19%|█▉        | 57/300 [01:36<05:59,  1.48s/it] 19%|█▉        | 58/300 [01:38<06:02,  1.50s/it] 20%|█▉        | 59/300 [01:39<05:59,  1.49s/it] 20%|██        | 60/300 [01:40<05:02,  1.26s/it]{'eval_loss': 0.5401301383972168, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9273318872017353, 'eval_runtime': 1.0065, 'eval_samples_per_second': 154.004, 'eval_steps_per_second': 4.968, 'epoch': 2.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.45it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.23it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.79it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 20%|██        | 60/300 [01:41<05:02,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.79it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 20%|██        | 61/300 [01:48<13:22,  3.36s/it] 21%|██        | 62/300 [01:50<11:08,  2.81s/it] 21%|██        | 63/300 [01:51<09:30,  2.41s/it] 21%|██▏       | 64/300 [01:53<08:20,  2.12s/it] 22%|██▏       | 65/300 [01:54<07:32,  1.93s/it] 22%|██▏       | 66/300 [01:56<06:58,  1.79s/it] 22%|██▏       | 67/300 [01:57<06:37,  1.71s/it] 23%|██▎       | 68/300 [01:59<06:19,  1.64s/it] 23%|██▎       | 69/300 [02:00<06:05,  1.58s/it] 23%|██▎       | 70/300 [02:02<05:56,  1.55s/it] 24%|██▎       | 71/300 [02:03<05:48,  1.52s/it] 24%|██▍       | 72/300 [02:05<05:47,  1.52s/it] 24%|██▍       | 73/300 [02:06<05:41,  1.51s/it] 25%|██▍       | 74/300 [02:08<05:37,  1.49s/it] 25%|██▌       | 75/300 [02:09<05:33,  1.48s/it] 25%|██▌       | 76/300 [02:11<05:31,  1.48s/it] 26%|██▌       | 77/300 [02:12<05:32,  1.49s/it] 26%|██▌       | 78/300 [02:14<05:29,  1.48s/it] 26%|██▋       | 79/300 [02:15<05:26,  1.48s/it] 27%|██▋       | 80/300 [02:16<04:35,  1.25s/it]{'eval_loss': 0.3583364188671112, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9276030368763557, 'eval_runtime': 1.0199, 'eval_samples_per_second': 151.977, 'eval_steps_per_second': 4.902, 'epoch': 3.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.53it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.32it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.89it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 27%|██▋       | 80/300 [02:17<04:35,  1.25s/it]
100%|██████████| 5/5 [00:00<00:00,  6.89it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 27%|██▋       | 81/300 [02:24<12:15,  3.36s/it] 27%|██▋       | 82/300 [02:25<10:08,  2.79s/it] 28%|██▊       | 83/300 [02:27<08:39,  2.39s/it] 28%|██▊       | 84/300 [02:28<07:36,  2.11s/it] 28%|██▊       | 85/300 [02:30<06:52,  1.92s/it] 29%|██▊       | 86/300 [02:31<06:25,  1.80s/it] 29%|██▉       | 87/300 [02:33<06:02,  1.70s/it] 29%|██▉       | 88/300 [02:34<05:45,  1.63s/it] 30%|██▉       | 89/300 [02:36<05:33,  1.58s/it] 30%|███       | 90/300 [02:37<05:24,  1.55s/it] 30%|███       | 91/300 [02:39<05:21,  1.54s/it] 31%|███       | 92/300 [02:40<05:15,  1.52s/it] 31%|███       | 93/300 [02:42<05:10,  1.50s/it] 31%|███▏      | 94/300 [02:43<05:06,  1.49s/it] 32%|███▏      | 95/300 [02:45<05:03,  1.48s/it] 32%|███▏      | 96/300 [02:46<05:04,  1.49s/it] 32%|███▏      | 97/300 [02:48<05:01,  1.48s/it] 33%|███▎      | 98/300 [02:49<04:58,  1.48s/it] 33%|███▎      | 99/300 [02:51<04:56,  1.48s/it] 33%|███▎      | 100/300 [02:51<04:10,  1.25s/it]{'eval_loss': 0.2340167611837387, 'eval_precision': 0.49222797927461137, 'eval_recall': 0.2486910994764398, 'eval_f1': 0.3304347826086957, 'eval_accuracy': 0.9406182212581344, 'eval_runtime': 1.0144, 'eval_samples_per_second': 152.802, 'eval_steps_per_second': 4.929, 'epoch': 4.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.63it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.31it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.13it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                 
                                             [A 33%|███▎      | 100/300 [02:52<04:10,  1.25s/it]
100%|██████████| 5/5 [00:00<00:00,  6.13it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 34%|███▎      | 101/300 [03:00<11:09,  3.36s/it] 34%|███▍      | 102/300 [03:01<09:13,  2.80s/it] 34%|███▍      | 103/300 [03:02<07:52,  2.40s/it] 35%|███▍      | 104/300 [03:04<06:55,  2.12s/it] 35%|███▌      | 105/300 [03:06<06:23,  1.96s/it] 35%|███▌      | 106/300 [03:07<05:52,  1.82s/it] 36%|███▌      | 107/300 [03:08<05:29,  1.71s/it] 36%|███▌      | 108/300 [03:10<05:14,  1.64s/it] 36%|███▋      | 109/300 [03:11<05:03,  1.59s/it] 37%|███▋      | 110/300 [03:13<05:01,  1.59s/it] 37%|███▋      | 111/300 [03:14<04:53,  1.55s/it] 37%|███▋      | 112/300 [03:16<04:47,  1.53s/it] 38%|███▊      | 113/300 [03:17<04:42,  1.51s/it] 38%|███▊      | 114/300 [03:19<04:38,  1.50s/it] 38%|███▊      | 115/300 [03:21<04:47,  1.55s/it] 39%|███▊      | 116/300 [03:22<04:41,  1.53s/it] 39%|███▉      | 117/300 [03:24<04:36,  1.51s/it] 39%|███▉      | 118/300 [03:25<04:32,  1.50s/it] 40%|███▉      | 119/300 [03:26<04:29,  1.49s/it] 40%|████      | 120/300 [03:27<03:55,  1.31s/it]{'eval_loss': 0.1673375964164734, 'eval_precision': 0.5576923076923077, 'eval_recall': 0.5314136125654451, 'eval_f1': 0.5442359249329759, 'eval_accuracy': 0.9585140997830802, 'eval_runtime': 1.073, 'eval_samples_per_second': 144.452, 'eval_steps_per_second': 4.66, 'epoch': 5.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.41it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.21it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.82it/s][A                                                 
                                             [A 40%|████      | 120/300 [03:28<03:55,  1.31s/it]
100%|██████████| 5/5 [00:00<00:00,  6.82it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 40%|████      | 121/300 [03:36<10:07,  3.39s/it] 41%|████      | 122/300 [03:37<08:21,  2.82s/it] 41%|████      | 123/300 [03:39<07:06,  2.41s/it] 41%|████▏     | 124/300 [03:40<06:23,  2.18s/it] 42%|████▏     | 125/300 [03:42<05:44,  1.97s/it] 42%|████▏     | 126/300 [03:43<05:16,  1.82s/it] 42%|████▏     | 127/300 [03:45<04:56,  1.71s/it] 43%|████▎     | 128/300 [03:46<04:41,  1.64s/it] 43%|████▎     | 129/300 [03:48<04:34,  1.61s/it] 43%|████▎     | 130/300 [03:49<04:25,  1.56s/it] 44%|████▎     | 131/300 [03:51<04:19,  1.54s/it] 44%|████▍     | 132/300 [03:52<04:14,  1.51s/it] 44%|████▍     | 133/300 [03:53<04:10,  1.50s/it] 45%|████▍     | 134/300 [03:55<04:14,  1.54s/it] 45%|████▌     | 135/300 [03:57<04:09,  1.51s/it] 45%|████▌     | 136/300 [03:58<04:05,  1.50s/it] 46%|████▌     | 137/300 [03:59<04:02,  1.49s/it] 46%|████▌     | 138/300 [04:01<04:00,  1.48s/it] 46%|████▋     | 139/300 [04:02<04:01,  1.50s/it] 47%|████▋     | 140/300 [04:03<03:22,  1.27s/it]{'eval_loss': 0.1350822150707245, 'eval_precision': 0.636144578313253, 'eval_recall': 0.6910994764397905, 'eval_f1': 0.6624843161856964, 'eval_accuracy': 0.9674620390455532, 'eval_runtime': 1.0208, 'eval_samples_per_second': 151.845, 'eval_steps_per_second': 4.898, 'epoch': 6.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.56it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.28it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.92it/s][A                                                 
                                             [A 47%|████▋     | 140/300 [04:04<03:22,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.92it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 47%|████▋     | 141/300 [04:11<08:57,  3.38s/it] 47%|████▋     | 142/300 [04:13<07:22,  2.80s/it] 48%|████▊     | 143/300 [04:14<06:19,  2.42s/it] 48%|████▊     | 144/300 [04:16<05:32,  2.13s/it] 48%|████▊     | 145/300 [04:17<04:59,  1.93s/it] 49%|████▊     | 146/300 [04:19<04:35,  1.79s/it] 49%|████▉     | 147/300 [04:20<04:19,  1.69s/it] 49%|████▉     | 148/300 [04:22<04:09,  1.64s/it] 50%|████▉     | 149/300 [04:23<03:59,  1.59s/it] 50%|█████     | 150/300 [04:25<03:52,  1.55s/it] 50%|█████     | 151/300 [04:26<03:46,  1.52s/it] 51%|█████     | 152/300 [04:28<03:42,  1.51s/it] 51%|█████     | 153/300 [04:29<03:41,  1.51s/it] 51%|█████▏    | 154/300 [04:31<03:38,  1.49s/it] 52%|█████▏    | 155/300 [04:32<03:35,  1.49s/it] 52%|█████▏    | 156/300 [04:34<03:32,  1.48s/it] 52%|█████▏    | 157/300 [04:35<03:30,  1.47s/it] 53%|█████▎    | 158/300 [04:37<03:31,  1.49s/it] 53%|█████▎    | 159/300 [04:38<03:28,  1.48s/it] 53%|█████▎    | 160/300 [04:39<02:55,  1.25s/it]{'eval_loss': 0.12020160257816315, 'eval_precision': 0.6930946291560103, 'eval_recall': 0.7094240837696335, 'eval_f1': 0.7011642949547219, 'eval_accuracy': 0.9712581344902386, 'eval_runtime': 1.0106, 'eval_samples_per_second': 153.372, 'eval_steps_per_second': 4.947, 'epoch': 7.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.54it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.94it/s][A                                                 
                                             [A 53%|█████▎    | 160/300 [04:40<02:55,  1.25s/it]
100%|██████████| 5/5 [00:00<00:00,  6.94it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 54%|█████▎    | 161/300 [04:47<07:53,  3.41s/it] 54%|█████▍    | 162/300 [04:49<06:29,  2.83s/it] 54%|█████▍    | 163/300 [04:50<05:35,  2.45s/it] 55%|█████▍    | 164/300 [04:52<04:53,  2.16s/it] 55%|█████▌    | 165/300 [04:53<04:23,  1.95s/it] 55%|█████▌    | 166/300 [04:55<04:02,  1.81s/it] 56%|█████▌    | 167/300 [04:56<03:47,  1.71s/it] 56%|█████▌    | 168/300 [04:58<03:40,  1.67s/it] 56%|█████▋    | 169/300 [04:59<03:31,  1.62s/it] 57%|█████▋    | 170/300 [05:01<03:24,  1.57s/it] 57%|█████▋    | 171/300 [05:02<03:19,  1.55s/it] 57%|█████▋    | 172/300 [05:04<03:19,  1.56s/it] 58%|█████▊    | 173/300 [05:05<03:14,  1.53s/it] 58%|█████▊    | 174/300 [05:07<03:10,  1.51s/it] 58%|█████▊    | 175/300 [05:08<03:08,  1.50s/it] 59%|█████▊    | 176/300 [05:10<03:05,  1.50s/it] 59%|█████▉    | 177/300 [05:11<03:07,  1.52s/it] 59%|█████▉    | 178/300 [05:13<03:04,  1.51s/it] 60%|█████▉    | 179/300 [05:14<03:01,  1.50s/it] 60%|██████    | 180/300 [05:15<02:32,  1.27s/it]{'eval_loss': 0.10840921849012375, 'eval_precision': 0.7270471464019851, 'eval_recall': 0.7670157068062827, 'eval_f1': 0.7464968152866241, 'eval_accuracy': 0.9738340563991323, 'eval_runtime': 1.0129, 'eval_samples_per_second': 153.029, 'eval_steps_per_second': 4.936, 'epoch': 8.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.39it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.22it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.78it/s][A                                                 
                                             [A 60%|██████    | 180/300 [05:16<02:32,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.78it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 60%|██████    | 181/300 [05:23<06:44,  3.40s/it] 61%|██████    | 182/300 [05:25<05:37,  2.86s/it] 61%|██████    | 183/300 [05:26<04:45,  2.44s/it] 61%|██████▏   | 184/300 [05:28<04:09,  2.15s/it] 62%|██████▏   | 185/300 [05:29<03:43,  1.94s/it] 62%|██████▏   | 186/300 [05:31<03:25,  1.80s/it] 62%|██████▏   | 187/300 [05:32<03:14,  1.72s/it] 63%|██████▎   | 188/300 [05:34<03:03,  1.64s/it] 63%|██████▎   | 189/300 [05:35<02:56,  1.59s/it] 63%|██████▎   | 190/300 [05:37<02:50,  1.55s/it] 64%|██████▎   | 191/300 [05:38<02:45,  1.52s/it] 64%|██████▍   | 192/300 [05:40<02:44,  1.52s/it] 64%|██████▍   | 193/300 [05:41<02:40,  1.50s/it] 65%|██████▍   | 194/300 [05:43<02:38,  1.49s/it] 65%|██████▌   | 195/300 [05:44<02:35,  1.48s/it] 65%|██████▌   | 196/300 [05:45<02:33,  1.48s/it] 66%|██████▌   | 197/300 [05:47<02:33,  1.49s/it] 66%|██████▌   | 198/300 [05:48<02:31,  1.48s/it] 66%|██████▋   | 199/300 [05:50<02:28,  1.47s/it] 67%|██████▋   | 200/300 [05:51<02:04,  1.25s/it]{'eval_loss': 0.11464612185955048, 'eval_precision': 0.7286432160804021, 'eval_recall': 0.7591623036649214, 'eval_f1': 0.7435897435897436, 'eval_accuracy': 0.9734273318872018, 'eval_runtime': 1.0242, 'eval_samples_per_second': 151.337, 'eval_steps_per_second': 4.882, 'epoch': 9.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.65it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.32it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A                                                 
                                             [A 67%|██████▋   | 200/300 [05:52<02:04,  1.25s/it]
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 67%|██████▋   | 201/300 [05:59<05:34,  3.38s/it] 67%|██████▋   | 202/300 [06:00<04:34,  2.81s/it] 68%|██████▊   | 203/300 [06:02<03:53,  2.40s/it] 68%|██████▊   | 204/300 [06:03<03:23,  2.12s/it] 68%|██████▊   | 205/300 [06:05<03:02,  1.92s/it] 69%|██████▊   | 206/300 [06:06<02:49,  1.80s/it] 69%|██████▉   | 207/300 [06:08<02:38,  1.70s/it] 69%|██████▉   | 208/300 [06:09<02:30,  1.63s/it] 70%|██████▉   | 209/300 [06:11<02:24,  1.58s/it] 70%|███████   | 210/300 [06:12<02:19,  1.55s/it] 70%|███████   | 211/300 [06:14<02:19,  1.57s/it] 71%|███████   | 212/300 [06:15<02:15,  1.54s/it] 71%|███████   | 213/300 [06:17<02:11,  1.52s/it] 71%|███████▏  | 214/300 [06:18<02:09,  1.50s/it] 72%|███████▏  | 215/300 [06:20<02:06,  1.49s/it] 72%|███████▏  | 216/300 [06:21<02:06,  1.51s/it] 72%|███████▏  | 217/300 [06:23<02:04,  1.50s/it] 73%|███████▎  | 218/300 [06:24<02:02,  1.49s/it] 73%|███████▎  | 219/300 [06:26<02:00,  1.49s/it] 73%|███████▎  | 220/300 [06:26<01:40,  1.26s/it]{'eval_loss': 0.1177692785859108, 'eval_precision': 0.7599009900990099, 'eval_recall': 0.8036649214659686, 'eval_f1': 0.7811704834605598, 'eval_accuracy': 0.9755965292841648, 'eval_runtime': 1.0162, 'eval_samples_per_second': 152.532, 'eval_steps_per_second': 4.92, 'epoch': 10.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.62it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.60it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.39it/s][A                                                 
                                             [A 73%|███████▎  | 220/300 [06:27<01:40,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.39it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 74%|███████▎  | 221/300 [06:35<04:37,  3.51s/it] 74%|███████▍  | 222/300 [06:37<03:45,  2.90s/it] 74%|███████▍  | 223/300 [06:38<03:09,  2.46s/it] 75%|███████▍  | 224/300 [06:40<02:44,  2.16s/it] 75%|███████▌  | 225/300 [06:41<02:27,  1.97s/it] 75%|███████▌  | 226/300 [06:43<02:14,  1.82s/it] 76%|███████▌  | 227/300 [06:44<02:04,  1.71s/it] 76%|███████▌  | 228/300 [06:45<01:57,  1.64s/it] 76%|███████▋  | 229/300 [06:47<01:52,  1.58s/it] 77%|███████▋  | 230/300 [06:48<01:49,  1.56s/it] 77%|███████▋  | 231/300 [06:50<01:45,  1.53s/it] 77%|███████▋  | 232/300 [06:51<01:42,  1.51s/it] 78%|███████▊  | 233/300 [06:53<01:40,  1.50s/it] 78%|███████▊  | 234/300 [06:54<01:37,  1.48s/it] 78%|███████▊  | 235/300 [06:56<01:37,  1.50s/it] 79%|███████▊  | 236/300 [06:57<01:35,  1.49s/it] 79%|███████▉  | 237/300 [06:59<01:33,  1.49s/it] 79%|███████▉  | 238/300 [07:00<01:31,  1.48s/it] 80%|███████▉  | 239/300 [07:02<01:30,  1.48s/it] 80%|████████  | 240/300 [07:02<01:15,  1.25s/it]{'eval_loss': 0.11990467458963394, 'eval_precision': 0.7625, 'eval_recall': 0.7984293193717278, 'eval_f1': 0.7800511508951405, 'eval_accuracy': 0.9758676789587852, 'eval_runtime': 1.0657, 'eval_samples_per_second': 145.444, 'eval_steps_per_second': 4.692, 'epoch': 11.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.57it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.85it/s][A                                                 
                                             [A 80%|████████  | 240/300 [07:04<01:15,  1.25s/it]
100%|██████████| 5/5 [00:00<00:00,  6.85it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 80%|████████  | 241/300 [07:11<03:24,  3.47s/it] 81%|████████  | 242/300 [07:13<02:46,  2.87s/it] 81%|████████  | 243/300 [07:14<02:19,  2.45s/it] 81%|████████▏ | 244/300 [07:16<02:03,  2.20s/it] 82%|████████▏ | 245/300 [07:17<01:49,  1.98s/it] 82%|████████▏ | 246/300 [07:19<01:38,  1.83s/it] 82%|████████▏ | 247/300 [07:20<01:31,  1.73s/it] 83%|████████▎ | 248/300 [07:22<01:25,  1.65s/it] 83%|████████▎ | 249/300 [07:23<01:22,  1.62s/it] 83%|████████▎ | 250/300 [07:25<01:18,  1.58s/it] 84%|████████▎ | 251/300 [07:26<01:15,  1.55s/it] 84%|████████▍ | 252/300 [07:27<01:13,  1.52s/it] 84%|████████▍ | 253/300 [07:29<01:10,  1.51s/it] 85%|████████▍ | 254/300 [07:31<01:10,  1.52s/it] 85%|████████▌ | 255/300 [07:32<01:07,  1.51s/it] 85%|████████▌ | 256/300 [07:33<01:05,  1.50s/it] 86%|████████▌ | 257/300 [07:35<01:04,  1.49s/it] 86%|████████▌ | 258/300 [07:36<01:02,  1.49s/it] 86%|████████▋ | 259/300 [07:38<01:01,  1.51s/it] 87%|████████▋ | 260/300 [07:39<00:50,  1.27s/it]{'eval_loss': 0.1173410713672638, 'eval_precision': 0.7777777777777778, 'eval_recall': 0.806282722513089, 'eval_f1': 0.7917737789203085, 'eval_accuracy': 0.9768167028199566, 'eval_runtime': 1.1505, 'eval_samples_per_second': 134.722, 'eval_steps_per_second': 4.346, 'epoch': 12.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.55it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.25it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.84it/s][A                                                 
                                             [A 87%|████████▋ | 260/300 [07:40<00:50,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.84it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 87%|████████▋ | 261/300 [07:47<02:14,  3.44s/it] 87%|████████▋ | 262/300 [07:49<01:48,  2.85s/it] 88%|████████▊ | 263/300 [07:50<01:29,  2.43s/it] 88%|████████▊ | 264/300 [07:52<01:17,  2.16s/it] 88%|████████▊ | 265/300 [07:53<01:08,  1.95s/it] 89%|████████▊ | 266/300 [07:55<01:01,  1.80s/it] 89%|████████▉ | 267/300 [07:56<00:56,  1.70s/it] 89%|████████▉ | 268/300 [07:58<00:52,  1.64s/it] 90%|████████▉ | 269/300 [07:59<00:49,  1.59s/it] 90%|█████████ | 270/300 [08:00<00:46,  1.55s/it] 90%|█████████ | 271/300 [08:02<00:44,  1.53s/it] 91%|█████████ | 272/300 [08:03<00:42,  1.51s/it] 91%|█████████ | 273/300 [08:05<00:40,  1.51s/it] 91%|█████████▏| 274/300 [08:06<00:38,  1.50s/it] 92%|█████████▏| 275/300 [08:08<00:37,  1.49s/it] 92%|█████████▏| 276/300 [08:09<00:35,  1.48s/it] 92%|█████████▏| 277/300 [08:11<00:33,  1.48s/it] 93%|█████████▎| 278/300 [08:12<00:32,  1.49s/it] 93%|█████████▎| 279/300 [08:14<00:31,  1.48s/it] 93%|█████████▎| 280/300 [08:14<00:25,  1.25s/it]{'eval_loss': 0.12896506488323212, 'eval_precision': 0.7506053268765133, 'eval_recall': 0.8115183246073299, 'eval_f1': 0.779874213836478, 'eval_accuracy': 0.9747830802603037, 'eval_runtime': 1.0174, 'eval_samples_per_second': 152.342, 'eval_steps_per_second': 4.914, 'epoch': 13.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.51it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.95it/s][A                                                 
                                             [A 93%|█████████▎| 280/300 [08:16<00:25,  1.25s/it]
100%|██████████| 5/5 [00:00<00:00,  6.95it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 94%|█████████▎| 281/300 [08:23<01:04,  3.41s/it] 94%|█████████▍| 282/300 [08:24<00:50,  2.83s/it] 94%|█████████▍| 283/300 [08:26<00:41,  2.45s/it] 95%|█████████▍| 284/300 [08:27<00:34,  2.16s/it] 95%|█████████▌| 285/300 [08:29<00:29,  1.96s/it] 95%|█████████▌| 286/300 [08:30<00:25,  1.81s/it] 96%|█████████▌| 287/300 [08:32<00:22,  1.71s/it] 96%|█████████▌| 288/300 [08:33<00:20,  1.67s/it] 96%|█████████▋| 289/300 [08:35<00:17,  1.62s/it] 97%|█████████▋| 290/300 [08:36<00:15,  1.57s/it] 97%|█████████▋| 291/300 [08:38<00:13,  1.55s/it] 97%|█████████▋| 292/300 [08:39<00:12,  1.53s/it] 98%|█████████▊| 293/300 [08:41<00:10,  1.54s/it] 98%|█████████▊| 294/300 [08:42<00:09,  1.52s/it] 98%|█████████▊| 295/300 [08:44<00:07,  1.51s/it] 99%|█████████▊| 296/300 [08:45<00:05,  1.50s/it] 99%|█████████▉| 297/300 [08:47<00:04,  1.49s/it] 99%|█████████▉| 298/300 [08:48<00:03,  1.52s/it]100%|█████████▉| 299/300 [08:50<00:01,  1.51s/it]100%|██████████| 300/300 [08:51<00:00,  1.27s/it]{'eval_loss': 0.13104943931102753, 'eval_precision': 0.7791878172588832, 'eval_recall': 0.8036649214659686, 'eval_f1': 0.7912371134020618, 'eval_accuracy': 0.9762744034707158, 'eval_runtime': 1.0088, 'eval_samples_per_second': 153.65, 'eval_steps_per_second': 4.956, 'epoch': 14.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.50it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.29it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.85it/s][A                                                 
                                             [A100%|██████████| 300/300 [08:52<00:00,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.85it/s][A
                                             [A                                                 100%|██████████| 300/300 [08:59<00:00,  1.27s/it]100%|██████████| 300/300 [08:59<00:00,  1.80s/it]
[I 2025-09-20 13:54:23,293] Trial 2 finished with value: 3.3552323290569457 and parameters: {'learning_rate': 1.3421349466675435e-05, 'num_train_epochs': 15, 'per_device_train_batch_size': 4, 'weight_decay': 2.1835305120223855e-06, 'warmup_ratio': 0.4882538788220329, 'optimizer': 'Adam'}. Best is trial 1 with value: 3.377708616309642.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁██████████████
wandb:                 eval/f1 ▁▁▁▄▆▇▇████████
wandb:               eval/loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          eval/precision ▁▁▁▅▆▇▇████████
wandb:             eval/recall ▁▁▁▃▆▇▇████████
wandb:            eval/runtime ▅▁▂▁▄▂▁▁▂▁▄█▂▁▂
wandb: eval/samples_per_second ▄█▇█▅▇██▇▇▅▁▇█▇
wandb:   eval/steps_per_second ▄█▇█▅▇██▇▇▅▁▇█▇
wandb:             train/epoch ▁▁▂▃▃▃▄▅▅▅▆▇▇▇██
wandb:       train/global_step ▁▁▂▃▃▃▄▅▅▅▆▇▇▇██
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.97641
wandb:                  eval/f1 0.79279
wandb:                eval/loss 0.1315
wandb:           eval/precision 0.77975
wandb:              eval/recall 0.80628
wandb:             eval/runtime 1.0176
wandb:  eval/samples_per_second 152.322
wandb:    eval/steps_per_second 4.914
wandb:               total_flos 4311741485514240.0
wandb:              train/epoch 15
wandb:        train/global_step 300
wandb:               train_loss 0.45699
wandb:            train_runtime 541.438
wandb: train_samples_per_second 34.298
wandb:   train_steps_per_second 0.554
wandb: 
wandb: 🚀 View run likely-smoke-779 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/yeg9vkrp
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250920_134523-yeg9vkrp/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_135426-zryc3e3t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-river-780
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/zryc3e3t
{'eval_loss': 0.13149715960025787, 'eval_precision': 0.779746835443038, 'eval_recall': 0.806282722513089, 'eval_f1': 0.7927927927927928, 'eval_accuracy': 0.976409978308026, 'eval_runtime': 1.0176, 'eval_samples_per_second': 152.322, 'eval_steps_per_second': 4.914, 'epoch': 15.0}
{'train_runtime': 541.438, 'train_samples_per_second': 34.298, 'train_steps_per_second': 0.554, 'train_loss': 0.45699137369791665, 'epoch': 15.0}
  0%|          | 0/741 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/741 [00:01<18:54,  1.53s/it]  0%|          | 2/741 [00:02<18:10,  1.48s/it]  0%|          | 3/741 [00:04<17:45,  1.44s/it]  1%|          | 4/741 [00:05<17:32,  1.43s/it]  1%|          | 5/741 [00:07<17:44,  1.45s/it]  1%|          | 6/741 [00:08<17:33,  1.43s/it]  1%|          | 7/741 [00:10<17:25,  1.42s/it]  1%|          | 8/741 [00:11<17:19,  1.42s/it]  1%|          | 9/741 [00:12<17:15,  1.41s/it]  1%|▏         | 10/741 [00:14<17:23,  1.43s/it]  1%|▏         | 11/741 [00:15<17:18,  1.42s/it]  2%|▏         | 12/741 [00:17<17:14,  1.42s/it]  2%|▏         | 13/741 [00:18<17:10,  1.42s/it]  2%|▏         | 14/741 [00:19<17:06,  1.41s/it]  2%|▏         | 15/741 [00:21<17:16,  1.43s/it]  2%|▏         | 16/741 [00:22<17:11,  1.42s/it]  2%|▏         | 17/741 [00:24<17:05,  1.42s/it]  2%|▏         | 18/741 [00:25<17:00,  1.41s/it]  3%|▎         | 19/741 [00:27<16:58,  1.41s/it]  3%|▎         | 20/741 [00:28<17:07,  1.42s/it]  3%|▎         | 21/741 [00:29<17:02,  1.42s/it]  3%|▎         | 22/741 [00:31<16:58,  1.42s/it]  3%|▎         | 23/741 [00:32<16:53,  1.41s/it]  3%|▎         | 24/741 [00:34<16:50,  1.41s/it]  3%|▎         | 25/741 [00:35<17:00,  1.42s/it]  4%|▎         | 26/741 [00:37<16:54,  1.42s/it]  4%|▎         | 27/741 [00:38<16:51,  1.42s/it]  4%|▍         | 28/741 [00:39<16:49,  1.42s/it]  4%|▍         | 29/741 [00:41<16:45,  1.41s/it]  4%|▍         | 30/741 [00:42<16:54,  1.43s/it]  4%|▍         | 31/741 [00:44<16:47,  1.42s/it]  4%|▍         | 32/741 [00:45<16:42,  1.41s/it]  4%|▍         | 33/741 [00:46<16:40,  1.41s/it]  5%|▍         | 34/741 [00:48<16:37,  1.41s/it]  5%|▍         | 35/741 [00:49<16:46,  1.43s/it]  5%|▍         | 36/741 [00:51<16:40,  1.42s/it]  5%|▍         | 37/741 [00:52<16:37,  1.42s/it]  5%|▌         | 38/741 [00:54<16:35,  1.42s/it]  5%|▌         | 39/741 [00:55<15:17,  1.31s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00,  8.87it/s][A
 60%|██████    | 3/5 [00:00<00:00,  7.24it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.64it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.48it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A  5%|▌         | 39/741 [00:56<15:17,  1.31s/it]
100%|██████████| 5/5 [00:00<00:00,  6.48it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  5%|▌         | 40/741 [01:03<41:16,  3.53s/it]  6%|▌         | 41/741 [01:05<33:47,  2.90s/it]  6%|▌         | 42/741 [01:06<28:33,  2.45s/it]  6%|▌         | 43/741 [01:08<25:03,  2.15s/it]  6%|▌         | 44/741 [01:09<22:27,  1.93s/it]  6%|▌         | 45/741 [01:10<20:36,  1.78s/it]  6%|▌         | 46/741 [01:12<19:20,  1.67s/it]  6%|▋         | 47/741 [01:13<18:24,  1.59s/it]  6%|▋         | 48/741 [01:15<17:56,  1.55s/it]  7%|▋         | 49/741 [01:16<17:24,  1.51s/it]  7%|▋         | 50/741 [01:18<17:01,  1.48s/it]  7%|▋         | 51/741 [01:19<16:45,  1.46s/it]  7%|▋         | 52/741 [01:20<16:32,  1.44s/it]  7%|▋         | 53/741 [01:22<16:35,  1.45s/it]  7%|▋         | 54/741 [01:23<16:26,  1.44s/it]  7%|▋         | 55/741 [01:25<16:18,  1.43s/it]  8%|▊         | 56/741 [01:26<16:11,  1.42s/it]  8%|▊         | 57/741 [01:27<16:08,  1.42s/it]  8%|▊         | 58/741 [01:29<16:18,  1.43s/it]  8%|▊         | 59/741 [01:30<16:14,  1.43s/it]  8%|▊         | 60/741 [01:32<16:08,  1.42s/it]  8%|▊         | 61/741 [01:33<16:04,  1.42s/it]  8%|▊         | 62/741 [01:35<16:01,  1.42s/it]  9%|▊         | 63/741 [01:36<16:10,  1.43s/it]  9%|▊         | 64/741 [01:37<16:04,  1.42s/it]  9%|▉         | 65/741 [01:39<15:59,  1.42s/it]  9%|▉         | 66/741 [01:40<15:55,  1.42s/it]  9%|▉         | 67/741 [01:42<15:52,  1.41s/it]  9%|▉         | 68/741 [01:43<16:02,  1.43s/it]  9%|▉         | 69/741 [01:44<15:57,  1.42s/it]  9%|▉         | 70/741 [01:46<15:54,  1.42s/it] 10%|▉         | 71/741 [01:47<15:51,  1.42s/it] 10%|▉         | 72/741 [01:49<15:48,  1.42s/it] 10%|▉         | 73/741 [01:50<16:18,  1.47s/it] 10%|▉         | 74/741 [01:52<16:05,  1.45s/it] 10%|█         | 75/741 [01:53<15:55,  1.43s/it] 10%|█         | 76/741 [01:55<15:49,  1.43s/it] 10%|█         | 77/741 [01:56<15:44,  1.42s/it] 11%|█         | 78/741 [01:57<14:58,  1.36s/it]{'eval_loss': 0.538324236869812, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9271963123644251, 'eval_runtime': 1.0598, 'eval_samples_per_second': 146.257, 'eval_steps_per_second': 4.718, 'epoch': 1.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.62it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.31it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.90it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 11%|█         | 78/741 [01:58<14:58,  1.36s/it]
100%|██████████| 5/5 [00:00<00:00,  6.90it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 11%|█         | 79/741 [02:06<39:27,  3.58s/it] 11%|█         | 80/741 [02:07<32:12,  2.92s/it] 11%|█         | 81/741 [02:09<27:08,  2.47s/it] 11%|█         | 82/741 [02:10<24:04,  2.19s/it] 11%|█         | 83/741 [02:12<21:26,  1.96s/it] 11%|█▏        | 84/741 [02:13<19:36,  1.79s/it] 11%|█▏        | 85/741 [02:14<18:20,  1.68s/it] 12%|█▏        | 86/741 [02:16<17:25,  1.60s/it] 12%|█▏        | 87/741 [02:17<16:59,  1.56s/it] 12%|█▏        | 88/741 [02:19<16:28,  1.51s/it] 12%|█▏        | 89/741 [02:20<16:07,  1.48s/it] 12%|█▏        | 90/741 [02:22<15:51,  1.46s/it] 12%|█▏        | 91/741 [02:23<15:40,  1.45s/it] 12%|█▏        | 92/741 [02:25<16:02,  1.48s/it] 13%|█▎        | 93/741 [02:26<15:47,  1.46s/it] 13%|█▎        | 94/741 [02:27<15:37,  1.45s/it] 13%|█▎        | 95/741 [02:29<15:29,  1.44s/it] 13%|█▎        | 96/741 [02:30<15:24,  1.43s/it] 13%|█▎        | 97/741 [02:32<15:32,  1.45s/it] 13%|█▎        | 98/741 [02:33<15:25,  1.44s/it] 13%|█▎        | 99/741 [02:35<15:20,  1.43s/it] 13%|█▎        | 100/741 [02:36<15:16,  1.43s/it] 14%|█▎        | 101/741 [02:37<15:12,  1.43s/it] 14%|█▍        | 102/741 [02:39<15:20,  1.44s/it] 14%|█▍        | 103/741 [02:40<15:15,  1.44s/it] 14%|█▍        | 104/741 [02:42<15:12,  1.43s/it] 14%|█▍        | 105/741 [02:43<15:08,  1.43s/it] 14%|█▍        | 106/741 [02:45<15:04,  1.42s/it] 14%|█▍        | 107/741 [02:46<15:14,  1.44s/it] 15%|█▍        | 108/741 [02:47<15:09,  1.44s/it] 15%|█▍        | 109/741 [02:49<15:05,  1.43s/it] 15%|█▍        | 110/741 [02:50<15:01,  1.43s/it] 15%|█▍        | 111/741 [02:52<14:56,  1.42s/it] 15%|█▌        | 112/741 [02:53<15:06,  1.44s/it] 15%|█▌        | 113/741 [02:55<15:01,  1.44s/it] 15%|█▌        | 114/741 [02:56<14:57,  1.43s/it] 16%|█▌        | 115/741 [02:57<14:52,  1.43s/it] 16%|█▌        | 116/741 [02:59<14:50,  1.42s/it] 16%|█▌        | 117/741 [03:00<13:49,  1.33s/it]{'eval_loss': 0.23287048935890198, 'eval_precision': 0.47706422018348627, 'eval_recall': 0.27225130890052357, 'eval_f1': 0.3466666666666667, 'eval_accuracy': 0.9419739696312365, 'eval_runtime': 1.0106, 'eval_samples_per_second': 153.376, 'eval_steps_per_second': 4.948, 'epoch': 2.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.52it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.28it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A                                                 
                                             [A 16%|█▌        | 117/741 [03:01<13:49,  1.33s/it]
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 16%|█▌        | 118/741 [03:08<35:39,  3.43s/it] 16%|█▌        | 119/741 [03:10<29:15,  2.82s/it] 16%|█▌        | 120/741 [03:11<24:47,  2.40s/it] 16%|█▋        | 121/741 [03:13<22:07,  2.14s/it] 16%|█▋        | 122/741 [03:14<19:48,  1.92s/it] 17%|█▋        | 123/741 [03:15<18:09,  1.76s/it] 17%|█▋        | 124/741 [03:17<17:01,  1.66s/it] 17%|█▋        | 125/741 [03:18<16:15,  1.58s/it] 17%|█▋        | 126/741 [03:20<15:52,  1.55s/it] 17%|█▋        | 127/741 [03:21<15:23,  1.50s/it] 17%|█▋        | 128/741 [03:23<15:03,  1.47s/it] 17%|█▋        | 129/741 [03:24<14:49,  1.45s/it] 18%|█▊        | 130/741 [03:25<14:38,  1.44s/it] 18%|█▊        | 131/741 [03:27<14:40,  1.44s/it] 18%|█▊        | 132/741 [03:28<14:33,  1.43s/it] 18%|█▊        | 133/741 [03:30<14:26,  1.43s/it] 18%|█▊        | 134/741 [03:31<14:20,  1.42s/it] 18%|█▊        | 135/741 [03:32<14:18,  1.42s/it] 18%|█▊        | 136/741 [03:34<14:24,  1.43s/it] 18%|█▊        | 137/741 [03:35<14:18,  1.42s/it] 19%|█▊        | 138/741 [03:37<14:14,  1.42s/it] 19%|█▉        | 139/741 [03:38<14:09,  1.41s/it] 19%|█▉        | 140/741 [03:40<14:16,  1.42s/it] 19%|█▉        | 141/741 [03:41<14:10,  1.42s/it] 19%|█▉        | 142/741 [03:42<14:05,  1.41s/it] 19%|█▉        | 143/741 [03:44<14:01,  1.41s/it] 19%|█▉        | 144/741 [03:45<13:59,  1.41s/it] 20%|█▉        | 145/741 [03:47<14:07,  1.42s/it] 20%|█▉        | 146/741 [03:48<14:02,  1.42s/it] 20%|█▉        | 147/741 [03:49<13:57,  1.41s/it] 20%|█▉        | 148/741 [03:51<13:54,  1.41s/it] 20%|██        | 149/741 [03:52<13:52,  1.41s/it] 20%|██        | 150/741 [03:54<13:59,  1.42s/it] 20%|██        | 151/741 [03:55<13:54,  1.41s/it] 21%|██        | 152/741 [03:57<13:50,  1.41s/it] 21%|██        | 153/741 [03:58<13:48,  1.41s/it] 21%|██        | 154/741 [03:59<13:45,  1.41s/it] 21%|██        | 155/741 [04:01<13:55,  1.43s/it] 21%|██        | 156/741 [04:02<12:48,  1.31s/it]{'eval_loss': 0.13807350397109985, 'eval_precision': 0.6098130841121495, 'eval_recall': 0.6832460732984293, 'eval_f1': 0.6444444444444445, 'eval_accuracy': 0.9669197396963124, 'eval_runtime': 1.0134, 'eval_samples_per_second': 152.946, 'eval_steps_per_second': 4.934, 'epoch': 3.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.64it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.33it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.92it/s][A                                                 
                                             [A 21%|██        | 156/741 [04:03<12:48,  1.31s/it]
100%|██████████| 5/5 [00:00<00:00,  6.92it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 21%|██        | 157/741 [04:11<35:40,  3.66s/it] 21%|██▏       | 158/741 [04:12<29:02,  2.99s/it] 21%|██▏       | 159/741 [04:14<24:49,  2.56s/it] 22%|██▏       | 160/741 [04:15<21:26,  2.21s/it] 22%|██▏       | 161/741 [04:17<19:02,  1.97s/it] 22%|██▏       | 162/741 [04:18<17:22,  1.80s/it] 22%|██▏       | 163/741 [04:20<16:13,  1.68s/it] 22%|██▏       | 164/741 [04:21<15:32,  1.62s/it] 22%|██▏       | 165/741 [04:22<14:55,  1.55s/it] 22%|██▏       | 166/741 [04:24<14:28,  1.51s/it] 23%|██▎       | 167/741 [04:25<14:08,  1.48s/it] 23%|██▎       | 168/741 [04:27<13:55,  1.46s/it] 23%|██▎       | 169/741 [04:28<14:08,  1.48s/it] 23%|██▎       | 170/741 [04:30<13:54,  1.46s/it] 23%|██▎       | 171/741 [04:31<13:44,  1.45s/it] 23%|██▎       | 172/741 [04:32<13:35,  1.43s/it] 23%|██▎       | 173/741 [04:34<13:29,  1.42s/it] 23%|██▎       | 174/741 [04:35<13:33,  1.43s/it] 24%|██▎       | 175/741 [04:37<13:26,  1.43s/it] 24%|██▍       | 176/741 [04:38<13:22,  1.42s/it] 24%|██▍       | 177/741 [04:40<13:17,  1.41s/it] 24%|██▍       | 178/741 [04:41<13:13,  1.41s/it] 24%|██▍       | 179/741 [04:42<13:20,  1.43s/it] 24%|██▍       | 180/741 [04:44<13:15,  1.42s/it] 24%|██▍       | 181/741 [04:45<13:12,  1.41s/it] 25%|██▍       | 182/741 [04:47<13:08,  1.41s/it] 25%|██▍       | 183/741 [04:48<13:06,  1.41s/it] 25%|██▍       | 184/741 [04:49<13:13,  1.42s/it] 25%|██▍       | 185/741 [04:51<13:08,  1.42s/it] 25%|██▌       | 186/741 [04:52<13:04,  1.41s/it] 25%|██▌       | 187/741 [04:54<13:00,  1.41s/it] 25%|██▌       | 188/741 [04:55<12:58,  1.41s/it] 26%|██▌       | 189/741 [04:57<13:03,  1.42s/it] 26%|██▌       | 190/741 [04:58<13:00,  1.42s/it] 26%|██▌       | 191/741 [04:59<12:57,  1.41s/it] 26%|██▌       | 192/741 [05:01<12:54,  1.41s/it] 26%|██▌       | 193/741 [05:02<12:51,  1.41s/it] 26%|██▌       | 194/741 [05:04<12:57,  1.42s/it] 26%|██▋       | 195/741 [05:05<11:55,  1.31s/it]{'eval_loss': 0.11389964818954468, 'eval_precision': 0.6787330316742082, 'eval_recall': 0.7853403141361257, 'eval_f1': 0.7281553398058254, 'eval_accuracy': 0.9696312364425163, 'eval_runtime': 1.0097, 'eval_samples_per_second': 153.506, 'eval_steps_per_second': 4.952, 'epoch': 4.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.52it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.25it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A                                                 
                                             [A 26%|██▋       | 195/741 [05:06<11:55,  1.31s/it]
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 26%|██▋       | 196/741 [05:13<31:10,  3.43s/it] 27%|██▋       | 197/741 [05:14<25:36,  2.82s/it] 27%|██▋       | 198/741 [05:16<21:50,  2.41s/it] 27%|██▋       | 199/741 [05:17<19:03,  2.11s/it] 27%|██▋       | 200/741 [05:19<17:07,  1.90s/it] 27%|██▋       | 201/741 [05:20<15:46,  1.75s/it] 27%|██▋       | 202/741 [05:21<14:48,  1.65s/it] 27%|██▋       | 203/741 [05:23<14:15,  1.59s/it] 28%|██▊       | 204/741 [05:24<13:43,  1.53s/it] 28%|██▊       | 205/741 [05:26<13:20,  1.49s/it] 28%|██▊       | 206/741 [05:27<13:04,  1.47s/it] 28%|██▊       | 207/741 [05:29<12:52,  1.45s/it] 28%|██▊       | 208/741 [05:30<12:52,  1.45s/it] 28%|██▊       | 209/741 [05:31<12:44,  1.44s/it] 28%|██▊       | 210/741 [05:33<12:38,  1.43s/it] 28%|██▊       | 211/741 [05:34<12:32,  1.42s/it] 29%|██▊       | 212/741 [05:36<12:27,  1.41s/it] 29%|██▊       | 213/741 [05:37<12:33,  1.43s/it] 29%|██▉       | 214/741 [05:38<12:28,  1.42s/it] 29%|██▉       | 215/741 [05:40<12:22,  1.41s/it] 29%|██▉       | 216/741 [05:41<12:19,  1.41s/it] 29%|██▉       | 217/741 [05:43<12:27,  1.43s/it] 29%|██▉       | 218/741 [05:44<12:22,  1.42s/it] 30%|██▉       | 219/741 [05:46<12:18,  1.41s/it] 30%|██▉       | 220/741 [05:47<12:14,  1.41s/it] 30%|██▉       | 221/741 [05:48<12:12,  1.41s/it] 30%|██▉       | 222/741 [05:50<12:18,  1.42s/it] 30%|███       | 223/741 [05:51<12:12,  1.41s/it] 30%|███       | 224/741 [05:53<12:09,  1.41s/it] 30%|███       | 225/741 [05:54<12:06,  1.41s/it] 30%|███       | 226/741 [05:55<12:04,  1.41s/it] 31%|███       | 227/741 [05:57<12:09,  1.42s/it] 31%|███       | 228/741 [05:58<12:06,  1.42s/it] 31%|███       | 229/741 [06:00<12:03,  1.41s/it] 31%|███       | 230/741 [06:01<12:00,  1.41s/it] 31%|███       | 231/741 [06:02<11:57,  1.41s/it] 31%|███▏      | 232/741 [06:04<12:04,  1.42s/it] 31%|███▏      | 233/741 [06:05<11:59,  1.42s/it] 32%|███▏      | 234/741 [06:06<11:01,  1.31s/it]{'eval_loss': 0.11126301437616348, 'eval_precision': 0.7408312958435208, 'eval_recall': 0.7931937172774869, 'eval_f1': 0.7661188369152971, 'eval_accuracy': 0.97220715835141, 'eval_runtime': 1.0167, 'eval_samples_per_second': 152.453, 'eval_steps_per_second': 4.918, 'epoch': 5.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.58it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A                                                 
                                             [A 32%|███▏      | 234/741 [06:07<11:01,  1.31s/it]
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 32%|███▏      | 235/741 [06:15<30:31,  3.62s/it] 32%|███▏      | 236/741 [06:17<25:16,  3.00s/it] 32%|███▏      | 237/741 [06:18<21:11,  2.52s/it] 32%|███▏      | 238/741 [06:20<18:22,  2.19s/it] 32%|███▏      | 239/741 [06:21<16:22,  1.96s/it] 32%|███▏      | 240/741 [06:23<14:57,  1.79s/it] 33%|███▎      | 241/741 [06:24<14:08,  1.70s/it] 33%|███▎      | 242/741 [06:25<13:23,  1.61s/it] 33%|███▎      | 243/741 [06:27<12:51,  1.55s/it] 33%|███▎      | 244/741 [06:28<12:28,  1.51s/it] 33%|███▎      | 245/741 [06:30<12:13,  1.48s/it] 33%|███▎      | 246/741 [06:31<12:24,  1.50s/it] 33%|███▎      | 247/741 [06:33<12:08,  1.48s/it] 33%|███▎      | 248/741 [06:34<11:57,  1.45s/it] 34%|███▎      | 249/741 [06:36<11:48,  1.44s/it] 34%|███▎      | 250/741 [06:37<11:42,  1.43s/it] 34%|███▍      | 251/741 [06:38<11:46,  1.44s/it] 34%|███▍      | 252/741 [06:40<11:40,  1.43s/it] 34%|███▍      | 253/741 [06:41<11:36,  1.43s/it] 34%|███▍      | 254/741 [06:43<11:32,  1.42s/it] 34%|███▍      | 255/741 [06:44<11:30,  1.42s/it] 35%|███▍      | 256/741 [06:46<11:36,  1.44s/it] 35%|███▍      | 257/741 [06:47<11:31,  1.43s/it] 35%|███▍      | 258/741 [06:48<11:28,  1.42s/it] 35%|███▍      | 259/741 [06:50<11:24,  1.42s/it] 35%|███▌      | 260/741 [06:51<11:22,  1.42s/it] 35%|███▌      | 261/741 [06:53<11:29,  1.44s/it] 35%|███▌      | 262/741 [06:54<11:24,  1.43s/it] 35%|███▌      | 263/741 [06:55<11:19,  1.42s/it] 36%|███▌      | 264/741 [06:57<11:16,  1.42s/it] 36%|███▌      | 265/741 [06:58<11:13,  1.42s/it] 36%|███▌      | 266/741 [07:00<11:20,  1.43s/it] 36%|███▌      | 267/741 [07:01<11:15,  1.43s/it] 36%|███▌      | 268/741 [07:03<11:12,  1.42s/it] 36%|███▋      | 269/741 [07:04<11:09,  1.42s/it] 36%|███▋      | 270/741 [07:05<11:07,  1.42s/it] 37%|███▋      | 271/741 [07:07<11:13,  1.43s/it] 37%|███▋      | 272/741 [07:08<11:09,  1.43s/it] 37%|███▋      | 273/741 [07:09<10:15,  1.32s/it]{'eval_loss': 0.11144992709159851, 'eval_precision': 0.7657430730478589, 'eval_recall': 0.7958115183246073, 'eval_f1': 0.7804878048780487, 'eval_accuracy': 0.976409978308026, 'eval_runtime': 1.0143, 'eval_samples_per_second': 152.81, 'eval_steps_per_second': 4.929, 'epoch': 6.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.56it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.29it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.81it/s][A                                                 
                                             [A 37%|███▋      | 273/741 [07:10<10:15,  1.32s/it]
100%|██████████| 5/5 [00:00<00:00,  6.81it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 37%|███▋      | 274/741 [07:18<27:00,  3.47s/it] 37%|███▋      | 275/741 [07:19<22:18,  2.87s/it] 37%|███▋      | 276/741 [07:21<18:54,  2.44s/it] 37%|███▋      | 277/741 [07:22<16:30,  2.13s/it] 38%|███▊      | 278/741 [07:24<14:47,  1.92s/it] 38%|███▊      | 279/741 [07:25<13:36,  1.77s/it] 38%|███▊      | 280/741 [07:26<12:56,  1.68s/it] 38%|███▊      | 281/741 [07:28<12:16,  1.60s/it] 38%|███▊      | 282/741 [07:29<11:47,  1.54s/it] 38%|███▊      | 283/741 [07:31<11:27,  1.50s/it] 38%|███▊      | 284/741 [07:32<11:13,  1.47s/it] 38%|███▊      | 285/741 [07:34<11:11,  1.47s/it] 39%|███▊      | 286/741 [07:35<11:01,  1.45s/it] 39%|███▊      | 287/741 [07:36<10:53,  1.44s/it] 39%|███▉      | 288/741 [07:38<10:47,  1.43s/it] 39%|███▉      | 289/741 [07:39<10:43,  1.42s/it] 39%|███▉      | 290/741 [07:41<10:48,  1.44s/it] 39%|███▉      | 291/741 [07:42<10:43,  1.43s/it] 39%|███▉      | 292/741 [07:43<10:38,  1.42s/it] 40%|███▉      | 293/741 [07:45<10:36,  1.42s/it] 40%|███▉      | 294/741 [07:46<10:42,  1.44s/it] 40%|███▉      | 295/741 [07:48<10:38,  1.43s/it] 40%|███▉      | 296/741 [07:49<10:32,  1.42s/it] 40%|████      | 297/741 [07:51<10:29,  1.42s/it] 40%|████      | 298/741 [07:52<10:26,  1.41s/it] 40%|████      | 299/741 [07:53<10:31,  1.43s/it] 40%|████      | 300/741 [07:55<10:28,  1.43s/it] 41%|████      | 301/741 [07:56<10:25,  1.42s/it] 41%|████      | 302/741 [07:58<10:23,  1.42s/it] 41%|████      | 303/741 [07:59<10:21,  1.42s/it] 41%|████      | 304/741 [08:01<10:27,  1.44s/it] 41%|████      | 305/741 [08:02<10:23,  1.43s/it] 41%|████▏     | 306/741 [08:03<10:18,  1.42s/it] 41%|████▏     | 307/741 [08:05<10:16,  1.42s/it] 42%|████▏     | 308/741 [08:06<10:13,  1.42s/it] 42%|████▏     | 309/741 [08:08<10:18,  1.43s/it] 42%|████▏     | 310/741 [08:09<10:14,  1.42s/it] 42%|████▏     | 311/741 [08:11<10:11,  1.42s/it] 42%|████▏     | 312/741 [08:12<09:22,  1.31s/it]{'eval_loss': 0.12827852368354797, 'eval_precision': 0.8054794520547945, 'eval_recall': 0.7696335078534031, 'eval_f1': 0.7871485943775101, 'eval_accuracy': 0.975732104121475, 'eval_runtime': 1.018, 'eval_samples_per_second': 152.261, 'eval_steps_per_second': 4.912, 'epoch': 7.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.64it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.33it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.84it/s][A                                                 
                                             [A 42%|████▏     | 312/741 [08:13<09:22,  1.31s/it]
100%|██████████| 5/5 [00:00<00:00,  6.84it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 42%|████▏     | 313/741 [08:20<24:53,  3.49s/it] 42%|████▏     | 314/741 [08:22<20:24,  2.87s/it] 43%|████▎     | 315/741 [08:23<17:16,  2.43s/it] 43%|████▎     | 316/741 [08:24<15:04,  2.13s/it] 43%|████▎     | 317/741 [08:26<13:30,  1.91s/it] 43%|████▎     | 318/741 [08:27<12:33,  1.78s/it] 43%|████▎     | 319/741 [08:29<11:44,  1.67s/it] 43%|████▎     | 320/741 [08:30<11:10,  1.59s/it] 43%|████▎     | 321/741 [08:32<10:45,  1.54s/it] 43%|████▎     | 322/741 [08:33<10:27,  1.50s/it] 44%|████▎     | 323/741 [08:34<10:23,  1.49s/it] 44%|████▎     | 324/741 [08:36<10:11,  1.47s/it] 44%|████▍     | 325/741 [08:37<10:03,  1.45s/it] 44%|████▍     | 326/741 [08:39<09:57,  1.44s/it] 44%|████▍     | 327/741 [08:40<09:52,  1.43s/it] 44%|████▍     | 328/741 [08:42<09:56,  1.44s/it] 44%|████▍     | 329/741 [08:43<09:49,  1.43s/it] 45%|████▍     | 330/741 [08:44<09:44,  1.42s/it] 45%|████▍     | 331/741 [08:46<09:40,  1.42s/it] 45%|████▍     | 332/741 [08:47<09:38,  1.41s/it] 45%|████▍     | 333/741 [08:49<09:43,  1.43s/it] 45%|████▌     | 334/741 [08:50<09:39,  1.42s/it] 45%|████▌     | 335/741 [08:51<09:35,  1.42s/it] 45%|████▌     | 336/741 [08:53<09:33,  1.42s/it] 45%|████▌     | 337/741 [08:54<09:31,  1.41s/it] 46%|████▌     | 338/741 [08:56<09:47,  1.46s/it] 46%|████▌     | 339/741 [08:57<09:39,  1.44s/it] 46%|████▌     | 340/741 [08:59<09:33,  1.43s/it] 46%|████▌     | 341/741 [09:00<09:29,  1.42s/it] 46%|████▌     | 342/741 [09:01<09:26,  1.42s/it] 46%|████▋     | 343/741 [09:03<09:30,  1.43s/it] 46%|████▋     | 344/741 [09:04<09:25,  1.43s/it] 47%|████▋     | 345/741 [09:06<09:21,  1.42s/it] 47%|████▋     | 346/741 [09:07<09:19,  1.42s/it] 47%|████▋     | 347/741 [09:09<09:17,  1.41s/it] 47%|████▋     | 348/741 [09:10<09:34,  1.46s/it] 47%|████▋     | 349/741 [09:12<09:27,  1.45s/it] 47%|████▋     | 350/741 [09:13<09:21,  1.44s/it] 47%|████▋     | 351/741 [09:14<08:35,  1.32s/it]{'eval_loss': 0.14290045201778412, 'eval_precision': 0.8521739130434782, 'eval_recall': 0.7696335078534031, 'eval_f1': 0.8088033012379643, 'eval_accuracy': 0.9774945770065075, 'eval_runtime': 1.0134, 'eval_samples_per_second': 152.949, 'eval_steps_per_second': 4.934, 'epoch': 8.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.60it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.84it/s][A                                                 
                                             [A 47%|████▋     | 351/741 [09:15<08:35,  1.32s/it]
100%|██████████| 5/5 [00:00<00:00,  6.84it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 48%|████▊     | 352/741 [09:22<22:14,  3.43s/it] 48%|████▊     | 353/741 [09:24<18:17,  2.83s/it] 48%|████▊     | 354/741 [09:25<15:29,  2.40s/it] 48%|████▊     | 355/741 [09:27<13:31,  2.10s/it] 48%|████▊     | 356/741 [09:28<12:09,  1.89s/it] 48%|████▊     | 357/741 [09:30<11:28,  1.79s/it] 48%|████▊     | 358/741 [09:31<10:44,  1.68s/it] 48%|████▊     | 359/741 [09:32<10:12,  1.60s/it] 49%|████▊     | 360/741 [09:34<09:49,  1.55s/it] 49%|████▊     | 361/741 [09:35<09:32,  1.51s/it] 49%|████▉     | 362/741 [09:37<09:27,  1.50s/it] 49%|████▉     | 363/741 [09:38<09:16,  1.47s/it] 49%|████▉     | 364/741 [09:40<09:07,  1.45s/it] 49%|████▉     | 365/741 [09:41<09:01,  1.44s/it] 49%|████▉     | 366/741 [09:42<08:58,  1.44s/it] 50%|████▉     | 367/741 [09:44<09:00,  1.45s/it] 50%|████▉     | 368/741 [09:45<08:55,  1.44s/it] 50%|████▉     | 369/741 [09:47<08:52,  1.43s/it] 50%|████▉     | 370/741 [09:48<08:49,  1.43s/it] 50%|█████     | 371/741 [09:49<08:47,  1.43s/it] 50%|█████     | 372/741 [09:51<08:51,  1.44s/it] 50%|█████     | 373/741 [09:52<08:47,  1.43s/it] 50%|█████     | 374/741 [09:54<08:43,  1.43s/it] 51%|█████     | 375/741 [09:55<08:40,  1.42s/it] 51%|█████     | 376/741 [09:57<08:37,  1.42s/it] 51%|█████     | 377/741 [09:58<08:42,  1.43s/it] 51%|█████     | 378/741 [09:59<08:37,  1.43s/it] 51%|█████     | 379/741 [10:01<08:36,  1.43s/it] 51%|█████▏    | 380/741 [10:02<08:33,  1.42s/it] 51%|█████▏    | 381/741 [10:04<08:30,  1.42s/it] 52%|█████▏    | 382/741 [10:05<08:34,  1.43s/it] 52%|█████▏    | 383/741 [10:07<08:30,  1.43s/it] 52%|█████▏    | 384/741 [10:08<08:27,  1.42s/it] 52%|█████▏    | 385/741 [10:09<08:25,  1.42s/it] 52%|█████▏    | 386/741 [10:11<08:23,  1.42s/it] 52%|█████▏    | 387/741 [10:12<08:26,  1.43s/it] 52%|█████▏    | 388/741 [10:14<08:23,  1.43s/it] 52%|█████▏    | 389/741 [10:15<08:21,  1.43s/it] 53%|█████▎    | 390/741 [10:16<07:41,  1.31s/it]{'eval_loss': 0.1466684341430664, 'eval_precision': 0.8266666666666667, 'eval_recall': 0.8115183246073299, 'eval_f1': 0.8190224570673713, 'eval_accuracy': 0.9774945770065075, 'eval_runtime': 1.0172, 'eval_samples_per_second': 152.38, 'eval_steps_per_second': 4.915, 'epoch': 9.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.62it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.32it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.89it/s][A                                                 
                                             [A 53%|█████▎    | 390/741 [10:17<07:41,  1.31s/it]
100%|██████████| 5/5 [00:00<00:00,  6.89it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 53%|█████▎    | 391/741 [10:25<21:35,  3.70s/it] 53%|█████▎    | 392/741 [10:27<17:32,  3.01s/it] 53%|█████▎    | 393/741 [10:28<14:42,  2.53s/it] 53%|█████▎    | 394/741 [10:30<12:42,  2.20s/it] 53%|█████▎    | 395/741 [10:31<11:18,  1.96s/it] 53%|█████▎    | 396/741 [10:33<10:26,  1.82s/it] 54%|█████▎    | 397/741 [10:34<09:42,  1.69s/it] 54%|█████▎    | 398/741 [10:35<09:12,  1.61s/it] 54%|█████▍    | 399/741 [10:37<08:51,  1.55s/it] 54%|█████▍    | 400/741 [10:38<08:35,  1.51s/it] 54%|█████▍    | 401/741 [10:40<08:31,  1.50s/it] 54%|█████▍    | 402/741 [10:41<08:21,  1.48s/it] 54%|█████▍    | 403/741 [10:43<08:14,  1.46s/it] 55%|█████▍    | 404/741 [10:44<08:07,  1.45s/it] 55%|█████▍    | 405/741 [10:45<08:02,  1.44s/it] 55%|█████▍    | 406/741 [10:47<08:05,  1.45s/it] 55%|█████▍    | 407/741 [10:48<08:00,  1.44s/it] 55%|█████▌    | 408/741 [10:50<07:55,  1.43s/it] 55%|█████▌    | 409/741 [10:51<07:52,  1.42s/it] 55%|█████▌    | 410/741 [10:53<07:49,  1.42s/it] 55%|█████▌    | 411/741 [10:54<07:53,  1.43s/it] 56%|█████▌    | 412/741 [10:55<07:49,  1.43s/it] 56%|█████▌    | 413/741 [10:57<07:46,  1.42s/it] 56%|█████▌    | 414/741 [10:58<07:43,  1.42s/it] 56%|█████▌    | 415/741 [11:00<07:41,  1.41s/it] 56%|█████▌    | 416/741 [11:01<07:45,  1.43s/it] 56%|█████▋    | 417/741 [11:03<07:42,  1.43s/it] 56%|█████▋    | 418/741 [11:04<07:39,  1.42s/it] 57%|█████▋    | 419/741 [11:05<07:36,  1.42s/it] 57%|█████▋    | 420/741 [11:07<07:40,  1.43s/it] 57%|█████▋    | 421/741 [11:08<07:36,  1.43s/it] 57%|█████▋    | 422/741 [11:10<07:33,  1.42s/it] 57%|█████▋    | 423/741 [11:11<07:31,  1.42s/it] 57%|█████▋    | 424/741 [11:12<07:29,  1.42s/it] 57%|█████▋    | 425/741 [11:14<07:32,  1.43s/it] 57%|█████▋    | 426/741 [11:15<07:29,  1.43s/it] 58%|█████▊    | 427/741 [11:17<07:26,  1.42s/it] 58%|█████▊    | 428/741 [11:18<07:24,  1.42s/it] 58%|█████▊    | 429/741 [11:19<06:49,  1.31s/it]{'eval_loss': 0.1501704752445221, 'eval_precision': 0.8162729658792651, 'eval_recall': 0.8141361256544503, 'eval_f1': 0.8152031454783747, 'eval_accuracy': 0.978443600867679, 'eval_runtime': 1.0108, 'eval_samples_per_second': 153.351, 'eval_steps_per_second': 4.947, 'epoch': 10.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.48it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.24it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.09it/s][A                                                 
                                             [A 58%|█████▊    | 429/741 [11:20<06:49,  1.31s/it]
100%|██████████| 5/5 [00:00<00:00,  6.09it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 58%|█████▊    | 430/741 [11:28<18:19,  3.54s/it] 58%|█████▊    | 431/741 [11:29<14:59,  2.90s/it] 58%|█████▊    | 432/741 [11:31<12:38,  2.45s/it] 58%|█████▊    | 433/741 [11:32<10:59,  2.14s/it] 59%|█████▊    | 434/741 [11:34<09:55,  1.94s/it] 59%|█████▊    | 435/741 [11:35<09:05,  1.78s/it] 59%|█████▉    | 436/741 [11:37<08:29,  1.67s/it] 59%|█████▉    | 437/741 [11:38<08:04,  1.59s/it] 59%|█████▉    | 438/741 [11:39<07:46,  1.54s/it] 59%|█████▉    | 439/741 [11:41<07:38,  1.52s/it] 59%|█████▉    | 440/741 [11:42<07:27,  1.49s/it] 60%|█████▉    | 441/741 [11:44<07:20,  1.47s/it] 60%|█████▉    | 442/741 [11:45<07:13,  1.45s/it] 60%|█████▉    | 443/741 [11:46<07:08,  1.44s/it] 60%|█████▉    | 444/741 [11:48<07:10,  1.45s/it] 60%|██████    | 445/741 [11:49<07:04,  1.44s/it] 60%|██████    | 446/741 [11:51<07:01,  1.43s/it] 60%|██████    | 447/741 [11:52<06:58,  1.42s/it] 60%|██████    | 448/741 [11:54<06:56,  1.42s/it] 61%|██████    | 449/741 [11:55<07:00,  1.44s/it] 61%|██████    | 450/741 [11:56<06:56,  1.43s/it] 61%|██████    | 451/741 [11:58<06:53,  1.43s/it] 61%|██████    | 452/741 [11:59<06:50,  1.42s/it] 61%|██████    | 453/741 [12:01<06:47,  1.42s/it] 61%|██████▏   | 454/741 [12:02<06:51,  1.43s/it] 61%|██████▏   | 455/741 [12:04<06:48,  1.43s/it] 62%|██████▏   | 456/741 [12:05<06:45,  1.42s/it] 62%|██████▏   | 457/741 [12:06<06:43,  1.42s/it] 62%|██████▏   | 458/741 [12:08<06:40,  1.42s/it] 62%|██████▏   | 459/741 [12:09<06:43,  1.43s/it] 62%|██████▏   | 460/741 [12:11<06:40,  1.42s/it] 62%|██████▏   | 461/741 [12:12<06:36,  1.42s/it] 62%|██████▏   | 462/741 [12:13<06:34,  1.41s/it] 62%|██████▏   | 463/741 [12:15<06:32,  1.41s/it] 63%|██████▎   | 464/741 [12:16<06:36,  1.43s/it] 63%|██████▎   | 465/741 [12:18<06:33,  1.43s/it] 63%|██████▎   | 466/741 [12:19<06:30,  1.42s/it] 63%|██████▎   | 467/741 [12:21<06:28,  1.42s/it] 63%|██████▎   | 468/741 [12:22<05:57,  1.31s/it]{'eval_loss': 0.16530607640743256, 'eval_precision': 0.7435294117647059, 'eval_recall': 0.8272251308900523, 'eval_f1': 0.7831474597273854, 'eval_accuracy': 0.9712581344902386, 'eval_runtime': 1.081, 'eval_samples_per_second': 143.391, 'eval_steps_per_second': 4.626, 'epoch': 11.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.53it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.46it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.29it/s][A                                                 
                                             [A 63%|██████▎   | 468/741 [12:23<05:57,  1.31s/it]
100%|██████████| 5/5 [00:00<00:00,  6.29it/s][A
                                             [A                                                  63%|██████▎   | 468/741 [12:30<05:57,  1.31s/it] 63%|██████▎   | 468/741 [12:30<07:17,  1.60s/it]
[I 2025-09-20 14:06:57,659] Trial 3 finished with value: 3.37224023577245 and parameters: {'learning_rate': 1.855997359084001e-05, 'num_train_epochs': 19, 'per_device_train_batch_size': 2, 'weight_decay': 0.09940580242566376, 'warmup_ratio': 0.19559674052826848, 'optimizer': 'AdamW'}. Best is trial 1 with value: 3.377708616309642.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▃▆▇▇█████▇█
wandb:                 eval/f1 ▁▄▇▇████████
wandb:               eval/loss █▃▁▁▁▁▁▂▂▂▂▂
wandb:          eval/precision ▁▅▆▇▇▇████▇█
wandb:             eval/recall ▁▃▇█████████
wandb:            eval/runtime ▆▁▁▁▂▁▂▁▂▁██
wandb: eval/samples_per_second ▃███▇█▇█▇█▁▁
wandb:   eval/steps_per_second ▃███▇█▇█▇█▁▁
wandb:             train/epoch ▁▂▂▃▄▄▅▅▆▇▇██
wandb:       train/global_step ▁▂▂▃▄▄▅▅▆▇▇██
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.97695
wandb:                  eval/f1 0.79843
wandb:                eval/loss 0.16507
wandb:           eval/precision 0.79843
wandb:              eval/recall 0.79843
wandb:             eval/runtime 1.0786
wandb:  eval/samples_per_second 143.705
wandb:    eval/steps_per_second 4.636
wandb:               total_flos 3449393188411392.0
wandb:              train/epoch 12
wandb:        train/global_step 468
wandb:               train_loss 0.27155
wandb:            train_runtime 752.6902
wandb: train_samples_per_second 31.251
wandb:   train_steps_per_second 0.984
wandb: 
wandb: 🚀 View run fine-river-780 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/zryc3e3t
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250920_135426-zryc3e3t/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_140701-vy62x9pi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-field-781
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/vy62x9pi
{'eval_loss': 0.16507357358932495, 'eval_precision': 0.7984293193717278, 'eval_recall': 0.7984293193717278, 'eval_f1': 0.7984293193717278, 'eval_accuracy': 0.9769522776572668, 'eval_runtime': 1.0786, 'eval_samples_per_second': 143.705, 'eval_steps_per_second': 4.636, 'epoch': 12.0}
{'train_runtime': 752.6902, 'train_samples_per_second': 31.251, 'train_steps_per_second': 0.984, 'train_loss': 0.2715540502825354, 'epoch': 12.0}
  0%|          | 0/15 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  7%|▋         | 1/15 [00:02<00:30,  2.17s/it] 13%|█▎        | 2/15 [00:04<00:27,  2.14s/it] 20%|██        | 3/15 [00:06<00:25,  2.14s/it] 27%|██▋       | 4/15 [00:08<00:23,  2.14s/it] 33%|███▎      | 5/15 [00:10<00:21,  2.12s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.51it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.27it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                              
                                             [A 33%|███▎      | 5/15 [00:11<00:21,  2.12s/it]
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 40%|████      | 6/15 [00:20<00:41,  4.60s/it] 47%|████▋     | 7/15 [00:22<00:30,  3.80s/it] 53%|█████▎    | 8/15 [00:24<00:22,  3.27s/it] 60%|██████    | 9/15 [00:26<00:17,  2.94s/it] 67%|██████▋   | 10/15 [00:28<00:13,  2.64s/it]{'eval_loss': 2.305087089538574, 'eval_precision': 0.0006404782237403928, 'eval_recall': 0.007853403141361256, 'eval_f1': 0.0011843663639952626, 'eval_accuracy': 0.31927874186550975, 'eval_runtime': 1.0343, 'eval_samples_per_second': 149.865, 'eval_steps_per_second': 4.834, 'epoch': 1.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.58it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.31it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 67%|██████▋   | 10/15 [00:29<00:13,  2.64s/it]
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 73%|███████▎  | 11/15 [00:38<00:19,  4.85s/it] 80%|████████  | 12/15 [00:40<00:12,  4.04s/it] 87%|████████▋ | 13/15 [00:42<00:06,  3.47s/it] 93%|█████████▎| 14/15 [00:44<00:03,  3.07s/it]100%|██████████| 15/15 [00:46<00:00,  2.74s/it]{'eval_loss': 0.5136048197746277, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.926382863340564, 'eval_runtime': 1.0129, 'eval_samples_per_second': 153.025, 'eval_steps_per_second': 4.936, 'epoch': 2.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.57it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.29it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A100%|██████████| 15/15 [00:47<00:00,  2.74s/it]
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A
                                             [A                                               100%|██████████| 15/15 [00:55<00:00,  2.74s/it]100%|██████████| 15/15 [00:55<00:00,  3.73s/it]
[I 2025-09-20 14:07:58,150] Trial 4 finished with value: 0.9267895878524945 and parameters: {'learning_rate': 1.5052416014192492e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 4.558455300857753e-06, 'warmup_ratio': 0.12638074493466406, 'optimizer': 'Adafactor'}. Best is trial 1 with value: 3.377708616309642.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁██
wandb:                 eval/f1 █▁▁
wandb:               eval/loss █▁▁
wandb:          eval/precision █▁▁
wandb:             eval/recall █▁▁
wandb:            eval/runtime █▁▁
wandb: eval/samples_per_second ▁██
wandb:   eval/steps_per_second ▁██
wandb:             train/epoch ▁▅██
wandb:       train/global_step ▁▅██
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.92679
wandb:                  eval/f1 0
wandb:                eval/loss 0.55311
wandb:           eval/precision 0
wandb:              eval/recall 0
wandb:             eval/runtime 1.0121
wandb:  eval/samples_per_second 153.147
wandb:    eval/steps_per_second 4.94
wandb:               total_flos 862348297102848.0
wandb:              train/epoch 3
wandb:        train/global_step 15
wandb:               train_loss 1.70607
wandb:            train_runtime 58.5157
wandb: train_samples_per_second 63.47
wandb:   train_steps_per_second 0.256
wandb: 
wandb: 🚀 View run ethereal-field-781 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/vy62x9pi
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250920_140701-vy62x9pi/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_140802-mxqram2h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-universe-782
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/mxqram2h
{'eval_loss': 0.5531090497970581, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9267895878524945, 'eval_runtime': 1.0121, 'eval_samples_per_second': 153.147, 'eval_steps_per_second': 4.94, 'epoch': 3.0}
{'train_runtime': 58.5157, 'train_samples_per_second': 63.47, 'train_steps_per_second': 0.256, 'train_loss': 1.706069819132487, 'epoch': 3.0}
  0%|          | 0/110 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  1%|          | 1/110 [00:01<03:04,  1.70s/it]  2%|▏         | 2/110 [00:03<02:59,  1.66s/it]  3%|▎         | 3/110 [00:04<02:56,  1.65s/it]  4%|▎         | 4/110 [00:06<02:54,  1.65s/it]  5%|▍         | 5/110 [00:08<02:55,  1.67s/it]  5%|▌         | 6/110 [00:09<02:53,  1.66s/it]  6%|▋         | 7/110 [00:11<02:50,  1.66s/it]  7%|▋         | 8/110 [00:13<02:48,  1.65s/it]  8%|▊         | 9/110 [00:14<02:46,  1.65s/it]  9%|▉         | 10/110 [00:16<02:33,  1.54s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.43it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.18it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.70it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A  9%|▉         | 10/110 [00:17<02:33,  1.54s/it]
100%|██████████| 5/5 [00:00<00:00,  6.70it/s][A
                                             [A  9%|▉         | 10/110 [00:17<02:52,  1.72s/it]
[I 2025-09-20 14:08:20,120] Trial 5 pruned. 
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁
wandb:                 eval/f1 ▁
wandb:               eval/loss ▁
wandb:          eval/precision ▁
wandb:             eval/recall ▁
wandb:            eval/runtime ▁
wandb: eval/samples_per_second ▁
wandb:   eval/steps_per_second ▁
wandb:             train/epoch ▁
wandb:       train/global_step ▁
wandb: 
wandb: Run summary:
wandb:           eval/accuracy 0.72641
wandb:                 eval/f1 0
wandb:               eval/loss 1.93521
wandb:          eval/precision 0
wandb:             eval/recall 0
wandb:            eval/runtime 1.0344
wandb: eval/samples_per_second 149.84
wandb:   eval/steps_per_second 4.834
wandb:             train/epoch 1
wandb:       train/global_step 10
wandb: 
wandb: 🚀 View run hearty-universe-782 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/mxqram2h
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250920_140802-mxqram2h/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_140823-2jftrw4o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-dream-783
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/2jftrw4o
{'eval_loss': 1.935210943222046, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.726409978308026, 'eval_runtime': 1.0344, 'eval_samples_per_second': 149.84, 'eval_steps_per_second': 4.834, 'epoch': 1.0}
  0%|          | 0/60 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  2%|▏         | 1/60 [00:02<02:07,  2.16s/it]  3%|▎         | 2/60 [00:04<02:04,  2.14s/it]  5%|▌         | 3/60 [00:06<02:01,  2.14s/it]  7%|▋         | 4/60 [00:08<01:59,  2.14s/it]  8%|▊         | 5/60 [00:10<01:56,  2.11s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.51it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.20it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.74it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                              
                                             [A  8%|▊         | 5/60 [00:11<01:56,  2.11s/it]
100%|██████████| 5/5 [00:00<00:00,  6.74it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 10%|█         | 6/60 [00:21<04:28,  4.97s/it] 12%|█▏        | 7/60 [00:23<03:34,  4.04s/it] 13%|█▎        | 8/60 [00:25<02:58,  3.43s/it] 15%|█▌        | 9/60 [00:27<02:35,  3.05s/it] 17%|█▋        | 10/60 [00:29<02:15,  2.72s/it]{'eval_loss': 2.368441581726074, 'eval_precision': 0.0009633911368015414, 'eval_recall': 0.013089005235602094, 'eval_f1': 0.0017946877243359654, 'eval_accuracy': 0.24376355748373102, 'eval_runtime': 1.0442, 'eval_samples_per_second': 148.444, 'eval_steps_per_second': 4.789, 'epoch': 1.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.64it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.32it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.89it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 17%|█▋        | 10/60 [00:30<02:15,  2.72s/it]
100%|██████████| 5/5 [00:00<00:00,  6.89it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 18%|█▊        | 11/60 [00:39<04:07,  5.05s/it] 20%|██        | 12/60 [00:42<03:22,  4.22s/it] 22%|██▏       | 13/60 [00:44<02:48,  3.59s/it] 23%|██▎       | 14/60 [00:46<02:25,  3.15s/it] 25%|██▌       | 15/60 [00:48<02:05,  2.80s/it]{'eval_loss': 0.5582662224769592, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9270607375271149, 'eval_runtime': 1.01, 'eval_samples_per_second': 153.472, 'eval_steps_per_second': 4.951, 'epoch': 2.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.45it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.19it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.76it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 25%|██▌       | 15/60 [00:49<02:05,  2.80s/it]
100%|██████████| 5/5 [00:00<00:00,  6.76it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 27%|██▋       | 16/60 [00:57<03:29,  4.77s/it] 28%|██▊       | 17/60 [00:59<02:51,  3.98s/it] 30%|███       | 18/60 [01:02<02:23,  3.42s/it] 32%|███▏      | 19/60 [01:04<02:04,  3.04s/it] 33%|███▎      | 20/60 [01:06<01:48,  2.72s/it]{'eval_loss': 0.4883870780467987, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9276030368763557, 'eval_runtime': 1.0248, 'eval_samples_per_second': 151.243, 'eval_steps_per_second': 4.879, 'epoch': 3.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.55it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.51it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.32it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 33%|███▎      | 20/60 [01:07<01:48,  2.72s/it]
100%|██████████| 5/5 [00:00<00:00,  6.32it/s][A
                                             [A                                                33%|███▎      | 20/60 [01:15<01:48,  2.72s/it] 33%|███▎      | 20/60 [01:15<02:30,  3.76s/it]
[I 2025-09-20 14:09:39,725] Trial 6 finished with value: 0.9276030368763557 and parameters: {'learning_rate': 9.866305675754662e-05, 'num_train_epochs': 12, 'per_device_train_batch_size': 16, 'weight_decay': 0.0001546052820892114, 'warmup_ratio': 0.3489619335152184, 'optimizer': 'Adam'}. Best is trial 1 with value: 3.377708616309642.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁███
wandb:                 eval/f1 █▁▁▁
wandb:               eval/loss █▁▁▁
wandb:          eval/precision █▁▁▁
wandb:             eval/recall █▁▁▁
wandb:            eval/runtime ▅▁▃█
wandb: eval/samples_per_second ▄█▆▁
wandb:   eval/steps_per_second ▄█▆▁
wandb:             train/epoch ▁▃▆██
wandb:       train/global_step ▁▃▆██
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.9276
wandb:                  eval/f1 0
wandb:                eval/loss 0.59686
wandb:           eval/precision 0
wandb:              eval/recall 0
wandb:             eval/runtime 1.0743
wandb:  eval/samples_per_second 144.277
wandb:    eval/steps_per_second 4.654
wandb:               total_flos 1437247161838080.0
wandb:              train/epoch 4
wandb:        train/global_step 20
wandb:               train_loss 1.36916
wandb:            train_runtime 77.803
wandb: train_samples_per_second 190.944
wandb:   train_steps_per_second 0.771
wandb: 
wandb: 🚀 View run deep-dream-783 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/2jftrw4o
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250920_140823-2jftrw4o/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_140942-01bm1uoy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-music-784
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/01bm1uoy
{'eval_loss': 0.596858561038971, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9276030368763557, 'eval_runtime': 1.0743, 'eval_samples_per_second': 144.277, 'eval_steps_per_second': 4.654, 'epoch': 4.0}
{'train_runtime': 77.803, 'train_samples_per_second': 190.944, 'train_steps_per_second': 0.771, 'train_loss': 1.3691584587097168, 'epoch': 4.0}
  0%|          | 0/15 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  7%|▋         | 1/15 [00:02<00:30,  2.17s/it] 13%|█▎        | 2/15 [00:04<00:27,  2.14s/it] 20%|██        | 3/15 [00:06<00:25,  2.14s/it] 27%|██▋       | 4/15 [00:08<00:23,  2.14s/it] 33%|███▎      | 5/15 [00:10<00:21,  2.11s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.60it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.31it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                              
                                             [A 33%|███▎      | 5/15 [00:11<00:21,  2.11s/it]
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 40%|████      | 6/15 [00:20<00:43,  4.85s/it] 47%|████▋     | 7/15 [00:22<00:31,  3.96s/it] 53%|█████▎    | 8/15 [00:25<00:23,  3.38s/it] 60%|██████    | 9/15 [00:27<00:18,  3.01s/it] 67%|██████▋   | 10/15 [00:29<00:13,  2.69s/it]{'eval_loss': 1.123910903930664, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9135032537960954, 'eval_runtime': 1.0122, 'eval_samples_per_second': 153.125, 'eval_steps_per_second': 4.94, 'epoch': 1.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.57it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.27it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 67%|██████▋   | 10/15 [00:30<00:13,  2.69s/it]
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 73%|███████▎  | 11/15 [00:39<00:19,  4.96s/it] 80%|████████  | 12/15 [00:41<00:12,  4.11s/it] 87%|████████▋ | 13/15 [00:43<00:07,  3.53s/it] 93%|█████████▎| 14/15 [00:45<00:03,  3.11s/it]100%|██████████| 15/15 [00:47<00:00,  2.77s/it]{'eval_loss': 0.47741609811782837, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9276030368763557, 'eval_runtime': 1.0139, 'eval_samples_per_second': 152.873, 'eval_steps_per_second': 4.931, 'epoch': 2.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.60it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A100%|██████████| 15/15 [00:48<00:00,  2.77s/it]
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A
                                             [A                                               100%|██████████| 15/15 [00:57<00:00,  2.77s/it]100%|██████████| 15/15 [00:57<00:00,  3.81s/it]
[I 2025-09-20 14:10:41,128] Trial 7 finished with value: 0.9276030368763557 and parameters: {'learning_rate': 2.6199275931829575e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.005757914489389838, 'warmup_ratio': 0.1043415607599415, 'optimizer': 'AdamW'}. Best is trial 1 with value: 3.377708616309642.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁██
wandb:                 eval/f1 ▁▁▁
wandb:               eval/loss █▁▁
wandb:          eval/precision ▁▁▁
wandb:             eval/recall ▁▁▁
wandb:            eval/runtime ▁█▅
wandb: eval/samples_per_second █▁▄
wandb:   eval/steps_per_second █▁▄
wandb:             train/epoch ▁▅██
wandb:       train/global_step ▁▅██
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.9276
wandb:                  eval/f1 0
wandb:                eval/loss 0.43235
wandb:           eval/precision 0
wandb:              eval/recall 0
wandb:             eval/runtime 1.0132
wandb:  eval/samples_per_second 152.974
wandb:    eval/steps_per_second 4.935
wandb:               total_flos 862348297102848.0
wandb:              train/epoch 3
wandb:        train/global_step 15
wandb:               train_loss 1.32987
wandb:            train_runtime 59.7666
wandb: train_samples_per_second 62.142
wandb:   train_steps_per_second 0.251
wandb: 
wandb: 🚀 View run fluent-music-784 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/01bm1uoy
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250920_140942-01bm1uoy/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_141044-9jadj0eg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-wildflower-785
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/9jadj0eg
{'eval_loss': 0.43235069513320923, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9276030368763557, 'eval_runtime': 1.0132, 'eval_samples_per_second': 152.974, 'eval_steps_per_second': 4.935, 'epoch': 3.0}
{'train_runtime': 59.7666, 'train_samples_per_second': 62.142, 'train_steps_per_second': 0.251, 'train_loss': 1.3298749287923177, 'epoch': 3.0}
  0%|          | 0/70 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  1%|▏         | 1/70 [00:01<01:57,  1.70s/it]  3%|▎         | 2/70 [00:03<01:53,  1.66s/it]  4%|▍         | 3/70 [00:04<01:50,  1.66s/it]  6%|▌         | 4/70 [00:06<01:49,  1.65s/it]  7%|▋         | 5/70 [00:08<01:50,  1.70s/it]  9%|▊         | 6/70 [00:10<01:47,  1.68s/it] 10%|█         | 7/70 [00:11<01:45,  1.67s/it] 11%|█▏        | 8/70 [00:13<01:43,  1.66s/it] 13%|█▎        | 9/70 [00:15<01:41,  1.66s/it] 14%|█▍        | 10/70 [00:16<01:33,  1.56s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.49it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.23it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 14%|█▍        | 10/70 [00:17<01:33,  1.56s/it]
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A
                                             [A 14%|█▍        | 10/70 [00:17<01:44,  1.74s/it]
[I 2025-09-20 14:11:02,257] Trial 8 pruned. 
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁
wandb:                 eval/f1 ▁
wandb:               eval/loss ▁
wandb:          eval/precision ▁
wandb:             eval/recall ▁
wandb:            eval/runtime ▁
wandb: eval/samples_per_second ▁
wandb:   eval/steps_per_second ▁
wandb:             train/epoch ▁
wandb:       train/global_step ▁
wandb: 
wandb: Run summary:
wandb:           eval/accuracy 0.12283
wandb:                 eval/f1 0.00097
wandb:               eval/loss 2.50518
wandb:          eval/precision 0.00052
wandb:             eval/recall 0.00785
wandb:            eval/runtime 1.0346
wandb: eval/samples_per_second 149.809
wandb:   eval/steps_per_second 4.833
wandb:             train/epoch 1
wandb:       train/global_step 10
wandb: 
wandb: 🚀 View run crimson-wildflower-785 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/9jadj0eg
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250920_141044-9jadj0eg/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_141105-0x6xpppe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-wildflower-786
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/0x6xpppe
{'eval_loss': 2.5051817893981934, 'eval_precision': 0.0005181347150259067, 'eval_recall': 0.007853403141361256, 'eval_f1': 0.0009721322099805574, 'eval_accuracy': 0.12283080260303687, 'eval_runtime': 1.0346, 'eval_samples_per_second': 149.809, 'eval_steps_per_second': 4.833, 'epoch': 1.0}
  0%|          | 0/351 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/351 [00:01<08:59,  1.54s/it]  1%|          | 2/351 [00:02<08:40,  1.49s/it]  1%|          | 3/351 [00:04<08:28,  1.46s/it]  1%|          | 4/351 [00:05<08:23,  1.45s/it]  1%|▏         | 5/351 [00:07<08:35,  1.49s/it]  2%|▏         | 6/351 [00:08<08:26,  1.47s/it]  2%|▏         | 7/351 [00:10<08:20,  1.45s/it]  2%|▏         | 8/351 [00:11<08:15,  1.44s/it]  3%|▎         | 9/351 [00:13<08:12,  1.44s/it]  3%|▎         | 10/351 [00:14<08:21,  1.47s/it]  3%|▎         | 11/351 [00:16<08:15,  1.46s/it]  3%|▎         | 12/351 [00:17<08:10,  1.45s/it]  4%|▎         | 13/351 [00:18<08:06,  1.44s/it]  4%|▍         | 14/351 [00:20<08:03,  1.43s/it]  4%|▍         | 15/351 [00:21<08:10,  1.46s/it]  5%|▍         | 16/351 [00:23<08:05,  1.45s/it]  5%|▍         | 17/351 [00:24<08:01,  1.44s/it]  5%|▌         | 18/351 [00:26<07:57,  1.43s/it]  5%|▌         | 19/351 [00:27<07:55,  1.43s/it]  6%|▌         | 20/351 [00:29<08:02,  1.46s/it]  6%|▌         | 21/351 [00:30<07:57,  1.45s/it]  6%|▋         | 22/351 [00:31<07:54,  1.44s/it]  7%|▋         | 23/351 [00:33<07:49,  1.43s/it]  7%|▋         | 24/351 [00:34<07:47,  1.43s/it]  7%|▋         | 25/351 [00:36<07:57,  1.46s/it]  7%|▋         | 26/351 [00:37<07:51,  1.45s/it]  8%|▊         | 27/351 [00:39<07:46,  1.44s/it]  8%|▊         | 28/351 [00:40<07:43,  1.43s/it]  8%|▊         | 29/351 [00:41<07:40,  1.43s/it]  9%|▊         | 30/351 [00:43<07:47,  1.46s/it]  9%|▉         | 31/351 [00:44<07:43,  1.45s/it]  9%|▉         | 32/351 [00:46<07:39,  1.44s/it]  9%|▉         | 33/351 [00:47<07:35,  1.43s/it] 10%|▉         | 34/351 [00:49<07:32,  1.43s/it] 10%|▉         | 35/351 [00:50<07:42,  1.46s/it] 10%|█         | 36/351 [00:52<07:37,  1.45s/it] 11%|█         | 37/351 [00:53<07:33,  1.44s/it] 11%|█         | 38/351 [00:55<07:29,  1.44s/it] 11%|█         | 39/351 [00:56<06:52,  1.32s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00,  7.24it/s][A
 60%|██████    | 3/5 [00:00<00:00,  6.49it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.23it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.15it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 11%|█         | 39/351 [00:57<06:52,  1.32s/it]
100%|██████████| 5/5 [00:00<00:00,  6.15it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 11%|█▏        | 40/351 [01:05<19:17,  3.72s/it] 12%|█▏        | 41/351 [01:06<15:38,  3.03s/it] 12%|█▏        | 42/351 [01:08<13:05,  2.54s/it] 12%|█▏        | 43/351 [01:09<11:20,  2.21s/it] 13%|█▎        | 44/351 [01:11<10:09,  1.98s/it] 13%|█▎        | 45/351 [01:12<09:14,  1.81s/it] 13%|█▎        | 46/351 [01:13<08:37,  1.70s/it] 13%|█▎        | 47/351 [01:15<08:09,  1.61s/it] 14%|█▎        | 48/351 [01:16<07:56,  1.57s/it] 14%|█▍        | 49/351 [01:18<07:40,  1.52s/it] 14%|█▍        | 50/351 [01:19<07:29,  1.49s/it] 15%|█▍        | 51/351 [01:21<07:20,  1.47s/it] 15%|█▍        | 52/351 [01:22<07:14,  1.45s/it] 15%|█▌        | 53/351 [01:23<07:17,  1.47s/it] 15%|█▌        | 54/351 [01:25<07:14,  1.46s/it] 16%|█▌        | 55/351 [01:26<07:09,  1.45s/it] 16%|█▌        | 56/351 [01:28<07:04,  1.44s/it] 16%|█▌        | 57/351 [01:29<07:02,  1.44s/it] 17%|█▋        | 58/351 [01:31<07:05,  1.45s/it] 17%|█▋        | 59/351 [01:32<07:00,  1.44s/it] 17%|█▋        | 60/351 [01:34<06:57,  1.43s/it] 17%|█▋        | 61/351 [01:35<06:54,  1.43s/it] 18%|█▊        | 62/351 [01:36<06:52,  1.43s/it] 18%|█▊        | 63/351 [01:38<06:55,  1.44s/it] 18%|█▊        | 64/351 [01:39<06:53,  1.44s/it] 19%|█▊        | 65/351 [01:41<06:49,  1.43s/it] 19%|█▉        | 66/351 [01:42<06:46,  1.43s/it] 19%|█▉        | 67/351 [01:44<06:44,  1.42s/it] 19%|█▉        | 68/351 [01:45<06:53,  1.46s/it] 20%|█▉        | 69/351 [01:46<06:48,  1.45s/it] 20%|█▉        | 70/351 [01:48<06:45,  1.44s/it] 20%|██        | 71/351 [01:49<06:41,  1.44s/it] 21%|██        | 72/351 [01:51<06:38,  1.43s/it] 21%|██        | 73/351 [01:52<06:42,  1.45s/it] 21%|██        | 74/351 [01:54<06:38,  1.44s/it] 21%|██▏       | 75/351 [01:55<06:35,  1.43s/it] 22%|██▏       | 76/351 [01:56<06:32,  1.43s/it] 22%|██▏       | 77/351 [01:58<06:32,  1.43s/it] 22%|██▏       | 78/351 [01:59<06:07,  1.35s/it]{'eval_loss': 0.2261698842048645, 'eval_precision': 0.36384976525821594, 'eval_recall': 0.40575916230366493, 'eval_f1': 0.38366336633663367, 'eval_accuracy': 0.9440075921908894, 'eval_runtime': 1.1227, 'eval_samples_per_second': 138.062, 'eval_steps_per_second': 4.454, 'epoch': 1.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.33it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.15it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.69it/s][A                                                
                                             [A 22%|██▏       | 78/351 [02:00<06:07,  1.35s/it]
100%|██████████| 5/5 [00:00<00:00,  6.69it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 23%|██▎       | 79/351 [02:09<17:07,  3.78s/it] 23%|██▎       | 80/351 [02:10<13:50,  3.07s/it] 23%|██▎       | 81/351 [02:11<11:33,  2.57s/it] 23%|██▎       | 82/351 [02:13<10:03,  2.24s/it] 24%|██▎       | 83/351 [02:14<08:54,  1.99s/it] 24%|██▍       | 84/351 [02:16<08:05,  1.82s/it] 24%|██▍       | 85/351 [02:17<07:31,  1.70s/it] 25%|██▍       | 86/351 [02:18<07:08,  1.62s/it] 25%|██▍       | 87/351 [02:20<06:55,  1.57s/it] 25%|██▌       | 88/351 [02:21<06:40,  1.52s/it] 25%|██▌       | 89/351 [02:23<06:30,  1.49s/it] 26%|██▌       | 90/351 [02:24<06:22,  1.47s/it] 26%|██▌       | 91/351 [02:26<06:17,  1.45s/it] 26%|██▌       | 92/351 [02:27<06:17,  1.46s/it] 26%|██▋       | 93/351 [02:28<06:12,  1.44s/it] 27%|██▋       | 94/351 [02:30<06:09,  1.44s/it] 27%|██▋       | 95/351 [02:31<06:06,  1.43s/it] 27%|██▋       | 96/351 [02:33<06:03,  1.43s/it] 28%|██▊       | 97/351 [02:34<06:08,  1.45s/it] 28%|██▊       | 98/351 [02:36<06:05,  1.44s/it] 28%|██▊       | 99/351 [02:37<06:02,  1.44s/it] 28%|██▊       | 100/351 [02:39<05:58,  1.43s/it] 29%|██▉       | 101/351 [02:40<05:56,  1.43s/it] 29%|██▉       | 102/351 [02:41<05:59,  1.44s/it] 29%|██▉       | 103/351 [02:43<05:56,  1.44s/it] 30%|██▉       | 104/351 [02:44<05:53,  1.43s/it] 30%|██▉       | 105/351 [02:46<05:50,  1.42s/it] 30%|███       | 106/351 [02:47<05:48,  1.42s/it] 30%|███       | 107/351 [02:49<05:50,  1.44s/it] 31%|███       | 108/351 [02:50<05:47,  1.43s/it] 31%|███       | 109/351 [02:51<05:45,  1.43s/it] 31%|███▏      | 110/351 [02:53<05:43,  1.43s/it] 32%|███▏      | 111/351 [02:54<05:41,  1.42s/it] 32%|███▏      | 112/351 [02:56<05:43,  1.44s/it] 32%|███▏      | 113/351 [02:57<05:40,  1.43s/it] 32%|███▏      | 114/351 [02:59<05:37,  1.42s/it] 33%|███▎      | 115/351 [03:00<05:35,  1.42s/it] 33%|███▎      | 116/351 [03:01<05:37,  1.44s/it] 33%|███▎      | 117/351 [03:02<05:09,  1.32s/it]{'eval_loss': 0.12169090658426285, 'eval_precision': 0.6712328767123288, 'eval_recall': 0.7696335078534031, 'eval_f1': 0.7170731707317073, 'eval_accuracy': 0.966648590021692, 'eval_runtime': 1.034, 'eval_samples_per_second': 149.899, 'eval_steps_per_second': 4.835, 'epoch': 2.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.64it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.33it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.91it/s][A                                                 
                                             [A 33%|███▎      | 117/351 [03:03<05:09,  1.32s/it]
100%|██████████| 5/5 [00:00<00:00,  6.91it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 34%|███▎      | 118/351 [03:12<14:35,  3.76s/it] 34%|███▍      | 119/351 [03:13<11:48,  3.05s/it] 34%|███▍      | 120/351 [03:15<09:51,  2.56s/it] 34%|███▍      | 121/351 [03:16<08:34,  2.24s/it] 35%|███▍      | 122/351 [03:18<07:35,  1.99s/it] 35%|███▌      | 123/351 [03:19<06:54,  1.82s/it] 35%|███▌      | 124/351 [03:20<06:25,  1.70s/it] 36%|███▌      | 125/351 [03:22<06:04,  1.61s/it] 36%|███▌      | 126/351 [03:23<05:53,  1.57s/it] 36%|███▌      | 127/351 [03:25<05:40,  1.52s/it] 36%|███▋      | 128/351 [03:26<05:31,  1.49s/it] 37%|███▋      | 129/351 [03:28<05:25,  1.47s/it] 37%|███▋      | 130/351 [03:29<05:24,  1.47s/it] 37%|███▋      | 131/351 [03:30<05:19,  1.45s/it] 38%|███▊      | 132/351 [03:32<05:15,  1.44s/it] 38%|███▊      | 133/351 [03:33<05:12,  1.43s/it] 38%|███▊      | 134/351 [03:35<05:09,  1.43s/it] 38%|███▊      | 135/351 [03:36<05:11,  1.44s/it] 39%|███▊      | 136/351 [03:38<05:08,  1.43s/it] 39%|███▉      | 137/351 [03:39<05:05,  1.43s/it] 39%|███▉      | 138/351 [03:40<05:03,  1.43s/it] 40%|███▉      | 139/351 [03:42<05:03,  1.43s/it] 40%|███▉      | 140/351 [03:43<05:06,  1.45s/it] 40%|████      | 141/351 [03:45<05:02,  1.44s/it] 40%|████      | 142/351 [03:46<04:59,  1.43s/it] 41%|████      | 143/351 [03:48<04:56,  1.43s/it] 41%|████      | 144/351 [03:49<04:53,  1.42s/it] 41%|████▏     | 145/351 [03:50<04:56,  1.44s/it] 42%|████▏     | 146/351 [03:52<04:53,  1.43s/it] 42%|████▏     | 147/351 [03:53<04:50,  1.42s/it] 42%|████▏     | 148/351 [03:55<04:48,  1.42s/it] 42%|████▏     | 149/351 [03:56<04:46,  1.42s/it] 43%|████▎     | 150/351 [03:58<04:48,  1.44s/it] 43%|████▎     | 151/351 [03:59<04:45,  1.43s/it] 43%|████▎     | 152/351 [04:00<04:43,  1.42s/it] 44%|████▎     | 153/351 [04:02<04:41,  1.42s/it] 44%|████▍     | 154/351 [04:03<04:39,  1.42s/it] 44%|████▍     | 155/351 [04:05<04:41,  1.44s/it] 44%|████▍     | 156/351 [04:06<04:17,  1.32s/it]{'eval_loss': 0.12575730681419373, 'eval_precision': 0.7819148936170213, 'eval_recall': 0.7696335078534031, 'eval_f1': 0.7757255936675462, 'eval_accuracy': 0.9713937093275488, 'eval_runtime': 1.01, 'eval_samples_per_second': 153.47, 'eval_steps_per_second': 4.951, 'epoch': 3.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.62it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.33it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.84it/s][A                                                 
                                             [A 44%|████▍     | 156/351 [04:07<04:17,  1.32s/it]
100%|██████████| 5/5 [00:00<00:00,  6.84it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 45%|████▍     | 157/351 [04:16<12:38,  3.91s/it] 45%|████▌     | 158/351 [04:17<10:11,  3.17s/it] 45%|████▌     | 159/351 [04:19<08:30,  2.66s/it] 46%|████▌     | 160/351 [04:20<07:16,  2.29s/it] 46%|████▌     | 161/351 [04:21<06:25,  2.03s/it] 46%|████▌     | 162/351 [04:23<05:48,  1.84s/it] 46%|████▋     | 163/351 [04:24<05:22,  1.72s/it] 47%|████▋     | 164/351 [04:26<05:08,  1.65s/it] 47%|████▋     | 165/351 [04:27<04:54,  1.58s/it] 47%|████▋     | 166/351 [04:29<04:43,  1.53s/it] 48%|████▊     | 167/351 [04:30<04:35,  1.50s/it] 48%|████▊     | 168/351 [04:32<04:29,  1.47s/it] 48%|████▊     | 169/351 [04:33<04:28,  1.47s/it] 48%|████▊     | 170/351 [04:34<04:23,  1.46s/it] 49%|████▊     | 171/351 [04:36<04:19,  1.44s/it] 49%|████▉     | 172/351 [04:37<04:16,  1.43s/it] 49%|████▉     | 173/351 [04:39<04:14,  1.43s/it] 50%|████▉     | 174/351 [04:40<04:15,  1.44s/it] 50%|████▉     | 175/351 [04:42<04:12,  1.44s/it] 50%|█████     | 176/351 [04:43<04:10,  1.43s/it] 50%|█████     | 177/351 [04:44<04:07,  1.42s/it] 51%|█████     | 178/351 [04:46<04:06,  1.42s/it] 51%|█████     | 179/351 [04:47<04:08,  1.45s/it] 51%|█████▏    | 180/351 [04:49<04:05,  1.44s/it] 52%|█████▏    | 181/351 [04:50<04:03,  1.43s/it] 52%|█████▏    | 182/351 [04:52<04:02,  1.44s/it] 52%|█████▏    | 183/351 [04:53<04:00,  1.43s/it] 52%|█████▏    | 184/351 [04:54<04:01,  1.45s/it] 53%|█████▎    | 185/351 [04:56<03:57,  1.43s/it] 53%|█████▎    | 186/351 [04:57<03:55,  1.43s/it] 53%|█████▎    | 187/351 [04:59<03:53,  1.42s/it] 54%|█████▎    | 188/351 [05:00<03:51,  1.42s/it] 54%|█████▍    | 189/351 [05:02<03:52,  1.44s/it] 54%|█████▍    | 190/351 [05:03<03:50,  1.43s/it] 54%|█████▍    | 191/351 [05:04<03:47,  1.42s/it] 55%|█████▍    | 192/351 [05:06<03:46,  1.42s/it] 55%|█████▍    | 193/351 [05:07<03:47,  1.44s/it] 55%|█████▌    | 194/351 [05:09<03:44,  1.43s/it] 56%|█████▌    | 195/351 [05:10<03:25,  1.32s/it]{'eval_loss': 0.10857044160366058, 'eval_precision': 0.7619047619047619, 'eval_recall': 0.7958115183246073, 'eval_f1': 0.7784891165172856, 'eval_accuracy': 0.975732104121475, 'eval_runtime': 1.0176, 'eval_samples_per_second': 152.326, 'eval_steps_per_second': 4.914, 'epoch': 4.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.57it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A                                                 
                                             [A 56%|█████▌    | 195/351 [05:11<03:25,  1.32s/it]
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 56%|█████▌    | 196/351 [05:19<09:44,  3.77s/it] 56%|█████▌    | 197/351 [05:21<07:52,  3.07s/it] 56%|█████▋    | 198/351 [05:22<06:37,  2.60s/it] 57%|█████▋    | 199/351 [05:24<05:40,  2.24s/it] 57%|█████▋    | 200/351 [05:25<05:01,  1.99s/it] 57%|█████▋    | 201/351 [05:26<04:34,  1.83s/it] 58%|█████▊    | 202/351 [05:28<04:14,  1.71s/it] 58%|█████▊    | 203/351 [05:29<04:02,  1.64s/it] 58%|█████▊    | 204/351 [05:31<03:50,  1.57s/it] 58%|█████▊    | 205/351 [05:32<03:42,  1.52s/it] 59%|█████▊    | 206/351 [05:34<03:35,  1.49s/it] 59%|█████▉    | 207/351 [05:35<03:32,  1.48s/it] 59%|█████▉    | 208/351 [05:36<03:28,  1.46s/it] 60%|█████▉    | 209/351 [05:38<03:25,  1.45s/it] 60%|█████▉    | 210/351 [05:39<03:22,  1.44s/it] 60%|██████    | 211/351 [05:41<03:20,  1.43s/it] 60%|██████    | 212/351 [05:42<03:20,  1.44s/it] 61%|██████    | 213/351 [05:44<03:17,  1.43s/it] 61%|██████    | 214/351 [05:45<03:15,  1.42s/it] 61%|██████▏   | 215/351 [05:46<03:13,  1.42s/it] 62%|██████▏   | 216/351 [05:48<03:11,  1.42s/it] 62%|██████▏   | 217/351 [05:49<03:11,  1.43s/it] 62%|██████▏   | 218/351 [05:51<03:09,  1.43s/it] 62%|██████▏   | 219/351 [05:52<03:07,  1.42s/it] 63%|██████▎   | 220/351 [05:54<03:05,  1.41s/it] 63%|██████▎   | 221/351 [05:55<03:03,  1.41s/it] 63%|██████▎   | 222/351 [05:56<03:04,  1.43s/it] 64%|██████▎   | 223/351 [05:58<03:02,  1.43s/it] 64%|██████▍   | 224/351 [05:59<03:00,  1.42s/it] 64%|██████▍   | 225/351 [06:01<03:00,  1.43s/it] 64%|██████▍   | 226/351 [06:02<02:58,  1.43s/it] 65%|██████▍   | 227/351 [06:04<02:58,  1.44s/it] 65%|██████▍   | 228/351 [06:05<02:56,  1.43s/it] 65%|██████▌   | 229/351 [06:06<02:54,  1.43s/it] 66%|██████▌   | 230/351 [06:08<02:52,  1.42s/it] 66%|██████▌   | 231/351 [06:09<02:50,  1.42s/it] 66%|██████▌   | 232/351 [06:11<02:50,  1.44s/it] 66%|██████▋   | 233/351 [06:12<02:48,  1.43s/it] 67%|██████▋   | 234/351 [06:13<02:33,  1.31s/it]{'eval_loss': 0.14144136011600494, 'eval_precision': 0.8328840970350404, 'eval_recall': 0.8089005235602095, 'eval_f1': 0.8207171314741036, 'eval_accuracy': 0.9747830802603037, 'eval_runtime': 1.0203, 'eval_samples_per_second': 151.91, 'eval_steps_per_second': 4.9, 'epoch': 5.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.58it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.31it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.82it/s][A                                                 
                                             [A 67%|██████▋   | 234/351 [06:14<02:33,  1.31s/it]
100%|██████████| 5/5 [00:00<00:00,  6.82it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 67%|██████▋   | 235/351 [06:23<07:22,  3.82s/it] 67%|██████▋   | 236/351 [06:24<05:57,  3.11s/it] 68%|██████▊   | 237/351 [06:26<04:56,  2.60s/it] 68%|██████▊   | 238/351 [06:27<04:13,  2.24s/it] 68%|██████▊   | 239/351 [06:28<03:43,  1.99s/it] 68%|██████▊   | 240/351 [06:30<03:21,  1.82s/it] 69%|██████▊   | 241/351 [06:31<03:08,  1.71s/it] 69%|██████▉   | 242/351 [06:33<02:57,  1.62s/it] 69%|██████▉   | 243/351 [06:34<02:48,  1.56s/it] 70%|██████▉   | 244/351 [06:36<02:43,  1.53s/it] 70%|██████▉   | 245/351 [06:37<02:38,  1.50s/it] 70%|███████   | 246/351 [06:39<02:37,  1.50s/it] 70%|███████   | 247/351 [06:40<02:34,  1.48s/it] 71%|███████   | 248/351 [06:41<02:30,  1.46s/it] 71%|███████   | 249/351 [06:43<02:27,  1.44s/it] 71%|███████   | 250/351 [06:44<02:24,  1.43s/it] 72%|███████▏  | 251/351 [06:46<02:24,  1.44s/it] 72%|███████▏  | 252/351 [06:47<02:22,  1.43s/it] 72%|███████▏  | 253/351 [06:49<02:19,  1.43s/it] 72%|███████▏  | 254/351 [06:50<02:17,  1.42s/it] 73%|███████▎  | 255/351 [06:51<02:15,  1.42s/it] 73%|███████▎  | 256/351 [06:53<02:15,  1.43s/it] 73%|███████▎  | 257/351 [06:54<02:13,  1.42s/it] 74%|███████▎  | 258/351 [06:56<02:11,  1.42s/it] 74%|███████▍  | 259/351 [06:57<02:10,  1.41s/it] 74%|███████▍  | 260/351 [06:58<02:08,  1.41s/it] 74%|███████▍  | 261/351 [07:00<02:08,  1.43s/it] 75%|███████▍  | 262/351 [07:01<02:06,  1.42s/it] 75%|███████▍  | 263/351 [07:03<02:05,  1.42s/it] 75%|███████▌  | 264/351 [07:04<02:03,  1.42s/it] 75%|███████▌  | 265/351 [07:06<02:01,  1.41s/it] 76%|███████▌  | 266/351 [07:07<02:01,  1.43s/it] 76%|███████▌  | 267/351 [07:08<01:59,  1.43s/it] 76%|███████▋  | 268/351 [07:10<01:58,  1.42s/it] 77%|███████▋  | 269/351 [07:11<01:56,  1.42s/it] 77%|███████▋  | 270/351 [07:13<01:56,  1.43s/it] 77%|███████▋  | 271/351 [07:14<01:54,  1.43s/it] 77%|███████▋  | 272/351 [07:16<01:53,  1.43s/it] 78%|███████▊  | 273/351 [07:17<01:42,  1.32s/it]{'eval_loss': 0.1425260305404663, 'eval_precision': 0.8184281842818428, 'eval_recall': 0.7905759162303665, 'eval_f1': 0.804260985352863, 'eval_accuracy': 0.9747830802603037, 'eval_runtime': 1.0177, 'eval_samples_per_second': 152.297, 'eval_steps_per_second': 4.913, 'epoch': 6.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.58it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.32it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.89it/s][A                                                 
                                             [A 78%|███████▊  | 273/351 [07:18<01:42,  1.32s/it]
100%|██████████| 5/5 [00:00<00:00,  6.89it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 78%|███████▊  | 274/351 [07:27<05:01,  3.92s/it] 78%|███████▊  | 275/351 [07:28<04:01,  3.18s/it] 79%|███████▊  | 276/351 [07:29<03:18,  2.65s/it] 79%|███████▉  | 277/351 [07:31<02:48,  2.28s/it] 79%|███████▉  | 278/351 [07:32<02:27,  2.01s/it] 79%|███████▉  | 279/351 [07:34<02:11,  1.83s/it] 80%|███████▉  | 280/351 [07:35<02:02,  1.72s/it] 80%|████████  | 281/351 [07:37<01:53,  1.63s/it] 80%|████████  | 282/351 [07:38<01:47,  1.56s/it] 81%|████████  | 283/351 [07:39<01:42,  1.51s/it] 81%|████████  | 284/351 [07:41<01:40,  1.50s/it] 81%|████████  | 285/351 [07:42<01:37,  1.47s/it] 81%|████████▏ | 286/351 [07:44<01:34,  1.46s/it] 82%|████████▏ | 287/351 [07:45<01:32,  1.44s/it] 82%|████████▏ | 288/351 [07:46<01:29,  1.43s/it] 82%|████████▏ | 289/351 [07:48<01:29,  1.44s/it] 83%|████████▎ | 290/351 [07:49<01:27,  1.43s/it] 83%|████████▎ | 291/351 [07:51<01:25,  1.42s/it] 83%|████████▎ | 292/351 [07:52<01:23,  1.42s/it] 83%|████████▎ | 293/351 [07:54<01:21,  1.41s/it] 84%|████████▍ | 294/351 [07:55<01:21,  1.43s/it] 84%|████████▍ | 295/351 [07:56<01:19,  1.42s/it] 84%|████████▍ | 296/351 [07:58<01:18,  1.42s/it] 85%|████████▍ | 297/351 [07:59<01:16,  1.41s/it] 85%|████████▍ | 298/351 [08:01<01:14,  1.41s/it] 85%|████████▌ | 299/351 [08:02<01:14,  1.43s/it] 85%|████████▌ | 300/351 [08:04<01:12,  1.42s/it] 86%|████████▌ | 301/351 [08:05<01:10,  1.42s/it] 86%|████████▌ | 302/351 [08:06<01:09,  1.41s/it] 86%|████████▋ | 303/351 [08:08<01:07,  1.41s/it] 87%|████████▋ | 304/351 [08:09<01:06,  1.42s/it] 87%|████████▋ | 305/351 [08:11<01:05,  1.42s/it] 87%|████████▋ | 306/351 [08:12<01:03,  1.41s/it] 87%|████████▋ | 307/351 [08:13<01:02,  1.41s/it] 88%|████████▊ | 308/351 [08:15<01:00,  1.41s/it] 88%|████████▊ | 309/351 [08:16<00:59,  1.43s/it] 88%|████████▊ | 310/351 [08:18<00:58,  1.42s/it] 89%|████████▊ | 311/351 [08:19<00:56,  1.42s/it] 89%|████████▉ | 312/351 [08:20<00:50,  1.31s/it]{'eval_loss': 0.16607476770877838, 'eval_precision': 0.8162162162162162, 'eval_recall': 0.7905759162303665, 'eval_f1': 0.8031914893617023, 'eval_accuracy': 0.9732917570498916, 'eval_runtime': 1.0122, 'eval_samples_per_second': 153.137, 'eval_steps_per_second': 4.94, 'epoch': 7.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.54it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A                                                 
                                             [A 89%|████████▉ | 312/351 [08:21<00:50,  1.31s/it]
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 89%|████████▉ | 313/351 [08:30<02:29,  3.94s/it] 89%|████████▉ | 314/351 [08:32<01:57,  3.18s/it] 90%|████████▉ | 315/351 [08:33<01:35,  2.65s/it] 90%|█████████ | 316/351 [08:34<01:19,  2.28s/it] 90%|█████████ | 317/351 [08:36<01:08,  2.02s/it] 91%|█████████ | 318/351 [08:37<01:01,  1.86s/it] 91%|█████████ | 319/351 [08:39<00:55,  1.72s/it] 91%|█████████ | 320/351 [08:40<00:50,  1.63s/it] 91%|█████████▏| 321/351 [08:42<00:46,  1.56s/it] 92%|█████████▏| 322/351 [08:43<00:44,  1.52s/it] 92%|█████████▏| 323/351 [08:44<00:42,  1.51s/it] 92%|█████████▏| 324/351 [08:46<00:39,  1.48s/it] 93%|█████████▎| 325/351 [08:47<00:37,  1.46s/it] 93%|█████████▎| 326/351 [08:49<00:36,  1.44s/it] 93%|█████████▎| 327/351 [08:50<00:34,  1.44s/it] 93%|█████████▎| 328/351 [08:52<00:33,  1.46s/it] 94%|█████████▎| 329/351 [08:53<00:31,  1.45s/it] 94%|█████████▍| 330/351 [08:54<00:30,  1.44s/it] 94%|█████████▍| 331/351 [08:56<00:28,  1.43s/it] 95%|█████████▍| 332/351 [08:57<00:27,  1.43s/it] 95%|█████████▍| 333/351 [08:59<00:25,  1.44s/it] 95%|█████████▌| 334/351 [09:00<00:24,  1.43s/it] 95%|█████████▌| 335/351 [09:02<00:22,  1.42s/it] 96%|█████████▌| 336/351 [09:03<00:21,  1.42s/it] 96%|█████████▌| 337/351 [09:04<00:19,  1.42s/it] 96%|█████████▋| 338/351 [09:06<00:18,  1.43s/it] 97%|█████████▋| 339/351 [09:07<00:17,  1.43s/it] 97%|█████████▋| 340/351 [09:09<00:15,  1.42s/it] 97%|█████████▋| 341/351 [09:10<00:14,  1.42s/it] 97%|█████████▋| 342/351 [09:12<00:12,  1.42s/it] 98%|█████████▊| 343/351 [09:13<00:11,  1.44s/it] 98%|█████████▊| 344/351 [09:14<00:10,  1.43s/it] 98%|█████████▊| 345/351 [09:16<00:08,  1.43s/it] 99%|█████████▊| 346/351 [09:17<00:07,  1.42s/it] 99%|█████████▉| 347/351 [09:19<00:05,  1.44s/it] 99%|█████████▉| 348/351 [09:20<00:04,  1.43s/it] 99%|█████████▉| 349/351 [09:22<00:02,  1.43s/it]100%|█████████▉| 350/351 [09:23<00:01,  1.43s/it]100%|██████████| 351/351 [09:24<00:00,  1.32s/it]{'eval_loss': 0.1613505780696869, 'eval_precision': 0.8267716535433071, 'eval_recall': 0.824607329842932, 'eval_f1': 0.8256880733944955, 'eval_accuracy': 0.9768167028199566, 'eval_runtime': 1.0151, 'eval_samples_per_second': 152.702, 'eval_steps_per_second': 4.926, 'epoch': 8.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.60it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.31it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A                                                 
                                             [A100%|██████████| 351/351 [09:25<00:00,  1.32s/it]
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A
                                             [A                                                 100%|██████████| 351/351 [09:33<00:00,  1.32s/it]100%|██████████| 351/351 [09:33<00:00,  1.63s/it]
[I 2025-09-20 14:20:39,774] Trial 9 finished with value: 3.4695526749403767 and parameters: {'learning_rate': 8.675619022725385e-05, 'num_train_epochs': 9, 'per_device_train_batch_size': 2, 'weight_decay': 1.7004986845131776e-06, 'warmup_ratio': 0.11101710773421669, 'optimizer': 'AdamW'}. Best is trial 9 with value: 3.4695526749403767.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▆▇███▇██
wandb:                 eval/f1 ▁▆▇▇█████
wandb:               eval/loss █▂▂▁▃▃▄▄▅
wandb:          eval/precision ▁▆▇▇█████
wandb:             eval/recall ▁▇▇▇▇▇▇██
wandb:            eval/runtime █▂▁▁▂▁▁▁▁
wandb: eval/samples_per_second ▁▆█▇▇▇███
wandb:   eval/steps_per_second ▁▆█▇▇▇███
wandb:             train/epoch ▁▂▃▄▅▅▆▇██
wandb:       train/global_step ▁▂▃▄▅▅▆▇██
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.97655
wandb:                  eval/f1 0.83077
wandb:                eval/loss 0.17471
wandb:           eval/precision 0.81407
wandb:              eval/recall 0.84817
wandb:             eval/runtime 1.0159
wandb:  eval/samples_per_second 152.58
wandb:    eval/steps_per_second 4.922
wandb:               total_flos 2874494323676160.0
wandb:              train/epoch 9
wandb:        train/global_step 351
wandb:               train_loss 0.1474
wandb:            train_runtime 575.6948
wandb: train_samples_per_second 19.354
wandb:   train_steps_per_second 0.61
wandb: 
wandb: 🚀 View run charmed-wildflower-786 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/0x6xpppe
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250920_141105-0x6xpppe/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_142043-9yt70gy0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-hill-787
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/9yt70gy0
{'eval_loss': 0.17471040785312653, 'eval_precision': 0.8140703517587939, 'eval_recall': 0.8481675392670157, 'eval_f1': 0.8307692307692307, 'eval_accuracy': 0.9765455531453362, 'eval_runtime': 1.0159, 'eval_samples_per_second': 152.58, 'eval_steps_per_second': 4.922, 'epoch': 9.0}
{'train_runtime': 575.6948, 'train_samples_per_second': 19.354, 'train_steps_per_second': 0.61, 'train_loss': 0.14740271717734485, 'epoch': 9.0}
  0%|          | 0/312 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/312 [00:01<07:58,  1.54s/it]  1%|          | 2/312 [00:02<07:38,  1.48s/it]  1%|          | 3/312 [00:04<07:28,  1.45s/it]  1%|▏         | 4/312 [00:05<07:24,  1.44s/it]  2%|▏         | 5/312 [00:07<07:29,  1.46s/it]  2%|▏         | 6/312 [00:08<07:22,  1.45s/it]  2%|▏         | 7/312 [00:10<07:18,  1.44s/it]  3%|▎         | 8/312 [00:11<07:14,  1.43s/it]  3%|▎         | 9/312 [00:12<07:12,  1.43s/it]  3%|▎         | 10/312 [00:14<07:17,  1.45s/it]  4%|▎         | 11/312 [00:15<07:12,  1.44s/it]  4%|▍         | 12/312 [00:17<07:09,  1.43s/it]  4%|▍         | 13/312 [00:18<07:07,  1.43s/it]  4%|▍         | 14/312 [00:20<07:04,  1.43s/it]  5%|▍         | 15/312 [00:21<07:10,  1.45s/it]  5%|▌         | 16/312 [00:23<07:10,  1.45s/it]  5%|▌         | 17/312 [00:24<07:06,  1.45s/it]  6%|▌         | 18/312 [00:25<07:03,  1.44s/it]  6%|▌         | 19/312 [00:27<06:59,  1.43s/it]  6%|▋         | 20/312 [00:28<07:02,  1.45s/it]  7%|▋         | 21/312 [00:30<06:58,  1.44s/it]  7%|▋         | 22/312 [00:31<06:55,  1.43s/it]  7%|▋         | 23/312 [00:33<06:52,  1.43s/it]  8%|▊         | 24/312 [00:34<06:50,  1.43s/it]  8%|▊         | 25/312 [00:36<06:54,  1.44s/it]  8%|▊         | 26/312 [00:37<06:50,  1.44s/it]  9%|▊         | 27/312 [00:38<06:47,  1.43s/it]  9%|▉         | 28/312 [00:40<06:44,  1.43s/it]  9%|▉         | 29/312 [00:41<06:43,  1.43s/it] 10%|▉         | 30/312 [00:43<06:47,  1.44s/it] 10%|▉         | 31/312 [00:44<06:43,  1.44s/it] 10%|█         | 32/312 [00:46<06:39,  1.43s/it] 11%|█         | 33/312 [00:47<06:37,  1.42s/it] 11%|█         | 34/312 [00:48<06:34,  1.42s/it] 11%|█         | 35/312 [00:50<06:37,  1.44s/it] 12%|█▏        | 36/312 [00:51<06:34,  1.43s/it] 12%|█▏        | 37/312 [00:53<06:32,  1.43s/it] 12%|█▏        | 38/312 [00:54<06:30,  1.42s/it] 12%|█▎        | 39/312 [00:55<05:59,  1.32s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00,  8.12it/s][A
 60%|██████    | 3/5 [00:00<00:00,  6.83it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.31it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.14it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 12%|█▎        | 39/312 [00:56<05:59,  1.32s/it]
100%|██████████| 5/5 [00:00<00:00,  6.14it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 13%|█▎        | 40/312 [01:05<17:08,  3.78s/it] 13%|█▎        | 41/312 [01:06<13:52,  3.07s/it] 13%|█▎        | 42/312 [01:08<11:34,  2.57s/it] 14%|█▍        | 43/312 [01:09<09:57,  2.22s/it] 14%|█▍        | 44/312 [01:10<08:55,  2.00s/it] 14%|█▍        | 45/312 [01:12<08:06,  1.82s/it] 15%|█▍        | 46/312 [01:13<07:32,  1.70s/it] 15%|█▌        | 47/312 [01:15<07:07,  1.61s/it] 15%|█▌        | 48/312 [01:16<06:54,  1.57s/it] 16%|█▌        | 49/312 [01:18<06:40,  1.52s/it] 16%|█▌        | 50/312 [01:19<06:30,  1.49s/it] 16%|█▋        | 51/312 [01:20<06:23,  1.47s/it] 17%|█▋        | 52/312 [01:22<06:17,  1.45s/it] 17%|█▋        | 53/312 [01:23<06:17,  1.46s/it] 17%|█▋        | 54/312 [01:25<06:12,  1.44s/it] 18%|█▊        | 55/312 [01:26<06:08,  1.43s/it] 18%|█▊        | 56/312 [01:27<06:05,  1.43s/it] 18%|█▊        | 57/312 [01:29<06:03,  1.42s/it] 19%|█▊        | 58/312 [01:30<06:06,  1.44s/it] 19%|█▉        | 59/312 [01:32<06:02,  1.43s/it] 19%|█▉        | 60/312 [01:33<06:00,  1.43s/it] 20%|█▉        | 61/312 [01:35<05:58,  1.43s/it] 20%|█▉        | 62/312 [01:36<05:56,  1.42s/it] 20%|██        | 63/312 [01:38<05:58,  1.44s/it] 21%|██        | 64/312 [01:39<05:54,  1.43s/it] 21%|██        | 65/312 [01:40<05:51,  1.42s/it] 21%|██        | 66/312 [01:42<05:48,  1.42s/it] 21%|██▏       | 67/312 [01:43<05:47,  1.42s/it] 22%|██▏       | 68/312 [01:45<05:56,  1.46s/it] 22%|██▏       | 69/312 [01:46<05:52,  1.45s/it] 22%|██▏       | 70/312 [01:48<05:47,  1.44s/it] 23%|██▎       | 71/312 [01:49<05:45,  1.43s/it] 23%|██▎       | 72/312 [01:50<05:42,  1.43s/it] 23%|██▎       | 73/312 [01:52<05:45,  1.45s/it] 24%|██▎       | 74/312 [01:53<05:42,  1.44s/it] 24%|██▍       | 75/312 [01:55<05:38,  1.43s/it] 24%|██▍       | 76/312 [01:56<05:36,  1.43s/it] 25%|██▍       | 77/312 [01:58<05:33,  1.42s/it] 25%|██▌       | 78/312 [01:59<05:11,  1.33s/it]{'eval_loss': 0.2593451738357544, 'eval_precision': 0.4383561643835616, 'eval_recall': 0.2513089005235602, 'eval_f1': 0.3194675540765391, 'eval_accuracy': 0.9358731019522777, 'eval_runtime': 1.1054, 'eval_samples_per_second': 140.223, 'eval_steps_per_second': 4.523, 'epoch': 1.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.65it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.32it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.89it/s][A                                                
                                             [A 25%|██▌       | 78/312 [02:00<05:11,  1.33s/it]
100%|██████████| 5/5 [00:00<00:00,  6.89it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 25%|██▌       | 79/312 [02:09<15:26,  3.98s/it] 26%|██▌       | 80/312 [02:10<12:25,  3.21s/it] 26%|██▌       | 81/312 [02:12<10:17,  2.68s/it] 26%|██▋       | 82/312 [02:13<08:54,  2.33s/it] 27%|██▋       | 83/312 [02:15<07:50,  2.05s/it] 27%|██▋       | 84/312 [02:16<07:05,  1.86s/it] 27%|██▋       | 85/312 [02:17<06:32,  1.73s/it] 28%|██▊       | 86/312 [02:19<06:09,  1.63s/it] 28%|██▊       | 87/312 [02:20<05:56,  1.58s/it] 28%|██▊       | 88/312 [02:22<05:43,  1.53s/it] 29%|██▊       | 89/312 [02:23<05:34,  1.50s/it] 29%|██▉       | 90/312 [02:25<05:27,  1.47s/it] 29%|██▉       | 91/312 [02:26<05:22,  1.46s/it] 29%|██▉       | 92/312 [02:27<05:22,  1.46s/it] 30%|██▉       | 93/312 [02:29<05:17,  1.45s/it] 30%|███       | 94/312 [02:30<05:14,  1.44s/it] 30%|███       | 95/312 [02:32<05:11,  1.43s/it] 31%|███       | 96/312 [02:33<05:08,  1.43s/it] 31%|███       | 97/312 [02:35<05:10,  1.44s/it] 31%|███▏      | 98/312 [02:36<05:07,  1.44s/it] 32%|███▏      | 99/312 [02:37<05:04,  1.43s/it] 32%|███▏      | 100/312 [02:39<05:03,  1.43s/it] 32%|███▏      | 101/312 [02:40<05:00,  1.43s/it] 33%|███▎      | 102/312 [02:42<05:03,  1.44s/it] 33%|███▎      | 103/312 [02:43<05:00,  1.44s/it] 33%|███▎      | 104/312 [02:45<04:58,  1.43s/it] 34%|███▎      | 105/312 [02:46<04:55,  1.43s/it] 34%|███▍      | 106/312 [02:47<04:53,  1.42s/it] 34%|███▍      | 107/312 [02:49<04:56,  1.44s/it] 35%|███▍      | 108/312 [02:50<04:53,  1.44s/it] 35%|███▍      | 109/312 [02:52<04:50,  1.43s/it] 35%|███▌      | 110/312 [02:53<04:47,  1.42s/it] 36%|███▌      | 111/312 [02:55<04:45,  1.42s/it] 36%|███▌      | 112/312 [02:56<04:46,  1.43s/it] 36%|███▌      | 113/312 [02:57<04:44,  1.43s/it] 37%|███▋      | 114/312 [02:59<04:41,  1.42s/it] 37%|███▋      | 115/312 [03:00<04:40,  1.42s/it] 37%|███▋      | 116/312 [03:02<04:41,  1.44s/it] 38%|███▊      | 117/312 [03:03<04:18,  1.32s/it]{'eval_loss': 0.12963972985744476, 'eval_precision': 0.6494117647058824, 'eval_recall': 0.7225130890052356, 'eval_f1': 0.6840148698884758, 'eval_accuracy': 0.9675976138828634, 'eval_runtime': 1.0128, 'eval_samples_per_second': 153.04, 'eval_steps_per_second': 4.937, 'epoch': 2.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.54it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.29it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A                                                 
                                             [A 38%|███▊      | 117/312 [03:04<04:18,  1.32s/it]
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 38%|███▊      | 118/312 [03:13<12:42,  3.93s/it] 38%|███▊      | 119/312 [03:14<10:14,  3.18s/it] 38%|███▊      | 120/312 [03:16<08:30,  2.66s/it] 39%|███▉      | 121/312 [03:17<07:19,  2.30s/it] 39%|███▉      | 122/312 [03:19<06:26,  2.04s/it] 39%|███▉      | 123/312 [03:20<05:49,  1.85s/it] 40%|███▉      | 124/312 [03:21<05:23,  1.72s/it] 40%|████      | 125/312 [03:23<05:04,  1.63s/it] 40%|████      | 126/312 [03:24<04:55,  1.59s/it] 41%|████      | 127/312 [03:26<04:43,  1.53s/it] 41%|████      | 128/312 [03:27<04:35,  1.49s/it] 41%|████▏     | 129/312 [03:29<04:28,  1.47s/it] 42%|████▏     | 130/312 [03:30<04:26,  1.47s/it] 42%|████▏     | 131/312 [03:31<04:22,  1.45s/it] 42%|████▏     | 132/312 [03:33<04:18,  1.44s/it] 43%|████▎     | 133/312 [03:34<04:15,  1.43s/it] 43%|████▎     | 134/312 [03:36<04:13,  1.42s/it] 43%|████▎     | 135/312 [03:37<04:14,  1.44s/it] 44%|████▎     | 136/312 [03:39<04:11,  1.43s/it] 44%|████▍     | 137/312 [03:40<04:09,  1.42s/it] 44%|████▍     | 138/312 [03:41<04:06,  1.42s/it] 45%|████▍     | 139/312 [03:43<04:04,  1.42s/it] 45%|████▍     | 140/312 [03:44<04:06,  1.43s/it] 45%|████▌     | 141/312 [03:46<04:03,  1.43s/it] 46%|████▌     | 142/312 [03:47<04:01,  1.42s/it] 46%|████▌     | 143/312 [03:48<04:00,  1.42s/it] 46%|████▌     | 144/312 [03:50<03:59,  1.43s/it] 46%|████▋     | 145/312 [03:51<04:00,  1.44s/it] 47%|████▋     | 146/312 [03:53<03:57,  1.43s/it] 47%|████▋     | 147/312 [03:54<03:54,  1.42s/it] 47%|████▋     | 148/312 [03:56<03:52,  1.42s/it] 48%|████▊     | 149/312 [03:57<03:50,  1.42s/it] 48%|████▊     | 150/312 [03:59<03:52,  1.44s/it] 48%|████▊     | 151/312 [04:00<03:49,  1.43s/it] 49%|████▊     | 152/312 [04:01<03:47,  1.42s/it] 49%|████▉     | 153/312 [04:03<03:45,  1.42s/it] 49%|████▉     | 154/312 [04:04<03:43,  1.41s/it] 50%|████▉     | 155/312 [04:06<03:43,  1.43s/it] 50%|█████     | 156/312 [04:07<03:24,  1.31s/it]{'eval_loss': 0.12087096273899078, 'eval_precision': 0.6956521739130435, 'eval_recall': 0.7958115183246073, 'eval_f1': 0.7423687423687424, 'eval_accuracy': 0.9709869848156182, 'eval_runtime': 1.0189, 'eval_samples_per_second': 152.122, 'eval_steps_per_second': 4.907, 'epoch': 3.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.60it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.79it/s][A                                                 
                                             [A 50%|█████     | 156/312 [04:08<03:24,  1.31s/it]
100%|██████████| 5/5 [00:00<00:00,  6.79it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 50%|█████     | 157/312 [04:16<09:45,  3.78s/it] 51%|█████     | 158/312 [04:18<07:51,  3.06s/it] 51%|█████     | 159/312 [04:19<06:35,  2.59s/it] 51%|█████▏    | 160/312 [04:20<05:39,  2.23s/it] 52%|█████▏    | 161/312 [04:22<04:59,  1.98s/it] 52%|█████▏    | 162/312 [04:23<04:32,  1.82s/it] 52%|█████▏    | 163/312 [04:25<04:12,  1.70s/it] 53%|█████▎    | 164/312 [04:26<04:01,  1.63s/it] 53%|█████▎    | 165/312 [04:28<03:49,  1.56s/it] 53%|█████▎    | 166/312 [04:29<03:41,  1.52s/it] 54%|█████▎    | 167/312 [04:30<03:35,  1.49s/it] 54%|█████▍    | 168/312 [04:32<03:30,  1.46s/it] 54%|█████▍    | 169/312 [04:33<03:29,  1.46s/it] 54%|█████▍    | 170/312 [04:35<03:25,  1.45s/it] 55%|█████▍    | 171/312 [04:36<03:22,  1.44s/it] 55%|█████▌    | 172/312 [04:38<03:19,  1.43s/it] 55%|█████▌    | 173/312 [04:39<03:17,  1.42s/it] 56%|█████▌    | 174/312 [04:40<03:18,  1.44s/it] 56%|█████▌    | 175/312 [04:42<03:15,  1.43s/it] 56%|█████▋    | 176/312 [04:43<03:13,  1.42s/it] 57%|█████▋    | 177/312 [04:45<03:11,  1.42s/it] 57%|█████▋    | 178/312 [04:46<03:10,  1.42s/it] 57%|█████▋    | 179/312 [04:48<03:10,  1.43s/it] 58%|█████▊    | 180/312 [04:49<03:08,  1.43s/it] 58%|█████▊    | 181/312 [04:50<03:05,  1.42s/it] 58%|█████▊    | 182/312 [04:52<03:03,  1.41s/it] 59%|█████▊    | 183/312 [04:53<03:02,  1.41s/it] 59%|█████▉    | 184/312 [04:55<03:03,  1.43s/it] 59%|█████▉    | 185/312 [04:56<03:00,  1.42s/it] 60%|█████▉    | 186/312 [04:57<02:58,  1.42s/it] 60%|█████▉    | 187/312 [04:59<02:57,  1.42s/it] 60%|██████    | 188/312 [05:00<02:55,  1.42s/it] 61%|██████    | 189/312 [05:02<02:55,  1.43s/it] 61%|██████    | 190/312 [05:03<02:53,  1.42s/it] 61%|██████    | 191/312 [05:05<02:51,  1.42s/it] 62%|██████▏   | 192/312 [05:06<02:49,  1.41s/it] 62%|██████▏   | 193/312 [05:07<02:50,  1.43s/it] 62%|██████▏   | 194/312 [05:09<02:48,  1.43s/it] 62%|██████▎   | 195/312 [05:10<02:33,  1.31s/it]{'eval_loss': 0.1180981770157814, 'eval_precision': 0.7667493796526055, 'eval_recall': 0.8089005235602095, 'eval_f1': 0.7872611464968153, 'eval_accuracy': 0.9743763557483731, 'eval_runtime': 1.0192, 'eval_samples_per_second': 152.076, 'eval_steps_per_second': 4.906, 'epoch': 4.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.30it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.25it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.85it/s][A                                                 
                                             [A 62%|██████▎   | 195/312 [05:11<02:33,  1.31s/it]
100%|██████████| 5/5 [00:00<00:00,  6.85it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 63%|██████▎   | 196/312 [05:19<07:03,  3.65s/it] 63%|██████▎   | 197/312 [05:20<05:42,  2.98s/it] 63%|██████▎   | 198/312 [05:22<04:48,  2.53s/it] 64%|██████▍   | 199/312 [05:23<04:08,  2.20s/it] 64%|██████▍   | 200/312 [05:25<03:39,  1.96s/it] 64%|██████▍   | 201/312 [05:26<03:19,  1.80s/it] 65%|██████▍   | 202/312 [05:28<03:04,  1.68s/it] 65%|██████▌   | 203/312 [05:29<02:56,  1.62s/it] 65%|██████▌   | 204/312 [05:30<02:48,  1.56s/it] 66%|██████▌   | 205/312 [05:32<02:41,  1.51s/it] 66%|██████▌   | 206/312 [05:33<02:38,  1.49s/it] 66%|██████▋   | 207/312 [05:35<02:37,  1.50s/it] 67%|██████▋   | 208/312 [05:36<02:33,  1.48s/it] 67%|██████▋   | 209/312 [05:38<02:31,  1.47s/it] 67%|██████▋   | 210/312 [05:39<02:28,  1.45s/it] 68%|██████▊   | 211/312 [05:40<02:25,  1.44s/it] 68%|██████▊   | 212/312 [05:42<02:25,  1.45s/it] 68%|██████▊   | 213/312 [05:43<02:22,  1.44s/it] 69%|██████▊   | 214/312 [05:45<02:20,  1.43s/it] 69%|██████▉   | 215/312 [05:46<02:18,  1.43s/it] 69%|██████▉   | 216/312 [05:48<02:16,  1.42s/it] 70%|██████▉   | 217/312 [05:49<02:16,  1.44s/it] 70%|██████▉   | 218/312 [05:50<02:14,  1.43s/it] 70%|███████   | 219/312 [05:52<02:12,  1.42s/it] 71%|███████   | 220/312 [05:53<02:10,  1.42s/it] 71%|███████   | 221/312 [05:55<02:08,  1.42s/it] 71%|███████   | 222/312 [05:56<02:08,  1.43s/it] 71%|███████▏  | 223/312 [05:58<02:06,  1.42s/it] 72%|███████▏  | 224/312 [05:59<02:05,  1.42s/it] 72%|███████▏  | 225/312 [06:00<02:03,  1.42s/it] 72%|███████▏  | 226/312 [06:02<02:02,  1.42s/it] 73%|███████▎  | 227/312 [06:03<02:01,  1.43s/it] 73%|███████▎  | 228/312 [06:05<01:59,  1.43s/it] 73%|███████▎  | 229/312 [06:06<01:58,  1.42s/it] 74%|███████▎  | 230/312 [06:08<01:56,  1.42s/it] 74%|███████▍  | 231/312 [06:09<01:54,  1.42s/it] 74%|███████▍  | 232/312 [06:10<01:54,  1.43s/it] 75%|███████▍  | 233/312 [06:12<01:53,  1.44s/it] 75%|███████▌  | 234/312 [06:13<01:43,  1.33s/it]{'eval_loss': 0.10709802061319351, 'eval_precision': 0.8062015503875969, 'eval_recall': 0.8167539267015707, 'eval_f1': 0.8114434330299091, 'eval_accuracy': 0.977087852494577, 'eval_runtime': 1.0185, 'eval_samples_per_second': 152.185, 'eval_steps_per_second': 4.909, 'epoch': 5.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.53it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.85it/s][A                                                 
                                             [A 75%|███████▌  | 234/312 [06:14<01:43,  1.33s/it]
100%|██████████| 5/5 [00:00<00:00,  6.85it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 75%|███████▌  | 235/312 [06:22<04:33,  3.56s/it] 76%|███████▌  | 236/312 [06:23<03:42,  2.93s/it] 76%|███████▌  | 237/312 [06:25<03:05,  2.47s/it] 76%|███████▋  | 238/312 [06:26<02:39,  2.16s/it] 77%|███████▋  | 239/312 [06:27<02:21,  1.93s/it] 77%|███████▋  | 240/312 [06:29<02:07,  1.78s/it] 77%|███████▋  | 241/312 [06:30<01:59,  1.68s/it] 78%|███████▊  | 242/312 [06:32<01:52,  1.61s/it] 78%|███████▊  | 243/312 [06:33<01:46,  1.55s/it] 78%|███████▊  | 244/312 [06:35<01:42,  1.51s/it] 79%|███████▊  | 245/312 [06:36<01:39,  1.48s/it] 79%|███████▉  | 246/312 [06:37<01:37,  1.48s/it] 79%|███████▉  | 247/312 [06:39<01:34,  1.46s/it] 79%|███████▉  | 248/312 [06:40<01:32,  1.45s/it] 80%|███████▉  | 249/312 [06:42<01:30,  1.44s/it] 80%|████████  | 250/312 [06:43<01:29,  1.44s/it] 80%|████████  | 251/312 [06:45<01:28,  1.45s/it] 81%|████████  | 252/312 [06:46<01:26,  1.44s/it] 81%|████████  | 253/312 [06:47<01:24,  1.44s/it] 81%|████████▏ | 254/312 [06:49<01:23,  1.43s/it] 82%|████████▏ | 255/312 [06:50<01:21,  1.43s/it] 82%|████████▏ | 256/312 [06:52<01:20,  1.44s/it] 82%|████████▏ | 257/312 [06:53<01:19,  1.44s/it] 83%|████████▎ | 258/312 [06:55<01:17,  1.43s/it] 83%|████████▎ | 259/312 [06:56<01:15,  1.43s/it] 83%|████████▎ | 260/312 [06:57<01:14,  1.42s/it] 84%|████████▎ | 261/312 [06:59<01:13,  1.44s/it] 84%|████████▍ | 262/312 [07:00<01:11,  1.43s/it] 84%|████████▍ | 263/312 [07:02<01:09,  1.43s/it] 85%|████████▍ | 264/312 [07:03<01:08,  1.43s/it] 85%|████████▍ | 265/312 [07:05<01:06,  1.43s/it] 85%|████████▌ | 266/312 [07:06<01:06,  1.44s/it] 86%|████████▌ | 267/312 [07:07<01:04,  1.44s/it] 86%|████████▌ | 268/312 [07:09<01:03,  1.44s/it] 86%|████████▌ | 269/312 [07:10<01:01,  1.44s/it] 87%|████████▋ | 270/312 [07:12<01:00,  1.45s/it] 87%|████████▋ | 271/312 [07:13<00:59,  1.44s/it] 87%|████████▋ | 272/312 [07:15<00:57,  1.44s/it] 88%|████████▊ | 273/312 [07:16<00:51,  1.33s/it]{'eval_loss': 0.12134000658988953, 'eval_precision': 0.8020565552699229, 'eval_recall': 0.8167539267015707, 'eval_f1': 0.8093385214007781, 'eval_accuracy': 0.9787147505422994, 'eval_runtime': 1.022, 'eval_samples_per_second': 151.668, 'eval_steps_per_second': 4.893, 'epoch': 6.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.53it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.26it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A                                                 
                                             [A 88%|████████▊ | 273/312 [07:17<00:51,  1.33s/it]
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 88%|████████▊ | 274/312 [07:24<02:13,  3.51s/it] 88%|████████▊ | 275/312 [07:26<01:48,  2.92s/it] 88%|████████▊ | 276/312 [07:27<01:28,  2.47s/it] 89%|████████▉ | 277/312 [07:29<01:15,  2.15s/it] 89%|████████▉ | 278/312 [07:30<01:05,  1.93s/it] 89%|████████▉ | 279/312 [07:32<00:58,  1.78s/it] 90%|████████▉ | 280/312 [07:33<00:54,  1.71s/it] 90%|█████████ | 281/312 [07:35<00:50,  1.62s/it] 90%|█████████ | 282/312 [07:36<00:46,  1.56s/it] 91%|█████████ | 283/312 [07:37<00:44,  1.52s/it] 91%|█████████ | 284/312 [07:39<00:42,  1.53s/it] 91%|█████████▏| 285/312 [07:40<00:40,  1.50s/it] 92%|█████████▏| 286/312 [07:42<00:38,  1.48s/it] 92%|█████████▏| 287/312 [07:43<00:36,  1.46s/it] 92%|█████████▏| 288/312 [07:45<00:34,  1.45s/it] 93%|█████████▎| 289/312 [07:46<00:34,  1.48s/it] 93%|█████████▎| 290/312 [07:48<00:32,  1.47s/it] 93%|█████████▎| 291/312 [07:49<00:30,  1.45s/it] 94%|█████████▎| 292/312 [07:50<00:28,  1.44s/it] 94%|█████████▍| 293/312 [07:52<00:27,  1.44s/it] 94%|█████████▍| 294/312 [07:53<00:26,  1.47s/it] 95%|█████████▍| 295/312 [07:55<00:24,  1.46s/it] 95%|█████████▍| 296/312 [07:56<00:23,  1.45s/it] 95%|█████████▌| 297/312 [07:58<00:21,  1.44s/it] 96%|█████████▌| 298/312 [07:59<00:20,  1.43s/it] 96%|█████████▌| 299/312 [08:01<00:19,  1.47s/it] 96%|█████████▌| 300/312 [08:02<00:17,  1.46s/it] 96%|█████████▋| 301/312 [08:04<00:15,  1.45s/it] 97%|█████████▋| 302/312 [08:05<00:14,  1.45s/it] 97%|█████████▋| 303/312 [08:06<00:12,  1.44s/it] 97%|█████████▋| 304/312 [08:08<00:11,  1.47s/it] 98%|█████████▊| 305/312 [08:09<00:10,  1.46s/it] 98%|█████████▊| 306/312 [08:11<00:08,  1.45s/it] 98%|█████████▊| 307/312 [08:12<00:07,  1.44s/it] 99%|█████████▊| 308/312 [08:14<00:05,  1.44s/it] 99%|█████████▉| 309/312 [08:15<00:04,  1.47s/it] 99%|█████████▉| 310/312 [08:17<00:02,  1.46s/it]100%|█████████▉| 311/312 [08:18<00:01,  1.45s/it]100%|██████████| 312/312 [08:19<00:00,  1.33s/it]{'eval_loss': 0.1302245706319809, 'eval_precision': 0.7692307692307693, 'eval_recall': 0.837696335078534, 'eval_f1': 0.8020050125313284, 'eval_accuracy': 0.9751898047722343, 'eval_runtime': 1.0168, 'eval_samples_per_second': 152.432, 'eval_steps_per_second': 4.917, 'epoch': 7.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.44it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.27it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.80it/s][A                                                 
                                             [A100%|██████████| 312/312 [08:20<00:00,  1.33s/it]
100%|██████████| 5/5 [00:00<00:00,  6.80it/s][A
                                             [A100%|██████████| 312/312 [08:20<00:00,  1.60s/it]
[I 2025-09-20 14:29:05,200] Trial 10 pruned. 
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▆▇▇██▇█
wandb:                 eval/f1 ▁▆▇█████
wandb:               eval/loss █▂▂▂▁▂▂▂
wandb:          eval/precision ▁▅▆▇██▇█
wandb:             eval/recall ▁▇██████
wandb:            eval/runtime █▁▁▁▁▂▁▂
wandb: eval/samples_per_second ▁█▇▇█▇█▇
wandb:   eval/steps_per_second ▁█▇▇█▇█▇
wandb:             train/epoch ▁▂▃▄▅▆▇█
wandb:       train/global_step ▁▂▃▄▅▆▇█
wandb: 
wandb: Run summary:
wandb:           eval/accuracy 0.97749
wandb:                 eval/f1 0.81395
wandb:               eval/loss 0.13131
wandb:          eval/precision 0.80357
wandb:             eval/recall 0.82461
wandb:            eval/runtime 1.0213
wandb: eval/samples_per_second 151.775
wandb:   eval/steps_per_second 4.896
wandb:             train/epoch 8
wandb:       train/global_step 312
wandb: 
wandb: 🚀 View run fragrant-hill-787 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/9yt70gy0
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250920_142043-9yt70gy0/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_142908-l37qmcdu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-dew-788
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/l37qmcdu
{'eval_loss': 0.13131286203861237, 'eval_precision': 0.8035714285714286, 'eval_recall': 0.824607329842932, 'eval_f1': 0.8139534883720931, 'eval_accuracy': 0.9774945770065075, 'eval_runtime': 1.0213, 'eval_samples_per_second': 151.775, 'eval_steps_per_second': 4.896, 'epoch': 8.0}
  0%|          | 0/380 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/380 [00:01<09:29,  1.50s/it]  1%|          | 2/380 [00:02<09:23,  1.49s/it]  1%|          | 3/380 [00:04<09:17,  1.48s/it]  1%|          | 4/380 [00:05<09:14,  1.47s/it]  1%|▏         | 5/380 [00:07<09:30,  1.52s/it]  2%|▏         | 6/380 [00:08<09:21,  1.50s/it]  2%|▏         | 7/380 [00:10<09:15,  1.49s/it]  2%|▏         | 8/380 [00:11<09:11,  1.48s/it]  2%|▏         | 9/380 [00:13<09:07,  1.48s/it]  3%|▎         | 10/380 [00:14<09:18,  1.51s/it]  3%|▎         | 11/380 [00:16<09:11,  1.50s/it]  3%|▎         | 12/380 [00:17<09:07,  1.49s/it]  3%|▎         | 13/380 [00:19<09:03,  1.48s/it]  4%|▎         | 14/380 [00:20<09:00,  1.48s/it]  4%|▍         | 15/380 [00:22<09:11,  1.51s/it]  4%|▍         | 16/380 [00:23<09:04,  1.50s/it]  4%|▍         | 17/380 [00:25<09:00,  1.49s/it]  5%|▍         | 18/380 [00:26<08:56,  1.48s/it]  5%|▌         | 19/380 [00:28<08:53,  1.48s/it]  5%|▌         | 20/380 [00:29<07:36,  1.27s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00,  7.25it/s][A
 60%|██████    | 3/5 [00:00<00:00,  6.55it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.24it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.14it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A  5%|▌         | 20/380 [00:30<07:36,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.14it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  6%|▌         | 21/380 [00:37<20:19,  3.40s/it]  6%|▌         | 22/380 [00:38<16:50,  2.82s/it]  6%|▌         | 23/380 [00:40<14:22,  2.42s/it]  6%|▋         | 24/380 [00:41<12:46,  2.15s/it]  7%|▋         | 25/380 [00:43<11:31,  1.95s/it]  7%|▋         | 26/380 [00:44<10:41,  1.81s/it]  7%|▋         | 27/380 [00:46<10:05,  1.71s/it]  7%|▋         | 28/380 [00:47<09:38,  1.64s/it]  8%|▊         | 29/380 [00:49<09:24,  1.61s/it]  8%|▊         | 30/380 [00:50<09:08,  1.57s/it]  8%|▊         | 31/380 [00:52<08:57,  1.54s/it]  8%|▊         | 32/380 [00:53<08:50,  1.52s/it]  9%|▊         | 33/380 [00:55<08:44,  1.51s/it]  9%|▉         | 34/380 [00:56<08:46,  1.52s/it]  9%|▉         | 35/380 [00:58<08:41,  1.51s/it]  9%|▉         | 36/380 [00:59<08:37,  1.50s/it] 10%|▉         | 37/380 [01:01<08:32,  1.50s/it] 10%|█         | 38/380 [01:02<08:29,  1.49s/it] 10%|█         | 39/380 [01:04<08:33,  1.51s/it] 11%|█         | 40/380 [01:05<07:12,  1.27s/it]{'eval_loss': 0.2972061336040497, 'eval_precision': 0.559322033898305, 'eval_recall': 0.17277486910994763, 'eval_f1': 0.26399999999999996, 'eval_accuracy': 0.936822125813449, 'eval_runtime': 1.1207, 'eval_samples_per_second': 138.304, 'eval_steps_per_second': 4.461, 'epoch': 1.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.61it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A                                                
                                             [A 11%|█         | 40/380 [01:06<07:12,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 11%|█         | 41/380 [01:13<19:47,  3.50s/it] 11%|█         | 42/380 [01:15<16:17,  2.89s/it] 11%|█▏        | 43/380 [01:16<13:56,  2.48s/it] 12%|█▏        | 44/380 [01:18<12:11,  2.18s/it] 12%|█▏        | 45/380 [01:19<10:58,  1.97s/it] 12%|█▏        | 46/380 [01:21<10:06,  1.82s/it] 12%|█▏        | 47/380 [01:22<09:30,  1.71s/it] 13%|█▎        | 48/380 [01:24<09:11,  1.66s/it] 13%|█▎        | 49/380 [01:25<08:50,  1.60s/it] 13%|█▎        | 50/380 [01:27<08:35,  1.56s/it] 13%|█▎        | 51/380 [01:28<08:24,  1.53s/it] 14%|█▎        | 52/380 [01:30<08:16,  1.51s/it] 14%|█▍        | 53/380 [01:31<08:16,  1.52s/it] 14%|█▍        | 54/380 [01:33<08:09,  1.50s/it] 14%|█▍        | 55/380 [01:34<08:04,  1.49s/it] 15%|█▍        | 56/380 [01:35<08:00,  1.48s/it] 15%|█▌        | 57/380 [01:37<07:57,  1.48s/it] 15%|█▌        | 58/380 [01:38<08:01,  1.50s/it] 16%|█▌        | 59/380 [01:40<07:56,  1.49s/it] 16%|█▌        | 60/380 [01:41<06:42,  1.26s/it]{'eval_loss': 0.14267078042030334, 'eval_precision': 0.5892857142857143, 'eval_recall': 0.6047120418848168, 'eval_f1': 0.5968992248062015, 'eval_accuracy': 0.9609544468546638, 'eval_runtime': 1.0159, 'eval_samples_per_second': 152.569, 'eval_steps_per_second': 4.922, 'epoch': 2.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.54it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.33it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.92it/s][A                                                
                                             [A 16%|█▌        | 60/380 [01:42<06:42,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.92it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 16%|█▌        | 61/380 [01:50<19:31,  3.67s/it] 16%|█▋        | 62/380 [01:51<16:03,  3.03s/it] 17%|█▋        | 63/380 [01:53<13:32,  2.56s/it] 17%|█▋        | 64/380 [01:54<11:46,  2.24s/it] 17%|█▋        | 65/380 [01:56<10:32,  2.01s/it] 17%|█▋        | 66/380 [01:57<09:40,  1.85s/it] 18%|█▊        | 67/380 [01:59<09:07,  1.75s/it] 18%|█▊        | 68/380 [02:00<08:40,  1.67s/it] 18%|█▊        | 69/380 [02:02<08:21,  1.61s/it] 18%|█▊        | 70/380 [02:03<08:06,  1.57s/it] 19%|█▊        | 71/380 [02:05<07:55,  1.54s/it] 19%|█▉        | 72/380 [02:06<07:52,  1.53s/it] 19%|█▉        | 73/380 [02:08<07:44,  1.51s/it] 19%|█▉        | 74/380 [02:09<07:38,  1.50s/it] 20%|█▉        | 75/380 [02:11<07:34,  1.49s/it] 20%|██        | 76/380 [02:12<07:31,  1.48s/it] 20%|██        | 77/380 [02:14<07:43,  1.53s/it] 21%|██        | 78/380 [02:15<07:36,  1.51s/it] 21%|██        | 79/380 [02:17<07:31,  1.50s/it] 21%|██        | 80/380 [02:17<06:20,  1.27s/it]{'eval_loss': 0.12433065474033356, 'eval_precision': 0.6222222222222222, 'eval_recall': 0.7329842931937173, 'eval_f1': 0.673076923076923, 'eval_accuracy': 0.9632592190889371, 'eval_runtime': 1.0114, 'eval_samples_per_second': 153.247, 'eval_steps_per_second': 4.943, 'epoch': 3.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.16it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.19it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.74it/s][A                                                
                                             [A 21%|██        | 80/380 [02:19<06:20,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.74it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 21%|██▏       | 81/380 [02:27<18:40,  3.75s/it] 22%|██▏       | 82/380 [02:28<15:13,  3.07s/it] 22%|██▏       | 83/380 [02:30<12:48,  2.59s/it] 22%|██▏       | 84/380 [02:31<11:06,  2.25s/it] 22%|██▏       | 85/380 [02:33<09:56,  2.02s/it] 23%|██▎       | 86/380 [02:35<09:18,  1.90s/it] 23%|██▎       | 87/380 [02:36<08:38,  1.77s/it] 23%|██▎       | 88/380 [02:37<08:11,  1.68s/it] 23%|██▎       | 89/380 [02:39<07:51,  1.62s/it] 24%|██▎       | 90/380 [02:40<07:37,  1.58s/it] 24%|██▍       | 91/380 [02:42<07:31,  1.56s/it] 24%|██▍       | 92/380 [02:43<07:22,  1.54s/it] 24%|██▍       | 93/380 [02:45<07:14,  1.52s/it] 25%|██▍       | 94/380 [02:46<07:09,  1.50s/it] 25%|██▌       | 95/380 [02:48<07:05,  1.49s/it] 25%|██▌       | 96/380 [02:49<07:06,  1.50s/it] 26%|██▌       | 97/380 [02:51<07:03,  1.50s/it] 26%|██▌       | 98/380 [02:52<06:59,  1.49s/it] 26%|██▌       | 99/380 [02:54<06:57,  1.49s/it] 26%|██▋       | 100/380 [02:55<05:52,  1.26s/it]{'eval_loss': 0.11782170087099075, 'eval_precision': 0.7172897196261683, 'eval_recall': 0.8036649214659686, 'eval_f1': 0.7580246913580247, 'eval_accuracy': 0.9703091106290672, 'eval_runtime': 1.0355, 'eval_samples_per_second': 149.693, 'eval_steps_per_second': 4.829, 'epoch': 4.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.42it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.25it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.17it/s][A                                                 
                                             [A 26%|██▋       | 100/380 [02:56<05:52,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.17it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 27%|██▋       | 101/380 [03:04<17:18,  3.72s/it] 27%|██▋       | 102/380 [03:05<14:06,  3.05s/it] 27%|██▋       | 103/380 [03:07<11:53,  2.57s/it] 27%|██▋       | 104/380 [03:08<10:19,  2.24s/it] 28%|██▊       | 105/380 [03:10<09:27,  2.07s/it] 28%|██▊       | 106/380 [03:12<08:37,  1.89s/it] 28%|██▊       | 107/380 [03:13<08:00,  1.76s/it] 28%|██▊       | 108/380 [03:14<07:35,  1.67s/it] 29%|██▊       | 109/380 [03:16<07:17,  1.61s/it] 29%|██▉       | 110/380 [03:17<07:09,  1.59s/it] 29%|██▉       | 111/380 [03:19<06:58,  1.56s/it] 29%|██▉       | 112/380 [03:20<06:50,  1.53s/it] 30%|██▉       | 113/380 [03:22<06:44,  1.51s/it] 30%|███       | 114/380 [03:23<06:39,  1.50s/it] 30%|███       | 115/380 [03:25<06:46,  1.53s/it] 31%|███       | 116/380 [03:26<06:39,  1.51s/it] 31%|███       | 117/380 [03:28<06:34,  1.50s/it] 31%|███       | 118/380 [03:29<06:30,  1.49s/it] 31%|███▏      | 119/380 [03:31<06:27,  1.48s/it] 32%|███▏      | 120/380 [03:32<05:27,  1.26s/it]{'eval_loss': 0.12430400401353836, 'eval_precision': 0.7440758293838863, 'eval_recall': 0.8219895287958116, 'eval_f1': 0.781094527363184, 'eval_accuracy': 0.9724783080260304, 'eval_runtime': 1.0734, 'eval_samples_per_second': 144.403, 'eval_steps_per_second': 4.658, 'epoch': 5.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00,  9.02it/s][A
 60%|██████    | 3/5 [00:00<00:00,  7.25it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.62it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.41it/s][A                                                 
                                             [A 32%|███▏      | 120/380 [03:33<05:27,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.41it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 32%|███▏      | 121/380 [03:41<16:01,  3.71s/it] 32%|███▏      | 122/380 [03:43<13:05,  3.04s/it] 32%|███▏      | 123/380 [03:44<11:02,  2.58s/it] 33%|███▎      | 124/380 [03:46<09:42,  2.27s/it] 33%|███▎      | 125/380 [03:47<08:39,  2.04s/it] 33%|███▎      | 126/380 [03:49<07:54,  1.87s/it] 33%|███▎      | 127/380 [03:50<07:23,  1.75s/it] 34%|███▎      | 128/380 [03:51<06:59,  1.67s/it] 34%|███▍      | 129/380 [03:53<06:49,  1.63s/it] 34%|███▍      | 130/380 [03:55<06:35,  1.58s/it] 34%|███▍      | 131/380 [03:56<06:25,  1.55s/it] 35%|███▍      | 132/380 [03:57<06:18,  1.52s/it] 35%|███▌      | 133/380 [03:59<06:12,  1.51s/it] 35%|███▌      | 134/380 [04:00<06:13,  1.52s/it] 36%|███▌      | 135/380 [04:02<06:08,  1.50s/it] 36%|███▌      | 136/380 [04:03<06:04,  1.49s/it] 36%|███▌      | 137/380 [04:05<06:01,  1.49s/it] 36%|███▋      | 138/380 [04:06<05:58,  1.48s/it] 37%|███▋      | 139/380 [04:08<06:00,  1.50s/it] 37%|███▋      | 140/380 [04:09<05:03,  1.27s/it]{'eval_loss': 0.13405729830265045, 'eval_precision': 0.7505938242280285, 'eval_recall': 0.8272251308900523, 'eval_f1': 0.7870485678704856, 'eval_accuracy': 0.97220715835141, 'eval_runtime': 1.0669, 'eval_samples_per_second': 145.276, 'eval_steps_per_second': 4.686, 'epoch': 6.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.60it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.33it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.90it/s][A                                                 
                                             [A 37%|███▋      | 140/380 [04:10<05:03,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.90it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 37%|███▋      | 141/380 [04:18<14:17,  3.59s/it] 37%|███▋      | 142/380 [04:19<11:42,  2.95s/it] 38%|███▊      | 143/380 [04:21<09:57,  2.52s/it] 38%|███▊      | 144/380 [04:22<08:40,  2.21s/it] 38%|███▊      | 145/380 [04:24<07:46,  1.98s/it] 38%|███▊      | 146/380 [04:25<07:08,  1.83s/it] 39%|███▊      | 147/380 [04:26<06:41,  1.72s/it] 39%|███▉      | 148/380 [04:28<06:25,  1.66s/it] 39%|███▉      | 149/380 [04:29<06:10,  1.61s/it] 39%|███▉      | 150/380 [04:31<06:00,  1.57s/it] 40%|███▉      | 151/380 [04:32<05:52,  1.54s/it] 40%|████      | 152/380 [04:34<05:46,  1.52s/it] 40%|████      | 153/380 [04:35<05:44,  1.52s/it] 41%|████      | 154/380 [04:37<05:40,  1.51s/it] 41%|████      | 155/380 [04:38<05:36,  1.50s/it] 41%|████      | 156/380 [04:40<05:33,  1.49s/it] 41%|████▏     | 157/380 [04:41<05:31,  1.49s/it] 42%|████▏     | 158/380 [04:43<05:32,  1.50s/it] 42%|████▏     | 159/380 [04:44<05:29,  1.49s/it] 42%|████▏     | 160/380 [04:45<04:37,  1.26s/it]{'eval_loss': 0.13653406500816345, 'eval_precision': 0.8116710875331565, 'eval_recall': 0.8010471204188482, 'eval_f1': 0.8063241106719369, 'eval_accuracy': 0.9747830802603037, 'eval_runtime': 1.0151, 'eval_samples_per_second': 152.694, 'eval_steps_per_second': 4.926, 'epoch': 7.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.56it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A                                                 
                                             [A 42%|████▏     | 160/380 [04:46<04:37,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 42%|████▏     | 161/380 [04:54<13:02,  3.57s/it] 43%|████▎     | 162/380 [04:55<10:41,  2.94s/it] 43%|████▎     | 163/380 [04:57<09:07,  2.52s/it] 43%|████▎     | 164/380 [04:58<07:56,  2.21s/it] 43%|████▎     | 165/380 [05:00<07:06,  1.98s/it] 44%|████▎     | 166/380 [05:01<06:31,  1.83s/it] 44%|████▍     | 167/380 [05:03<06:06,  1.72s/it] 44%|████▍     | 168/380 [05:04<05:52,  1.66s/it] 44%|████▍     | 169/380 [05:06<05:38,  1.61s/it] 45%|████▍     | 170/380 [05:07<05:29,  1.57s/it] 45%|████▌     | 171/380 [05:09<05:21,  1.54s/it] 45%|████▌     | 172/380 [05:10<05:15,  1.52s/it] 46%|████▌     | 173/380 [05:12<05:14,  1.52s/it] 46%|████▌     | 174/380 [05:13<05:10,  1.51s/it] 46%|████▌     | 175/380 [05:15<05:06,  1.50s/it] 46%|████▋     | 176/380 [05:16<05:03,  1.49s/it] 47%|████▋     | 177/380 [05:18<05:01,  1.48s/it] 47%|████▋     | 178/380 [05:19<05:02,  1.50s/it] 47%|████▋     | 179/380 [05:21<04:59,  1.49s/it] 47%|████▋     | 180/380 [05:21<04:12,  1.26s/it]{'eval_loss': 0.15714694559574127, 'eval_precision': 0.7434679334916865, 'eval_recall': 0.819371727748691, 'eval_f1': 0.7795765877957659, 'eval_accuracy': 0.9700379609544468, 'eval_runtime': 1.0154, 'eval_samples_per_second': 152.651, 'eval_steps_per_second': 4.924, 'epoch': 8.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.58it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.29it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A                                                 
                                             [A 47%|████▋     | 180/380 [05:22<04:12,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 48%|████▊     | 181/380 [05:31<12:22,  3.73s/it] 48%|████▊     | 182/380 [05:32<10:07,  3.07s/it] 48%|████▊     | 183/380 [05:34<08:30,  2.59s/it] 48%|████▊     | 184/380 [05:35<07:21,  2.25s/it] 49%|████▊     | 185/380 [05:37<06:32,  2.02s/it] 49%|████▉     | 186/380 [05:38<05:58,  1.85s/it] 49%|████▉     | 187/380 [05:40<05:38,  1.75s/it] 49%|████▉     | 188/380 [05:41<05:19,  1.66s/it] 50%|████▉     | 189/380 [05:43<05:06,  1.61s/it] 50%|█████     | 190/380 [05:44<04:57,  1.56s/it] 50%|█████     | 191/380 [05:46<04:49,  1.53s/it] 51%|█████     | 192/380 [05:47<04:47,  1.53s/it] 51%|█████     | 193/380 [05:49<04:42,  1.51s/it] 51%|█████     | 194/380 [05:50<04:38,  1.50s/it] 51%|█████▏    | 195/380 [05:52<04:35,  1.49s/it] 52%|█████▏    | 196/380 [05:53<04:35,  1.50s/it] 52%|█████▏    | 197/380 [05:55<04:32,  1.49s/it] 52%|█████▏    | 198/380 [05:56<04:29,  1.48s/it] 52%|█████▏    | 199/380 [05:58<04:27,  1.48s/it] 53%|█████▎    | 200/380 [05:58<03:45,  1.25s/it]{'eval_loss': 0.14503762125968933, 'eval_precision': 0.7994858611825193, 'eval_recall': 0.8141361256544503, 'eval_f1': 0.8067444876783397, 'eval_accuracy': 0.9745119305856833, 'eval_runtime': 1.0196, 'eval_samples_per_second': 152.016, 'eval_steps_per_second': 4.904, 'epoch': 9.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.64it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A                                                 
                                             [A 53%|█████▎    | 200/380 [05:59<03:45,  1.25s/it]
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 53%|█████▎    | 201/380 [06:08<11:09,  3.74s/it] 53%|█████▎    | 202/380 [06:09<09:04,  3.06s/it] 53%|█████▎    | 203/380 [06:11<07:36,  2.58s/it] 54%|█████▎    | 204/380 [06:12<06:35,  2.25s/it] 54%|█████▍    | 205/380 [06:14<05:52,  2.01s/it] 54%|█████▍    | 206/380 [06:15<05:24,  1.87s/it] 54%|█████▍    | 207/380 [06:17<05:02,  1.75s/it] 55%|█████▍    | 208/380 [06:18<04:46,  1.66s/it] 55%|█████▌    | 209/380 [06:20<04:34,  1.60s/it] 55%|█████▌    | 210/380 [06:21<04:28,  1.58s/it] 56%|█████▌    | 211/380 [06:23<04:21,  1.55s/it] 56%|█████▌    | 212/380 [06:24<04:16,  1.53s/it] 56%|█████▌    | 213/380 [06:26<04:12,  1.51s/it] 56%|█████▋    | 214/380 [06:27<04:09,  1.50s/it] 57%|█████▋    | 215/380 [06:29<04:14,  1.54s/it] 57%|█████▋    | 216/380 [06:30<04:09,  1.52s/it] 57%|█████▋    | 217/380 [06:32<04:05,  1.50s/it] 57%|█████▋    | 218/380 [06:33<04:02,  1.49s/it] 58%|█████▊    | 219/380 [06:35<03:59,  1.49s/it] 58%|█████▊    | 220/380 [06:35<03:21,  1.26s/it]{'eval_loss': 0.16199429333209991, 'eval_precision': 0.7913486005089059, 'eval_recall': 0.8141361256544503, 'eval_f1': 0.8025806451612902, 'eval_accuracy': 0.9727494577006508, 'eval_runtime': 1.0183, 'eval_samples_per_second': 152.216, 'eval_steps_per_second': 4.91, 'epoch': 10.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00,  8.68it/s][A
 60%|██████    | 3/5 [00:00<00:00,  7.08it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.55it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.34it/s][A                                                 
                                             [A 58%|█████▊    | 220/380 [06:36<03:21,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.34it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 58%|█████▊    | 221/380 [06:45<10:11,  3.85s/it] 58%|█████▊    | 222/380 [06:47<08:15,  3.13s/it] 59%|█████▊    | 223/380 [06:48<06:53,  2.63s/it] 59%|█████▉    | 224/380 [06:50<05:55,  2.28s/it] 59%|█████▉    | 225/380 [06:51<05:19,  2.06s/it] 59%|█████▉    | 226/380 [06:53<04:49,  1.88s/it] 60%|█████▉    | 227/380 [06:54<04:28,  1.75s/it] 60%|██████    | 228/380 [06:55<04:13,  1.67s/it] 60%|██████    | 229/380 [06:57<04:02,  1.61s/it] 61%|██████    | 230/380 [06:58<03:57,  1.58s/it] 61%|██████    | 231/380 [07:00<03:50,  1.55s/it] 61%|██████    | 232/380 [07:01<03:45,  1.52s/it] 61%|██████▏   | 233/380 [07:03<03:40,  1.50s/it] 62%|██████▏   | 234/380 [07:04<03:38,  1.49s/it] 62%|██████▏   | 235/380 [07:06<03:37,  1.50s/it] 62%|██████▏   | 236/380 [07:07<03:34,  1.49s/it] 62%|██████▏   | 237/380 [07:09<03:32,  1.48s/it] 63%|██████▎   | 238/380 [07:10<03:29,  1.48s/it] 63%|██████▎   | 239/380 [07:12<03:27,  1.47s/it] 63%|██████▎   | 240/380 [07:13<02:57,  1.27s/it]{'eval_loss': 0.15870991349220276, 'eval_precision': 0.8252688172043011, 'eval_recall': 0.8036649214659686, 'eval_f1': 0.8143236074270557, 'eval_accuracy': 0.9780368763557483, 'eval_runtime': 1.0772, 'eval_samples_per_second': 143.888, 'eval_steps_per_second': 4.642, 'epoch': 11.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.61it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.29it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A                                                 
                                             [A 63%|██████▎   | 240/380 [07:14<02:57,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 63%|██████▎   | 241/380 [07:22<08:38,  3.73s/it] 64%|██████▎   | 242/380 [07:23<07:00,  3.05s/it] 64%|██████▍   | 243/380 [07:25<05:52,  2.57s/it] 64%|██████▍   | 244/380 [07:26<05:07,  2.26s/it] 64%|██████▍   | 245/380 [07:28<04:32,  2.02s/it] 65%|██████▍   | 246/380 [07:29<04:08,  1.85s/it] 65%|██████▌   | 247/380 [07:31<03:51,  1.74s/it] 65%|██████▌   | 248/380 [07:32<03:38,  1.66s/it] 66%|██████▌   | 249/380 [07:34<03:31,  1.62s/it] 66%|██████▌   | 250/380 [07:35<03:24,  1.57s/it] 66%|██████▌   | 251/380 [07:37<03:18,  1.54s/it] 66%|██████▋   | 252/380 [07:38<03:14,  1.52s/it] 67%|██████▋   | 253/380 [07:40<03:10,  1.50s/it] 67%|██████▋   | 254/380 [07:41<03:10,  1.51s/it] 67%|██████▋   | 255/380 [07:43<03:07,  1.50s/it] 67%|██████▋   | 256/380 [07:44<03:04,  1.49s/it] 68%|██████▊   | 257/380 [07:46<03:02,  1.48s/it] 68%|██████▊   | 258/380 [07:47<02:59,  1.47s/it] 68%|██████▊   | 259/380 [07:49<03:00,  1.49s/it] 68%|██████▊   | 260/380 [07:49<02:31,  1.26s/it]{'eval_loss': 0.1687593311071396, 'eval_precision': 0.80306905370844, 'eval_recall': 0.8219895287958116, 'eval_f1': 0.8124191461836998, 'eval_accuracy': 0.976409978308026, 'eval_runtime': 1.0125, 'eval_samples_per_second': 153.094, 'eval_steps_per_second': 4.939, 'epoch': 12.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.43it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.27it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A                                                 
                                             [A 68%|██████▊   | 260/380 [07:50<02:31,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 69%|██████▊   | 261/380 [07:59<07:21,  3.71s/it] 69%|██████▉   | 262/380 [08:00<05:58,  3.04s/it] 69%|██████▉   | 263/380 [08:02<05:05,  2.61s/it] 69%|██████▉   | 264/380 [08:03<04:23,  2.27s/it] 70%|██████▉   | 265/380 [08:05<03:53,  2.03s/it] 70%|███████   | 266/380 [08:06<03:32,  1.86s/it] 70%|███████   | 267/380 [08:08<03:16,  1.74s/it] 71%|███████   | 268/380 [08:09<03:08,  1.68s/it] 71%|███████   | 269/380 [08:11<02:59,  1.62s/it] 71%|███████   | 270/380 [08:12<02:53,  1.57s/it] 71%|███████▏  | 271/380 [08:14<02:48,  1.55s/it] 72%|███████▏  | 272/380 [08:15<02:44,  1.52s/it] 72%|███████▏  | 273/380 [08:17<02:42,  1.52s/it] 72%|███████▏  | 274/380 [08:18<02:39,  1.51s/it] 72%|███████▏  | 275/380 [08:20<02:37,  1.50s/it] 73%|███████▎  | 276/380 [08:21<02:35,  1.49s/it] 73%|███████▎  | 277/380 [08:23<02:33,  1.49s/it] 73%|███████▎  | 278/380 [08:24<02:33,  1.50s/it] 73%|███████▎  | 279/380 [08:26<02:30,  1.49s/it] 74%|███████▎  | 280/380 [08:26<02:06,  1.26s/it]{'eval_loss': 0.18158245086669922, 'eval_precision': 0.8142493638676844, 'eval_recall': 0.837696335078534, 'eval_f1': 0.8258064516129032, 'eval_accuracy': 0.976409978308026, 'eval_runtime': 1.0143, 'eval_samples_per_second': 152.811, 'eval_steps_per_second': 4.929, 'epoch': 13.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.57it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.24it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.80it/s][A                                                 
                                             [A 74%|███████▎  | 280/380 [08:27<02:06,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.80it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 74%|███████▍  | 281/380 [08:36<06:12,  3.76s/it] 74%|███████▍  | 282/380 [08:37<05:02,  3.09s/it] 74%|███████▍  | 283/380 [08:39<04:12,  2.60s/it] 75%|███████▍  | 284/380 [08:40<03:36,  2.26s/it] 75%|███████▌  | 285/380 [08:42<03:12,  2.02s/it] 75%|███████▌  | 286/380 [08:43<02:54,  1.86s/it] 76%|███████▌  | 287/380 [08:45<02:43,  1.75s/it] 76%|███████▌  | 288/380 [08:46<02:33,  1.67s/it] 76%|███████▌  | 289/380 [08:48<02:26,  1.61s/it] 76%|███████▋  | 290/380 [08:49<02:20,  1.56s/it] 77%|███████▋  | 291/380 [08:51<02:16,  1.53s/it] 77%|███████▋  | 292/380 [08:52<02:17,  1.56s/it] 77%|███████▋  | 293/380 [08:54<02:13,  1.53s/it] 77%|███████▋  | 294/380 [08:55<02:09,  1.51s/it] 78%|███████▊  | 295/380 [08:57<02:07,  1.50s/it] 78%|███████▊  | 296/380 [08:58<02:04,  1.49s/it] 78%|███████▊  | 297/380 [09:00<02:04,  1.50s/it] 78%|███████▊  | 298/380 [09:01<02:02,  1.49s/it] 79%|███████▊  | 299/380 [09:03<02:00,  1.49s/it] 79%|███████▉  | 300/380 [09:03<01:41,  1.27s/it]{'eval_loss': 0.1871960461139679, 'eval_precision': 0.8188976377952756, 'eval_recall': 0.8167539267015707, 'eval_f1': 0.817824377457405, 'eval_accuracy': 0.9762744034707158, 'eval_runtime': 1.0212, 'eval_samples_per_second': 151.785, 'eval_steps_per_second': 4.896, 'epoch': 14.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.39it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.22it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A                                                 
                                             [A 79%|███████▉  | 300/380 [09:04<01:41,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 79%|███████▉  | 301/380 [09:13<04:54,  3.72s/it] 79%|███████▉  | 302/380 [09:14<03:57,  3.05s/it] 80%|███████▉  | 303/380 [09:16<03:17,  2.57s/it] 80%|████████  | 304/380 [09:17<02:50,  2.24s/it] 80%|████████  | 305/380 [09:19<02:30,  2.01s/it] 81%|████████  | 306/380 [09:20<02:17,  1.86s/it] 81%|████████  | 307/380 [09:22<02:07,  1.74s/it] 81%|████████  | 308/380 [09:23<01:59,  1.66s/it] 81%|████████▏ | 309/380 [09:25<01:53,  1.60s/it] 82%|████████▏ | 310/380 [09:26<01:49,  1.56s/it] 82%|████████▏ | 311/380 [09:28<01:46,  1.54s/it] 82%|████████▏ | 312/380 [09:29<01:43,  1.52s/it] 82%|████████▏ | 313/380 [09:30<01:40,  1.50s/it] 83%|████████▎ | 314/380 [09:32<01:38,  1.49s/it] 83%|████████▎ | 315/380 [09:33<01:36,  1.48s/it] 83%|████████▎ | 316/380 [09:35<01:35,  1.49s/it] 83%|████████▎ | 317/380 [09:36<01:33,  1.49s/it] 84%|████████▎ | 318/380 [09:38<01:31,  1.48s/it] 84%|████████▍ | 319/380 [09:39<01:30,  1.48s/it] 84%|████████▍ | 320/380 [09:40<01:15,  1.25s/it]{'eval_loss': 0.19086210429668427, 'eval_precision': 0.801980198019802, 'eval_recall': 0.8481675392670157, 'eval_f1': 0.8244274809160305, 'eval_accuracy': 0.9754609544468547, 'eval_runtime': 1.0233, 'eval_samples_per_second': 151.469, 'eval_steps_per_second': 4.886, 'epoch': 15.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.57it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A                                                 
                                             [A 84%|████████▍ | 320/380 [09:41<01:15,  1.25s/it]
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 84%|████████▍ | 321/380 [09:49<03:35,  3.65s/it] 85%|████████▍ | 322/380 [09:51<02:53,  2.99s/it] 85%|████████▌ | 323/380 [09:52<02:24,  2.53s/it] 85%|████████▌ | 324/380 [09:54<02:03,  2.21s/it] 86%|████████▌ | 325/380 [09:55<01:49,  1.99s/it] 86%|████████▌ | 326/380 [09:57<01:40,  1.86s/it] 86%|████████▌ | 327/380 [09:58<01:32,  1.75s/it] 86%|████████▋ | 328/380 [10:00<01:26,  1.66s/it] 87%|████████▋ | 329/380 [10:01<01:21,  1.60s/it] 87%|████████▋ | 330/380 [10:03<01:18,  1.56s/it] 87%|████████▋ | 331/380 [10:04<01:16,  1.57s/it] 87%|████████▋ | 332/380 [10:06<01:13,  1.54s/it] 88%|████████▊ | 333/380 [10:07<01:11,  1.52s/it] 88%|████████▊ | 334/380 [10:09<01:09,  1.50s/it] 88%|████████▊ | 335/380 [10:10<01:07,  1.49s/it] 88%|████████▊ | 336/380 [10:12<01:06,  1.52s/it] 89%|████████▊ | 337/380 [10:13<01:04,  1.50s/it] 89%|████████▉ | 338/380 [10:15<01:02,  1.49s/it] 89%|████████▉ | 339/380 [10:16<01:00,  1.49s/it] 89%|████████▉ | 340/380 [10:17<00:50,  1.26s/it]{'eval_loss': 0.1888948231935501, 'eval_precision': 0.8328912466843501, 'eval_recall': 0.8219895287958116, 'eval_f1': 0.8274044795783926, 'eval_accuracy': 0.976409978308026, 'eval_runtime': 1.0132, 'eval_samples_per_second': 152.983, 'eval_steps_per_second': 4.935, 'epoch': 16.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.56it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.11it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.08it/s][A                                                 
                                             [A 89%|████████▉ | 340/380 [10:18<00:50,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.08it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 90%|████████▉ | 341/380 [10:26<02:17,  3.53s/it] 90%|█████████ | 342/380 [10:27<01:50,  2.91s/it] 90%|█████████ | 343/380 [10:28<01:31,  2.48s/it] 91%|█████████ | 344/380 [10:30<01:18,  2.17s/it] 91%|█████████ | 345/380 [10:31<01:09,  1.97s/it] 91%|█████████ | 346/380 [10:33<01:01,  1.82s/it] 91%|█████████▏| 347/380 [10:34<00:56,  1.71s/it] 92%|█████████▏| 348/380 [10:36<00:52,  1.64s/it] 92%|█████████▏| 349/380 [10:37<00:49,  1.59s/it] 92%|█████████▏| 350/380 [10:39<00:46,  1.56s/it] 92%|█████████▏| 351/380 [10:40<00:44,  1.53s/it] 93%|█████████▎| 352/380 [10:42<00:42,  1.51s/it] 93%|█████████▎| 353/380 [10:43<00:40,  1.50s/it] 93%|█████████▎| 354/380 [10:45<00:38,  1.48s/it] 93%|█████████▎| 355/380 [10:46<00:37,  1.49s/it] 94%|█████████▎| 356/380 [10:48<00:35,  1.48s/it] 94%|█████████▍| 357/380 [10:49<00:34,  1.48s/it] 94%|█████████▍| 358/380 [10:51<00:32,  1.48s/it] 94%|█████████▍| 359/380 [10:52<00:30,  1.48s/it] 95%|█████████▍| 360/380 [10:53<00:25,  1.26s/it]{'eval_loss': 0.19168230891227722, 'eval_precision': 0.8302872062663186, 'eval_recall': 0.8324607329842932, 'eval_f1': 0.8313725490196078, 'eval_accuracy': 0.977087852494577, 'eval_runtime': 1.1095, 'eval_samples_per_second': 139.696, 'eval_steps_per_second': 4.506, 'epoch': 17.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.62it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.31it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A                                                 
                                             [A 95%|█████████▍| 360/380 [10:54<00:25,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 95%|█████████▌| 361/380 [11:02<01:08,  3.62s/it] 95%|█████████▌| 362/380 [11:03<00:53,  2.98s/it] 96%|█████████▌| 363/380 [11:05<00:42,  2.52s/it] 96%|█████████▌| 364/380 [11:06<00:35,  2.22s/it] 96%|█████████▌| 365/380 [11:08<00:29,  2.00s/it] 96%|█████████▋| 366/380 [11:09<00:25,  1.84s/it] 97%|█████████▋| 367/380 [11:11<00:22,  1.73s/it] 97%|█████████▋| 368/380 [11:12<00:19,  1.65s/it] 97%|█████████▋| 369/380 [11:14<00:18,  1.64s/it] 97%|█████████▋| 370/380 [11:15<00:15,  1.59s/it] 98%|█████████▊| 371/380 [11:17<00:13,  1.55s/it] 98%|█████████▊| 372/380 [11:18<00:12,  1.53s/it] 98%|█████████▊| 373/380 [11:20<00:10,  1.51s/it] 98%|█████████▊| 374/380 [11:21<00:09,  1.52s/it] 99%|█████████▊| 375/380 [11:23<00:07,  1.52s/it] 99%|█████████▉| 376/380 [11:24<00:06,  1.50s/it] 99%|█████████▉| 377/380 [11:26<00:04,  1.49s/it] 99%|█████████▉| 378/380 [11:27<00:02,  1.48s/it]100%|█████████▉| 379/380 [11:29<00:01,  1.50s/it]100%|██████████| 380/380 [11:29<00:00,  1.27s/it]{'eval_loss': 0.19769513607025146, 'eval_precision': 0.8165829145728644, 'eval_recall': 0.8507853403141361, 'eval_f1': 0.8333333333333334, 'eval_accuracy': 0.9761388286334056, 'eval_runtime': 1.0145, 'eval_samples_per_second': 152.787, 'eval_steps_per_second': 4.929, 'epoch': 18.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.60it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.29it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A                                                 
                                             [A100%|██████████| 380/380 [11:31<00:00,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A
                                             [A                                                 100%|██████████| 380/380 [11:38<00:00,  1.27s/it]100%|██████████| 380/380 [11:38<00:00,  1.84s/it]
[I 2025-09-20 14:40:48,176] Trial 11 finished with value: 3.4676793227412293 and parameters: {'learning_rate': 4.1801142802562196e-05, 'num_train_epochs': 19, 'per_device_train_batch_size': 4, 'weight_decay': 4.060428220332491e-05, 'warmup_ratio': 0.010318206796879448, 'optimizer': 'Adafactor'}. Best is trial 9 with value: 3.4695526749403767.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▅▅▇▇▇▇▇▇▇█████████
wandb:                 eval/f1 ▁▅▆▇▇▇█▇███████████
wandb:               eval/loss █▂▁▁▁▂▂▃▂▃▃▃▃▄▄▄▄▄▄
wandb:          eval/precision ▁▂▃▅▆▆▇▆▇▇█▇██▇████
wandb:             eval/recall ▁▅▇███▇████████████
wandb:            eval/runtime █▁▁▃▅▅▁▁▂▁▅▁▁▂▂▁▇▁█
wandb: eval/samples_per_second ▁██▆▄▄██▇█▄██▇▇█▂█▁
wandb:   eval/steps_per_second ▁██▆▄▄██▇█▄██▇▇█▂█▁
wandb:             train/epoch ▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇███
wandb:       train/global_step ▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇███
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.97614
wandb:                  eval/f1 0.83033
wandb:                eval/loss 0.19774
wandb:           eval/precision 0.81566
wandb:              eval/recall 0.84555
wandb:             eval/runtime 1.1224
wandb:  eval/samples_per_second 138.093
wandb:    eval/steps_per_second 4.455
wandb:               total_flos 7761134673925632.0
wandb:              train/epoch 19
wandb:        train/global_step 380
wandb:               train_loss 0.08247
wandb:            train_runtime 701.0132
wandb: train_samples_per_second 33.554
wandb:   train_steps_per_second 0.542
wandb: 
wandb: 🚀 View run lively-dew-788 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/l37qmcdu
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250920_142908-l37qmcdu/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_144051-t49n2fpl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-glade-789
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/t49n2fpl
{'eval_loss': 0.19774101674556732, 'eval_precision': 0.8156565656565656, 'eval_recall': 0.8455497382198953, 'eval_f1': 0.8303341902313626, 'eval_accuracy': 0.9761388286334056, 'eval_runtime': 1.1224, 'eval_samples_per_second': 138.093, 'eval_steps_per_second': 4.455, 'epoch': 19.0}
{'train_runtime': 701.0132, 'train_samples_per_second': 33.554, 'train_steps_per_second': 0.542, 'train_loss': 0.08247038690667403, 'epoch': 19.0}
  0%|          | 0/240 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/240 [00:01<05:59,  1.50s/it]  1%|          | 2/240 [00:02<05:55,  1.49s/it]  1%|▏         | 3/240 [00:04<05:52,  1.49s/it]  2%|▏         | 4/240 [00:05<05:50,  1.48s/it]  2%|▏         | 5/240 [00:07<05:55,  1.51s/it]  2%|▎         | 6/240 [00:08<05:50,  1.50s/it]  3%|▎         | 7/240 [00:10<05:47,  1.49s/it]  3%|▎         | 8/240 [00:11<05:44,  1.49s/it]  4%|▍         | 9/240 [00:13<05:42,  1.48s/it]  4%|▍         | 10/240 [00:14<05:46,  1.51s/it]  5%|▍         | 11/240 [00:16<05:43,  1.50s/it]  5%|▌         | 12/240 [00:17<05:40,  1.49s/it]  5%|▌         | 13/240 [00:19<05:38,  1.49s/it]  6%|▌         | 14/240 [00:20<05:36,  1.49s/it]  6%|▋         | 15/240 [00:22<05:40,  1.51s/it]  7%|▋         | 16/240 [00:23<05:36,  1.50s/it]  7%|▋         | 17/240 [00:25<05:33,  1.50s/it]  8%|▊         | 18/240 [00:26<05:31,  1.49s/it]  8%|▊         | 19/240 [00:28<05:28,  1.49s/it]  8%|▊         | 20/240 [00:29<04:40,  1.28s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00,  7.74it/s][A
 60%|██████    | 3/5 [00:00<00:00,  6.74it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.36it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.26it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A  8%|▊         | 20/240 [00:30<04:40,  1.28s/it]
100%|██████████| 5/5 [00:00<00:00,  6.26it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  9%|▉         | 21/240 [00:43<19:05,  5.23s/it]  9%|▉         | 22/240 [00:45<14:53,  4.10s/it] 10%|▉         | 23/240 [00:46<11:58,  3.31s/it] 10%|█         | 24/240 [00:48<10:05,  2.80s/it] 10%|█         | 25/240 [00:49<08:37,  2.41s/it] 11%|█         | 26/240 [00:51<07:35,  2.13s/it] 11%|█▏        | 27/240 [00:52<06:52,  1.94s/it] 12%|█▏        | 28/240 [00:54<06:21,  1.80s/it] 12%|█▏        | 29/240 [00:55<06:05,  1.73s/it] 12%|█▎        | 30/240 [00:57<05:48,  1.66s/it] 13%|█▎        | 31/240 [00:58<05:35,  1.60s/it] 13%|█▎        | 32/240 [01:00<05:25,  1.57s/it] 14%|█▍        | 33/240 [01:01<05:19,  1.54s/it] 14%|█▍        | 34/240 [01:03<05:22,  1.57s/it] 15%|█▍        | 35/240 [01:04<05:15,  1.54s/it] 15%|█▌        | 36/240 [01:06<05:10,  1.52s/it] 15%|█▌        | 37/240 [01:07<05:05,  1.51s/it] 16%|█▌        | 38/240 [01:09<05:02,  1.50s/it] 16%|█▋        | 39/240 [01:10<05:04,  1.52s/it] 17%|█▋        | 40/240 [01:11<04:15,  1.28s/it]{'eval_loss': 0.417908251285553, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9276030368763557, 'eval_runtime': 1.0999, 'eval_samples_per_second': 140.926, 'eval_steps_per_second': 4.546, 'epoch': 1.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.54it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.27it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.82it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 17%|█▋        | 40/240 [01:12<04:15,  1.28s/it]
100%|██████████| 5/5 [00:00<00:00,  6.82it/s][A
                                             [A 17%|█▋        | 40/240 [01:12<06:02,  1.81s/it]
[I 2025-09-20 14:42:04,261] Trial 12 pruned. 
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy █▁
wandb:                 eval/f1 ▁█
wandb:               eval/loss █▁
wandb:          eval/precision ▁█
wandb:             eval/recall ▁█
wandb:            eval/runtime █▁
wandb: eval/samples_per_second ▁█
wandb:   eval/steps_per_second ▁█
wandb:             train/epoch ▁█
wandb:       train/global_step ▁█
wandb: 
wandb: Run summary:
wandb:           eval/accuracy 0.91838
wandb:                 eval/f1 0.30842
wandb:               eval/loss 0.28924
wandb:          eval/precision 0.282
wandb:             eval/recall 0.34031
wandb:            eval/runtime 1.0252
wandb: eval/samples_per_second 151.184
wandb:   eval/steps_per_second 4.877
wandb:             train/epoch 2
wandb:       train/global_step 40
wandb: 
wandb: 🚀 View run clear-glade-789 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/t49n2fpl
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250920_144051-t49n2fpl/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_144207-mc5eod65
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-dew-790
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/mc5eod65
{'eval_loss': 0.28924426436424255, 'eval_precision': 0.28199566160520606, 'eval_recall': 0.3403141361256545, 'eval_f1': 0.30842230130486364, 'eval_accuracy': 0.9183839479392625, 'eval_runtime': 1.0252, 'eval_samples_per_second': 151.184, 'eval_steps_per_second': 4.877, 'epoch': 2.0}
  0%|          | 0/273 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/273 [00:01<06:56,  1.53s/it]  1%|          | 2/273 [00:02<06:40,  1.48s/it]  1%|          | 3/273 [00:04<06:30,  1.45s/it]  1%|▏         | 4/273 [00:05<06:26,  1.44s/it]  2%|▏         | 5/273 [00:07<06:32,  1.46s/it]  2%|▏         | 6/273 [00:08<06:25,  1.45s/it]  3%|▎         | 7/273 [00:10<06:23,  1.44s/it]  3%|▎         | 8/273 [00:11<06:18,  1.43s/it]  3%|▎         | 9/273 [00:12<06:15,  1.42s/it]  4%|▎         | 10/273 [00:14<06:20,  1.45s/it]  4%|▍         | 11/273 [00:15<06:16,  1.44s/it]  4%|▍         | 12/273 [00:17<06:13,  1.43s/it]  5%|▍         | 13/273 [00:18<06:10,  1.42s/it]  5%|▌         | 14/273 [00:20<06:07,  1.42s/it]  5%|▌         | 15/273 [00:21<06:12,  1.44s/it]  6%|▌         | 16/273 [00:23<06:08,  1.43s/it]  6%|▌         | 17/273 [00:24<06:04,  1.43s/it]  7%|▋         | 18/273 [00:25<06:02,  1.42s/it]  7%|▋         | 19/273 [00:27<06:00,  1.42s/it]  7%|▋         | 20/273 [00:28<06:05,  1.44s/it]  8%|▊         | 21/273 [00:30<06:02,  1.44s/it]  8%|▊         | 22/273 [00:31<05:59,  1.43s/it]  8%|▊         | 23/273 [00:33<05:57,  1.43s/it]  9%|▉         | 24/273 [00:34<05:55,  1.43s/it]  9%|▉         | 25/273 [00:35<06:00,  1.45s/it] 10%|▉         | 26/273 [00:37<05:55,  1.44s/it] 10%|▉         | 27/273 [00:38<05:52,  1.43s/it] 10%|█         | 28/273 [00:40<05:50,  1.43s/it] 11%|█         | 29/273 [00:41<05:47,  1.43s/it] 11%|█         | 30/273 [00:43<05:52,  1.45s/it] 11%|█▏        | 31/273 [00:44<05:48,  1.44s/it] 12%|█▏        | 32/273 [00:45<05:44,  1.43s/it] 12%|█▏        | 33/273 [00:47<05:42,  1.43s/it] 12%|█▏        | 34/273 [00:48<05:41,  1.43s/it] 13%|█▎        | 35/273 [00:50<05:46,  1.46s/it] 13%|█▎        | 36/273 [00:51<05:42,  1.45s/it] 14%|█▎        | 37/273 [00:53<05:39,  1.44s/it] 14%|█▍        | 38/273 [00:54<05:36,  1.43s/it] 14%|█▍        | 39/273 [00:55<05:07,  1.32s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00,  7.76it/s][A
 60%|██████    | 3/5 [00:00<00:00,  6.75it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.35it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.22it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 14%|█▍        | 39/273 [00:56<05:07,  1.32s/it]
100%|██████████| 5/5 [00:00<00:00,  6.22it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 15%|█▍        | 40/273 [01:06<16:11,  4.17s/it] 15%|█▌        | 41/273 [01:07<12:55,  3.34s/it] 15%|█▌        | 42/273 [01:09<10:38,  2.76s/it] 16%|█▌        | 43/273 [01:10<09:02,  2.36s/it] 16%|█▌        | 44/273 [01:12<07:59,  2.09s/it] 16%|█▋        | 45/273 [01:13<07:11,  1.89s/it] 17%|█▋        | 46/273 [01:15<06:37,  1.75s/it] 17%|█▋        | 47/273 [01:16<06:13,  1.65s/it] 18%|█▊        | 48/273 [01:17<06:00,  1.60s/it] 18%|█▊        | 49/273 [01:19<05:46,  1.55s/it] 18%|█▊        | 50/273 [01:20<05:36,  1.51s/it] 19%|█▊        | 51/273 [01:22<05:29,  1.48s/it] 19%|█▉        | 52/273 [01:23<05:23,  1.46s/it] 19%|█▉        | 53/273 [01:25<05:23,  1.47s/it] 20%|█▉        | 54/273 [01:26<05:19,  1.46s/it] 20%|██        | 55/273 [01:27<05:15,  1.45s/it] 21%|██        | 56/273 [01:29<05:11,  1.44s/it] 21%|██        | 57/273 [01:30<05:09,  1.43s/it] 21%|██        | 58/273 [01:32<05:10,  1.45s/it] 22%|██▏       | 59/273 [01:33<05:07,  1.44s/it] 22%|██▏       | 60/273 [01:35<05:04,  1.43s/it] 22%|██▏       | 61/273 [01:36<05:03,  1.43s/it] 23%|██▎       | 62/273 [01:37<05:00,  1.43s/it] 23%|██▎       | 63/273 [01:39<05:03,  1.45s/it] 23%|██▎       | 64/273 [01:40<05:00,  1.44s/it] 24%|██▍       | 65/273 [01:42<04:58,  1.43s/it] 24%|██▍       | 66/273 [01:43<04:55,  1.43s/it] 25%|██▍       | 67/273 [01:45<04:53,  1.43s/it] 25%|██▍       | 68/273 [01:46<05:01,  1.47s/it] 25%|██▌       | 69/273 [01:48<04:56,  1.46s/it] 26%|██▌       | 70/273 [01:49<04:54,  1.45s/it] 26%|██▌       | 71/273 [01:50<04:50,  1.44s/it] 26%|██▋       | 72/273 [01:52<04:47,  1.43s/it] 27%|██▋       | 73/273 [01:53<04:51,  1.46s/it] 27%|██▋       | 74/273 [01:55<04:47,  1.44s/it] 27%|██▋       | 75/273 [01:56<04:44,  1.43s/it] 28%|██▊       | 76/273 [01:58<04:41,  1.43s/it] 28%|██▊       | 77/273 [01:59<04:40,  1.43s/it] 29%|██▊       | 78/273 [02:00<04:21,  1.34s/it]{'eval_loss': 0.2694534659385681, 'eval_precision': 0.4863013698630137, 'eval_recall': 0.18586387434554974, 'eval_f1': 0.2689393939393939, 'eval_accuracy': 0.9372288503253796, 'eval_runtime': 1.1027, 'eval_samples_per_second': 140.57, 'eval_steps_per_second': 4.535, 'epoch': 1.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.61it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.29it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A                                                
                                             [A 29%|██▊       | 78/273 [02:01<04:21,  1.34s/it]
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 29%|██▉       | 79/273 [02:11<13:14,  4.09s/it] 29%|██▉       | 80/273 [02:12<10:34,  3.29s/it] 30%|██▉       | 81/273 [02:14<08:43,  2.73s/it] 30%|███       | 82/273 [02:15<07:29,  2.35s/it] 30%|███       | 83/273 [02:16<06:34,  2.07s/it] 31%|███       | 84/273 [02:18<05:54,  1.88s/it] 31%|███       | 85/273 [02:19<05:26,  1.74s/it] 32%|███▏      | 86/273 [02:21<05:07,  1.64s/it] 32%|███▏      | 87/273 [02:22<04:56,  1.59s/it] 32%|███▏      | 88/273 [02:24<04:45,  1.54s/it] 33%|███▎      | 89/273 [02:25<04:37,  1.51s/it] 33%|███▎      | 90/273 [02:26<04:31,  1.48s/it] 33%|███▎      | 91/273 [02:28<04:26,  1.46s/it] 34%|███▎      | 92/273 [02:29<04:26,  1.47s/it] 34%|███▍      | 93/273 [02:31<04:22,  1.46s/it] 34%|███▍      | 94/273 [02:32<04:19,  1.45s/it] 35%|███▍      | 95/273 [02:34<04:16,  1.44s/it] 35%|███▌      | 96/273 [02:35<04:14,  1.44s/it] 36%|███▌      | 97/273 [02:37<04:16,  1.46s/it] 36%|███▌      | 98/273 [02:38<04:13,  1.45s/it] 36%|███▋      | 99/273 [02:39<04:09,  1.44s/it] 37%|███▋      | 100/273 [02:41<04:07,  1.43s/it] 37%|███▋      | 101/273 [02:42<04:05,  1.43s/it] 37%|███▋      | 102/273 [02:44<04:06,  1.44s/it] 38%|███▊      | 103/273 [02:45<04:03,  1.43s/it] 38%|███▊      | 104/273 [02:47<04:01,  1.43s/it] 38%|███▊      | 105/273 [02:48<03:59,  1.43s/it] 39%|███▉      | 106/273 [02:49<03:57,  1.42s/it] 39%|███▉      | 107/273 [02:51<03:58,  1.44s/it] 40%|███▉      | 108/273 [02:52<03:56,  1.43s/it] 40%|███▉      | 109/273 [02:54<03:54,  1.43s/it] 40%|████      | 110/273 [02:55<03:52,  1.42s/it] 41%|████      | 111/273 [02:57<03:50,  1.42s/it] 41%|████      | 112/273 [02:58<03:51,  1.44s/it] 41%|████▏     | 113/273 [02:59<03:49,  1.44s/it] 42%|████▏     | 114/273 [03:01<03:47,  1.43s/it] 42%|████▏     | 115/273 [03:02<03:45,  1.43s/it] 42%|████▏     | 116/273 [03:04<03:46,  1.44s/it] 43%|████▎     | 117/273 [03:05<03:27,  1.33s/it]{'eval_loss': 0.1255083829164505, 'eval_precision': 0.6461187214611872, 'eval_recall': 0.7408376963350786, 'eval_f1': 0.6902439024390244, 'eval_accuracy': 0.9644793926247288, 'eval_runtime': 1.0147, 'eval_samples_per_second': 152.756, 'eval_steps_per_second': 4.928, 'epoch': 2.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.64it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.31it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.89it/s][A                                                 
                                             [A 43%|████▎     | 117/273 [03:06<03:27,  1.33s/it]
100%|██████████| 5/5 [00:00<00:00,  6.89it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 43%|████▎     | 118/273 [03:14<09:33,  3.70s/it] 44%|████▎     | 119/273 [03:15<07:43,  3.01s/it] 44%|████▍     | 120/273 [03:17<06:27,  2.54s/it] 44%|████▍     | 121/273 [03:18<05:36,  2.22s/it] 45%|████▍     | 122/273 [03:20<04:58,  1.98s/it] 45%|████▌     | 123/273 [03:21<04:31,  1.81s/it] 45%|████▌     | 124/273 [03:23<04:12,  1.69s/it] 46%|████▌     | 125/273 [03:24<03:58,  1.61s/it] 46%|████▌     | 126/273 [03:25<03:51,  1.57s/it] 47%|████▋     | 127/273 [03:27<03:43,  1.53s/it] 47%|████▋     | 128/273 [03:28<03:36,  1.49s/it] 47%|████▋     | 129/273 [03:30<03:31,  1.47s/it] 48%|████▊     | 130/273 [03:31<03:30,  1.47s/it] 48%|████▊     | 131/273 [03:33<03:27,  1.46s/it] 48%|████▊     | 132/273 [03:34<03:24,  1.45s/it] 49%|████▊     | 133/273 [03:36<03:21,  1.44s/it] 49%|████▉     | 134/273 [03:37<03:19,  1.44s/it] 49%|████▉     | 135/273 [03:38<03:19,  1.45s/it] 50%|████▉     | 136/273 [03:40<03:17,  1.44s/it] 50%|█████     | 137/273 [03:41<03:15,  1.43s/it] 51%|█████     | 138/273 [03:43<03:13,  1.43s/it] 51%|█████     | 139/273 [03:44<03:11,  1.43s/it] 51%|█████▏    | 140/273 [03:46<03:12,  1.45s/it] 52%|█████▏    | 141/273 [03:47<03:09,  1.44s/it] 52%|█████▏    | 142/273 [03:48<03:07,  1.43s/it] 52%|█████▏    | 143/273 [03:50<03:05,  1.43s/it] 53%|█████▎    | 144/273 [03:51<03:03,  1.43s/it] 53%|█████▎    | 145/273 [03:53<03:04,  1.44s/it] 53%|█████▎    | 146/273 [03:54<03:02,  1.43s/it] 54%|█████▍    | 147/273 [03:56<02:59,  1.43s/it] 54%|█████▍    | 148/273 [03:57<02:58,  1.43s/it] 55%|█████▍    | 149/273 [03:58<02:56,  1.43s/it] 55%|█████▍    | 150/273 [04:00<02:57,  1.44s/it] 55%|█████▌    | 151/273 [04:01<02:54,  1.43s/it] 56%|█████▌    | 152/273 [04:03<02:53,  1.43s/it] 56%|█████▌    | 153/273 [04:04<02:50,  1.42s/it] 56%|█████▋    | 154/273 [04:06<02:49,  1.42s/it] 57%|█████▋    | 155/273 [04:07<02:50,  1.44s/it] 57%|█████▋    | 156/273 [04:08<02:35,  1.33s/it]{'eval_loss': 0.10625144094228745, 'eval_precision': 0.7786885245901639, 'eval_recall': 0.7460732984293194, 'eval_f1': 0.7620320855614974, 'eval_accuracy': 0.9730206073752712, 'eval_runtime': 1.0125, 'eval_samples_per_second': 153.089, 'eval_steps_per_second': 4.938, 'epoch': 3.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.61it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.32it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A                                                 
                                             [A 57%|█████▋    | 156/273 [04:09<02:35,  1.33s/it]
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 58%|█████▊    | 157/273 [04:17<07:05,  3.67s/it] 58%|█████▊    | 158/273 [04:19<05:44,  2.99s/it] 58%|█████▊    | 159/273 [04:20<04:49,  2.54s/it] 59%|█████▊    | 160/273 [04:22<04:10,  2.21s/it] 59%|█████▉    | 161/273 [04:23<03:41,  1.98s/it] 59%|█████▉    | 162/273 [04:24<03:21,  1.81s/it] 60%|█████▉    | 163/273 [04:26<03:06,  1.70s/it] 60%|██████    | 164/273 [04:27<02:57,  1.63s/it] 60%|██████    | 165/273 [04:29<02:49,  1.57s/it] 61%|██████    | 166/273 [04:30<02:42,  1.52s/it] 61%|██████    | 167/273 [04:32<02:37,  1.49s/it] 62%|██████▏   | 168/273 [04:33<02:34,  1.47s/it] 62%|██████▏   | 169/273 [04:35<02:33,  1.47s/it] 62%|██████▏   | 170/273 [04:36<02:29,  1.45s/it] 63%|██████▎   | 171/273 [04:37<02:27,  1.44s/it] 63%|██████▎   | 172/273 [04:39<02:24,  1.44s/it] 63%|██████▎   | 173/273 [04:40<02:22,  1.43s/it] 64%|██████▎   | 174/273 [04:42<02:22,  1.44s/it] 64%|██████▍   | 175/273 [04:43<02:20,  1.43s/it] 64%|██████▍   | 176/273 [04:44<02:18,  1.43s/it] 65%|██████▍   | 177/273 [04:46<02:16,  1.43s/it] 65%|██████▌   | 178/273 [04:47<02:15,  1.42s/it] 66%|██████▌   | 179/273 [04:49<02:15,  1.44s/it] 66%|██████▌   | 180/273 [04:50<02:13,  1.43s/it] 66%|██████▋   | 181/273 [04:52<02:12,  1.44s/it] 67%|██████▋   | 182/273 [04:53<02:10,  1.43s/it] 67%|██████▋   | 183/273 [04:54<02:08,  1.43s/it] 67%|██████▋   | 184/273 [04:56<02:09,  1.45s/it] 68%|██████▊   | 185/273 [04:57<02:07,  1.45s/it] 68%|██████▊   | 186/273 [04:59<02:05,  1.44s/it] 68%|██████▊   | 187/273 [05:00<02:03,  1.44s/it] 69%|██████▉   | 188/273 [05:02<02:01,  1.43s/it] 69%|██████▉   | 189/273 [05:03<02:01,  1.45s/it] 70%|██████▉   | 190/273 [05:05<01:59,  1.44s/it] 70%|██████▉   | 191/273 [05:06<01:57,  1.43s/it] 70%|███████   | 192/273 [05:07<01:55,  1.43s/it] 71%|███████   | 193/273 [05:09<01:55,  1.44s/it] 71%|███████   | 194/273 [05:10<01:53,  1.43s/it] 71%|███████▏  | 195/273 [05:11<01:42,  1.32s/it]{'eval_loss': 0.11666838079690933, 'eval_precision': 0.8061797752808989, 'eval_recall': 0.7513089005235603, 'eval_f1': 0.7777777777777778, 'eval_accuracy': 0.9738340563991323, 'eval_runtime': 1.0158, 'eval_samples_per_second': 152.586, 'eval_steps_per_second': 4.922, 'epoch': 4.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.59it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.83it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.56it/s][A                                                 
                                             [A 71%|███████▏  | 195/273 [05:12<01:42,  1.32s/it]
100%|██████████| 5/5 [00:00<00:00,  6.56it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 72%|███████▏  | 196/273 [05:20<04:36,  3.59s/it] 72%|███████▏  | 197/273 [05:22<03:43,  2.94s/it] 73%|███████▎  | 198/273 [05:23<03:07,  2.50s/it] 73%|███████▎  | 199/273 [05:25<02:41,  2.18s/it] 73%|███████▎  | 200/273 [05:26<02:23,  1.96s/it] 74%|███████▎  | 201/273 [05:27<02:09,  1.80s/it] 74%|███████▍  | 202/273 [05:29<01:59,  1.69s/it] 74%|███████▍  | 203/273 [05:30<01:53,  1.62s/it] 75%|███████▍  | 204/273 [05:32<01:47,  1.56s/it] 75%|███████▌  | 205/273 [05:33<01:43,  1.52s/it] 75%|███████▌  | 206/273 [05:35<01:39,  1.49s/it] 76%|███████▌  | 207/273 [05:36<01:37,  1.48s/it] 76%|███████▌  | 208/273 [05:38<01:35,  1.47s/it] 77%|███████▋  | 209/273 [05:39<01:32,  1.45s/it] 77%|███████▋  | 210/273 [05:40<01:30,  1.44s/it] 77%|███████▋  | 211/273 [05:42<01:28,  1.43s/it] 78%|███████▊  | 212/273 [05:43<01:28,  1.45s/it] 78%|███████▊  | 213/273 [05:45<01:26,  1.44s/it] 78%|███████▊  | 214/273 [05:46<01:24,  1.43s/it] 79%|███████▉  | 215/273 [05:48<01:22,  1.43s/it] 79%|███████▉  | 216/273 [05:49<01:21,  1.43s/it] 79%|███████▉  | 217/273 [05:50<01:20,  1.44s/it] 80%|███████▉  | 218/273 [05:52<01:18,  1.43s/it] 80%|████████  | 219/273 [05:53<01:17,  1.43s/it] 81%|████████  | 220/273 [05:55<01:15,  1.42s/it] 81%|████████  | 221/273 [05:56<01:13,  1.42s/it] 81%|████████▏ | 222/273 [05:58<01:13,  1.44s/it] 82%|████████▏ | 223/273 [05:59<01:11,  1.44s/it] 82%|████████▏ | 224/273 [06:00<01:10,  1.44s/it] 82%|████████▏ | 225/273 [06:02<01:08,  1.44s/it] 83%|████████▎ | 226/273 [06:03<01:07,  1.43s/it] 83%|████████▎ | 227/273 [06:05<01:06,  1.45s/it] 84%|████████▎ | 228/273 [06:06<01:04,  1.43s/it] 84%|████████▍ | 229/273 [06:08<01:02,  1.43s/it] 84%|████████▍ | 230/273 [06:09<01:01,  1.42s/it] 85%|████████▍ | 231/273 [06:10<00:59,  1.42s/it] 85%|████████▍ | 232/273 [06:12<00:58,  1.43s/it] 85%|████████▌ | 233/273 [06:13<00:56,  1.42s/it] 86%|████████▌ | 234/273 [06:14<00:51,  1.32s/it]{'eval_loss': 0.12030359357595444, 'eval_precision': 0.8010610079575596, 'eval_recall': 0.7905759162303665, 'eval_f1': 0.7957839262187089, 'eval_accuracy': 0.9768167028199566, 'eval_runtime': 1.0464, 'eval_samples_per_second': 148.123, 'eval_steps_per_second': 4.778, 'epoch': 5.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.53it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A                                                 
                                             [A 86%|████████▌ | 234/273 [06:15<00:51,  1.32s/it]
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 86%|████████▌ | 235/273 [06:23<02:15,  3.56s/it] 86%|████████▋ | 236/273 [06:25<01:48,  2.94s/it] 87%|████████▋ | 237/273 [06:26<01:29,  2.48s/it] 87%|████████▋ | 238/273 [06:27<01:15,  2.16s/it] 88%|████████▊ | 239/273 [06:29<01:05,  1.94s/it] 88%|████████▊ | 240/273 [06:30<00:58,  1.78s/it] 88%|████████▊ | 241/273 [06:32<00:54,  1.69s/it] 89%|████████▊ | 242/273 [06:33<00:50,  1.61s/it] 89%|████████▉ | 243/273 [06:35<00:46,  1.56s/it] 89%|████████▉ | 244/273 [06:36<00:43,  1.52s/it] 90%|████████▉ | 245/273 [06:37<00:41,  1.49s/it] 90%|█████████ | 246/273 [06:39<00:40,  1.49s/it] 90%|█████████ | 247/273 [06:40<00:38,  1.46s/it] 91%|█████████ | 248/273 [06:42<00:36,  1.45s/it] 91%|█████████ | 249/273 [06:43<00:34,  1.44s/it] 92%|█████████▏| 250/273 [06:45<00:32,  1.43s/it] 92%|█████████▏| 251/273 [06:46<00:31,  1.45s/it] 92%|█████████▏| 252/273 [06:48<00:30,  1.44s/it] 93%|█████████▎| 253/273 [06:49<00:28,  1.43s/it] 93%|█████████▎| 254/273 [06:50<00:27,  1.43s/it] 93%|█████████▎| 255/273 [06:52<00:25,  1.42s/it] 94%|█████████▍| 256/273 [06:53<00:24,  1.44s/it] 94%|█████████▍| 257/273 [06:55<00:22,  1.43s/it] 95%|█████████▍| 258/273 [06:56<00:21,  1.43s/it] 95%|█████████▍| 259/273 [06:57<00:19,  1.42s/it] 95%|█████████▌| 260/273 [06:59<00:18,  1.42s/it] 96%|█████████▌| 261/273 [07:00<00:17,  1.44s/it] 96%|█████████▌| 262/273 [07:02<00:15,  1.43s/it] 96%|█████████▋| 263/273 [07:03<00:14,  1.42s/it] 97%|█████████▋| 264/273 [07:05<00:12,  1.42s/it] 97%|█████████▋| 265/273 [07:06<00:11,  1.42s/it] 97%|█████████▋| 266/273 [07:07<00:10,  1.44s/it] 98%|█████████▊| 267/273 [07:09<00:08,  1.43s/it] 98%|█████████▊| 268/273 [07:10<00:07,  1.43s/it] 99%|█████████▊| 269/273 [07:12<00:05,  1.42s/it] 99%|█████████▉| 270/273 [07:13<00:04,  1.44s/it] 99%|█████████▉| 271/273 [07:15<00:02,  1.43s/it]100%|█████████▉| 272/273 [07:16<00:01,  1.43s/it]100%|██████████| 273/273 [07:17<00:00,  1.32s/it]{'eval_loss': 0.12033893167972565, 'eval_precision': 0.7835820895522388, 'eval_recall': 0.824607329842932, 'eval_f1': 0.8035714285714286, 'eval_accuracy': 0.9760032537960954, 'eval_runtime': 1.0128, 'eval_samples_per_second': 153.04, 'eval_steps_per_second': 4.937, 'epoch': 6.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.59it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.32it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.89it/s][A                                                 
                                             [A100%|██████████| 273/273 [07:18<00:00,  1.32s/it]
100%|██████████| 5/5 [00:00<00:00,  6.89it/s][A
                                             [A                                                 100%|██████████| 273/273 [07:26<00:00,  1.32s/it]100%|██████████| 273/273 [07:26<00:00,  1.63s/it]
[I 2025-09-20 14:49:34,628] Trial 13 finished with value: 3.4281400669967823 and parameters: {'learning_rate': 4.494501715080668e-05, 'num_train_epochs': 7, 'per_device_train_batch_size': 2, 'weight_decay': 1.222396149205397e-06, 'warmup_ratio': 0.19709207365718484, 'optimizer': 'Adafactor'}. Best is trial 9 with value: 3.4695526749403767.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▆▇▇███
wandb:                 eval/f1 ▁▆▇████
wandb:               eval/loss █▂▁▁▂▂▂
wandb:          eval/precision ▁▄▇▇▇▇█
wandb:             eval/recall ▁▇▇▇███
wandb:            eval/runtime █▁▁▁▄▁▁
wandb: eval/samples_per_second ▁███▅██
wandb:   eval/steps_per_second ▁███▅██
wandb:             train/epoch ▁▂▃▅▆▇██
wandb:       train/global_step ▁▂▃▅▆▇██
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.97749
wandb:                  eval/f1 0.8166
wandb:                eval/loss 0.12639
wandb:           eval/precision 0.83562
wandb:              eval/recall 0.79843
wandb:             eval/runtime 1.0116
wandb:  eval/samples_per_second 153.215
wandb:    eval/steps_per_second 4.942
wandb:               total_flos 2587044891308544.0
wandb:              train/epoch 7
wandb:        train/global_step 273
wandb:               train_loss 0.2407
wandb:            train_runtime 448.5366
wandb: train_samples_per_second 19.321
wandb:   train_steps_per_second 0.609
wandb: 
wandb: 🚀 View run toasty-dew-790 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/mc5eod65
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250920_144207-mc5eod65/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_144938-v9rm2juf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-lion-791
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/v9rm2juf
{'eval_loss': 0.12638992071151733, 'eval_precision': 0.8356164383561644, 'eval_recall': 0.7984293193717278, 'eval_f1': 0.8165997322623828, 'eval_accuracy': 0.9774945770065075, 'eval_runtime': 1.0116, 'eval_samples_per_second': 153.215, 'eval_steps_per_second': 4.942, 'epoch': 7.0}
{'train_runtime': 448.5366, 'train_samples_per_second': 19.321, 'train_steps_per_second': 0.609, 'train_loss': 0.24070289807441908, 'epoch': 7.0}
  0%|          | 0/400 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/400 [00:01<09:58,  1.50s/it]  0%|          | 2/400 [00:02<09:55,  1.50s/it]  1%|          | 3/400 [00:04<09:50,  1.49s/it]  1%|          | 4/400 [00:05<09:47,  1.48s/it]  1%|▏         | 5/400 [00:07<09:54,  1.50s/it]  2%|▏         | 6/400 [00:08<09:48,  1.49s/it]  2%|▏         | 7/400 [00:10<09:43,  1.49s/it]  2%|▏         | 8/400 [00:11<09:40,  1.48s/it]  2%|▏         | 9/400 [00:13<09:38,  1.48s/it]  2%|▎         | 10/400 [00:14<09:46,  1.50s/it]  3%|▎         | 11/400 [00:16<09:39,  1.49s/it]  3%|▎         | 12/400 [00:17<09:35,  1.48s/it]  3%|▎         | 13/400 [00:19<09:32,  1.48s/it]  4%|▎         | 14/400 [00:20<09:30,  1.48s/it]  4%|▍         | 15/400 [00:22<09:35,  1.50s/it]  4%|▍         | 16/400 [00:23<09:31,  1.49s/it]  4%|▍         | 17/400 [00:25<09:28,  1.48s/it]  4%|▍         | 18/400 [00:26<09:25,  1.48s/it]  5%|▍         | 19/400 [00:28<09:23,  1.48s/it]  5%|▌         | 20/400 [00:29<08:03,  1.27s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00,  8.50it/s][A
 60%|██████    | 3/5 [00:00<00:00,  7.09it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.55it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.32it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A  5%|▌         | 20/400 [00:30<08:03,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.32it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  5%|▌         | 21/400 [00:38<23:46,  3.76s/it]  6%|▌         | 22/400 [00:40<19:21,  3.07s/it]  6%|▌         | 23/400 [00:41<16:16,  2.59s/it]  6%|▌         | 24/400 [00:43<14:17,  2.28s/it]  6%|▋         | 25/400 [00:44<12:43,  2.04s/it]  6%|▋         | 26/400 [00:46<11:38,  1.87s/it]  7%|▋         | 27/400 [00:47<10:50,  1.75s/it]  7%|▋         | 28/400 [00:48<10:18,  1.66s/it]  7%|▋         | 29/400 [00:50<10:04,  1.63s/it]  8%|▊         | 30/400 [00:51<09:44,  1.58s/it]  8%|▊         | 31/400 [00:53<09:31,  1.55s/it]  8%|▊         | 32/400 [00:54<09:20,  1.52s/it]  8%|▊         | 33/400 [00:56<09:12,  1.51s/it]  8%|▊         | 34/400 [00:57<09:16,  1.52s/it]  9%|▉         | 35/400 [00:59<09:09,  1.51s/it]  9%|▉         | 36/400 [01:00<09:03,  1.49s/it]  9%|▉         | 37/400 [01:02<08:58,  1.48s/it] 10%|▉         | 38/400 [01:03<08:55,  1.48s/it] 10%|▉         | 39/400 [01:05<09:02,  1.50s/it] 10%|█         | 40/400 [01:06<07:36,  1.27s/it]{'eval_loss': 0.3227851986885071, 'eval_precision': 0.2313937753721245, 'eval_recall': 0.4476439790575916, 'eval_f1': 0.30508474576271183, 'eval_accuracy': 0.9065889370932755, 'eval_runtime': 1.0831, 'eval_samples_per_second': 143.102, 'eval_steps_per_second': 4.616, 'epoch': 1.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.60it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.31it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.84it/s][A                                                
                                             [A 10%|█         | 40/400 [01:07<07:36,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.84it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 10%|█         | 41/400 [01:14<21:06,  3.53s/it] 10%|█         | 42/400 [01:16<17:21,  2.91s/it] 11%|█         | 43/400 [01:17<14:50,  2.49s/it] 11%|█         | 44/400 [01:19<12:58,  2.19s/it] 11%|█▏        | 45/400 [01:20<11:40,  1.97s/it] 12%|█▏        | 46/400 [01:22<10:45,  1.82s/it] 12%|█▏        | 47/400 [01:23<10:07,  1.72s/it] 12%|█▏        | 48/400 [01:25<09:47,  1.67s/it] 12%|█▏        | 49/400 [01:26<09:24,  1.61s/it] 12%|█▎        | 50/400 [01:28<09:08,  1.57s/it] 13%|█▎        | 51/400 [01:29<08:58,  1.54s/it] 13%|█▎        | 52/400 [01:31<08:49,  1.52s/it] 13%|█▎        | 53/400 [01:32<08:50,  1.53s/it] 14%|█▎        | 54/400 [01:34<08:43,  1.51s/it] 14%|█▍        | 55/400 [01:35<08:38,  1.50s/it] 14%|█▍        | 56/400 [01:37<08:34,  1.50s/it] 14%|█▍        | 57/400 [01:38<08:31,  1.49s/it] 14%|█▍        | 58/400 [01:40<08:41,  1.53s/it] 15%|█▍        | 59/400 [01:41<08:34,  1.51s/it] 15%|█▌        | 60/400 [01:42<07:13,  1.27s/it]{'eval_loss': 0.12936265766620636, 'eval_precision': 0.6093023255813953, 'eval_recall': 0.6858638743455497, 'eval_f1': 0.645320197044335, 'eval_accuracy': 0.9654284164859002, 'eval_runtime': 1.0155, 'eval_samples_per_second': 152.631, 'eval_steps_per_second': 4.924, 'epoch': 2.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.59it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A                                                
                                             [A 15%|█▌        | 60/400 [01:43<07:13,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 15%|█▌        | 61/400 [01:51<20:17,  3.59s/it] 16%|█▌        | 62/400 [01:53<16:45,  2.97s/it] 16%|█▌        | 63/400 [01:54<14:11,  2.53s/it] 16%|█▌        | 64/400 [01:55<12:22,  2.21s/it] 16%|█▋        | 65/400 [01:57<11:07,  1.99s/it] 16%|█▋        | 66/400 [01:58<10:14,  1.84s/it] 17%|█▋        | 67/400 [02:00<09:51,  1.78s/it] 17%|█▋        | 68/400 [02:02<09:20,  1.69s/it] 17%|█▋        | 69/400 [02:03<08:57,  1.62s/it] 18%|█▊        | 70/400 [02:05<08:41,  1.58s/it] 18%|█▊        | 71/400 [02:06<08:30,  1.55s/it] 18%|█▊        | 72/400 [02:08<08:27,  1.55s/it] 18%|█▊        | 73/400 [02:09<08:19,  1.53s/it] 18%|█▊        | 74/400 [02:10<08:13,  1.51s/it] 19%|█▉        | 75/400 [02:12<08:07,  1.50s/it] 19%|█▉        | 76/400 [02:13<08:04,  1.49s/it] 19%|█▉        | 77/400 [02:15<08:07,  1.51s/it] 20%|█▉        | 78/400 [02:16<08:03,  1.50s/it] 20%|█▉        | 79/400 [02:18<07:59,  1.49s/it] 20%|██        | 80/400 [02:19<06:43,  1.26s/it]{'eval_loss': 0.1017988845705986, 'eval_precision': 0.7077294685990339, 'eval_recall': 0.7670157068062827, 'eval_f1': 0.7361809045226132, 'eval_accuracy': 0.9718004338394793, 'eval_runtime': 1.0187, 'eval_samples_per_second': 152.149, 'eval_steps_per_second': 4.908, 'epoch': 3.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.62it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.31it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A                                                
                                             [A 20%|██        | 80/400 [02:20<06:43,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 20%|██        | 81/400 [02:28<19:50,  3.73s/it] 20%|██        | 82/400 [02:30<16:17,  3.07s/it] 21%|██        | 83/400 [02:31<13:42,  2.59s/it] 21%|██        | 84/400 [02:33<11:53,  2.26s/it] 21%|██▏       | 85/400 [02:34<10:38,  2.03s/it] 22%|██▏       | 86/400 [02:36<09:44,  1.86s/it] 22%|██▏       | 87/400 [02:37<09:12,  1.77s/it] 22%|██▏       | 88/400 [02:39<08:43,  1.68s/it] 22%|██▏       | 89/400 [02:40<08:22,  1.61s/it] 22%|██▎       | 90/400 [02:42<08:07,  1.57s/it] 23%|██▎       | 91/400 [02:43<08:01,  1.56s/it] 23%|██▎       | 92/400 [02:45<07:52,  1.53s/it] 23%|██▎       | 93/400 [02:46<07:45,  1.52s/it] 24%|██▎       | 94/400 [02:48<07:39,  1.50s/it] 24%|██▍       | 95/400 [02:49<07:35,  1.49s/it] 24%|██▍       | 96/400 [02:51<07:38,  1.51s/it] 24%|██▍       | 97/400 [02:52<07:33,  1.50s/it] 24%|██▍       | 98/400 [02:53<07:30,  1.49s/it] 25%|██▍       | 99/400 [02:55<07:27,  1.49s/it] 25%|██▌       | 100/400 [02:56<06:17,  1.26s/it]{'eval_loss': 0.11872095614671707, 'eval_precision': 0.8022922636103151, 'eval_recall': 0.7329842931937173, 'eval_f1': 0.7660738714090287, 'eval_accuracy': 0.9724783080260304, 'eval_runtime': 1.0101, 'eval_samples_per_second': 153.449, 'eval_steps_per_second': 4.95, 'epoch': 4.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.58it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.29it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A                                                 
                                             [A 25%|██▌       | 100/400 [02:57<06:17,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 25%|██▌       | 101/400 [03:05<18:56,  3.80s/it] 26%|██▌       | 102/400 [03:07<15:24,  3.10s/it] 26%|██▌       | 103/400 [03:08<12:57,  2.62s/it] 26%|██▌       | 104/400 [03:10<11:14,  2.28s/it] 26%|██▋       | 105/400 [03:11<10:00,  2.04s/it] 26%|██▋       | 106/400 [03:13<09:14,  1.89s/it] 27%|██▋       | 107/400 [03:14<08:36,  1.76s/it] 27%|██▋       | 108/400 [03:16<08:08,  1.67s/it] 27%|██▋       | 109/400 [03:17<07:49,  1.61s/it] 28%|██▊       | 110/400 [03:19<07:36,  1.57s/it] 28%|██▊       | 111/400 [03:20<07:30,  1.56s/it] 28%|██▊       | 112/400 [03:22<07:20,  1.53s/it] 28%|██▊       | 113/400 [03:23<07:14,  1.51s/it] 28%|██▊       | 114/400 [03:25<07:09,  1.50s/it] 29%|██▉       | 115/400 [03:26<07:05,  1.49s/it] 29%|██▉       | 116/400 [03:28<07:07,  1.51s/it] 29%|██▉       | 117/400 [03:29<07:03,  1.50s/it] 30%|██▉       | 118/400 [03:31<06:59,  1.49s/it] 30%|██▉       | 119/400 [03:32<06:57,  1.48s/it] 30%|███       | 120/400 [03:33<05:52,  1.26s/it]{'eval_loss': 0.12102429568767548, 'eval_precision': 0.7953367875647669, 'eval_recall': 0.8036649214659686, 'eval_f1': 0.7994791666666667, 'eval_accuracy': 0.9758676789587852, 'eval_runtime': 1.015, 'eval_samples_per_second': 152.713, 'eval_steps_per_second': 4.926, 'epoch': 5.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.56it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.43it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.26it/s][A                                                 
                                             [A 30%|███       | 120/400 [03:34<05:52,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.26it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 30%|███       | 121/400 [03:43<17:36,  3.79s/it] 30%|███       | 122/400 [03:44<14:19,  3.09s/it] 31%|███       | 123/400 [03:46<12:10,  2.64s/it] 31%|███       | 124/400 [03:47<10:30,  2.29s/it] 31%|███▏      | 125/400 [03:49<09:26,  2.06s/it] 32%|███▏      | 126/400 [03:50<08:35,  1.88s/it] 32%|███▏      | 127/400 [03:52<07:59,  1.76s/it] 32%|███▏      | 128/400 [03:53<07:34,  1.67s/it] 32%|███▏      | 129/400 [03:54<07:17,  1.61s/it] 32%|███▎      | 130/400 [03:56<07:09,  1.59s/it] 33%|███▎      | 131/400 [03:57<06:57,  1.55s/it] 33%|███▎      | 132/400 [03:59<06:49,  1.53s/it] 33%|███▎      | 133/400 [04:00<06:43,  1.51s/it] 34%|███▎      | 134/400 [04:02<06:38,  1.50s/it] 34%|███▍      | 135/400 [04:03<06:40,  1.51s/it] 34%|███▍      | 136/400 [04:05<06:36,  1.50s/it] 34%|███▍      | 137/400 [04:06<06:33,  1.50s/it] 34%|███▍      | 138/400 [04:08<06:32,  1.50s/it] 35%|███▍      | 139/400 [04:09<06:30,  1.50s/it] 35%|███▌      | 140/400 [04:10<05:34,  1.29s/it]{'eval_loss': 0.13252250850200653, 'eval_precision': 0.7892030848329049, 'eval_recall': 0.8036649214659686, 'eval_f1': 0.7963683527885862, 'eval_accuracy': 0.9754609544468547, 'eval_runtime': 1.0781, 'eval_samples_per_second': 143.767, 'eval_steps_per_second': 4.638, 'epoch': 6.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.59it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A                                                 
                                             [A 35%|███▌      | 140/400 [04:11<05:34,  1.29s/it]
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 35%|███▌      | 141/400 [04:20<16:06,  3.73s/it] 36%|███▌      | 142/400 [04:21<13:07,  3.05s/it] 36%|███▌      | 143/400 [04:23<11:02,  2.58s/it] 36%|███▌      | 144/400 [04:24<09:41,  2.27s/it] 36%|███▋      | 145/400 [04:26<08:37,  2.03s/it] 36%|███▋      | 146/400 [04:27<07:53,  1.86s/it] 37%|███▋      | 147/400 [04:29<07:21,  1.75s/it] 37%|███▋      | 148/400 [04:30<06:58,  1.66s/it] 37%|███▋      | 149/400 [04:32<06:48,  1.63s/it] 38%|███▊      | 150/400 [04:33<06:36,  1.58s/it] 38%|███▊      | 151/400 [04:34<06:26,  1.55s/it] 38%|███▊      | 152/400 [04:36<06:18,  1.53s/it] 38%|███▊      | 153/400 [04:37<06:13,  1.51s/it] 38%|███▊      | 154/400 [04:39<06:15,  1.53s/it] 39%|███▉      | 155/400 [04:40<06:09,  1.51s/it] 39%|███▉      | 156/400 [04:42<06:05,  1.50s/it] 39%|███▉      | 157/400 [04:43<06:02,  1.49s/it] 40%|███▉      | 158/400 [04:45<05:59,  1.48s/it] 40%|███▉      | 159/400 [04:46<06:03,  1.51s/it] 40%|████      | 160/400 [04:47<05:05,  1.27s/it]{'eval_loss': 0.13861504197120667, 'eval_precision': 0.7657430730478589, 'eval_recall': 0.7958115183246073, 'eval_f1': 0.7804878048780487, 'eval_accuracy': 0.9732917570498916, 'eval_runtime': 1.0134, 'eval_samples_per_second': 152.948, 'eval_steps_per_second': 4.934, 'epoch': 7.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.58it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.34it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.89it/s][A                                                 
                                             [A 40%|████      | 160/400 [04:48<05:05,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.89it/s][A
                                             [A                                                  40%|████      | 160/400 [04:56<05:05,  1.27s/it] 40%|████      | 160/400 [04:56<07:24,  1.85s/it]
[I 2025-09-20 14:54:35,924] Trial 14 finished with value: 3.370605097975689 and parameters: {'learning_rate': 4.920276778426311e-05, 'num_train_epochs': 20, 'per_device_train_batch_size': 4, 'weight_decay': 1.565201451502416e-05, 'warmup_ratio': 0.002066990472469603, 'optimizer': 'Adafactor'}. Best is trial 9 with value: 3.4695526749403767.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▇██████
wandb:                 eval/f1 ▁▆▇█████
wandb:               eval/loss █▂▁▂▂▂▂▃
wandb:          eval/precision ▁▆▇█████
wandb:             eval/recall ▁▅▇▆██▇█
wandb:            eval/runtime █▂▂▁▁█▁▁
wandb: eval/samples_per_second ▁▇▇██▁██
wandb:   eval/steps_per_second ▁▇▇█▇▁██
wandb:             train/epoch ▁▂▃▄▅▆▇██
wandb:       train/global_step ▁▂▃▄▅▆▇██
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.97356
wandb:                  eval/f1 0.79848
wandb:                eval/loss 0.16564
wandb:           eval/precision 0.77396
wandb:              eval/recall 0.82461
wandb:             eval/runtime 1.0124
wandb:  eval/samples_per_second 153.098
wandb:    eval/steps_per_second 4.939
wandb:               total_flos 2299595458940928.0
wandb:              train/epoch 8
wandb:        train/global_step 160
wandb:               train_loss 0.15071
wandb:            train_runtime 298.6468
wandb: train_samples_per_second 82.907
wandb:   train_steps_per_second 1.339
wandb: 
wandb: 🚀 View run royal-lion-791 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/v9rm2juf
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250920_144938-v9rm2juf/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_145439-z20cj04q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-yogurt-792
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/z20cj04q
{'eval_loss': 0.1656433343887329, 'eval_precision': 0.773955773955774, 'eval_recall': 0.824607329842932, 'eval_f1': 0.7984790874524714, 'eval_accuracy': 0.973562906724512, 'eval_runtime': 1.0124, 'eval_samples_per_second': 153.098, 'eval_steps_per_second': 4.939, 'epoch': 8.0}
{'train_runtime': 298.6468, 'train_samples_per_second': 82.907, 'train_steps_per_second': 1.339, 'train_loss': 0.15070669651031493, 'epoch': 8.0}
  0%|          | 0/390 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/390 [00:01<09:52,  1.52s/it]  1%|          | 2/390 [00:02<09:30,  1.47s/it]  1%|          | 3/390 [00:04<09:18,  1.44s/it]  1%|          | 4/390 [00:05<09:10,  1.43s/it]  1%|▏         | 5/390 [00:07<09:14,  1.44s/it]  2%|▏         | 6/390 [00:08<09:07,  1.43s/it]  2%|▏         | 7/390 [00:10<09:04,  1.42s/it]  2%|▏         | 8/390 [00:11<09:00,  1.41s/it]  2%|▏         | 9/390 [00:12<08:57,  1.41s/it]  3%|▎         | 10/390 [00:14<09:01,  1.43s/it]  3%|▎         | 11/390 [00:15<08:57,  1.42s/it]  3%|▎         | 12/390 [00:17<08:54,  1.41s/it]  3%|▎         | 13/390 [00:18<08:52,  1.41s/it]  4%|▎         | 14/390 [00:19<08:50,  1.41s/it]  4%|▍         | 15/390 [00:21<08:54,  1.43s/it]  4%|▍         | 16/390 [00:22<08:50,  1.42s/it]  4%|▍         | 17/390 [00:24<08:47,  1.41s/it]  5%|▍         | 18/390 [00:25<08:49,  1.42s/it]  5%|▍         | 19/390 [00:27<08:51,  1.43s/it]  5%|▌         | 20/390 [00:28<08:55,  1.45s/it]  5%|▌         | 21/390 [00:29<08:49,  1.43s/it]  6%|▌         | 22/390 [00:31<08:44,  1.42s/it]  6%|▌         | 23/390 [00:32<08:40,  1.42s/it]  6%|▌         | 24/390 [00:34<08:37,  1.41s/it]  6%|▋         | 25/390 [00:35<08:41,  1.43s/it]  7%|▋         | 26/390 [00:37<08:36,  1.42s/it]  7%|▋         | 27/390 [00:38<08:33,  1.41s/it]  7%|▋         | 28/390 [00:39<08:30,  1.41s/it]  7%|▋         | 29/390 [00:41<08:28,  1.41s/it]  8%|▊         | 30/390 [00:42<08:32,  1.42s/it]  8%|▊         | 31/390 [00:44<08:28,  1.42s/it]  8%|▊         | 32/390 [00:45<08:25,  1.41s/it]  8%|▊         | 33/390 [00:46<08:23,  1.41s/it]  9%|▊         | 34/390 [00:48<08:21,  1.41s/it]  9%|▉         | 35/390 [00:49<08:25,  1.42s/it]  9%|▉         | 36/390 [00:51<08:22,  1.42s/it]  9%|▉         | 37/390 [00:52<08:19,  1.41s/it] 10%|▉         | 38/390 [00:54<08:17,  1.41s/it] 10%|█         | 39/390 [00:55<07:38,  1.31s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00,  8.76it/s][A
 60%|██████    | 3/5 [00:00<00:00,  7.20it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.60it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.37it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 10%|█         | 39/390 [00:56<07:38,  1.31s/it]
100%|██████████| 5/5 [00:00<00:00,  6.37it/s][A
                                             [A 10%|█         | 39/390 [00:56<08:25,  1.44s/it]
[I 2025-09-20 14:55:35,801] Trial 15 pruned. 
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁
wandb:                 eval/f1 ▁
wandb:               eval/loss ▁
wandb:          eval/precision ▁
wandb:             eval/recall ▁
wandb:            eval/runtime ▁
wandb: eval/samples_per_second ▁
wandb:   eval/steps_per_second ▁
wandb:             train/epoch ▁
wandb:       train/global_step ▁
wandb: 
wandb: Run summary:
wandb:           eval/accuracy 0.9276
wandb:                 eval/f1 0
wandb:               eval/loss 0.39224
wandb:          eval/precision 0
wandb:             eval/recall 0
wandb:            eval/runtime 1.0691
wandb: eval/samples_per_second 144.982
wandb:   eval/steps_per_second 4.677
wandb:             train/epoch 1
wandb:       train/global_step 39
wandb: 
wandb: 🚀 View run valiant-yogurt-792 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/z20cj04q
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250920_145439-z20cj04q/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_145539-oy96ogd8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-plasma-793
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/oy96ogd8
{'eval_loss': 0.3922366797924042, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9276030368763557, 'eval_runtime': 1.0691, 'eval_samples_per_second': 144.982, 'eval_steps_per_second': 4.677, 'epoch': 1.0}
  0%|          | 0/300 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/300 [00:01<07:30,  1.51s/it]  1%|          | 2/300 [00:03<07:28,  1.51s/it]  1%|          | 3/300 [00:04<07:22,  1.49s/it]  1%|▏         | 4/300 [00:05<07:18,  1.48s/it]  2%|▏         | 5/300 [00:07<07:26,  1.51s/it]  2%|▏         | 6/300 [00:08<07:20,  1.50s/it]  2%|▏         | 7/300 [00:10<07:16,  1.49s/it]  3%|▎         | 8/300 [00:11<07:13,  1.48s/it]  3%|▎         | 9/300 [00:13<07:11,  1.48s/it]  3%|▎         | 10/300 [00:14<07:17,  1.51s/it]  4%|▎         | 11/300 [00:16<07:12,  1.50s/it]  4%|▍         | 12/300 [00:17<07:09,  1.49s/it]  4%|▍         | 13/300 [00:19<07:06,  1.49s/it]  5%|▍         | 14/300 [00:20<07:04,  1.48s/it]  5%|▌         | 15/300 [00:22<07:09,  1.51s/it]  5%|▌         | 16/300 [00:23<07:04,  1.50s/it]  6%|▌         | 17/300 [00:25<07:01,  1.49s/it]  6%|▌         | 18/300 [00:26<06:58,  1.48s/it]  6%|▋         | 19/300 [00:28<06:56,  1.48s/it]  7%|▋         | 20/300 [00:29<05:56,  1.27s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00,  7.70it/s][A
 60%|██████    | 3/5 [00:00<00:00,  6.74it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.37it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.24it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A  7%|▋         | 20/300 [00:30<05:56,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.24it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  7%|▋         | 21/300 [00:38<16:38,  3.58s/it]  7%|▋         | 22/300 [00:39<13:38,  2.94s/it]  8%|▊         | 23/300 [00:41<11:32,  2.50s/it]  8%|▊         | 24/300 [00:42<10:15,  2.23s/it]  8%|▊         | 25/300 [00:44<09:10,  2.00s/it]  9%|▊         | 26/300 [00:45<08:24,  1.84s/it]  9%|▉         | 27/300 [00:47<07:52,  1.73s/it]  9%|▉         | 28/300 [00:48<07:28,  1.65s/it] 10%|▉         | 29/300 [00:50<07:17,  1.61s/it] 10%|█         | 30/300 [00:51<07:03,  1.57s/it] 10%|█         | 31/300 [00:52<06:53,  1.54s/it] 11%|█         | 32/300 [00:54<06:46,  1.52s/it] 11%|█         | 33/300 [00:55<06:40,  1.50s/it] 11%|█▏        | 34/300 [00:57<06:48,  1.54s/it] 12%|█▏        | 35/300 [00:58<06:41,  1.52s/it] 12%|█▏        | 36/300 [01:00<06:35,  1.50s/it] 12%|█▏        | 37/300 [01:01<06:31,  1.49s/it] 13%|█▎        | 38/300 [01:03<06:30,  1.49s/it] 13%|█▎        | 39/300 [01:04<06:34,  1.51s/it] 13%|█▎        | 40/300 [01:05<05:32,  1.28s/it]{'eval_loss': 0.3761371374130249, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9276030368763557, 'eval_runtime': 1.0996, 'eval_samples_per_second': 140.964, 'eval_steps_per_second': 4.547, 'epoch': 1.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.62it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.21it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.75it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 13%|█▎        | 40/300 [01:06<05:32,  1.28s/it]
100%|██████████| 5/5 [00:00<00:00,  6.75it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 14%|█▎        | 41/300 [01:15<16:07,  3.74s/it] 14%|█▍        | 42/300 [01:16<13:08,  3.05s/it] 14%|█▍        | 43/300 [01:18<11:14,  2.63s/it] 15%|█▍        | 44/300 [01:19<09:43,  2.28s/it] 15%|█▌        | 45/300 [01:21<08:39,  2.04s/it] 15%|█▌        | 46/300 [01:22<07:54,  1.87s/it] 16%|█▌        | 47/300 [01:24<07:22,  1.75s/it] 16%|█▌        | 48/300 [01:25<07:04,  1.69s/it] 16%|█▋        | 49/300 [01:27<06:47,  1.62s/it] 17%|█▋        | 50/300 [01:28<06:34,  1.58s/it] 17%|█▋        | 51/300 [01:30<06:24,  1.55s/it] 17%|█▋        | 52/300 [01:31<06:17,  1.52s/it] 18%|█▊        | 53/300 [01:33<06:24,  1.56s/it] 18%|█▊        | 54/300 [01:34<06:17,  1.53s/it] 18%|█▊        | 55/300 [01:36<06:10,  1.51s/it] 19%|█▊        | 56/300 [01:37<06:06,  1.50s/it] 19%|█▉        | 57/300 [01:39<06:04,  1.50s/it] 19%|█▉        | 58/300 [01:40<06:06,  1.52s/it] 20%|█▉        | 59/300 [01:42<06:02,  1.50s/it] 20%|██        | 60/300 [01:42<05:05,  1.27s/it]{'eval_loss': 0.16943666338920593, 'eval_precision': 0.548926014319809, 'eval_recall': 0.6020942408376964, 'eval_f1': 0.5742821473158553, 'eval_accuracy': 0.9564804772234273, 'eval_runtime': 1.0234, 'eval_samples_per_second': 151.462, 'eval_steps_per_second': 4.886, 'epoch': 2.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.56it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.27it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.79it/s][A                                                
                                             [A 20%|██        | 60/300 [01:43<05:05,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.79it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 20%|██        | 61/300 [01:52<15:06,  3.79s/it] 21%|██        | 62/300 [01:54<12:20,  3.11s/it] 21%|██        | 63/300 [01:55<10:20,  2.62s/it] 21%|██▏       | 64/300 [01:56<08:56,  2.27s/it] 22%|██▏       | 65/300 [01:58<07:56,  2.03s/it] 22%|██▏       | 66/300 [01:59<07:15,  1.86s/it] 22%|██▏       | 67/300 [02:01<06:51,  1.77s/it] 23%|██▎       | 68/300 [02:02<06:29,  1.68s/it] 23%|██▎       | 69/300 [02:04<06:14,  1.62s/it] 23%|██▎       | 70/300 [02:05<06:03,  1.58s/it] 24%|██▎       | 71/300 [02:07<05:54,  1.55s/it] 24%|██▍       | 72/300 [02:08<05:52,  1.54s/it] 24%|██▍       | 73/300 [02:10<05:45,  1.52s/it] 25%|██▍       | 74/300 [02:11<05:40,  1.51s/it] 25%|██▌       | 75/300 [02:13<05:37,  1.50s/it] 25%|██▌       | 76/300 [02:14<05:34,  1.49s/it] 26%|██▌       | 77/300 [02:16<05:35,  1.51s/it] 26%|██▌       | 78/300 [02:17<05:33,  1.50s/it] 26%|██▋       | 79/300 [02:19<05:31,  1.50s/it] 27%|██▋       | 80/300 [02:20<04:39,  1.27s/it]{'eval_loss': 0.11881520599126816, 'eval_precision': 0.7164948453608248, 'eval_recall': 0.7277486910994765, 'eval_f1': 0.7220779220779221, 'eval_accuracy': 0.9711225596529284, 'eval_runtime': 1.0228, 'eval_samples_per_second': 151.551, 'eval_steps_per_second': 4.889, 'epoch': 3.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.59it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.32it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A                                                
                                             [A 27%|██▋       | 80/300 [02:21<04:39,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 27%|██▋       | 81/300 [02:29<13:34,  3.72s/it] 27%|██▋       | 82/300 [02:31<11:09,  3.07s/it] 28%|██▊       | 83/300 [02:32<09:22,  2.59s/it] 28%|██▊       | 84/300 [02:34<08:07,  2.26s/it] 28%|██▊       | 85/300 [02:35<07:14,  2.02s/it] 29%|██▊       | 86/300 [02:37<06:40,  1.87s/it] 29%|██▉       | 87/300 [02:38<06:12,  1.75s/it] 29%|██▉       | 88/300 [02:39<05:53,  1.67s/it] 30%|██▉       | 89/300 [02:41<05:38,  1.60s/it] 30%|███       | 90/300 [02:42<05:28,  1.56s/it] 30%|███       | 91/300 [02:44<05:28,  1.57s/it] 31%|███       | 92/300 [02:45<05:20,  1.54s/it] 31%|███       | 93/300 [02:47<05:14,  1.52s/it] 31%|███▏      | 94/300 [02:48<05:09,  1.50s/it] 32%|███▏      | 95/300 [02:50<05:05,  1.49s/it] 32%|███▏      | 96/300 [02:51<05:06,  1.50s/it] 32%|███▏      | 97/300 [02:53<05:02,  1.49s/it] 33%|███▎      | 98/300 [02:54<05:00,  1.49s/it] 33%|███▎      | 99/300 [02:56<04:57,  1.48s/it] 33%|███▎      | 100/300 [02:56<04:10,  1.25s/it]{'eval_loss': 0.13500970602035522, 'eval_precision': 0.8147058823529412, 'eval_recall': 0.725130890052356, 'eval_f1': 0.7673130193905816, 'eval_accuracy': 0.972885032537961, 'eval_runtime': 1.0131, 'eval_samples_per_second': 152.999, 'eval_steps_per_second': 4.935, 'epoch': 4.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.53it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.31it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A                                                 
                                             [A 33%|███▎      | 100/300 [02:58<04:10,  1.25s/it]
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 34%|███▎      | 101/300 [03:06<12:41,  3.83s/it] 34%|███▍      | 102/300 [03:08<10:17,  3.12s/it] 34%|███▍      | 103/300 [03:09<08:36,  2.62s/it] 35%|███▍      | 104/300 [03:11<07:25,  2.28s/it] 35%|███▌      | 105/300 [03:12<06:36,  2.03s/it] 35%|███▌      | 106/300 [03:14<06:05,  1.88s/it] 36%|███▌      | 107/300 [03:15<05:39,  1.76s/it] 36%|███▌      | 108/300 [03:17<05:20,  1.67s/it] 36%|███▋      | 109/300 [03:18<05:07,  1.61s/it] 37%|███▋      | 110/300 [03:20<04:57,  1.57s/it] 37%|███▋      | 111/300 [03:21<04:58,  1.58s/it] 37%|███▋      | 112/300 [03:23<04:50,  1.55s/it] 38%|███▊      | 113/300 [03:24<04:46,  1.53s/it] 38%|███▊      | 114/300 [03:26<04:41,  1.51s/it] 38%|███▊      | 115/300 [03:27<04:37,  1.50s/it] 39%|███▊      | 116/300 [03:29<04:38,  1.51s/it] 39%|███▉      | 117/300 [03:30<04:34,  1.50s/it] 39%|███▉      | 118/300 [03:32<04:30,  1.49s/it] 40%|███▉      | 119/300 [03:33<04:28,  1.48s/it] 40%|████      | 120/300 [03:34<03:45,  1.25s/it]{'eval_loss': 0.11723297089338303, 'eval_precision': 0.8159340659340659, 'eval_recall': 0.7774869109947644, 'eval_f1': 0.7962466487935657, 'eval_accuracy': 0.9754609544468547, 'eval_runtime': 1.0134, 'eval_samples_per_second': 152.953, 'eval_steps_per_second': 4.934, 'epoch': 5.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.53it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.37it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.26it/s][A                                                 
                                             [A 40%|████      | 120/300 [03:35<03:45,  1.25s/it]
100%|██████████| 5/5 [00:00<00:00,  6.26it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 40%|████      | 121/300 [03:44<11:20,  3.80s/it] 41%|████      | 122/300 [03:45<09:12,  3.10s/it] 41%|████      | 123/300 [03:46<07:42,  2.62s/it] 41%|████▏     | 124/300 [03:48<06:40,  2.28s/it] 42%|████▏     | 125/300 [03:49<06:00,  2.06s/it] 42%|████▏     | 126/300 [03:51<05:28,  1.89s/it] 42%|████▏     | 127/300 [03:52<05:05,  1.76s/it] 43%|████▎     | 128/300 [03:54<04:48,  1.68s/it] 43%|████▎     | 129/300 [03:55<04:36,  1.62s/it] 43%|████▎     | 130/300 [03:57<04:31,  1.60s/it] 44%|████▎     | 131/300 [03:58<04:24,  1.56s/it] 44%|████▍     | 132/300 [04:00<04:18,  1.54s/it] 44%|████▍     | 133/300 [04:01<04:14,  1.52s/it] 45%|████▍     | 134/300 [04:03<04:10,  1.51s/it] 45%|████▌     | 135/300 [04:04<04:11,  1.52s/it] 45%|████▌     | 136/300 [04:06<04:06,  1.51s/it] 46%|████▌     | 137/300 [04:07<04:03,  1.49s/it] 46%|████▌     | 138/300 [04:09<04:01,  1.49s/it] 46%|████▋     | 139/300 [04:10<03:59,  1.49s/it] 47%|████▋     | 140/300 [04:11<03:21,  1.26s/it]{'eval_loss': 0.13876432180404663, 'eval_precision': 0.8010899182561307, 'eval_recall': 0.7696335078534031, 'eval_f1': 0.7850467289719626, 'eval_accuracy': 0.9726138828633406, 'eval_runtime': 1.0809, 'eval_samples_per_second': 143.402, 'eval_steps_per_second': 4.626, 'epoch': 6.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.59it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.29it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A                                                 
                                             [A 47%|████▋     | 140/300 [04:12<03:21,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 47%|████▋     | 141/300 [04:20<09:24,  3.55s/it] 47%|████▋     | 142/300 [04:21<07:41,  2.92s/it] 48%|████▊     | 143/300 [04:23<06:30,  2.49s/it] 48%|████▊     | 144/300 [04:24<05:44,  2.21s/it] 48%|████▊     | 145/300 [04:26<05:08,  1.99s/it] 49%|████▊     | 146/300 [04:27<04:42,  1.83s/it] 49%|████▉     | 147/300 [04:29<04:23,  1.72s/it] 49%|████▉     | 148/300 [04:30<04:10,  1.65s/it] 50%|████▉     | 149/300 [04:32<04:05,  1.63s/it] 50%|█████     | 150/300 [04:33<03:56,  1.58s/it] 50%|█████     | 151/300 [04:35<03:50,  1.55s/it] 51%|█████     | 152/300 [04:36<03:45,  1.52s/it] 51%|█████     | 153/300 [04:38<03:41,  1.51s/it] 51%|█████▏    | 154/300 [04:39<03:42,  1.52s/it] 52%|█████▏    | 155/300 [04:41<03:39,  1.51s/it] 52%|█████▏    | 156/300 [04:42<03:35,  1.50s/it] 52%|█████▏    | 157/300 [04:44<03:33,  1.49s/it] 53%|█████▎    | 158/300 [04:45<03:31,  1.49s/it] 53%|█████▎    | 159/300 [04:47<03:33,  1.51s/it] 53%|█████▎    | 160/300 [04:48<02:58,  1.28s/it]{'eval_loss': 0.13580511510372162, 'eval_precision': 0.8211382113821138, 'eval_recall': 0.7931937172774869, 'eval_f1': 0.8069241011984022, 'eval_accuracy': 0.9750542299349241, 'eval_runtime': 1.1659, 'eval_samples_per_second': 132.948, 'eval_steps_per_second': 4.289, 'epoch': 7.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.59it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.27it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.84it/s][A                                                 
                                             [A 53%|█████▎    | 160/300 [04:49<02:58,  1.28s/it]
100%|██████████| 5/5 [00:00<00:00,  6.84it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 54%|█████▎    | 161/300 [04:57<08:20,  3.60s/it] 54%|█████▍    | 162/300 [04:58<06:48,  2.96s/it] 54%|█████▍    | 163/300 [05:00<05:46,  2.53s/it] 55%|█████▍    | 164/300 [05:01<05:01,  2.21s/it] 55%|█████▌    | 165/300 [05:03<04:28,  1.99s/it] 55%|█████▌    | 166/300 [05:04<04:06,  1.84s/it] 56%|█████▌    | 167/300 [05:05<03:49,  1.73s/it] 56%|█████▌    | 168/300 [05:07<03:40,  1.67s/it] 56%|█████▋    | 169/300 [05:08<03:32,  1.62s/it] 57%|█████▋    | 170/300 [05:10<03:25,  1.58s/it] 57%|█████▋    | 171/300 [05:11<03:20,  1.55s/it] 57%|█████▋    | 172/300 [05:13<03:15,  1.53s/it] 58%|█████▊    | 173/300 [05:14<03:14,  1.53s/it] 58%|█████▊    | 174/300 [05:16<03:10,  1.51s/it] 58%|█████▊    | 175/300 [05:17<03:07,  1.50s/it] 59%|█████▊    | 176/300 [05:19<03:04,  1.49s/it] 59%|█████▉    | 177/300 [05:20<03:02,  1.48s/it] 59%|█████▉    | 178/300 [05:22<03:02,  1.50s/it] 60%|█████▉    | 179/300 [05:23<03:00,  1.49s/it] 60%|██████    | 180/300 [05:24<02:31,  1.26s/it]{'eval_loss': 0.15913747251033783, 'eval_precision': 0.8243626062322946, 'eval_recall': 0.7617801047120419, 'eval_f1': 0.7918367346938777, 'eval_accuracy': 0.9734273318872018, 'eval_runtime': 1.0153, 'eval_samples_per_second': 152.665, 'eval_steps_per_second': 4.925, 'epoch': 8.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.62it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.28it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A                                                 
                                             [A 60%|██████    | 180/300 [05:25<02:31,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 60%|██████    | 181/300 [05:34<07:30,  3.78s/it] 61%|██████    | 182/300 [05:35<06:04,  3.09s/it] 61%|██████    | 183/300 [05:37<05:06,  2.62s/it] 61%|██████▏   | 184/300 [05:38<04:24,  2.28s/it] 62%|██████▏   | 185/300 [05:40<03:54,  2.04s/it] 62%|██████▏   | 186/300 [05:41<03:32,  1.87s/it] 62%|██████▏   | 187/300 [05:43<03:17,  1.75s/it] 63%|██████▎   | 188/300 [05:44<03:09,  1.69s/it] 63%|██████▎   | 189/300 [05:46<03:01,  1.63s/it] 63%|██████▎   | 190/300 [05:47<02:54,  1.59s/it] 64%|██████▎   | 191/300 [05:49<02:49,  1.55s/it] 64%|██████▍   | 192/300 [05:50<02:45,  1.53s/it] 64%|██████▍   | 193/300 [05:52<02:43,  1.53s/it] 65%|██████▍   | 194/300 [05:53<02:40,  1.51s/it] 65%|██████▌   | 195/300 [05:55<02:37,  1.50s/it] 65%|██████▌   | 196/300 [05:56<02:34,  1.49s/it] 66%|██████▌   | 197/300 [05:58<02:32,  1.48s/it] 66%|██████▌   | 198/300 [05:59<02:32,  1.49s/it] 66%|██████▋   | 199/300 [06:01<02:30,  1.49s/it] 67%|██████▋   | 200/300 [06:01<02:05,  1.26s/it]{'eval_loss': 0.13082054257392883, 'eval_precision': 0.8072916666666666, 'eval_recall': 0.8115183246073299, 'eval_f1': 0.8093994778067886, 'eval_accuracy': 0.9781724511930586, 'eval_runtime': 1.0188, 'eval_samples_per_second': 152.141, 'eval_steps_per_second': 4.908, 'epoch': 9.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.53it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A                                                 
                                             [A 67%|██████▋   | 200/300 [06:02<02:05,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 67%|██████▋   | 201/300 [06:11<06:03,  3.67s/it] 67%|██████▋   | 202/300 [06:12<04:57,  3.04s/it] 68%|██████▊   | 203/300 [06:14<04:09,  2.58s/it] 68%|██████▊   | 204/300 [06:15<03:35,  2.24s/it] 68%|██████▊   | 205/300 [06:17<03:10,  2.01s/it] 69%|██████▊   | 206/300 [06:18<02:53,  1.85s/it] 69%|██████▉   | 207/300 [06:20<02:43,  1.75s/it] 69%|██████▉   | 208/300 [06:21<02:33,  1.67s/it] 70%|██████▉   | 209/300 [06:22<02:26,  1.61s/it] 70%|███████   | 210/300 [06:24<02:20,  1.56s/it] 70%|███████   | 211/300 [06:25<02:16,  1.53s/it] 71%|███████   | 212/300 [06:27<02:14,  1.53s/it] 71%|███████   | 213/300 [06:28<02:11,  1.51s/it] 71%|███████▏  | 214/300 [06:30<02:08,  1.50s/it] 72%|███████▏  | 215/300 [06:31<02:06,  1.49s/it] 72%|███████▏  | 216/300 [06:33<02:05,  1.50s/it] 72%|███████▏  | 217/300 [06:34<02:03,  1.49s/it] 73%|███████▎  | 218/300 [06:36<02:01,  1.48s/it] 73%|███████▎  | 219/300 [06:37<01:59,  1.48s/it] 73%|███████▎  | 220/300 [06:38<01:39,  1.25s/it]{'eval_loss': 0.1328335404396057, 'eval_precision': 0.8184210526315789, 'eval_recall': 0.8141361256544503, 'eval_f1': 0.816272965879265, 'eval_accuracy': 0.9789859002169198, 'eval_runtime': 1.0139, 'eval_samples_per_second': 152.88, 'eval_steps_per_second': 4.932, 'epoch': 10.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.61it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.30it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A                                                 
                                             [A 73%|███████▎  | 220/300 [06:39<01:39,  1.25s/it]
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 74%|███████▎  | 221/300 [06:47<04:52,  3.71s/it] 74%|███████▍  | 222/300 [06:49<03:56,  3.04s/it] 74%|███████▍  | 223/300 [06:50<03:17,  2.57s/it] 75%|███████▍  | 224/300 [06:52<02:50,  2.24s/it] 75%|███████▌  | 225/300 [06:53<02:30,  2.01s/it] 75%|███████▌  | 226/300 [06:55<02:19,  1.88s/it] 76%|███████▌  | 227/300 [06:56<02:08,  1.76s/it] 76%|███████▌  | 228/300 [06:58<02:00,  1.67s/it] 76%|███████▋  | 229/300 [06:59<01:54,  1.61s/it] 77%|███████▋  | 230/300 [07:01<01:51,  1.59s/it] 77%|███████▋  | 231/300 [07:02<01:47,  1.56s/it] 77%|███████▋  | 232/300 [07:04<01:44,  1.53s/it] 78%|███████▊  | 233/300 [07:05<01:41,  1.51s/it] 78%|███████▊  | 234/300 [07:07<01:38,  1.50s/it] 78%|███████▊  | 235/300 [07:08<01:39,  1.53s/it] 79%|███████▊  | 236/300 [07:10<01:36,  1.51s/it] 79%|███████▉  | 237/300 [07:11<01:34,  1.50s/it] 79%|███████▉  | 238/300 [07:13<01:32,  1.49s/it] 80%|███████▉  | 239/300 [07:14<01:30,  1.48s/it] 80%|████████  | 240/300 [07:15<01:15,  1.26s/it]{'eval_loss': 0.1371660828590393, 'eval_precision': 0.8285714285714286, 'eval_recall': 0.8350785340314136, 'eval_f1': 0.8318122555410692, 'eval_accuracy': 0.9796637744034707, 'eval_runtime': 1.0142, 'eval_samples_per_second': 152.824, 'eval_steps_per_second': 4.93, 'epoch': 11.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00,  7.73it/s][A
 60%|██████    | 3/5 [00:00<00:00,  6.75it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.36it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.25it/s][A                                                 
                                             [A 80%|████████  | 240/300 [07:16<01:15,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.25it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 80%|████████  | 241/300 [07:24<03:25,  3.48s/it] 81%|████████  | 242/300 [07:25<02:47,  2.88s/it] 81%|████████  | 243/300 [07:27<02:20,  2.47s/it] 81%|████████▏ | 244/300 [07:28<02:01,  2.17s/it] 82%|████████▏ | 245/300 [07:30<01:48,  1.98s/it] 82%|████████▏ | 246/300 [07:31<01:38,  1.82s/it] 82%|████████▏ | 247/300 [07:33<01:30,  1.72s/it] 83%|████████▎ | 248/300 [07:34<01:25,  1.64s/it] 83%|████████▎ | 249/300 [07:35<01:20,  1.59s/it] 83%|████████▎ | 250/300 [07:37<01:18,  1.57s/it] 84%|████████▎ | 251/300 [07:38<01:15,  1.54s/it] 84%|████████▍ | 252/300 [07:40<01:12,  1.51s/it] 84%|████████▍ | 253/300 [07:41<01:10,  1.50s/it] 85%|████████▍ | 254/300 [07:43<01:08,  1.49s/it] 85%|████████▌ | 255/300 [07:44<01:07,  1.50s/it] 85%|████████▌ | 256/300 [07:46<01:05,  1.49s/it] 86%|████████▌ | 257/300 [07:47<01:03,  1.48s/it] 86%|████████▌ | 258/300 [07:49<01:02,  1.48s/it] 86%|████████▋ | 259/300 [07:50<01:00,  1.48s/it] 87%|████████▋ | 260/300 [07:51<00:50,  1.27s/it]{'eval_loss': 0.14959104359149933, 'eval_precision': 0.8209718670076727, 'eval_recall': 0.8403141361256544, 'eval_f1': 0.8305304010349289, 'eval_accuracy': 0.9779013015184381, 'eval_runtime': 1.0997, 'eval_samples_per_second': 140.949, 'eval_steps_per_second': 4.547, 'epoch': 12.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.60it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.29it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.90it/s][A                                                 
                                             [A 87%|████████▋ | 260/300 [07:52<00:50,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.90it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 87%|████████▋ | 261/300 [08:00<02:24,  3.72s/it] 87%|████████▋ | 262/300 [08:02<01:55,  3.05s/it] 88%|████████▊ | 263/300 [08:03<01:35,  2.58s/it] 88%|████████▊ | 264/300 [08:05<01:21,  2.26s/it] 88%|████████▊ | 265/300 [08:06<01:10,  2.02s/it] 89%|████████▊ | 266/300 [08:08<01:03,  1.85s/it] 89%|████████▉ | 267/300 [08:09<00:57,  1.74s/it] 89%|████████▉ | 268/300 [08:11<00:52,  1.66s/it] 90%|████████▉ | 269/300 [08:12<00:50,  1.61s/it] 90%|█████████ | 270/300 [08:14<00:47,  1.57s/it] 90%|█████████ | 271/300 [08:15<00:44,  1.54s/it] 91%|█████████ | 272/300 [08:17<00:42,  1.52s/it] 91%|█████████ | 273/300 [08:18<00:40,  1.51s/it] 91%|█████████▏| 274/300 [08:20<00:39,  1.51s/it] 92%|█████████▏| 275/300 [08:21<00:37,  1.50s/it] 92%|█████████▏| 276/300 [08:23<00:35,  1.49s/it] 92%|█████████▏| 277/300 [08:24<00:34,  1.48s/it] 93%|█████████▎| 278/300 [08:26<00:32,  1.48s/it] 93%|█████████▎| 279/300 [08:27<00:31,  1.49s/it] 93%|█████████▎| 280/300 [08:28<00:25,  1.26s/it]{'eval_loss': 0.16582559049129486, 'eval_precision': 0.8260869565217391, 'eval_recall': 0.8455497382198953, 'eval_f1': 0.8357050452781372, 'eval_accuracy': 0.9792570498915402, 'eval_runtime': 1.011, 'eval_samples_per_second': 153.314, 'eval_steps_per_second': 4.946, 'epoch': 13.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.59it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.32it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A                                                 
                                             [A 93%|█████████▎| 280/300 [08:29<00:25,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 94%|█████████▎| 281/300 [08:37<01:09,  3.64s/it] 94%|█████████▍| 282/300 [08:39<00:53,  3.00s/it] 94%|█████████▍| 283/300 [08:40<00:43,  2.56s/it] 95%|█████████▍| 284/300 [08:42<00:35,  2.23s/it] 95%|█████████▌| 285/300 [08:43<00:30,  2.00s/it] 95%|█████████▌| 286/300 [08:44<00:25,  1.84s/it] 96%|█████████▌| 287/300 [08:46<00:22,  1.73s/it] 96%|█████████▌| 288/300 [08:47<00:20,  1.67s/it] 96%|█████████▋| 289/300 [08:49<00:17,  1.61s/it] 97%|█████████▋| 290/300 [08:50<00:15,  1.57s/it] 97%|█████████▋| 291/300 [08:52<00:13,  1.54s/it] 97%|█████████▋| 292/300 [08:53<00:12,  1.52s/it] 98%|█████████▊| 293/300 [08:55<00:10,  1.52s/it] 98%|█████████▊| 294/300 [08:56<00:09,  1.51s/it] 98%|█████████▊| 295/300 [08:58<00:07,  1.50s/it] 99%|█████████▊| 296/300 [08:59<00:05,  1.49s/it] 99%|█████████▉| 297/300 [09:01<00:04,  1.48s/it] 99%|█████████▉| 298/300 [09:02<00:02,  1.50s/it]100%|█████████▉| 299/300 [09:04<00:01,  1.49s/it]100%|██████████| 300/300 [09:04<00:00,  1.26s/it]{'eval_loss': 0.16165080666542053, 'eval_precision': 0.835509138381201, 'eval_recall': 0.837696335078534, 'eval_f1': 0.8366013071895424, 'eval_accuracy': 0.9795281995661606, 'eval_runtime': 1.0138, 'eval_samples_per_second': 152.888, 'eval_steps_per_second': 4.932, 'epoch': 14.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.56it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.27it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.84it/s][A                                                 
                                             [A100%|██████████| 300/300 [09:06<00:00,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.84it/s][A
                                             [A                                                 100%|██████████| 300/300 [09:14<00:00,  1.26s/it]100%|██████████| 300/300 [09:14<00:00,  1.85s/it]
[I 2025-09-20 15:04:54,376] Trial 16 finished with value: 3.5065526296811678 and parameters: {'learning_rate': 7.005425687793712e-05, 'num_train_epochs': 15, 'per_device_train_batch_size': 4, 'weight_decay': 7.95137550895256e-06, 'warmup_ratio': 0.1342717579616191, 'optimizer': 'Adafactor'}. Best is trial 16 with value: 3.5065526296811678.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▅▇▇▇▇▇▇███████
wandb:                 eval/f1 ▁▆▇▇███████████
wandb:               eval/loss █▂▁▁▁▂▂▂▁▁▂▂▂▂▂
wandb:          eval/precision ▁▆▇████████████
wandb:             eval/recall ▁▆▇▇▇▇█▇███████
wandb:            eval/runtime ▅▂▂▁▁▄█▁▁▁▁▅▁▁▁
wandb: eval/samples_per_second ▄▇▇██▅▁████▄███
wandb:   eval/steps_per_second ▄▇▇██▅▁████▄███
wandb:             train/epoch ▁▁▂▃▃▃▄▅▅▅▆▇▇▇██
wandb:       train/global_step ▁▁▂▃▃▃▄▅▅▅▆▇▇▇██
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.9798
wandb:                  eval/f1 0.84224
wandb:                eval/loss 0.16368
wandb:           eval/precision 0.83896
wandb:              eval/recall 0.84555
wandb:             eval/runtime 1.0157
wandb:  eval/samples_per_second 152.605
wandb:    eval/steps_per_second 4.923
wandb:               total_flos 4599190917881856.0
wandb:              train/epoch 15
wandb:        train/global_step 300
wandb:               train_loss 0.1567
wandb:            train_runtime 556.7216
wandb: train_samples_per_second 33.356
wandb:   train_steps_per_second 0.539
wandb: 
wandb: 🚀 View run expert-plasma-793 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/oy96ogd8
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250920_145539-oy96ogd8/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_150457-l40az4g1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-tree-794
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/l40az4g1
{'eval_loss': 0.16367612779140472, 'eval_precision': 0.8389610389610389, 'eval_recall': 0.8455497382198953, 'eval_f1': 0.8422425032594524, 'eval_accuracy': 0.9797993492407809, 'eval_runtime': 1.0157, 'eval_samples_per_second': 152.605, 'eval_steps_per_second': 4.923, 'epoch': 15.0}
{'train_runtime': 556.7216, 'train_samples_per_second': 33.356, 'train_steps_per_second': 0.539, 'train_loss': 0.15670345306396485, 'epoch': 15.0}
  0%|          | 0/546 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/546 [00:01<13:55,  1.53s/it]  0%|          | 2/546 [00:02<13:22,  1.47s/it]  1%|          | 3/546 [00:04<13:03,  1.44s/it]  1%|          | 4/546 [00:05<12:55,  1.43s/it]  1%|          | 5/546 [00:07<13:05,  1.45s/it]  1%|          | 6/546 [00:08<12:56,  1.44s/it]  1%|▏         | 7/546 [00:10<12:51,  1.43s/it]  1%|▏         | 8/546 [00:11<12:48,  1.43s/it]  2%|▏         | 9/546 [00:12<12:45,  1.43s/it]  2%|▏         | 10/546 [00:14<12:54,  1.44s/it]  2%|▏         | 11/546 [00:15<12:48,  1.44s/it]  2%|▏         | 12/546 [00:17<12:43,  1.43s/it]  2%|▏         | 13/546 [00:18<12:40,  1.43s/it]  3%|▎         | 14/546 [00:20<12:37,  1.42s/it]  3%|▎         | 15/546 [00:21<12:45,  1.44s/it]  3%|▎         | 16/546 [00:22<12:39,  1.43s/it]  3%|▎         | 17/546 [00:24<12:35,  1.43s/it]  3%|▎         | 18/546 [00:25<12:31,  1.42s/it]  3%|▎         | 19/546 [00:27<12:32,  1.43s/it]  4%|▎         | 20/546 [00:28<12:38,  1.44s/it]  4%|▍         | 21/546 [00:30<12:32,  1.43s/it]  4%|▍         | 22/546 [00:31<12:28,  1.43s/it]  4%|▍         | 23/546 [00:32<12:26,  1.43s/it]  4%|▍         | 24/546 [00:34<12:24,  1.43s/it]  5%|▍         | 25/546 [00:35<12:33,  1.45s/it]  5%|▍         | 26/546 [00:37<12:26,  1.44s/it]  5%|▍         | 27/546 [00:38<12:21,  1.43s/it]  5%|▌         | 28/546 [00:40<12:18,  1.43s/it]  5%|▌         | 29/546 [00:41<12:15,  1.42s/it]  5%|▌         | 30/546 [00:43<12:23,  1.44s/it]  6%|▌         | 31/546 [00:44<12:20,  1.44s/it]  6%|▌         | 32/546 [00:45<12:15,  1.43s/it]  6%|▌         | 33/546 [00:47<12:12,  1.43s/it]  6%|▌         | 34/546 [00:48<12:12,  1.43s/it]  6%|▋         | 35/546 [00:50<12:18,  1.45s/it]  7%|▋         | 36/546 [00:51<12:12,  1.44s/it]  7%|▋         | 37/546 [00:53<12:07,  1.43s/it]  7%|▋         | 38/546 [00:54<12:04,  1.43s/it]  7%|▋         | 39/546 [00:55<11:06,  1.31s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00,  8.37it/s][A
 60%|██████    | 3/5 [00:00<00:00,  7.05it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.52it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.31it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A  7%|▋         | 39/546 [00:56<11:06,  1.31s/it]
100%|██████████| 5/5 [00:00<00:00,  6.31it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  7%|▋         | 40/546 [01:04<31:22,  3.72s/it]  8%|▊         | 41/546 [01:06<25:29,  3.03s/it]  8%|▊         | 42/546 [01:07<21:22,  2.55s/it]  8%|▊         | 43/546 [01:09<18:29,  2.21s/it]  8%|▊         | 44/546 [01:10<16:41,  2.00s/it]  8%|▊         | 45/546 [01:12<15:13,  1.82s/it]  8%|▊         | 46/546 [01:13<14:10,  1.70s/it]  9%|▊         | 47/546 [01:14<13:26,  1.62s/it]  9%|▉         | 48/546 [01:16<13:09,  1.59s/it]  9%|▉         | 49/546 [01:17<12:42,  1.53s/it]  9%|▉         | 50/546 [01:19<12:22,  1.50s/it]  9%|▉         | 51/546 [01:20<12:09,  1.47s/it] 10%|▉         | 52/546 [01:22<12:00,  1.46s/it] 10%|▉         | 53/546 [01:23<12:07,  1.47s/it] 10%|▉         | 54/546 [01:24<11:56,  1.46s/it] 10%|█         | 55/546 [01:26<11:51,  1.45s/it] 10%|█         | 56/546 [01:27<11:46,  1.44s/it] 10%|█         | 57/546 [01:29<11:40,  1.43s/it] 11%|█         | 58/546 [01:30<11:49,  1.45s/it] 11%|█         | 59/546 [01:32<11:43,  1.44s/it] 11%|█         | 60/546 [01:33<11:37,  1.44s/it] 11%|█         | 61/546 [01:35<11:36,  1.44s/it] 11%|█▏        | 62/546 [01:36<11:33,  1.43s/it] 12%|█▏        | 63/546 [01:37<11:44,  1.46s/it] 12%|█▏        | 64/546 [01:39<11:37,  1.45s/it] 12%|█▏        | 65/546 [01:40<11:33,  1.44s/it] 12%|█▏        | 66/546 [01:42<11:29,  1.44s/it] 12%|█▏        | 67/546 [01:43<11:26,  1.43s/it] 12%|█▏        | 68/546 [01:45<11:43,  1.47s/it] 13%|█▎        | 69/546 [01:46<11:34,  1.46s/it] 13%|█▎        | 70/546 [01:48<11:27,  1.45s/it] 13%|█▎        | 71/546 [01:49<11:23,  1.44s/it] 13%|█▎        | 72/546 [01:50<11:18,  1.43s/it] 13%|█▎        | 73/546 [01:52<11:28,  1.45s/it] 14%|█▎        | 74/546 [01:53<11:21,  1.44s/it] 14%|█▎        | 75/546 [01:55<11:15,  1.43s/it] 14%|█▍        | 76/546 [01:56<11:10,  1.43s/it] 14%|█▍        | 77/546 [01:58<11:06,  1.42s/it] 14%|█▍        | 78/546 [01:59<10:26,  1.34s/it]{'eval_loss': 0.27034780383110046, 'eval_precision': 0.47904191616766467, 'eval_recall': 0.2094240837696335, 'eval_f1': 0.29143897996357016, 'eval_accuracy': 0.9353308026030369, 'eval_runtime': 1.0827, 'eval_samples_per_second': 143.166, 'eval_steps_per_second': 4.618, 'epoch': 1.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.60it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.29it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.81it/s][A                                                
                                             [A 14%|█▍        | 78/546 [02:00<10:26,  1.34s/it]
100%|██████████| 5/5 [00:00<00:00,  6.81it/s][A
                                             [A 14%|█▍        | 78/546 [02:00<12:01,  1.54s/it]
[I 2025-09-20 15:06:58,340] Trial 17 pruned. 
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁█
wandb:                 eval/f1 ▁█
wandb:               eval/loss █▁
wandb:          eval/precision ▁█
wandb:             eval/recall ▁█
wandb:            eval/runtime █▁
wandb: eval/samples_per_second ▁█
wandb:   eval/steps_per_second ▁█
wandb:             train/epoch ▁█
wandb:       train/global_step ▁█
wandb: 
wandb: Run summary:
wandb:           eval/accuracy 0.96272
wandb:                 eval/f1 0.61578
wandb:               eval/loss 0.12949
wandb:          eval/precision 0.59901
wandb:             eval/recall 0.63351
wandb:            eval/runtime 1.0185
wandb: eval/samples_per_second 152.185
wandb:   eval/steps_per_second 4.909
wandb:             train/epoch 2
wandb:       train/global_step 78
wandb: 
wandb: 🚀 View run gentle-tree-794 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/l40az4g1
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250920_150457-l40az4g1/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_150701-zf57p3io
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-yogurt-795
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/zf57p3io
{'eval_loss': 0.1294875591993332, 'eval_precision': 0.599009900990099, 'eval_recall': 0.6335078534031413, 'eval_f1': 0.6157760814249362, 'eval_accuracy': 0.9627169197396963, 'eval_runtime': 1.0185, 'eval_samples_per_second': 152.185, 'eval_steps_per_second': 4.909, 'epoch': 2.0}
  0%|          | 0/90 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  1%|          | 1/90 [00:01<02:31,  1.70s/it]  2%|▏         | 2/90 [00:03<02:26,  1.66s/it]  3%|▎         | 3/90 [00:04<02:24,  1.66s/it]  4%|▍         | 4/90 [00:06<02:22,  1.66s/it]  6%|▌         | 5/90 [00:08<02:23,  1.69s/it]  7%|▋         | 6/90 [00:10<02:20,  1.68s/it]  8%|▊         | 7/90 [00:11<02:18,  1.67s/it]  9%|▉         | 8/90 [00:13<02:16,  1.66s/it] 10%|█         | 9/90 [00:14<02:14,  1.66s/it] 11%|█         | 10/90 [00:16<02:03,  1.55s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.61it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.31it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 11%|█         | 10/90 [00:17<02:03,  1.55s/it]
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A
                                             [A 11%|█         | 10/90 [00:17<02:18,  1.73s/it]
[I 2025-09-20 15:07:19,693] Trial 18 pruned. 
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁
wandb:                 eval/f1 ▁
wandb:               eval/loss ▁
wandb:          eval/precision ▁
wandb:             eval/recall ▁
wandb:            eval/runtime ▁
wandb: eval/samples_per_second ▁
wandb:   eval/steps_per_second ▁
wandb:             train/epoch ▁
wandb:       train/global_step ▁
wandb: 
wandb: Run summary:
wandb:           eval/accuracy 0.92665
wandb:                 eval/f1 0
wandb:               eval/loss 0.64615
wandb:          eval/precision 0
wandb:             eval/recall 0
wandb:            eval/runtime 1.012
wandb: eval/samples_per_second 153.164
wandb:   eval/steps_per_second 4.941
wandb:             train/epoch 1
wandb:       train/global_step 10
wandb: 
wandb: 🚀 View run trim-yogurt-795 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/zf57p3io
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250920_150701-zf57p3io/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/wandb/run-20250920_150722-xury54mj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-frog-796
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/xury54mj
{'eval_loss': 0.646150529384613, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9266540130151844, 'eval_runtime': 1.012, 'eval_samples_per_second': 153.164, 'eval_steps_per_second': 4.941, 'epoch': 1.0}
  0%|          | 0/546 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/546 [00:01<13:53,  1.53s/it]  0%|          | 2/546 [00:02<13:22,  1.47s/it]  1%|          | 3/546 [00:04<13:04,  1.45s/it]  1%|          | 4/546 [00:05<12:55,  1.43s/it]  1%|          | 5/546 [00:07<13:12,  1.46s/it]  1%|          | 6/546 [00:08<13:04,  1.45s/it]  1%|▏         | 7/546 [00:10<12:56,  1.44s/it]  1%|▏         | 8/546 [00:11<12:51,  1.43s/it]  2%|▏         | 9/546 [00:12<12:48,  1.43s/it]  2%|▏         | 10/546 [00:14<13:00,  1.46s/it]  2%|▏         | 11/546 [00:15<12:53,  1.45s/it]  2%|▏         | 12/546 [00:17<12:51,  1.44s/it]  2%|▏         | 13/546 [00:18<12:46,  1.44s/it]  3%|▎         | 14/546 [00:20<12:41,  1.43s/it]  3%|▎         | 15/546 [00:21<12:52,  1.45s/it]  3%|▎         | 16/546 [00:23<12:44,  1.44s/it]  3%|▎         | 17/546 [00:24<12:39,  1.44s/it]  3%|▎         | 18/546 [00:25<12:34,  1.43s/it]  3%|▎         | 19/546 [00:27<12:30,  1.42s/it]  4%|▎         | 20/546 [00:28<12:40,  1.45s/it]  4%|▍         | 21/546 [00:30<12:33,  1.44s/it]  4%|▍         | 22/546 [00:31<12:29,  1.43s/it]  4%|▍         | 23/546 [00:33<12:24,  1.42s/it]  4%|▍         | 24/546 [00:34<12:20,  1.42s/it]  5%|▍         | 25/546 [00:36<12:32,  1.44s/it]  5%|▍         | 26/546 [00:37<12:26,  1.44s/it]  5%|▍         | 27/546 [00:38<12:21,  1.43s/it]  5%|▌         | 28/546 [00:40<12:16,  1.42s/it]  5%|▌         | 29/546 [00:41<12:14,  1.42s/it]  5%|▌         | 30/546 [00:43<12:25,  1.44s/it]  6%|▌         | 31/546 [00:44<12:20,  1.44s/it]  6%|▌         | 32/546 [00:46<12:15,  1.43s/it]  6%|▌         | 33/546 [00:47<12:11,  1.43s/it]  6%|▌         | 34/546 [00:48<12:09,  1.43s/it]  6%|▋         | 35/546 [00:50<12:22,  1.45s/it]  7%|▋         | 36/546 [00:51<12:15,  1.44s/it]  7%|▋         | 37/546 [00:53<12:09,  1.43s/it]  7%|▋         | 38/546 [00:54<12:05,  1.43s/it]  7%|▋         | 39/546 [00:55<11:07,  1.32s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00,  7.72it/s][A
 60%|██████    | 3/5 [00:00<00:00,  6.76it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.38it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.21it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A  7%|▋         | 39/546 [00:56<11:07,  1.32s/it]
100%|██████████| 5/5 [00:00<00:00,  6.21it/s][A
                                             [A  7%|▋         | 39/546 [00:56<12:18,  1.46s/it]
[I 2025-09-20 15:08:20,249] Trial 19 pruned. 
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
/home/s27mhusa_hpc/Master-Thesis/FineTune19SeptEnglish/fine_tune_xlm_roberta_old.py:315: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'eval_loss': 0.41966158151626587, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9276030368763557, 'eval_runtime': 1.1002, 'eval_samples_per_second': 140.879, 'eval_steps_per_second': 4.544, 'epoch': 1.0}
Best trial: BestRun(run_id='16', objective=3.5065526296811678, hyperparameters={'learning_rate': 7.005425687793712e-05, 'num_train_epochs': 15, 'per_device_train_batch_size': 4, 'weight_decay': 7.95137550895256e-06, 'warmup_ratio': 0.1342717579616191, 'optimizer': 'Adafactor'}, run_summary=None)
  0%|          | 0/300 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/300 [00:01<07:33,  1.52s/it]  1%|          | 2/300 [00:03<07:29,  1.51s/it]  1%|          | 3/300 [00:04<07:22,  1.49s/it]  1%|▏         | 4/300 [00:05<07:19,  1.48s/it]  2%|▏         | 5/300 [00:07<07:25,  1.51s/it]  2%|▏         | 6/300 [00:08<07:19,  1.50s/it]  2%|▏         | 7/300 [00:10<07:15,  1.49s/it]  3%|▎         | 8/300 [00:11<07:11,  1.48s/it]  3%|▎         | 9/300 [00:13<07:09,  1.47s/it]  3%|▎         | 10/300 [00:14<07:20,  1.52s/it]  4%|▎         | 11/300 [00:16<07:13,  1.50s/it]  4%|▍         | 12/300 [00:17<07:09,  1.49s/it]  4%|▍         | 13/300 [00:19<07:05,  1.48s/it]  5%|▍         | 14/300 [00:20<07:02,  1.48s/it]  5%|▌         | 15/300 [00:22<07:08,  1.50s/it]  5%|▌         | 16/300 [00:23<07:03,  1.49s/it]  6%|▌         | 17/300 [00:25<07:00,  1.49s/it]  6%|▌         | 18/300 [00:26<06:57,  1.48s/it]  6%|▋         | 19/300 [00:28<06:54,  1.48s/it]  7%|▋         | 20/300 [00:29<05:54,  1.27s/it]
  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.48it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.27it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.85it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A  7%|▋         | 20/300 [00:30<05:54,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.85it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  7%|▋         | 21/300 [00:38<16:48,  3.61s/it]  7%|▋         | 22/300 [00:39<13:46,  2.97s/it]  8%|▊         | 23/300 [00:41<11:39,  2.53s/it]  8%|▊         | 24/300 [00:42<10:20,  2.25s/it]  8%|▊         | 25/300 [00:44<09:15,  2.02s/it]  9%|▊         | 26/300 [00:45<08:27,  1.85s/it]  9%|▉         | 27/300 [00:47<07:54,  1.74s/it]  9%|▉         | 28/300 [00:48<07:31,  1.66s/it] 10%|▉         | 29/300 [00:50<07:18,  1.62s/it] 10%|█         | 30/300 [00:51<07:05,  1.58s/it] 10%|█         | 31/300 [00:53<06:56,  1.55s/it] 11%|█         | 32/300 [00:54<06:48,  1.53s/it] 11%|█         | 33/300 [00:56<06:43,  1.51s/it] 11%|█▏        | 34/300 [00:57<06:51,  1.55s/it] 12%|█▏        | 35/300 [00:59<06:47,  1.54s/it] 12%|█▏        | 36/300 [01:00<06:40,  1.52s/it] 12%|█▏        | 37/300 [01:02<06:35,  1.50s/it] 13%|█▎        | 38/300 [01:03<06:31,  1.50s/it] 13%|█▎        | 39/300 [01:05<06:33,  1.51s/it] 13%|█▎        | 40/300 [01:05<05:30,  1.27s/it]{'eval_loss': 0.44990110397338867, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9276030368763557, 'eval_runtime': 1.1059, 'eval_samples_per_second': 140.155, 'eval_steps_per_second': 4.521, 'epoch': 1.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.57it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.29it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.85it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 13%|█▎        | 40/300 [01:06<05:30,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.85it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 14%|█▎        | 41/300 [01:15<15:41,  3.64s/it] 14%|█▍        | 42/300 [01:16<12:50,  2.99s/it] 14%|█▍        | 43/300 [01:18<10:54,  2.55s/it] 15%|█▍        | 44/300 [01:19<09:28,  2.22s/it] 15%|█▌        | 45/300 [01:20<08:28,  1.99s/it] 15%|█▌        | 46/300 [01:22<07:46,  1.84s/it] 16%|█▌        | 47/300 [01:23<07:16,  1.72s/it] 16%|█▌        | 48/300 [01:25<06:58,  1.66s/it] 16%|█▋        | 49/300 [01:26<06:42,  1.60s/it] 17%|█▋        | 50/300 [01:28<06:30,  1.56s/it] 17%|█▋        | 51/300 [01:29<06:21,  1.53s/it] 17%|█▋        | 52/300 [01:31<06:14,  1.51s/it] 18%|█▊        | 53/300 [01:32<06:22,  1.55s/it] 18%|█▊        | 54/300 [01:34<06:14,  1.52s/it] 18%|█▊        | 55/300 [01:35<06:09,  1.51s/it] 19%|█▊        | 56/300 [01:37<06:04,  1.50s/it] 19%|█▉        | 57/300 [01:38<06:00,  1.48s/it] 19%|█▉        | 58/300 [01:40<06:01,  1.50s/it] 20%|█▉        | 59/300 [01:41<05:57,  1.48s/it] 20%|██        | 60/300 [01:42<05:01,  1.26s/it]{'eval_loss': 0.2678990066051483, 'eval_precision': 0.2953125, 'eval_recall': 0.49476439790575916, 'eval_f1': 0.36986301369863017, 'eval_accuracy': 0.9243492407809111, 'eval_runtime': 1.0181, 'eval_samples_per_second': 152.242, 'eval_steps_per_second': 4.911, 'epoch': 2.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.60it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.28it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A                                                
                                             [A 20%|██        | 60/300 [01:43<05:01,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.86it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 20%|██        | 61/300 [01:51<14:10,  3.56s/it] 21%|██        | 62/300 [01:52<11:43,  2.96s/it] 21%|██        | 63/300 [01:54<09:55,  2.51s/it] 21%|██▏       | 64/300 [01:55<08:40,  2.20s/it] 22%|██▏       | 65/300 [01:57<07:46,  1.99s/it] 22%|██▏       | 66/300 [01:58<07:08,  1.83s/it] 22%|██▏       | 67/300 [02:00<06:49,  1.76s/it] 23%|██▎       | 68/300 [02:01<06:28,  1.68s/it] 23%|██▎       | 69/300 [02:03<06:13,  1.62s/it] 23%|██▎       | 70/300 [02:04<06:01,  1.57s/it] 24%|██▎       | 71/300 [02:06<05:53,  1.54s/it] 24%|██▍       | 72/300 [02:07<05:54,  1.55s/it] 24%|██▍       | 73/300 [02:09<05:46,  1.53s/it] 25%|██▍       | 74/300 [02:10<05:41,  1.51s/it] 25%|██▌       | 75/300 [02:12<05:37,  1.50s/it] 25%|██▌       | 76/300 [02:13<05:34,  1.49s/it] 26%|██▌       | 77/300 [02:15<05:36,  1.51s/it] 26%|██▌       | 78/300 [02:16<05:32,  1.50s/it] 26%|██▋       | 79/300 [02:18<05:30,  1.49s/it] 27%|██▋       | 80/300 [02:19<04:38,  1.26s/it]{'eval_loss': 0.14781497418880463, 'eval_precision': 0.5429864253393665, 'eval_recall': 0.6282722513089005, 'eval_f1': 0.5825242718446602, 'eval_accuracy': 0.9568872017353579, 'eval_runtime': 1.0155, 'eval_samples_per_second': 152.641, 'eval_steps_per_second': 4.924, 'epoch': 3.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.51it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.28it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A                                                
                                             [A 27%|██▋       | 80/300 [02:20<04:38,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.83it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 27%|██▋       | 81/300 [02:28<13:15,  3.63s/it] 27%|██▋       | 82/300 [02:29<10:51,  2.99s/it] 28%|██▊       | 83/300 [02:31<09:09,  2.53s/it] 28%|██▊       | 84/300 [02:32<07:57,  2.21s/it] 28%|██▊       | 85/300 [02:34<07:08,  1.99s/it] 29%|██▊       | 86/300 [02:35<06:38,  1.86s/it] 29%|██▉       | 87/300 [02:37<06:11,  1.74s/it] 29%|██▉       | 88/300 [02:38<05:52,  1.66s/it] 30%|██▉       | 89/300 [02:40<05:38,  1.60s/it] 30%|███       | 90/300 [02:41<05:28,  1.57s/it] 30%|███       | 91/300 [02:43<05:27,  1.57s/it] 31%|███       | 92/300 [02:44<05:19,  1.54s/it] 31%|███       | 93/300 [02:46<05:14,  1.52s/it] 31%|███▏      | 94/300 [02:47<05:09,  1.50s/it] 32%|███▏      | 95/300 [02:48<05:05,  1.49s/it] 32%|███▏      | 96/300 [02:50<05:10,  1.52s/it] 32%|███▏      | 97/300 [02:52<05:05,  1.50s/it] 33%|███▎      | 98/300 [02:53<05:02,  1.50s/it] 33%|███▎      | 99/300 [02:54<04:59,  1.49s/it] 33%|███▎      | 100/300 [02:55<04:11,  1.26s/it]{'eval_loss': 0.12589271366596222, 'eval_precision': 0.8205882352941176, 'eval_recall': 0.7303664921465969, 'eval_f1': 0.7728531855955678, 'eval_accuracy': 0.9734273318872018, 'eval_runtime': 1.0148, 'eval_samples_per_second': 152.734, 'eval_steps_per_second': 4.927, 'epoch': 4.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.62it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.32it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.90it/s][A                                                 
                                             [A 33%|███▎      | 100/300 [02:56<04:11,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.90it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 34%|███▎      | 101/300 [03:04<11:40,  3.52s/it] 34%|███▍      | 102/300 [03:05<09:34,  2.90s/it] 34%|███▍      | 103/300 [03:07<08:06,  2.47s/it] 35%|███▍      | 104/300 [03:08<07:05,  2.17s/it] 35%|███▌      | 105/300 [03:10<06:27,  1.99s/it] 35%|███▌      | 106/300 [03:11<05:55,  1.83s/it] 36%|███▌      | 107/300 [03:13<05:32,  1.72s/it] 36%|███▌      | 108/300 [03:14<05:17,  1.65s/it] 36%|███▋      | 109/300 [03:16<05:05,  1.60s/it] 37%|███▋      | 110/300 [03:17<05:02,  1.59s/it] 37%|███▋      | 111/300 [03:19<04:53,  1.56s/it] 37%|███▋      | 112/300 [03:20<04:48,  1.53s/it] 38%|███▊      | 113/300 [03:22<04:43,  1.52s/it] 38%|███▊      | 114/300 [03:23<04:39,  1.51s/it] 38%|███▊      | 115/300 [03:25<04:43,  1.53s/it] 39%|███▊      | 116/300 [03:26<04:38,  1.51s/it] 39%|███▉      | 117/300 [03:28<04:34,  1.50s/it] 39%|███▉      | 118/300 [03:29<04:31,  1.49s/it] 40%|███▉      | 119/300 [03:31<04:29,  1.49s/it] 40%|████      | 120/300 [03:32<03:46,  1.26s/it]{'eval_loss': 0.12510980665683746, 'eval_precision': 0.7866666666666666, 'eval_recall': 0.7722513089005235, 'eval_f1': 0.7793923381770145, 'eval_accuracy': 0.9720715835140998, 'eval_runtime': 1.0134, 'eval_samples_per_second': 152.957, 'eval_steps_per_second': 4.934, 'epoch': 5.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00,  7.40it/s][A
 60%|██████    | 3/5 [00:00<00:00,  6.61it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.27it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.15it/s][A                                                 
                                             [A 40%|████      | 120/300 [03:33<03:46,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.15it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 40%|████      | 121/300 [03:40<10:22,  3.48s/it] 41%|████      | 122/300 [03:42<08:31,  2.87s/it] 41%|████      | 123/300 [03:43<07:13,  2.45s/it] 41%|████▏     | 124/300 [03:45<06:23,  2.18s/it] 42%|████▏     | 125/300 [03:46<05:44,  1.97s/it] 42%|████▏     | 126/300 [03:48<05:15,  1.81s/it] 42%|████▏     | 127/300 [03:49<04:55,  1.71s/it] 43%|████▎     | 128/300 [03:51<04:41,  1.64s/it] 43%|████▎     | 129/300 [03:52<04:36,  1.62s/it] 43%|████▎     | 130/300 [03:54<04:26,  1.57s/it] 44%|████▎     | 131/300 [03:55<04:20,  1.54s/it] 44%|████▍     | 132/300 [03:56<04:14,  1.52s/it] 44%|████▍     | 133/300 [03:58<04:10,  1.50s/it] 45%|████▍     | 134/300 [04:00<04:12,  1.52s/it] 45%|████▌     | 135/300 [04:01<04:08,  1.50s/it] 45%|████▌     | 136/300 [04:02<04:04,  1.49s/it] 46%|████▌     | 137/300 [04:04<04:01,  1.48s/it] 46%|████▌     | 138/300 [04:05<03:59,  1.48s/it] 46%|████▋     | 139/300 [04:07<04:02,  1.50s/it] 47%|████▋     | 140/300 [04:08<03:23,  1.27s/it]{'eval_loss': 0.12914378941059113, 'eval_precision': 0.7587064676616916, 'eval_recall': 0.7984293193717278, 'eval_f1': 0.778061224489796, 'eval_accuracy': 0.9730206073752712, 'eval_runtime': 1.1194, 'eval_samples_per_second': 138.473, 'eval_steps_per_second': 4.467, 'epoch': 6.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.63it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.32it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A                                                 
                                             [A 47%|████▋     | 140/300 [04:09<03:23,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 47%|████▋     | 141/300 [04:17<09:29,  3.58s/it] 47%|████▋     | 142/300 [04:18<07:45,  2.95s/it] 48%|████▊     | 143/300 [04:20<06:37,  2.53s/it] 48%|████▊     | 144/300 [04:21<05:45,  2.21s/it] 48%|████▊     | 145/300 [04:23<05:08,  1.99s/it] 49%|████▊     | 146/300 [04:24<04:42,  1.84s/it] 49%|████▉     | 147/300 [04:26<04:24,  1.73s/it] 49%|████▉     | 148/300 [04:27<04:14,  1.68s/it] 50%|████▉     | 149/300 [04:29<04:03,  1.61s/it] 50%|█████     | 150/300 [04:30<03:55,  1.57s/it] 50%|█████     | 151/300 [04:32<03:49,  1.54s/it] 51%|█████     | 152/300 [04:33<03:44,  1.52s/it] 51%|█████     | 153/300 [04:35<03:44,  1.53s/it] 51%|█████▏    | 154/300 [04:36<03:40,  1.51s/it] 52%|█████▏    | 155/300 [04:37<03:37,  1.50s/it] 52%|█████▏    | 156/300 [04:39<03:34,  1.49s/it] 52%|█████▏    | 157/300 [04:40<03:31,  1.48s/it] 53%|█████▎    | 158/300 [04:42<03:33,  1.50s/it] 53%|█████▎    | 159/300 [04:43<03:30,  1.49s/it] 53%|█████▎    | 160/300 [04:44<02:56,  1.26s/it]{'eval_loss': 0.1399640440940857, 'eval_precision': 0.7580246913580246, 'eval_recall': 0.8036649214659686, 'eval_f1': 0.7801778907242695, 'eval_accuracy': 0.973562906724512, 'eval_runtime': 1.0152, 'eval_samples_per_second': 152.679, 'eval_steps_per_second': 4.925, 'epoch': 7.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.59it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.29it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A                                                 
                                             [A 53%|█████▎    | 160/300 [04:45<02:56,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.87it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 54%|█████▎    | 161/300 [04:54<08:40,  3.74s/it] 54%|█████▍    | 162/300 [04:55<07:02,  3.06s/it] 54%|█████▍    | 163/300 [04:57<05:56,  2.60s/it] 55%|█████▍    | 164/300 [04:58<05:08,  2.27s/it] 55%|█████▌    | 165/300 [05:00<04:34,  2.03s/it] 55%|█████▌    | 166/300 [05:01<04:09,  1.86s/it] 56%|█████▌    | 167/300 [05:03<03:51,  1.74s/it] 56%|█████▌    | 168/300 [05:04<03:42,  1.68s/it] 56%|█████▋    | 169/300 [05:06<03:32,  1.62s/it] 57%|█████▋    | 170/300 [05:07<03:24,  1.57s/it] 57%|█████▋    | 171/300 [05:09<03:19,  1.55s/it] 57%|█████▋    | 172/300 [05:10<03:15,  1.53s/it] 58%|█████▊    | 173/300 [05:12<03:13,  1.52s/it] 58%|█████▊    | 174/300 [05:13<03:10,  1.51s/it] 58%|█████▊    | 175/300 [05:14<03:07,  1.50s/it] 59%|█████▊    | 176/300 [05:16<03:04,  1.49s/it] 59%|█████▉    | 177/300 [05:17<03:02,  1.48s/it] 59%|█████▉    | 178/300 [05:19<03:02,  1.50s/it] 60%|█████▉    | 179/300 [05:20<03:00,  1.49s/it] 60%|██████    | 180/300 [05:21<02:31,  1.27s/it]{'eval_loss': 0.14088799059391022, 'eval_precision': 0.7475961538461539, 'eval_recall': 0.8141361256544503, 'eval_f1': 0.7794486215538847, 'eval_accuracy': 0.9727494577006508, 'eval_runtime': 1.0138, 'eval_samples_per_second': 152.886, 'eval_steps_per_second': 4.932, 'epoch': 8.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.41it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.22it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.73it/s][A                                                 
                                             [A 60%|██████    | 180/300 [05:22<02:31,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.73it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 60%|██████    | 181/300 [05:31<07:24,  3.73s/it] 61%|██████    | 182/300 [05:32<06:02,  3.07s/it] 61%|██████    | 183/300 [05:34<05:03,  2.59s/it] 61%|██████▏   | 184/300 [05:35<04:21,  2.25s/it] 62%|██████▏   | 185/300 [05:37<03:51,  2.02s/it] 62%|██████▏   | 186/300 [05:38<03:31,  1.85s/it] 62%|██████▏   | 187/300 [05:40<03:17,  1.75s/it] 63%|██████▎   | 188/300 [05:41<03:06,  1.67s/it] 63%|██████▎   | 189/300 [05:43<02:58,  1.60s/it] 63%|██████▎   | 190/300 [05:44<02:51,  1.56s/it] 64%|██████▎   | 191/300 [05:45<02:47,  1.53s/it] 64%|██████▍   | 192/300 [05:47<02:45,  1.53s/it] 64%|██████▍   | 193/300 [05:48<02:41,  1.51s/it] 65%|██████▍   | 194/300 [05:50<02:38,  1.50s/it] 65%|██████▌   | 195/300 [05:51<02:36,  1.49s/it] 65%|██████▌   | 196/300 [05:53<02:36,  1.50s/it] 66%|██████▌   | 197/300 [05:54<02:33,  1.49s/it] 66%|██████▌   | 198/300 [05:56<02:31,  1.48s/it] 66%|██████▋   | 199/300 [05:57<02:30,  1.49s/it] 67%|██████▋   | 200/300 [05:58<02:06,  1.27s/it]{'eval_loss': 0.15599432587623596, 'eval_precision': 0.7665847665847666, 'eval_recall': 0.8167539267015707, 'eval_f1': 0.790874524714829, 'eval_accuracy': 0.9734273318872018, 'eval_runtime': 1.0349, 'eval_samples_per_second': 149.776, 'eval_steps_per_second': 4.831, 'epoch': 9.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.52it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.28it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.80it/s][A                                                 
                                             [A 67%|██████▋   | 200/300 [05:59<02:06,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.80it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 67%|██████▋   | 201/300 [06:08<06:29,  3.94s/it] 67%|██████▋   | 202/300 [06:10<05:13,  3.20s/it] 68%|██████▊   | 203/300 [06:11<04:19,  2.68s/it] 68%|██████▊   | 204/300 [06:13<03:42,  2.32s/it] 68%|██████▊   | 205/300 [06:14<03:16,  2.06s/it] 69%|██████▊   | 206/300 [06:16<02:59,  1.91s/it] 69%|██████▉   | 207/300 [06:17<02:45,  1.78s/it] 69%|██████▉   | 208/300 [06:19<02:34,  1.68s/it] 70%|██████▉   | 209/300 [06:20<02:27,  1.62s/it] 70%|███████   | 210/300 [06:22<02:24,  1.60s/it] 70%|███████   | 211/300 [06:23<02:18,  1.56s/it] 71%|███████   | 212/300 [06:25<02:14,  1.53s/it] 71%|███████   | 213/300 [06:26<02:11,  1.51s/it] 71%|███████▏  | 214/300 [06:28<02:08,  1.50s/it] 72%|███████▏  | 215/300 [06:29<02:09,  1.53s/it] 72%|███████▏  | 216/300 [06:31<02:06,  1.51s/it] 72%|███████▏  | 217/300 [06:32<02:04,  1.50s/it] 73%|███████▎  | 218/300 [06:34<02:02,  1.49s/it] 73%|███████▎  | 219/300 [06:35<02:00,  1.48s/it] 73%|███████▎  | 220/300 [06:36<01:40,  1.26s/it]{'eval_loss': 0.1587914526462555, 'eval_precision': 0.7933673469387755, 'eval_recall': 0.8141361256544503, 'eval_f1': 0.8036175710594315, 'eval_accuracy': 0.9761388286334056, 'eval_runtime': 1.0169, 'eval_samples_per_second': 152.431, 'eval_steps_per_second': 4.917, 'epoch': 10.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00,  7.34it/s][A
 60%|██████    | 3/5 [00:00<00:00,  6.57it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.26it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.16it/s][A                                                 
                                             [A 73%|███████▎  | 220/300 [06:37<01:40,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.16it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 74%|███████▎  | 221/300 [06:45<04:43,  3.59s/it] 74%|███████▍  | 222/300 [06:46<03:50,  2.96s/it] 74%|███████▍  | 223/300 [06:48<03:13,  2.51s/it] 75%|███████▍  | 224/300 [06:49<02:46,  2.20s/it] 75%|███████▌  | 225/300 [06:51<02:30,  2.01s/it] 75%|███████▌  | 226/300 [06:52<02:16,  1.85s/it] 76%|███████▌  | 227/300 [06:54<02:06,  1.74s/it] 76%|███████▌  | 228/300 [06:55<01:59,  1.66s/it] 76%|███████▋  | 229/300 [06:57<01:53,  1.60s/it] 77%|███████▋  | 230/300 [06:58<01:51,  1.59s/it] 77%|███████▋  | 231/300 [07:00<01:47,  1.55s/it] 77%|███████▋  | 232/300 [07:01<01:44,  1.53s/it] 78%|███████▊  | 233/300 [07:03<01:41,  1.51s/it] 78%|███████▊  | 234/300 [07:04<01:39,  1.51s/it] 78%|███████▊  | 235/300 [07:06<01:39,  1.53s/it] 79%|███████▊  | 236/300 [07:07<01:36,  1.51s/it] 79%|███████▉  | 237/300 [07:09<01:34,  1.50s/it] 79%|███████▉  | 238/300 [07:10<01:32,  1.49s/it] 80%|███████▉  | 239/300 [07:12<01:30,  1.49s/it] 80%|████████  | 240/300 [07:12<01:17,  1.29s/it]{'eval_loss': 0.15783432126045227, 'eval_precision': 0.8149100257069408, 'eval_recall': 0.8298429319371727, 'eval_f1': 0.8223086900129701, 'eval_accuracy': 0.9773590021691974, 'eval_runtime': 1.1172, 'eval_samples_per_second': 138.74, 'eval_steps_per_second': 4.475, 'epoch': 11.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 10.84it/s][A
 80%|████████  | 4/5 [00:00<00:00,  6.91it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.55it/s][A                                                 
                                             [A 80%|████████  | 240/300 [07:13<01:17,  1.29s/it]
100%|██████████| 5/5 [00:00<00:00,  6.55it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 80%|████████  | 241/300 [07:22<03:39,  3.73s/it] 81%|████████  | 242/300 [07:23<02:56,  3.05s/it] 81%|████████  | 243/300 [07:25<02:26,  2.57s/it] 81%|████████▏ | 244/300 [07:26<02:06,  2.26s/it] 82%|████████▏ | 245/300 [07:28<01:51,  2.02s/it] 82%|████████▏ | 246/300 [07:29<01:39,  1.85s/it] 82%|████████▏ | 247/300 [07:31<01:31,  1.73s/it] 83%|████████▎ | 248/300 [07:32<01:25,  1.65s/it] 83%|████████▎ | 249/300 [07:34<01:22,  1.61s/it] 83%|████████▎ | 250/300 [07:35<01:18,  1.57s/it] 84%|████████▎ | 251/300 [07:37<01:15,  1.54s/it] 84%|████████▍ | 252/300 [07:38<01:12,  1.52s/it] 84%|████████▍ | 253/300 [07:39<01:10,  1.50s/it] 85%|████████▍ | 254/300 [07:41<01:09,  1.51s/it] 85%|████████▌ | 255/300 [07:42<01:07,  1.50s/it] 85%|████████▌ | 256/300 [07:44<01:05,  1.49s/it] 86%|████████▌ | 257/300 [07:45<01:03,  1.48s/it] 86%|████████▌ | 258/300 [07:47<01:02,  1.49s/it] 86%|████████▋ | 259/300 [07:48<01:01,  1.51s/it] 87%|████████▋ | 260/300 [07:49<00:50,  1.27s/it]{'eval_loss': 0.16300782561302185, 'eval_precision': 0.8015075376884422, 'eval_recall': 0.8350785340314136, 'eval_f1': 0.817948717948718, 'eval_accuracy': 0.9768167028199566, 'eval_runtime': 1.0524, 'eval_samples_per_second': 147.288, 'eval_steps_per_second': 4.751, 'epoch': 12.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.58it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.21it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.78it/s][A                                                 
                                             [A 87%|████████▋ | 260/300 [07:50<00:50,  1.27s/it]
100%|██████████| 5/5 [00:00<00:00,  6.78it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 87%|████████▋ | 261/300 [07:59<02:25,  3.73s/it] 87%|████████▋ | 262/300 [08:00<01:56,  3.05s/it] 88%|████████▊ | 263/300 [08:02<01:36,  2.61s/it] 88%|████████▊ | 264/300 [08:03<01:21,  2.27s/it] 88%|████████▊ | 265/300 [08:05<01:11,  2.03s/it] 89%|████████▊ | 266/300 [08:06<01:03,  1.86s/it] 89%|████████▉ | 267/300 [08:08<00:57,  1.75s/it] 89%|████████▉ | 268/300 [08:09<00:54,  1.70s/it] 90%|████████▉ | 269/300 [08:11<00:50,  1.63s/it] 90%|█████████ | 270/300 [08:12<00:47,  1.58s/it] 90%|█████████ | 271/300 [08:14<00:44,  1.55s/it] 91%|█████████ | 272/300 [08:15<00:42,  1.53s/it] 91%|█████████ | 273/300 [08:17<00:41,  1.54s/it] 91%|█████████▏| 274/300 [08:18<00:39,  1.52s/it] 92%|█████████▏| 275/300 [08:20<00:37,  1.51s/it] 92%|█████████▏| 276/300 [08:21<00:35,  1.50s/it] 92%|█████████▏| 277/300 [08:23<00:34,  1.50s/it] 93%|█████████▎| 278/300 [08:24<00:33,  1.53s/it] 93%|█████████▎| 279/300 [08:26<00:31,  1.51s/it] 93%|█████████▎| 280/300 [08:26<00:25,  1.28s/it]{'eval_loss': 0.17158907651901245, 'eval_precision': 0.799492385786802, 'eval_recall': 0.824607329842932, 'eval_f1': 0.8118556701030929, 'eval_accuracy': 0.9761388286334056, 'eval_runtime': 1.0224, 'eval_samples_per_second': 151.605, 'eval_steps_per_second': 4.89, 'epoch': 13.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.59it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.29it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A                                                 
                                             [A 93%|█████████▎| 280/300 [08:27<00:25,  1.28s/it]
100%|██████████| 5/5 [00:00<00:00,  6.88it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 94%|█████████▎| 281/300 [08:36<01:09,  3.66s/it] 94%|█████████▍| 282/300 [08:37<00:54,  3.04s/it] 94%|█████████▍| 283/300 [08:39<00:43,  2.57s/it] 95%|█████████▍| 284/300 [08:40<00:35,  2.24s/it] 95%|█████████▌| 285/300 [08:42<00:30,  2.01s/it] 95%|█████████▌| 286/300 [08:43<00:25,  1.85s/it] 96%|█████████▌| 287/300 [08:45<00:22,  1.76s/it] 96%|█████████▌| 288/300 [08:46<00:20,  1.67s/it] 96%|█████████▋| 289/300 [08:48<00:17,  1.61s/it] 97%|█████████▋| 290/300 [08:49<00:15,  1.57s/it] 97%|█████████▋| 291/300 [08:50<00:13,  1.54s/it] 97%|█████████▋| 292/300 [08:52<00:12,  1.57s/it] 98%|█████████▊| 293/300 [08:54<00:10,  1.55s/it] 98%|█████████▊| 294/300 [08:55<00:09,  1.52s/it] 98%|█████████▊| 295/300 [08:57<00:07,  1.51s/it] 99%|█████████▊| 296/300 [08:58<00:05,  1.50s/it] 99%|█████████▉| 297/300 [09:00<00:04,  1.51s/it] 99%|█████████▉| 298/300 [09:01<00:03,  1.50s/it]100%|█████████▉| 299/300 [09:03<00:01,  1.49s/it]100%|██████████| 300/300 [09:03<00:00,  1.26s/it]{'eval_loss': 0.1814667284488678, 'eval_precision': 0.8144329896907216, 'eval_recall': 0.8272251308900523, 'eval_f1': 0.8207792207792208, 'eval_accuracy': 0.9768167028199566, 'eval_runtime': 1.0143, 'eval_samples_per_second': 152.819, 'eval_steps_per_second': 4.93, 'epoch': 14.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 40%|████      | 2/5 [00:00<00:00, 11.35it/s][A
 80%|████████  | 4/5 [00:00<00:00,  7.23it/s][A
100%|██████████| 5/5 [00:00<00:00,  6.81it/s][A                                                 
                                             [A100%|██████████| 300/300 [09:04<00:00,  1.26s/it]
100%|██████████| 5/5 [00:00<00:00,  6.81it/s][A
                                             [A                                                 100%|██████████| 300/300 [09:12<00:00,  1.26s/it]100%|██████████| 300/300 [09:12<00:00,  1.84s/it]
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
{'eval_loss': 0.18123187124729156, 'eval_precision': 0.8170103092783505, 'eval_recall': 0.8298429319371727, 'eval_f1': 0.8233766233766233, 'eval_accuracy': 0.9773590021691974, 'eval_runtime': 1.0183, 'eval_samples_per_second': 152.209, 'eval_steps_per_second': 4.91, 'epoch': 15.0}
{'train_runtime': 552.7031, 'train_samples_per_second': 33.599, 'train_steps_per_second': 0.543, 'train_loss': 0.10016903559366862, 'epoch': 15.0}

Evaluating on validation data...
  0%|          | 0/5 [00:00<?, ?it/s] 40%|████      | 2/5 [00:00<00:00, 11.51it/s] 80%|████████  | 4/5 [00:00<00:00,  7.25it/s]100%|██████████| 5/5 [00:00<00:00,  5.81it/s]100%|██████████| 5/5 [00:00<00:00,  5.64it/s]
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
Pred: ['O', 'O', 'O', 'O', 'O', 'O', 'B-startTime', 'I-startTime', 'I-startTime', 'O', 'B-startTime', 'I-startTime', 'I-startTime', 'I-startTime', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-duration', 'I-duration', 'O', 'O']
Gold: ['O', 'O', 'O', 'O', 'O', 'O', 'B-startTime', 'I-startTime', 'I-startTime', 'O', 'B-endTime', 'I-endTime', 'I-endTime', 'I-endTime', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']

Pred: ['O', 'O', 'O', 'O', 'B-cropSpecies', 'B-cropSpecies', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-cropSpecies', 'B-cropSpecies', 'O', 'O', 'O', 'O', 'O', 'O']
Gold: ['O', 'O', 'O', 'O', 'B-cropSpecies', 'B-cropSpecies', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-cropSpecies', 'B-cropSpecies', 'O', 'O', 'O', 'O', 'O', 'O']

Pred: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-cropSpecies', 'B-cropSpecies', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']
Gold: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-cropSpecies', 'B-cropSpecies', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']


============================================================
VALIDATION CLASSIFICATION REPORTS
============================================================

Validation - Token-level Classification Report:
--------------------------------------------------
               precision    recall  f1-score   support

       B-Soil       0.82      0.62      0.70        50
       B-city       0.87      0.77      0.82        26
    B-country       0.89      0.86      0.87        36
B-cropSpecies       0.90      0.95      0.92       122
   B-duration       0.57      0.68      0.62        19
    B-endTime       0.71      0.75      0.73        20
     B-region       0.78      0.86      0.82        49
  B-startTime       0.88      0.88      0.88        60
       I-Soil       0.53      0.30      0.38        27
I-cropSpecies       0.86      0.91      0.89        56
   I-duration       0.69      0.80      0.74        25
    I-endTime       0.00      0.00      0.00         4
     I-region       0.78      0.74      0.76        34
  I-startTime       0.60      1.00      0.75         6
            O       0.99      0.99      0.99      6842

     accuracy                           0.98      7376
    macro avg       0.72      0.74      0.72      7376
 weighted avg       0.98      0.98      0.98      7376


Validation - Entity-level Classification Report:
--------------------------------------------------
              precision    recall  f1-score   support

        Soil       0.79      0.62      0.70        50
        city       0.87      0.77      0.82        26
     country       0.89      0.86      0.87        36
 cropSpecies       0.87      0.93      0.90       122
    duration       0.52      0.68      0.59        19
     endTime       0.71      0.75      0.73        20
      region       0.74      0.82      0.78        49
   startTime       0.88      0.88      0.88        60

   micro avg       0.82      0.83      0.82       382
   macro avg       0.78      0.79      0.78       382
weighted avg       0.82      0.83      0.82       382


Validation - Additional Statistics:
------------------------------
Total sequences: 155
Total tokens: 7376
Unique labels in predictions: 14
Unique labels in ground truth: 15

Evaluating on test data...
  0%|          | 0/8 [00:00<?, ?it/s] 25%|██▌       | 2/8 [00:00<00:00, 11.44it/s] 50%|█████     | 4/8 [00:00<00:00,  6.66it/s] 62%|██████▎   | 5/8 [00:00<00:00,  6.35it/s] 75%|███████▌  | 6/8 [00:00<00:00,  6.17it/s] 88%|████████▊ | 7/8 [00:01<00:00,  6.09it/s]100%|██████████| 8/8 [00:01<00:00,  6.09it/s]100%|██████████| 8/8 [00:01<00:00,  5.75it/s]

Test Metrics:
{'test_loss': 0.20972256362438202, 'test_precision': 0.6800847457627118, 'test_recall': 0.7117516629711752, 'test_f1': 0.695557963163597, 'test_accuracy': 0.9717730079388415, 'test_runtime': 1.5779, 'test_samples_per_second': 147.664, 'test_steps_per_second': 5.07}

============================================================
TEST CLASSIFICATION REPORTS
============================================================

Test - Token-level Classification Report:
--------------------------------------------------
               precision    recall  f1-score   support

       B-Soil       0.74      0.49      0.59        57
       B-city       0.65      0.74      0.69        35
    B-country       0.76      0.92      0.83        24
B-cropSpecies       0.71      0.88      0.79       168
   B-duration       0.78      0.68      0.72        31
    B-endTime       0.88      0.58      0.70        38
     B-region       0.58      0.56      0.57        27
  B-startTime       0.80      0.83      0.81        71
       I-Soil       0.87      0.67      0.75        30
I-cropSpecies       0.64      0.74      0.69        70
   I-duration       0.79      0.71      0.75        21
    I-endTime       1.00      0.33      0.50         3
     I-region       0.25      0.57      0.35         7
  I-startTime       0.14      0.50      0.21         6
            O       0.99      0.99      0.99      9615

     accuracy                           0.97     10203
    macro avg       0.70      0.68      0.66     10203
 weighted avg       0.97      0.97      0.97     10203


Test - Entity-level Classification Report:
--------------------------------------------------
              precision    recall  f1-score   support

        Soil       0.66      0.47      0.55        57
        city       0.65      0.74      0.69        35
     country       0.76      0.92      0.83        24
 cropSpecies       0.69      0.85      0.76       168
    duration       0.61      0.55      0.58        31
     endTime       0.88      0.58      0.70        38
      region       0.58      0.56      0.57        27
   startTime       0.64      0.69      0.67        71

   micro avg       0.68      0.71      0.70       451
   macro avg       0.68      0.67      0.67       451
weighted avg       0.68      0.71      0.69       451


Test - Additional Statistics:
------------------------------
Total sequences: 233
Total tokens: 10203
Unique labels in predictions: 15
Unique labels in ground truth: 15

============================================================
TRAINING COMPLETED SUCCESSFULLY!
Classification reports saved to:
- validation_classification_report.txt
- test_classification_report.txt
============================================================
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mflowing-frog-796[0m at: [34mhttps://wandb.ai/murtuzanh-university-bonn/huggingface/runs/xury54mj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250920_150722-xury54mj/logs[0m
Stopping resource monitoring...
job-finetune-generic-bash-xlm-roberta-old.bash: line 57: kill: (1067828) - No such process
Total GPU execution time: 6247 seconds
Fetching SLURM job summary...
JobID           Elapsed     MaxRSS    CPUTime ExitCode 
------------ ---------- ---------- ---------- -------- 
23420039       22:53:42            61-01:16:48      0:0 
23420039.ex+   22:53:42            61-01:16:48      0:0 
23420039.0     22:53:28            61-01:01:52      0:0 
All logs are saved in: /home/s27mhusa_hpc/Master-Thesis/OutputNewDatasets20thSeptemberFineTuneEnglish/job_monitor_logs_xlm-roberta-old1.0_23420039_20250920_133334
