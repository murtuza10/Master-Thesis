no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/condabin/conda
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/bin/conda
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/bin/conda-env
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/bin/activate
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/bin/deactivate
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/etc/profile.d/conda.sh
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/etc/fish/conf.d/conda.fish
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/shell/condabin/Conda.psm1
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/shell/condabin/conda-hook.ps1
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/lib/python3.10/site-packages/xontrib/conda.xsh
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/etc/profile.d/conda.csh
no change     /home/s27mhusa_hpc/.bashrc
No action taken.
Starting resource monitoring every 30 seconds...
Logs will be stored in: /home/s27mhusa_hpc/Master-Thesis/OutputNewDatasets6thSeptemberFineTune/job_monitor_logs_mdeberta-crf-reg_23200897_20250909_120602
job-finetune-generic-bash.bash: line 42: iostat: command not found
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Appending key for api.wandb.ai to your netrc file: /home/s27mhusa_hpc/.netrc
wandb: Currently logged in as: murtuzanh (murtuzanh-university-bonn) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
Map:   0%|          | 0/103 [00:00<?, ? examples/s]Map: 100%|██████████| 103/103 [00:00<00:00, 663.68 examples/s]Map: 100%|██████████| 103/103 [00:00<00:00, 651.37 examples/s]
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
/home/s27mhusa_hpc/Master-Thesis/Fine-tune/fine_tune_mdeberta-crf.py:332: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `DebertaCRFTrainer.__init__`. Use `processing_class` instead.
  trainer = DebertaCRFTrainer(
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[I 2025-09-09 12:06:16,401] A new study created in memory with name: no-name-870c7c23-a61a-43f3-b7da-21cc768f51e9
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_120617-koj6it4h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-firebrand-705
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/koj6it4h
  0%|          | 0/208 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/208 [00:03<11:22,  3.30s/it]  1%|          | 2/208 [00:05<08:44,  2.55s/it]  1%|▏         | 3/208 [00:07<07:53,  2.31s/it]  2%|▏         | 4/208 [00:09<07:27,  2.19s/it]  2%|▏         | 5/208 [00:11<07:13,  2.13s/it]  3%|▎         | 6/208 [00:13<07:03,  2.10s/it]  3%|▎         | 7/208 [00:15<06:54,  2.06s/it]  4%|▍         | 8/208 [00:16<05:23,  1.62s/it]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.46it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.67it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A                                               
                                             [A  4%|▍         | 8/208 [00:18<05:23,  1.62s/it]
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  4%|▍         | 9/208 [00:24<12:19,  3.71s/it]  5%|▍         | 10/208 [00:26<10:32,  3.19s/it]  5%|▌         | 11/208 [00:28<09:18,  2.84s/it]  6%|▌         | 12/208 [00:30<08:27,  2.59s/it]  6%|▋         | 13/208 [00:32<07:52,  2.42s/it]  7%|▋         | 14/208 [00:34<07:26,  2.30s/it]  7%|▋         | 15/208 [00:36<07:06,  2.21s/it]  8%|▊         | 16/208 [00:37<05:34,  1.74s/it]{'eval_loss': 156.795654296875, 'eval_precision': 0.005477899508877975, 'eval_recall': 0.1124031007751938, 'eval_f1': 0.010446685878962535, 'eval_accuracy': 0.037241625089094794, 'eval_runtime': 2.5144, 'eval_samples_per_second': 40.965, 'eval_steps_per_second': 1.591, 'epoch': 1.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.71it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.61it/s][A                                                
                                             [A  8%|▊         | 16/208 [00:39<05:34,  1.74s/it]
100%|██████████| 4/4 [00:01<00:00,  2.61it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  8%|▊         | 17/208 [00:45<11:30,  3.61s/it]  9%|▊         | 18/208 [00:47<09:55,  3.14s/it]  9%|▉         | 19/208 [00:49<08:49,  2.80s/it] 10%|▉         | 20/208 [00:51<08:02,  2.57s/it] 10%|█         | 21/208 [00:53<07:29,  2.40s/it] 11%|█         | 22/208 [00:55<07:05,  2.29s/it] 11%|█         | 23/208 [00:57<06:46,  2.20s/it] 12%|█▏        | 24/208 [00:57<05:19,  1.74s/it]{'eval_loss': 138.31773376464844, 'eval_precision': 0.005097879282218597, 'eval_recall': 0.09689922480620156, 'eval_f1': 0.009686168151879117, 'eval_accuracy': 0.11297220242337848, 'eval_runtime': 2.1288, 'eval_samples_per_second': 48.384, 'eval_steps_per_second': 1.879, 'epoch': 2.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.88it/s][A
 75%|███████▌  | 3/4 [00:00<00:00,  2.87it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.69it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 12%|█▏        | 24/208 [00:59<05:19,  1.74s/it]
100%|██████████| 4/4 [00:01<00:00,  2.69it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 12%|█▏        | 25/208 [01:05<10:39,  3.49s/it] 12%|█▎        | 26/208 [01:07<09:15,  3.05s/it] 13%|█▎        | 27/208 [01:09<08:16,  2.74s/it] 13%|█▎        | 28/208 [01:11<07:34,  2.53s/it] 14%|█▍        | 29/208 [01:13<07:05,  2.38s/it] 14%|█▍        | 30/208 [01:15<06:44,  2.27s/it] 15%|█▍        | 31/208 [01:17<06:27,  2.19s/it] 15%|█▌        | 32/208 [01:18<05:04,  1.73s/it]{'eval_loss': 109.12509155273438, 'eval_precision': 0.0041572184429327285, 'eval_recall': 0.04263565891472868, 'eval_f1': 0.007575757575757576, 'eval_accuracy': 0.5035637918745546, 'eval_runtime': 2.0586, 'eval_samples_per_second': 50.035, 'eval_steps_per_second': 1.943, 'epoch': 3.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.91it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.81it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.56it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 15%|█▌        | 32/208 [01:20<05:04,  1.73s/it]
100%|██████████| 4/4 [00:01<00:00,  2.56it/s][A
                                             [A                                                 15%|█▌        | 32/208 [01:24<05:04,  1.73s/it] 15%|█▌        | 32/208 [01:24<07:44,  2.64s/it]
[I 2025-09-09 12:07:42,791] Trial 0 finished with value: 0.9440883630241907 and parameters: {'learning_rate': 1.2389138770915765e-05, 'num_train_epochs': 26, 'per_device_train_batch_size': 16, 'weight_decay': 2.7569745729594415e-06, 'warmup_ratio': 0.23815499076185576, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.9440883630241907.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▂▅█
wandb:                 eval/f1 █▇▄▁
wandb:               eval/loss █▇▄▁
wandb:          eval/precision ▃▂▁█
wandb:             eval/recall █▇▄▁
wandb:            eval/runtime █▂▁▄
wandb: eval/samples_per_second ▁▇█▅
wandb:   eval/steps_per_second ▁▇█▅
wandb:             train/epoch ▁▃▆██
wandb:       train/global_step ▁▃▆██
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.92463
wandb:                  eval/f1 0.00559
wandb:                eval/loss 68.97375
wandb:           eval/precision 0.01
wandb:              eval/recall 0.00388
wandb:             eval/runtime 2.2363
wandb:  eval/samples_per_second 46.059
wandb:    eval/steps_per_second 1.789
wandb:               total_flos 0
wandb:              train/epoch 4
wandb:        train/global_step 32
wandb:               train_loss 266.34277
wandb:            train_runtime 85.1598
wandb: train_samples_per_second 282.105
wandb:   train_steps_per_second 2.442
wandb: 
wandb: 🚀 View run dazzling-firebrand-705 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/koj6it4h
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250909_120617-koj6it4h/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_120745-8bt5lqo5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-capybara-706
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/8bt5lqo5
{'eval_loss': 68.97374725341797, 'eval_precision': 0.01, 'eval_recall': 0.003875968992248062, 'eval_f1': 0.00558659217877095, 'eval_accuracy': 0.9246258018531718, 'eval_runtime': 2.2363, 'eval_samples_per_second': 46.059, 'eval_steps_per_second': 1.789, 'epoch': 4.0}
{'train_runtime': 85.1598, 'train_samples_per_second': 282.105, 'train_steps_per_second': 2.442, 'train_loss': 266.3427734375, 'epoch': 4.0}
  0%|          | 0/152 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  1%|          | 1/152 [00:02<05:09,  2.05s/it]  1%|▏         | 2/152 [00:04<05:03,  2.02s/it]  2%|▏         | 3/152 [00:06<04:59,  2.01s/it]  3%|▎         | 4/152 [00:08<04:57,  2.01s/it]  3%|▎         | 5/152 [00:10<04:55,  2.01s/it]  4%|▍         | 6/152 [00:12<04:53,  2.01s/it]  5%|▍         | 7/152 [00:14<04:49,  2.00s/it]  5%|▌         | 8/152 [00:14<03:45,  1.57s/it]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.83it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.81it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A  5%|▌         | 8/152 [00:16<03:45,  1.57s/it]
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  6%|▌         | 9/152 [00:22<08:19,  3.49s/it]  7%|▋         | 10/152 [00:24<07:10,  3.03s/it]  7%|▋         | 11/152 [00:26<06:23,  2.72s/it]  8%|▊         | 12/152 [00:28<05:50,  2.50s/it]  9%|▊         | 13/152 [00:30<05:27,  2.35s/it]  9%|▉         | 14/152 [00:32<05:10,  2.25s/it] 10%|▉         | 15/152 [00:34<04:56,  2.17s/it] 11%|█         | 16/152 [00:35<03:52,  1.71s/it]{'eval_loss': 116.27586364746094, 'eval_precision': 0.004659289458357601, 'eval_recall': 0.06201550387596899, 'eval_f1': 0.00866738894907909, 'eval_accuracy': 0.3699215965787598, 'eval_runtime': 2.1183, 'eval_samples_per_second': 48.624, 'eval_steps_per_second': 1.888, 'epoch': 1.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.88it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.64it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 11%|█         | 16/152 [00:37<03:52,  1.71s/it]
100%|██████████| 4/4 [00:01<00:00,  2.64it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 11%|█         | 17/152 [00:42<07:41,  3.42s/it] 12%|█▏        | 18/152 [00:44<06:41,  2.99s/it] 12%|█▎        | 19/152 [00:46<05:58,  2.70s/it] 13%|█▎        | 20/152 [00:48<05:28,  2.49s/it] 14%|█▍        | 21/152 [00:50<05:07,  2.35s/it] 14%|█▍        | 22/152 [00:52<04:51,  2.24s/it] 15%|█▌        | 23/152 [00:54<04:39,  2.16s/it] 16%|█▌        | 24/152 [00:55<03:38,  1.71s/it]{'eval_loss': 23.58576774597168, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9397719173200285, 'eval_runtime': 2.0749, 'eval_samples_per_second': 49.64, 'eval_steps_per_second': 1.928, 'epoch': 2.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.88it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.76it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 16%|█▌        | 24/152 [00:57<03:38,  1.71s/it]
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 16%|█▋        | 25/152 [01:02<07:23,  3.49s/it] 17%|█▋        | 26/152 [01:04<06:24,  3.05s/it] 18%|█▊        | 27/152 [01:06<05:42,  2.74s/it] 18%|█▊        | 28/152 [01:08<05:12,  2.52s/it] 19%|█▉        | 29/152 [01:10<04:51,  2.37s/it] 20%|█▉        | 30/152 [01:12<04:35,  2.26s/it] 20%|██        | 31/152 [01:14<04:23,  2.18s/it] 21%|██        | 32/152 [01:15<03:26,  1.72s/it]{'eval_loss': 18.71055793762207, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9397719173200285, 'eval_runtime': 2.1103, 'eval_samples_per_second': 48.809, 'eval_steps_per_second': 1.895, 'epoch': 3.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.74it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.79it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.70it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 21%|██        | 32/152 [01:17<03:26,  1.72s/it]
100%|██████████| 4/4 [00:01<00:00,  2.70it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 22%|██▏       | 33/152 [01:23<06:54,  3.49s/it] 22%|██▏       | 34/152 [01:25<05:59,  3.05s/it] 23%|██▎       | 35/152 [01:27<05:25,  2.78s/it] 24%|██▎       | 36/152 [01:29<04:55,  2.55s/it] 24%|██▍       | 37/152 [01:31<04:34,  2.39s/it] 25%|██▌       | 38/152 [01:33<04:19,  2.27s/it] 26%|██▌       | 39/152 [01:35<04:06,  2.19s/it] 26%|██▋       | 40/152 [01:35<03:13,  1.72s/it]{'eval_loss': 14.704967498779297, 'eval_precision': 0.2916666666666667, 'eval_recall': 0.027131782945736434, 'eval_f1': 0.04964539007092198, 'eval_accuracy': 0.9390591589451176, 'eval_runtime': 2.0599, 'eval_samples_per_second': 50.002, 'eval_steps_per_second': 1.942, 'epoch': 4.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.95it/s][A
 75%|███████▌  | 3/4 [00:00<00:00,  2.85it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.65it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 26%|██▋       | 40/152 [01:38<03:13,  1.72s/it]
100%|██████████| 4/4 [00:01<00:00,  2.65it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 27%|██▋       | 41/152 [01:43<06:22,  3.44s/it] 28%|██▊       | 42/152 [01:45<05:31,  3.01s/it] 28%|██▊       | 43/152 [01:47<04:55,  2.71s/it] 29%|██▉       | 44/152 [01:49<04:30,  2.50s/it] 30%|██▉       | 45/152 [01:51<04:11,  2.35s/it] 30%|███       | 46/152 [01:53<03:58,  2.25s/it] 31%|███       | 47/152 [01:55<03:47,  2.17s/it] 32%|███▏      | 48/152 [01:56<02:58,  1.71s/it]{'eval_loss': 12.599691390991211, 'eval_precision': 0.7, 'eval_recall': 0.13565891472868216, 'eval_f1': 0.22727272727272727, 'eval_accuracy': 0.9461867426942266, 'eval_runtime': 2.0784, 'eval_samples_per_second': 49.557, 'eval_steps_per_second': 1.925, 'epoch': 5.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.78it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.79it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.64it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 32%|███▏      | 48/152 [01:58<02:58,  1.71s/it]
100%|██████████| 4/4 [00:01<00:00,  2.64it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 32%|███▏      | 49/152 [02:03<05:53,  3.43s/it] 33%|███▎      | 50/152 [02:05<05:06,  3.00s/it] 34%|███▎      | 51/152 [02:07<04:33,  2.70s/it] 34%|███▍      | 52/152 [02:09<04:09,  2.50s/it] 35%|███▍      | 53/152 [02:11<03:52,  2.35s/it] 36%|███▌      | 54/152 [02:13<03:40,  2.25s/it] 36%|███▌      | 55/152 [02:15<03:30,  2.17s/it] 37%|███▋      | 56/152 [02:16<02:44,  1.71s/it]{'eval_loss': 10.419309616088867, 'eval_precision': 0.3190789473684211, 'eval_recall': 0.375968992248062, 'eval_f1': 0.34519572953736655, 'eval_accuracy': 0.9506414825374199, 'eval_runtime': 2.074, 'eval_samples_per_second': 49.661, 'eval_steps_per_second': 1.929, 'epoch': 6.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.92it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.79it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.72it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 37%|███▋      | 56/152 [02:18<02:44,  1.71s/it]
100%|██████████| 4/4 [00:01<00:00,  2.72it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 38%|███▊      | 57/152 [02:23<05:27,  3.44s/it] 38%|███▊      | 58/152 [02:25<04:43,  3.01s/it] 39%|███▉      | 59/152 [02:27<04:12,  2.71s/it] 39%|███▉      | 60/152 [02:29<03:50,  2.50s/it] 40%|████      | 61/152 [02:31<03:33,  2.35s/it] 41%|████      | 62/152 [02:33<03:22,  2.25s/it] 41%|████▏     | 63/152 [02:35<03:12,  2.17s/it] 42%|████▏     | 64/152 [02:36<02:30,  1.71s/it]{'eval_loss': 8.420937538146973, 'eval_precision': 0.59375, 'eval_recall': 0.4418604651162791, 'eval_f1': 0.5066666666666667, 'eval_accuracy': 0.9634711332858161, 'eval_runtime': 2.0312, 'eval_samples_per_second': 50.709, 'eval_steps_per_second': 1.969, 'epoch': 7.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.62it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.71it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.63it/s][A                                                
                                             [A 42%|████▏     | 64/152 [02:38<02:30,  1.71s/it]
100%|██████████| 4/4 [00:01<00:00,  2.63it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 43%|████▎     | 65/152 [02:44<05:09,  3.56s/it] 43%|████▎     | 66/152 [02:46<04:25,  3.09s/it] 44%|████▍     | 67/152 [02:48<03:55,  2.77s/it] 45%|████▍     | 68/152 [02:50<03:36,  2.58s/it] 45%|████▌     | 69/152 [02:52<03:19,  2.41s/it] 46%|████▌     | 70/152 [02:54<03:07,  2.29s/it] 47%|████▋     | 71/152 [02:56<02:57,  2.19s/it] 47%|████▋     | 72/152 [02:56<02:18,  1.73s/it]{'eval_loss': 7.051206588745117, 'eval_precision': 0.5117845117845118, 'eval_recall': 0.5891472868217055, 'eval_f1': 0.5477477477477477, 'eval_accuracy': 0.9668567355666429, 'eval_runtime': 2.1241, 'eval_samples_per_second': 48.491, 'eval_steps_per_second': 1.883, 'epoch': 8.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.74it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.77it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.64it/s][A                                                
                                             [A 47%|████▋     | 72/152 [02:59<02:18,  1.73s/it]
100%|██████████| 4/4 [00:01<00:00,  2.64it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 48%|████▊     | 73/152 [03:04<04:39,  3.53s/it] 49%|████▊     | 74/152 [03:06<04:00,  3.08s/it] 49%|████▉     | 75/152 [03:08<03:32,  2.76s/it] 50%|█████     | 76/152 [03:10<03:12,  2.53s/it] 51%|█████     | 77/152 [03:12<02:57,  2.37s/it] 51%|█████▏    | 78/152 [03:14<02:47,  2.26s/it] 52%|█████▏    | 79/152 [03:16<02:38,  2.18s/it] 53%|█████▎    | 80/152 [03:17<02:03,  1.72s/it]{'eval_loss': 6.795415878295898, 'eval_precision': 0.5684210526315789, 'eval_recall': 0.627906976744186, 'eval_f1': 0.5966850828729281, 'eval_accuracy': 0.9670349251603706, 'eval_runtime': 2.0819, 'eval_samples_per_second': 49.474, 'eval_steps_per_second': 1.921, 'epoch': 9.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.72it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.78it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.80it/s][A                                                
                                             [A 53%|█████▎    | 80/152 [03:19<02:03,  1.72s/it]
100%|██████████| 4/4 [00:01<00:00,  2.80it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 53%|█████▎    | 81/152 [03:24<04:01,  3.40s/it] 54%|█████▍    | 82/152 [03:26<03:28,  2.98s/it] 55%|█████▍    | 83/152 [03:28<03:05,  2.69s/it] 55%|█████▌    | 84/152 [03:30<02:48,  2.49s/it] 56%|█████▌    | 85/152 [03:32<02:36,  2.34s/it] 57%|█████▋    | 86/152 [03:34<02:27,  2.24s/it] 57%|█████▋    | 87/152 [03:36<02:20,  2.16s/it] 58%|█████▊    | 88/152 [03:37<01:49,  1.71s/it]{'eval_loss': 7.454284191131592, 'eval_precision': 0.538961038961039, 'eval_recall': 0.6434108527131783, 'eval_f1': 0.5865724381625441, 'eval_accuracy': 0.9631147540983607, 'eval_runtime': 2.009, 'eval_samples_per_second': 51.268, 'eval_steps_per_second': 1.991, 'epoch': 10.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.91it/s][A
 75%|███████▌  | 3/4 [00:00<00:00,  2.85it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.72it/s][A                                                
                                             [A 58%|█████▊    | 88/152 [03:39<01:49,  1.71s/it]
100%|██████████| 4/4 [00:01<00:00,  2.72it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 59%|█████▊    | 89/152 [03:44<03:34,  3.41s/it] 59%|█████▉    | 90/152 [03:46<03:05,  2.99s/it] 60%|█████▉    | 91/152 [03:48<02:44,  2.70s/it] 61%|██████    | 92/152 [03:50<02:29,  2.49s/it] 61%|██████    | 93/152 [03:52<02:18,  2.34s/it] 62%|██████▏   | 94/152 [03:54<02:10,  2.24s/it] 62%|██████▎   | 95/152 [03:56<02:05,  2.20s/it] 63%|██████▎   | 96/152 [03:57<01:37,  1.74s/it]{'eval_loss': 4.870820045471191, 'eval_precision': 0.7291666666666666, 'eval_recall': 0.6782945736434108, 'eval_f1': 0.7028112449799196, 'eval_accuracy': 0.9784390591589451, 'eval_runtime': 2.0507, 'eval_samples_per_second': 50.227, 'eval_steps_per_second': 1.951, 'epoch': 11.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.72it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.78it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A                                                
                                             [A 63%|██████▎   | 96/152 [03:59<01:37,  1.74s/it]
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 64%|██████▍   | 97/152 [04:04<03:09,  3.44s/it] 64%|██████▍   | 98/152 [04:06<02:42,  3.02s/it] 65%|██████▌   | 99/152 [04:09<02:24,  2.72s/it] 66%|██████▌   | 100/152 [04:11<02:10,  2.51s/it] 66%|██████▋   | 101/152 [04:13<02:00,  2.37s/it] 67%|██████▋   | 102/152 [04:15<01:53,  2.26s/it] 68%|██████▊   | 103/152 [04:17<01:46,  2.18s/it] 68%|██████▊   | 104/152 [04:17<01:22,  1.72s/it]{'eval_loss': 4.66089391708374, 'eval_precision': 0.6911196911196911, 'eval_recall': 0.6937984496124031, 'eval_f1': 0.6924564796905222, 'eval_accuracy': 0.9775481111903065, 'eval_runtime': 2.1009, 'eval_samples_per_second': 49.027, 'eval_steps_per_second': 1.904, 'epoch': 12.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.76it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.77it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A                                                 
                                             [A 68%|██████▊   | 104/152 [04:19<01:22,  1.72s/it]
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 69%|██████▉   | 105/152 [04:25<02:41,  3.45s/it] 70%|██████▉   | 106/152 [04:27<02:18,  3.02s/it] 70%|███████   | 107/152 [04:29<02:02,  2.72s/it] 71%|███████   | 108/152 [04:31<01:50,  2.51s/it] 72%|███████▏  | 109/152 [04:33<01:41,  2.37s/it] 72%|███████▏  | 110/152 [04:35<01:35,  2.26s/it] 73%|███████▎  | 111/152 [04:37<01:29,  2.19s/it] 74%|███████▎  | 112/152 [04:37<01:09,  1.73s/it]{'eval_loss': 4.197951316833496, 'eval_precision': 0.6946564885496184, 'eval_recall': 0.7054263565891473, 'eval_f1': 0.7000000000000001, 'eval_accuracy': 0.9796863863150392, 'eval_runtime': 2.0851, 'eval_samples_per_second': 49.399, 'eval_steps_per_second': 1.918, 'epoch': 13.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.90it/s][A
 75%|███████▌  | 3/4 [00:00<00:00,  2.84it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.67it/s][A                                                 
                                             [A 74%|███████▎  | 112/152 [04:40<01:09,  1.73s/it]
100%|██████████| 4/4 [00:01<00:00,  2.67it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 74%|███████▍  | 113/152 [04:45<02:14,  3.46s/it] 75%|███████▌  | 114/152 [04:47<01:55,  3.03s/it] 76%|███████▌  | 115/152 [04:49<01:40,  2.73s/it] 76%|███████▋  | 116/152 [04:51<01:30,  2.52s/it] 77%|███████▋  | 117/152 [04:53<01:22,  2.37s/it] 78%|███████▊  | 118/152 [04:55<01:17,  2.27s/it] 78%|███████▊  | 119/152 [04:57<01:12,  2.19s/it] 79%|███████▉  | 120/152 [04:58<00:55,  1.73s/it]{'eval_loss': 4.3157501220703125, 'eval_precision': 0.703971119133574, 'eval_recall': 0.7558139534883721, 'eval_f1': 0.7289719626168224, 'eval_accuracy': 0.9793300071275838, 'eval_runtime': 2.0467, 'eval_samples_per_second': 50.325, 'eval_steps_per_second': 1.954, 'epoch': 14.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.88it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.82it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.70it/s][A                                                 
                                             [A 79%|███████▉  | 120/152 [05:00<00:55,  1.73s/it]
100%|██████████| 4/4 [00:01<00:00,  2.70it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 80%|███████▉  | 121/152 [05:07<02:03,  3.97s/it] 80%|████████  | 122/152 [05:09<01:41,  3.39s/it] 81%|████████  | 123/152 [05:11<01:26,  2.98s/it] 82%|████████▏ | 124/152 [05:13<01:15,  2.70s/it] 82%|████████▏ | 125/152 [05:15<01:07,  2.49s/it] 83%|████████▎ | 126/152 [05:17<01:01,  2.35s/it] 84%|████████▎ | 127/152 [05:19<00:56,  2.25s/it] 84%|████████▍ | 128/152 [05:20<00:42,  1.77s/it]{'eval_loss': 4.452611446380615, 'eval_precision': 0.7198443579766537, 'eval_recall': 0.7170542635658915, 'eval_f1': 0.7184466019417476, 'eval_accuracy': 0.9777263007840342, 'eval_runtime': 2.0692, 'eval_samples_per_second': 49.778, 'eval_steps_per_second': 1.933, 'epoch': 15.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.76it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.79it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.69it/s][A                                                 
                                             [A 84%|████████▍ | 128/152 [05:22<00:42,  1.77s/it]
100%|██████████| 4/4 [00:01<00:00,  2.69it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 85%|████████▍ | 129/152 [05:27<01:21,  3.53s/it] 86%|████████▌ | 130/152 [05:29<01:07,  3.08s/it] 86%|████████▌ | 131/152 [05:31<00:58,  2.76s/it] 87%|████████▋ | 132/152 [05:33<00:50,  2.54s/it] 88%|████████▊ | 133/152 [05:35<00:45,  2.39s/it] 88%|████████▊ | 134/152 [05:38<00:41,  2.28s/it] 89%|████████▉ | 135/152 [05:40<00:37,  2.20s/it] 89%|████████▉ | 136/152 [05:40<00:27,  1.73s/it]{'eval_loss': 4.408295631408691, 'eval_precision': 0.7142857142857143, 'eval_recall': 0.7945736434108527, 'eval_f1': 0.7522935779816513, 'eval_accuracy': 0.9782608695652174, 'eval_runtime': 2.0677, 'eval_samples_per_second': 49.815, 'eval_steps_per_second': 1.935, 'epoch': 16.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.92it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.83it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.67it/s][A                                                 
                                             [A 89%|████████▉ | 136/152 [05:42<00:27,  1.73s/it]
100%|██████████| 4/4 [00:01<00:00,  2.67it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 90%|█████████ | 137/152 [05:48<00:51,  3.42s/it] 91%|█████████ | 138/152 [05:50<00:42,  3.01s/it] 91%|█████████▏| 139/152 [05:52<00:35,  2.71s/it] 92%|█████████▏| 140/152 [05:54<00:30,  2.51s/it] 93%|█████████▎| 141/152 [05:56<00:25,  2.36s/it] 93%|█████████▎| 142/152 [05:58<00:22,  2.26s/it] 94%|█████████▍| 143/152 [06:00<00:19,  2.19s/it] 95%|█████████▍| 144/152 [06:00<00:13,  1.73s/it]{'eval_loss': 4.096144199371338, 'eval_precision': 0.7295373665480427, 'eval_recall': 0.7945736434108527, 'eval_f1': 0.7606679035250462, 'eval_accuracy': 0.9802209550962224, 'eval_runtime': 2.0734, 'eval_samples_per_second': 49.677, 'eval_steps_per_second': 1.929, 'epoch': 17.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.88it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.83it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.69it/s][A                                                 
                                             [A 95%|█████████▍| 144/152 [06:02<00:13,  1.73s/it]
100%|██████████| 4/4 [00:01<00:00,  2.69it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 95%|█████████▌| 145/152 [06:08<00:24,  3.45s/it] 96%|█████████▌| 146/152 [06:10<00:18,  3.03s/it] 97%|█████████▋| 147/152 [06:12<00:13,  2.73s/it] 97%|█████████▋| 148/152 [06:14<00:10,  2.52s/it] 98%|█████████▊| 149/152 [06:16<00:07,  2.37s/it] 99%|█████████▊| 150/152 [06:18<00:04,  2.27s/it] 99%|█████████▉| 151/152 [06:20<00:02,  2.19s/it]100%|██████████| 152/152 [06:21<00:00,  1.73s/it]{'eval_loss': 3.9157638549804688, 'eval_precision': 0.767175572519084, 'eval_recall': 0.7790697674418605, 'eval_f1': 0.7730769230769231, 'eval_accuracy': 0.9814682822523164, 'eval_runtime': 2.0593, 'eval_samples_per_second': 50.018, 'eval_steps_per_second': 1.942, 'epoch': 18.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.73it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.78it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.55it/s][A                                                 
                                             [A100%|██████████| 152/152 [06:23<00:00,  1.73s/it]
100%|██████████| 4/4 [00:01<00:00,  2.55it/s][A
                                             [A                                                 100%|██████████| 152/152 [06:27<00:00,  1.73s/it]100%|██████████| 152/152 [06:27<00:00,  2.55s/it]
[I 2025-09-09 12:14:13,624] Trial 1 finished with value: 3.319722221030952 and parameters: {'learning_rate': 9.26296801481127e-05, 'num_train_epochs': 19, 'per_device_train_batch_size': 16, 'weight_decay': 1.0744532406301703e-06, 'warmup_ratio': 0.2819965715376136, 'optimizer': 'Adam'}. Best is trial 1 with value: 3.319722221030952.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁██████████████████
wandb:                 eval/f1 ▁▁▁▁▃▄▆▆▆▆▇▇▇█▇████
wandb:               eval/loss █▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          eval/precision ▁▁▁▄▇▄▆▆▆▆█▇▇▇█████
wandb:             eval/recall ▂▁▁▁▂▄▅▆▇▇▇▇▇█▇████
wandb:            eval/runtime ▇▅▇▄▅▅▂█▅▁▃▆▅▃▄▄▅▄█
wandb: eval/samples_per_second ▂▄▂▅▄▄▇▁▄█▆▃▄▆▄▅▄▅▁
wandb:   eval/steps_per_second ▂▄▂▅▄▄▇▁▄█▆▃▃▆▄▅▄▅▁
wandb:             train/epoch ▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇███
wandb:       train/global_step ▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇███
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.98076
wandb:                  eval/f1 0.77947
wandb:                eval/loss 3.99171
wandb:           eval/precision 0.76493
wandb:              eval/recall 0.79457
wandb:             eval/runtime 2.1302
wandb:  eval/samples_per_second 48.352
wandb:    eval/steps_per_second 1.878
wandb:               total_flos 0
wandb:              train/epoch 19
wandb:        train/global_step 152
wandb:               train_loss 37.24425
wandb:            train_runtime 389.598
wandb: train_samples_per_second 45.062
wandb:   train_steps_per_second 0.39
wandb: 
wandb: 🚀 View run restful-capybara-706 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/8bt5lqo5
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250909_120745-8bt5lqo5/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_121416-ltovs114
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-terrain-707
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/ltovs114
{'eval_loss': 3.991710662841797, 'eval_precision': 0.7649253731343284, 'eval_recall': 0.7945736434108527, 'eval_f1': 0.779467680608365, 'eval_accuracy': 0.9807555238774056, 'eval_runtime': 2.1302, 'eval_samples_per_second': 48.352, 'eval_steps_per_second': 1.878, 'epoch': 19.0}
{'train_runtime': 389.598, 'train_samples_per_second': 45.062, 'train_steps_per_second': 0.39, 'train_loss': 37.24424984580592, 'epoch': 19.0}
  0%|          | 0/360 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/360 [00:01<08:34,  1.43s/it]  1%|          | 2/360 [00:02<08:29,  1.42s/it]  1%|          | 3/360 [00:04<08:27,  1.42s/it]  1%|          | 4/360 [00:05<08:25,  1.42s/it]  1%|▏         | 5/360 [00:07<08:23,  1.42s/it]  2%|▏         | 6/360 [00:08<08:22,  1.42s/it]  2%|▏         | 7/360 [00:09<08:20,  1.42s/it]  2%|▏         | 8/360 [00:11<08:19,  1.42s/it]  2%|▎         | 9/360 [00:12<08:17,  1.42s/it]  3%|▎         | 10/360 [00:14<08:16,  1.42s/it]  3%|▎         | 11/360 [00:15<08:14,  1.42s/it]  3%|▎         | 12/360 [00:17<08:13,  1.42s/it]  4%|▎         | 13/360 [00:18<08:12,  1.42s/it]  4%|▍         | 14/360 [00:19<08:10,  1.42s/it]  4%|▍         | 15/360 [00:20<06:48,  1.19s/it]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.70it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.66it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.55it/s][A                                                
                                             [A  4%|▍         | 15/360 [00:22<06:48,  1.19s/it]
100%|██████████| 4/4 [00:01<00:00,  2.55it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  4%|▍         | 16/360 [00:27<16:29,  2.88s/it]  5%|▍         | 17/360 [00:28<13:56,  2.44s/it]  5%|▌         | 18/360 [00:30<12:08,  2.13s/it]  5%|▌         | 19/360 [00:31<10:53,  1.92s/it]  6%|▌         | 20/360 [00:32<10:00,  1.77s/it]  6%|▌         | 21/360 [00:34<09:23,  1.66s/it]  6%|▌         | 22/360 [00:35<08:57,  1.59s/it]  6%|▋         | 23/360 [00:37<08:38,  1.54s/it]  7%|▋         | 24/360 [00:38<08:24,  1.50s/it]  7%|▋         | 25/360 [00:40<08:14,  1.48s/it]  7%|▋         | 26/360 [00:41<08:07,  1.46s/it]  8%|▊         | 27/360 [00:42<08:01,  1.45s/it]  8%|▊         | 28/360 [00:44<07:57,  1.44s/it]  8%|▊         | 29/360 [00:45<07:53,  1.43s/it]  8%|▊         | 30/360 [00:46<06:34,  1.20s/it]{'eval_loss': 160.8795928955078, 'eval_precision': 0.00546036527960836, 'eval_recall': 0.1124031007751938, 'eval_f1': 0.010414796193212426, 'eval_accuracy': 0.0311831789023521, 'eval_runtime': 2.1651, 'eval_samples_per_second': 47.573, 'eval_steps_per_second': 1.848, 'epoch': 1.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.79it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.79it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.41it/s][A                                                
                                             [A  8%|▊         | 30/360 [00:48<06:34,  1.20s/it]
100%|██████████| 4/4 [00:01<00:00,  2.41it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  9%|▊         | 31/360 [00:53<15:56,  2.91s/it]  9%|▉         | 32/360 [00:54<13:26,  2.46s/it]  9%|▉         | 33/360 [00:56<11:41,  2.15s/it]  9%|▉         | 34/360 [00:57<10:28,  1.93s/it] 10%|▉         | 35/360 [00:58<09:36,  1.78s/it] 10%|█         | 36/360 [01:00<09:00,  1.67s/it] 10%|█         | 37/360 [01:01<08:34,  1.59s/it] 11%|█         | 38/360 [01:03<08:16,  1.54s/it] 11%|█         | 39/360 [01:04<08:02,  1.50s/it] 11%|█         | 40/360 [01:06<07:53,  1.48s/it] 11%|█▏        | 41/360 [01:07<07:46,  1.46s/it] 12%|█▏        | 42/360 [01:08<07:40,  1.45s/it] 12%|█▏        | 43/360 [01:10<07:36,  1.44s/it] 12%|█▏        | 44/360 [01:11<07:32,  1.43s/it] 12%|█▎        | 45/360 [01:12<06:17,  1.20s/it]{'eval_loss': 156.24911499023438, 'eval_precision': 0.0056753688989784334, 'eval_recall': 0.11627906976744186, 'eval_f1': 0.010822510822510822, 'eval_accuracy': 0.03902352102637206, 'eval_runtime': 2.1879, 'eval_samples_per_second': 47.078, 'eval_steps_per_second': 1.828, 'epoch': 2.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.86it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.83it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.76it/s][A                                                
                                             [A 12%|█▎        | 45/360 [01:14<06:17,  1.20s/it]
100%|██████████| 4/4 [00:01<00:00,  2.76it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 13%|█▎        | 46/360 [01:19<14:55,  2.85s/it] 13%|█▎        | 47/360 [01:20<12:37,  2.42s/it] 13%|█▎        | 48/360 [01:21<11:01,  2.12s/it] 14%|█▎        | 49/360 [01:23<09:53,  1.91s/it] 14%|█▍        | 50/360 [01:24<09:06,  1.76s/it] 14%|█▍        | 51/360 [01:26<08:32,  1.66s/it] 14%|█▍        | 52/360 [01:27<08:08,  1.59s/it] 15%|█▍        | 53/360 [01:29<07:51,  1.54s/it] 15%|█▌        | 54/360 [01:30<07:39,  1.50s/it] 15%|█▌        | 55/360 [01:31<07:30,  1.48s/it] 16%|█▌        | 56/360 [01:33<07:23,  1.46s/it] 16%|█▌        | 57/360 [01:34<07:18,  1.45s/it] 16%|█▌        | 58/360 [01:36<07:14,  1.44s/it] 16%|█▋        | 59/360 [01:37<07:10,  1.43s/it] 17%|█▋        | 60/360 [01:38<05:58,  1.20s/it]{'eval_loss': 148.22264099121094, 'eval_precision': 0.005031933423650087, 'eval_recall': 0.10077519379844961, 'eval_f1': 0.009585253456221196, 'eval_accuracy': 0.06414825374198146, 'eval_runtime': 2.0605, 'eval_samples_per_second': 49.988, 'eval_steps_per_second': 1.941, 'epoch': 3.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.76it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.78it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.58it/s][A                                                
                                             [A 17%|█▋        | 60/360 [01:40<05:58,  1.20s/it]
100%|██████████| 4/4 [00:01<00:00,  2.58it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 17%|█▋        | 61/360 [01:44<14:20,  2.88s/it] 17%|█▋        | 62/360 [01:46<12:06,  2.44s/it] 18%|█▊        | 63/360 [01:47<10:33,  2.13s/it] 18%|█▊        | 64/360 [01:49<09:27,  1.92s/it] 18%|█▊        | 65/360 [01:50<08:41,  1.77s/it] 18%|█▊        | 66/360 [01:52<08:08,  1.66s/it] 19%|█▊        | 67/360 [01:53<07:45,  1.59s/it] 19%|█▉        | 68/360 [01:54<07:28,  1.54s/it] 19%|█▉        | 69/360 [01:56<07:17,  1.50s/it] 19%|█▉        | 70/360 [01:57<07:20,  1.52s/it] 20%|█▉        | 71/360 [01:59<07:10,  1.49s/it] 20%|██        | 72/360 [02:00<07:02,  1.47s/it] 20%|██        | 73/360 [02:02<06:56,  1.45s/it] 21%|██        | 74/360 [02:03<06:52,  1.44s/it] 21%|██        | 75/360 [02:04<05:43,  1.20s/it]{'eval_loss': 136.6981201171875, 'eval_precision': 0.005199667221297837, 'eval_recall': 0.09689922480620156, 'eval_f1': 0.00986971969996052, 'eval_accuracy': 0.12918745545260157, 'eval_runtime': 2.1276, 'eval_samples_per_second': 48.411, 'eval_steps_per_second': 1.88, 'epoch': 4.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.73it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.71it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.68it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 21%|██        | 75/360 [02:06<05:43,  1.20s/it]
100%|██████████| 4/4 [00:01<00:00,  2.68it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 21%|██        | 76/360 [02:11<13:40,  2.89s/it] 21%|██▏       | 77/360 [02:12<11:32,  2.45s/it] 22%|██▏       | 78/360 [02:13<10:03,  2.14s/it] 22%|██▏       | 79/360 [02:15<09:00,  1.92s/it] 22%|██▏       | 80/360 [02:16<08:16,  1.77s/it] 22%|██▎       | 81/360 [02:18<07:44,  1.67s/it] 23%|██▎       | 82/360 [02:19<07:22,  1.59s/it] 23%|██▎       | 83/360 [02:20<07:06,  1.54s/it] 23%|██▎       | 84/360 [02:22<06:54,  1.50s/it] 24%|██▎       | 85/360 [02:23<06:46,  1.48s/it] 24%|██▍       | 86/360 [02:25<06:40,  1.46s/it] 24%|██▍       | 87/360 [02:26<06:35,  1.45s/it] 24%|██▍       | 88/360 [02:28<06:31,  1.44s/it] 25%|██▍       | 89/360 [02:29<06:27,  1.43s/it] 25%|██▌       | 90/360 [02:30<05:23,  1.20s/it]{'eval_loss': 122.39260864257812, 'eval_precision': 0.005897435897435898, 'eval_recall': 0.08914728682170543, 'eval_f1': 0.011063011063011063, 'eval_accuracy': 0.2900926585887384, 'eval_runtime': 2.1056, 'eval_samples_per_second': 48.917, 'eval_steps_per_second': 1.9, 'epoch': 5.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.91it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.82it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.64it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 25%|██▌       | 90/360 [02:32<05:23,  1.20s/it]
100%|██████████| 4/4 [00:01<00:00,  2.64it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 25%|██▌       | 91/360 [02:36<12:57,  2.89s/it] 26%|██▌       | 92/360 [02:38<10:56,  2.45s/it] 26%|██▌       | 93/360 [02:39<09:31,  2.14s/it] 26%|██▌       | 94/360 [02:41<08:31,  1.92s/it] 26%|██▋       | 95/360 [02:42<07:49,  1.77s/it] 27%|██▋       | 96/360 [02:44<07:19,  1.67s/it] 27%|██▋       | 97/360 [02:45<06:58,  1.59s/it] 27%|██▋       | 98/360 [02:46<06:43,  1.54s/it] 28%|██▊       | 99/360 [02:48<06:32,  1.50s/it] 28%|██▊       | 100/360 [02:49<06:24,  1.48s/it] 28%|██▊       | 101/360 [02:51<06:18,  1.46s/it] 28%|██▊       | 102/360 [02:52<06:13,  1.45s/it] 29%|██▊       | 103/360 [02:53<06:10,  1.44s/it] 29%|██▉       | 104/360 [02:55<06:06,  1.43s/it] 29%|██▉       | 105/360 [02:56<05:05,  1.20s/it]{'eval_loss': 108.20012664794922, 'eval_precision': 0.005204163330664532, 'eval_recall': 0.050387596899224806, 'eval_f1': 0.009433962264150945, 'eval_accuracy': 0.5295794725588026, 'eval_runtime': 2.0972, 'eval_samples_per_second': 49.113, 'eval_steps_per_second': 1.907, 'epoch': 6.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.73it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.70it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.65it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                 
                                             [A 29%|██▉       | 105/360 [02:58<05:05,  1.20s/it]
100%|██████████| 4/4 [00:01<00:00,  2.65it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 29%|██▉       | 106/360 [03:02<12:18,  2.91s/it] 30%|██▉       | 107/360 [03:04<10:22,  2.46s/it] 30%|███       | 108/360 [03:05<09:11,  2.19s/it] 30%|███       | 109/360 [03:07<08:11,  1.96s/it] 31%|███       | 110/360 [03:08<07:29,  1.80s/it] 31%|███       | 111/360 [03:10<06:59,  1.68s/it] 31%|███       | 112/360 [03:11<06:37,  1.60s/it] 31%|███▏      | 113/360 [03:12<06:22,  1.55s/it] 32%|███▏      | 114/360 [03:14<06:11,  1.51s/it] 32%|███▏      | 115/360 [03:15<06:03,  1.48s/it] 32%|███▏      | 116/360 [03:17<05:57,  1.46s/it] 32%|███▎      | 117/360 [03:18<05:52,  1.45s/it] 33%|███▎      | 118/360 [03:20<05:48,  1.44s/it] 33%|███▎      | 119/360 [03:21<05:45,  1.43s/it] 33%|███▎      | 120/360 [03:22<04:47,  1.20s/it]{'eval_loss': 94.35025787353516, 'eval_precision': 0.004205214465937763, 'eval_recall': 0.01937984496124031, 'eval_f1': 0.006910850034554251, 'eval_accuracy': 0.7507127583749109, 'eval_runtime': 2.0833, 'eval_samples_per_second': 49.442, 'eval_steps_per_second': 1.92, 'epoch': 7.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.98it/s][A
 75%|███████▌  | 3/4 [00:00<00:00,  2.86it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.75it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                 
                                             [A 33%|███▎      | 120/360 [03:24<04:47,  1.20s/it]
100%|██████████| 4/4 [00:01<00:00,  2.75it/s][A
                                             [A                                                  33%|███▎      | 120/360 [03:27<04:47,  1.20s/it] 33%|███▎      | 120/360 [03:27<06:55,  1.73s/it]
[I 2025-09-09 12:17:45,420] Trial 2 finished with value: 0.888691367929936 and parameters: {'learning_rate': 1.2279744909231083e-06, 'num_train_epochs': 24, 'per_device_train_batch_size': 8, 'weight_decay': 0.10351813241486499, 'warmup_ratio': 0.18420506096070777, 'optimizer': 'AdamW'}. Best is trial 1 with value: 3.319722221030952.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▁▁▂▃▅▇█
wandb:                 eval/f1 ▇█▇▇█▇▄▁
wandb:               eval/loss ██▇▆▅▃▂▁
wandb:          eval/precision ▇█▆▇█▇▄▁
wandb:             eval/recall ██▇▇▆▄▂▁
wandb:            eval/runtime ▇█▃▆▅▄▄▁
wandb: eval/samples_per_second ▂▁▆▃▄▄▅█
wandb:   eval/steps_per_second ▂▁▆▃▄▄▅█
wandb:             train/epoch ▁▂▃▄▅▆▇██
wandb:       train/global_step ▁▂▃▄▅▆▇██
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.87919
wandb:                  eval/f1 0.00308
wandb:                eval/loss 80.51755
wandb:           eval/precision 0.00255
wandb:              eval/recall 0.00388
wandb:             eval/runtime 2.0133
wandb:  eval/samples_per_second 51.16
wandb:    eval/steps_per_second 1.987
wandb:               total_flos 0
wandb:              train/epoch 8
wandb:        train/global_step 120
wandb:               train_loss 274.6347
wandb:            train_runtime 210.4943
wandb: train_samples_per_second 105.352
wandb:   train_steps_per_second 1.71
wandb: 
wandb: 🚀 View run breezy-terrain-707 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/ltovs114
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250909_121416-ltovs114/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_121748-fnsozj3e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-waterfall-708
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/fnsozj3e
{'eval_loss': 80.51754760742188, 'eval_precision': 0.002551020408163265, 'eval_recall': 0.003875968992248062, 'eval_f1': 0.0030769230769230774, 'eval_accuracy': 0.8791874554526016, 'eval_runtime': 2.0133, 'eval_samples_per_second': 51.16, 'eval_steps_per_second': 1.987, 'epoch': 8.0}
{'train_runtime': 210.4943, 'train_samples_per_second': 105.352, 'train_steps_per_second': 1.71, 'train_loss': 274.63470052083335, 'epoch': 8.0}
  0%|          | 0/75 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  1%|▏         | 1/75 [00:01<01:46,  1.44s/it]  3%|▎         | 2/75 [00:02<01:43,  1.42s/it]  4%|▍         | 3/75 [00:04<01:42,  1.42s/it]  5%|▌         | 4/75 [00:05<01:40,  1.42s/it]  7%|▋         | 5/75 [00:07<01:39,  1.42s/it]  8%|▊         | 6/75 [00:08<01:37,  1.42s/it]  9%|▉         | 7/75 [00:09<01:36,  1.42s/it] 11%|█         | 8/75 [00:11<01:35,  1.42s/it] 12%|█▏        | 9/75 [00:12<01:33,  1.42s/it] 13%|█▎        | 10/75 [00:14<01:32,  1.42s/it] 15%|█▍        | 11/75 [00:15<01:30,  1.42s/it] 16%|█▌        | 12/75 [00:17<01:29,  1.42s/it] 17%|█▋        | 13/75 [00:18<01:27,  1.42s/it] 19%|█▊        | 14/75 [00:19<01:26,  1.42s/it] 20%|██        | 15/75 [00:20<01:11,  1.18s/it]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.74it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A                                               
                                             [A 20%|██        | 15/75 [00:22<01:11,  1.18s/it]
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 21%|██▏       | 16/75 [00:27<02:54,  2.95s/it] 23%|██▎       | 17/75 [00:28<02:24,  2.49s/it] 24%|██▍       | 18/75 [00:30<02:03,  2.17s/it] 25%|██▌       | 19/75 [00:31<01:48,  1.94s/it] 27%|██▋       | 20/75 [00:33<01:38,  1.79s/it] 28%|██▊       | 21/75 [00:34<01:30,  1.68s/it] 29%|██▉       | 22/75 [00:36<01:24,  1.60s/it] 31%|███       | 23/75 [00:37<01:20,  1.54s/it] 32%|███▏      | 24/75 [00:38<01:16,  1.51s/it] 33%|███▎      | 25/75 [00:40<01:14,  1.48s/it] 35%|███▍      | 26/75 [00:41<01:11,  1.46s/it] 36%|███▌      | 27/75 [00:43<01:09,  1.45s/it] 37%|███▋      | 28/75 [00:44<01:07,  1.44s/it] 39%|███▊      | 29/75 [00:46<01:05,  1.43s/it] 40%|████      | 30/75 [00:46<00:53,  1.20s/it]{'eval_loss': 142.4319305419922, 'eval_precision': 0.00518237990831174, 'eval_recall': 0.10077519379844961, 'eval_f1': 0.00985781990521327, 'eval_accuracy': 0.09176764076977904, 'eval_runtime': 2.1343, 'eval_samples_per_second': 48.26, 'eval_steps_per_second': 1.874, 'epoch': 1.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.75it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.78it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.38it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 40%|████      | 30/75 [00:48<00:53,  1.20s/it]
100%|██████████| 4/4 [00:01<00:00,  2.38it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 41%|████▏     | 31/75 [00:53<02:09,  2.95s/it] 43%|████▎     | 32/75 [00:55<01:47,  2.49s/it] 44%|████▍     | 33/75 [00:56<01:31,  2.17s/it] 45%|████▌     | 34/75 [00:57<01:19,  1.94s/it] 47%|████▋     | 35/75 [00:59<01:11,  1.79s/it] 48%|████▊     | 36/75 [01:00<01:05,  1.68s/it] 49%|████▉     | 37/75 [01:02<01:00,  1.60s/it] 51%|█████     | 38/75 [01:03<00:57,  1.54s/it] 52%|█████▏    | 39/75 [01:05<00:54,  1.51s/it] 53%|█████▎    | 40/75 [01:06<00:51,  1.48s/it] 55%|█████▍    | 41/75 [01:07<00:49,  1.46s/it] 56%|█████▌    | 42/75 [01:09<00:47,  1.45s/it] 57%|█████▋    | 43/75 [01:10<00:46,  1.44s/it] 59%|█████▊    | 44/75 [01:12<00:44,  1.43s/it] 60%|██████    | 45/75 [01:12<00:35,  1.20s/it]{'eval_loss': 121.67819213867188, 'eval_precision': 0.005417956656346749, 'eval_recall': 0.08139534883720931, 'eval_f1': 0.010159651669085631, 'eval_accuracy': 0.29454739843193156, 'eval_runtime': 2.1922, 'eval_samples_per_second': 46.985, 'eval_steps_per_second': 1.825, 'epoch': 2.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.87it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.82it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 60%|██████    | 45/75 [01:14<00:35,  1.20s/it]
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 61%|██████▏   | 46/75 [01:19<01:24,  2.92s/it] 63%|██████▎   | 47/75 [01:21<01:09,  2.47s/it] 64%|██████▍   | 48/75 [01:22<00:58,  2.15s/it] 65%|██████▌   | 49/75 [01:23<00:50,  1.93s/it] 67%|██████▋   | 50/75 [01:25<00:44,  1.78s/it] 68%|██████▊   | 51/75 [01:26<00:40,  1.67s/it] 69%|██████▉   | 52/75 [01:28<00:36,  1.59s/it] 71%|███████   | 53/75 [01:29<00:33,  1.54s/it] 72%|███████▏  | 54/75 [01:31<00:31,  1.50s/it] 73%|███████▎  | 55/75 [01:32<00:29,  1.48s/it] 75%|███████▍  | 56/75 [01:33<00:27,  1.46s/it] 76%|███████▌  | 57/75 [01:35<00:26,  1.45s/it] 77%|███████▋  | 58/75 [01:36<00:25,  1.48s/it] 79%|███████▊  | 59/75 [01:38<00:23,  1.46s/it] 80%|████████  | 60/75 [01:38<00:18,  1.22s/it]{'eval_loss': 107.01297760009766, 'eval_precision': 0.004517453798767967, 'eval_recall': 0.04263565891472868, 'eval_f1': 0.008169327887114742, 'eval_accuracy': 0.5402708481824662, 'eval_runtime': 2.1107, 'eval_samples_per_second': 48.798, 'eval_steps_per_second': 1.895, 'epoch': 3.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.70it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.68it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 80%|████████  | 60/75 [01:41<00:18,  1.22s/it]
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 81%|████████▏ | 61/75 [01:45<00:40,  2.92s/it] 83%|████████▎ | 62/75 [01:47<00:32,  2.48s/it] 84%|████████▍ | 63/75 [01:48<00:26,  2.17s/it] 85%|████████▌ | 64/75 [01:50<00:21,  1.95s/it] 87%|████████▋ | 65/75 [01:51<00:18,  1.80s/it] 88%|████████▊ | 66/75 [01:53<00:15,  1.69s/it] 89%|████████▉ | 67/75 [01:54<00:12,  1.62s/it] 91%|█████████ | 68/75 [01:55<00:10,  1.57s/it] 92%|█████████▏| 69/75 [01:57<00:09,  1.53s/it] 93%|█████████▎| 70/75 [01:58<00:07,  1.50s/it] 95%|█████████▍| 71/75 [02:00<00:05,  1.49s/it] 96%|█████████▌| 72/75 [02:01<00:04,  1.47s/it] 97%|█████████▋| 73/75 [02:03<00:02,  1.47s/it] 99%|█████████▊| 74/75 [02:04<00:01,  1.46s/it]100%|██████████| 75/75 [02:05<00:00,  1.22s/it]{'eval_loss': 97.8447265625, 'eval_precision': 0.003911342894393742, 'eval_recall': 0.023255813953488372, 'eval_f1': 0.006696428571428572, 'eval_accuracy': 0.6929793300071276, 'eval_runtime': 2.21, 'eval_samples_per_second': 46.606, 'eval_steps_per_second': 1.81, 'epoch': 4.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.74it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A100%|██████████| 75/75 [02:07<00:00,  1.22s/it]
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A
                                             [A                                               100%|██████████| 75/75 [02:11<00:00,  1.22s/it]100%|██████████| 75/75 [02:11<00:00,  1.75s/it]
[I 2025-09-09 12:20:00,588] Trial 3 finished with value: 0.7722558791406525 and parameters: {'learning_rate': 2.347553883135984e-06, 'num_train_epochs': 5, 'per_device_train_batch_size': 8, 'weight_decay': 0.08073480626743697, 'warmup_ratio': 0.07106698395583848, 'optimizer': 'Adam'}. Best is trial 1 with value: 3.319722221030952.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▃▆██
wandb:                 eval/f1 ▇█▄▁▃
wandb:               eval/loss █▅▃▁▁
wandb:          eval/precision ▇█▄▁▅
wandb:             eval/recall █▆▃▁▁
wandb:            eval/runtime ▃▇▁█▁
wandb: eval/samples_per_second ▆▂█▁█
wandb:   eval/steps_per_second ▆▂█▁█
wandb:             train/epoch ▁▃▅▆██
wandb:       train/global_step ▁▃▅▆██
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.73646
wandb:                  eval/f1 0.00783
wandb:                eval/loss 94.56773
wandb:           eval/precision 0.00471
wandb:              eval/recall 0.02326
wandb:             eval/runtime 2.1114
wandb:  eval/samples_per_second 48.782
wandb:    eval/steps_per_second 1.894
wandb:               total_flos 0
wandb:              train/epoch 5
wandb:        train/global_step 75
wandb:               train_loss 248.90284
wandb:            train_runtime 133.9096
wandb: train_samples_per_second 34.501
wandb:   train_steps_per_second 0.56
wandb: 
wandb: 🚀 View run glamorous-waterfall-708 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/fnsozj3e
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250909_121748-fnsozj3e/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_122003-716lr9es
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-gorge-709
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/716lr9es
{'eval_loss': 94.5677261352539, 'eval_precision': 0.004709576138147566, 'eval_recall': 0.023255813953488372, 'eval_f1': 0.007832898172323759, 'eval_accuracy': 0.7364575908766928, 'eval_runtime': 2.1114, 'eval_samples_per_second': 48.782, 'eval_steps_per_second': 1.894, 'epoch': 5.0}
{'train_runtime': 133.9096, 'train_samples_per_second': 34.501, 'train_steps_per_second': 0.56, 'train_loss': 248.90283854166665, 'epoch': 5.0}
  0%|          | 0/96 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  1%|          | 1/96 [00:02<03:17,  2.08s/it]  2%|▏         | 2/96 [00:04<03:13,  2.06s/it]  3%|▎         | 3/96 [00:06<03:10,  2.05s/it]  4%|▍         | 4/96 [00:08<03:07,  2.04s/it]  5%|▌         | 5/96 [00:10<03:05,  2.04s/it]  6%|▋         | 6/96 [00:12<03:03,  2.04s/it]  7%|▋         | 7/96 [00:14<03:00,  2.03s/it]  8%|▊         | 8/96 [00:14<02:20,  1.59s/it]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.86it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.79it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A                                              
                                             [A  8%|▊         | 8/96 [00:17<02:20,  1.59s/it]
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  9%|▉         | 9/96 [00:22<05:12,  3.59s/it] 10%|█         | 10/96 [00:24<04:27,  3.11s/it] 11%|█▏        | 11/96 [00:26<03:56,  2.78s/it] 12%|█▎        | 12/96 [00:29<03:34,  2.56s/it] 14%|█▎        | 13/96 [00:31<03:19,  2.40s/it] 15%|█▍        | 14/96 [00:33<03:07,  2.29s/it] 16%|█▌        | 15/96 [00:35<02:58,  2.20s/it] 17%|█▋        | 16/96 [00:35<02:19,  1.74s/it]{'eval_loss': 158.06712341308594, 'eval_precision': 0.005470665912092058, 'eval_recall': 0.1124031007751938, 'eval_f1': 0.010433531210649397, 'eval_accuracy': 0.035281539558089804, 'eval_runtime': 2.1202, 'eval_samples_per_second': 48.58, 'eval_steps_per_second': 1.887, 'epoch': 1.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.86it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.80it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.66it/s][A                                               
                                             [A 17%|█▋        | 16/96 [00:37<02:19,  1.74s/it]
100%|██████████| 4/4 [00:01<00:00,  2.66it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 18%|█▊        | 17/96 [00:44<05:07,  3.89s/it] 19%|█▉        | 18/96 [00:46<04:19,  3.33s/it] 20%|█▉        | 19/96 [00:48<03:46,  2.94s/it] 21%|██        | 20/96 [00:50<03:22,  2.67s/it] 22%|██▏       | 21/96 [00:52<03:06,  2.48s/it] 23%|██▎       | 22/96 [00:54<02:53,  2.35s/it] 24%|██▍       | 23/96 [00:56<02:44,  2.25s/it] 25%|██▌       | 24/96 [00:57<02:07,  1.77s/it]{'eval_loss': 148.5157928466797, 'eval_precision': 0.005031933423650087, 'eval_recall': 0.10077519379844961, 'eval_f1': 0.009585253456221196, 'eval_accuracy': 0.06325730577334283, 'eval_runtime': 2.0808, 'eval_samples_per_second': 49.5, 'eval_steps_per_second': 1.922, 'epoch': 2.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.95it/s][A
 75%|███████▌  | 3/4 [00:00<00:00,  2.87it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.63it/s][A                                               
                                             [A 25%|██▌       | 24/96 [00:59<02:07,  1.77s/it]
100%|██████████| 4/4 [00:01<00:00,  2.63it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 26%|██▌       | 25/96 [01:06<04:39,  3.94s/it] 27%|██▋       | 26/96 [01:08<03:55,  3.37s/it] 28%|██▊       | 27/96 [01:10<03:28,  3.02s/it] 29%|██▉       | 28/96 [01:12<03:05,  2.72s/it] 30%|███       | 29/96 [01:14<02:48,  2.51s/it] 31%|███▏      | 30/96 [01:16<02:36,  2.37s/it] 32%|███▏      | 31/96 [01:18<02:27,  2.26s/it] 33%|███▎      | 32/96 [01:19<01:54,  1.78s/it]{'eval_loss': 139.8118133544922, 'eval_precision': 0.0050566343042071195, 'eval_recall': 0.09689922480620156, 'eval_f1': 0.009611687812379853, 'eval_accuracy': 0.10548823948681398, 'eval_runtime': 2.0786, 'eval_samples_per_second': 49.552, 'eval_steps_per_second': 1.924, 'epoch': 3.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.89it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.80it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A                                               
                                             [A 33%|███▎      | 32/96 [01:21<01:54,  1.78s/it]
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A
                                             [A                                                33%|███▎      | 32/96 [01:26<01:54,  1.78s/it] 33%|███▎      | 32/96 [01:26<02:53,  2.71s/it]
[I 2025-09-09 12:21:31,442] Trial 4 finished with value: 0.2610247742405178 and parameters: {'learning_rate': 1.5288194237620954e-06, 'num_train_epochs': 12, 'per_device_train_batch_size': 16, 'weight_decay': 3.5753435829508057e-06, 'warmup_ratio': 0.08004415853361634, 'optimizer': 'AdamW'}. Best is trial 1 with value: 3.319722221030952.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▃▅█
wandb:                 eval/f1 █▄▄▁
wandb:               eval/loss █▅▃▁
wandb:          eval/precision █▄▄▁
wandb:             eval/recall █▅▄▁
wandb:            eval/runtime █▁▁▄
wandb: eval/samples_per_second ▁██▅
wandb:   eval/steps_per_second ▁██▅
wandb:             train/epoch ▁▃▆██
wandb:       train/global_step ▁▃▆██
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.16197
wandb:                  eval/f1 0.00902
wandb:                eval/loss 132.06064
wandb:           eval/precision 0.00476
wandb:              eval/recall 0.08527
wandb:             eval/runtime 2.0986
wandb:  eval/samples_per_second 49.08
wandb:    eval/steps_per_second 1.906
wandb:               total_flos 0
wandb:              train/epoch 4
wandb:        train/global_step 32
wandb:               train_loss 298.03461
wandb:            train_runtime 89.3163
wandb: train_samples_per_second 124.143
wandb:   train_steps_per_second 1.075
wandb: 
wandb: 🚀 View run elated-gorge-709 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/716lr9es
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250909_122003-716lr9es/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_122134-1gh7zcb8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-fire-710
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/1gh7zcb8
{'eval_loss': 132.06063842773438, 'eval_precision': 0.004760874269638607, 'eval_recall': 0.08527131782945736, 'eval_f1': 0.009018241442918632, 'eval_accuracy': 0.1619743406985032, 'eval_runtime': 2.0986, 'eval_samples_per_second': 49.08, 'eval_steps_per_second': 1.906, 'epoch': 4.0}
{'train_runtime': 89.3163, 'train_samples_per_second': 124.143, 'train_steps_per_second': 1.075, 'train_loss': 298.03460693359375, 'epoch': 4.0}
  0%|          | 0/480 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/480 [00:01<11:38,  1.46s/it]  0%|          | 2/480 [00:02<11:32,  1.45s/it]  1%|          | 3/480 [00:04<11:29,  1.45s/it]  1%|          | 4/480 [00:05<11:27,  1.44s/it]  1%|          | 5/480 [00:07<11:25,  1.44s/it]  1%|▏         | 6/480 [00:08<11:24,  1.44s/it]  1%|▏         | 7/480 [00:10<11:22,  1.44s/it]  2%|▏         | 8/480 [00:11<11:21,  1.44s/it]  2%|▏         | 9/480 [00:12<11:19,  1.44s/it]  2%|▏         | 10/480 [00:14<11:18,  1.44s/it]  2%|▏         | 11/480 [00:15<11:16,  1.44s/it]  2%|▎         | 12/480 [00:17<11:15,  1.44s/it]  3%|▎         | 13/480 [00:18<11:14,  1.44s/it]  3%|▎         | 14/480 [00:20<11:12,  1.44s/it]  3%|▎         | 15/480 [00:20<09:21,  1.21s/it]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.84it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.80it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.61it/s][A                                                
                                             [A  3%|▎         | 15/480 [00:23<09:21,  1.21s/it]
100%|██████████| 4/4 [00:01<00:00,  2.61it/s][A
                                             [A  3%|▎         | 15/480 [00:23<11:53,  1.54s/it]
[I 2025-09-09 12:21:58,145] Trial 5 pruned. 
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁
wandb:                 eval/f1 ▁
wandb:               eval/loss ▁
wandb:          eval/precision ▁
wandb:             eval/recall ▁
wandb:            eval/runtime ▁
wandb: eval/samples_per_second ▁
wandb:   eval/steps_per_second ▁
wandb:             train/epoch ▁
wandb:       train/global_step ▁
wandb: 
wandb: Run summary:
wandb:           eval/accuracy 0.04205
wandb:                 eval/f1 0.01085
wandb:               eval/loss 154.58354
wandb:          eval/precision 0.00569
wandb:             eval/recall 0.11628
wandb:            eval/runtime 2.1547
wandb: eval/samples_per_second 47.803
wandb:   eval/steps_per_second 1.856
wandb:             train/epoch 1
wandb:       train/global_step 15
wandb: 
wandb: 🚀 View run likely-fire-710 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/1gh7zcb8
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250909_122134-1gh7zcb8/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_122200-fpfrr3bf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-glade-711
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/fpfrr3bf
{'eval_loss': 154.5835418701172, 'eval_precision': 0.005690440060698027, 'eval_recall': 0.11627906976744186, 'eval_f1': 0.0108499095840868, 'eval_accuracy': 0.042052744119743406, 'eval_runtime': 2.1547, 'eval_samples_per_second': 47.803, 'eval_steps_per_second': 1.856, 'epoch': 1.0}
  0%|          | 0/296 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/296 [00:02<10:12,  2.08s/it]  1%|          | 2/296 [00:04<10:02,  2.05s/it]  1%|          | 3/296 [00:06<09:58,  2.04s/it]  1%|▏         | 4/296 [00:08<09:54,  2.04s/it]  2%|▏         | 5/296 [00:10<09:52,  2.04s/it]  2%|▏         | 6/296 [00:12<09:50,  2.03s/it]  2%|▏         | 7/296 [00:14<09:45,  2.03s/it]  3%|▎         | 8/296 [00:14<07:38,  1.59s/it]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.72it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A                                               
                                             [A  3%|▎         | 8/296 [00:17<07:38,  1.59s/it]
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A
                                             [A  3%|▎         | 8/296 [00:17<10:13,  2.13s/it]
[I 2025-09-09 12:22:18,642] Trial 6 pruned. 
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb: uploading history steps 0-0, summary, console lines 2-7
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁
wandb:                 eval/f1 ▁
wandb:               eval/loss ▁
wandb:          eval/precision ▁
wandb:             eval/recall ▁
wandb:            eval/runtime ▁
wandb: eval/samples_per_second ▁
wandb:   eval/steps_per_second ▁
wandb:             train/epoch ▁
wandb:       train/global_step ▁
wandb: 
wandb: Run summary:
wandb:           eval/accuracy 0.03154
wandb:                 eval/f1 0.01041
wandb:               eval/loss 160.62845
wandb:          eval/precision 0.00546
wandb:             eval/recall 0.1124
wandb:            eval/runtime 2.1391
wandb: eval/samples_per_second 48.152
wandb:   eval/steps_per_second 1.87
wandb:             train/epoch 1
wandb:       train/global_step 8
wandb: 
wandb: 🚀 View run logical-glade-711 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/fpfrr3bf
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250909_122200-fpfrr3bf/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_122221-5a39fyo8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-snowflake-712
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/5a39fyo8
{'eval_loss': 160.62844848632812, 'eval_precision': 0.005457282649604818, 'eval_recall': 0.1124031007751938, 'eval_f1': 0.0104091888011486, 'eval_accuracy': 0.03153955808980755, 'eval_runtime': 2.1391, 'eval_samples_per_second': 48.152, 'eval_steps_per_second': 1.87, 'epoch': 1.0}
  0%|          | 0/174 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  1%|          | 1/174 [00:01<02:56,  1.02s/it]  1%|          | 2/174 [00:02<02:52,  1.00s/it]  2%|▏         | 3/174 [00:03<02:51,  1.01s/it]  2%|▏         | 4/174 [00:04<02:51,  1.01s/it]  3%|▎         | 5/174 [00:05<02:50,  1.01s/it]  3%|▎         | 6/174 [00:06<02:49,  1.01s/it]  4%|▍         | 7/174 [00:07<02:48,  1.01s/it]  5%|▍         | 8/174 [00:08<02:47,  1.01s/it]  5%|▌         | 9/174 [00:09<02:46,  1.01s/it]  6%|▌         | 10/174 [00:10<02:45,  1.01s/it]  6%|▋         | 11/174 [00:11<02:43,  1.00s/it]  7%|▋         | 12/174 [00:12<02:42,  1.00s/it]  7%|▋         | 13/174 [00:13<02:41,  1.01s/it]  8%|▊         | 14/174 [00:14<02:40,  1.01s/it]  9%|▊         | 15/174 [00:15<02:39,  1.01s/it]  9%|▉         | 16/174 [00:16<02:39,  1.01s/it] 10%|▉         | 17/174 [00:17<02:38,  1.01s/it] 10%|█         | 18/174 [00:18<02:37,  1.01s/it] 11%|█         | 19/174 [00:19<02:36,  1.01s/it] 11%|█▏        | 20/174 [00:20<02:34,  1.01s/it] 12%|█▏        | 21/174 [00:21<02:33,  1.00s/it] 13%|█▎        | 22/174 [00:22<02:32,  1.00s/it] 13%|█▎        | 23/174 [00:23<02:31,  1.01s/it] 14%|█▍        | 24/174 [00:24<02:30,  1.01s/it] 14%|█▍        | 25/174 [00:25<02:29,  1.01s/it] 15%|█▍        | 26/174 [00:26<02:28,  1.01s/it] 16%|█▌        | 27/174 [00:27<02:27,  1.01s/it] 16%|█▌        | 28/174 [00:28<02:26,  1.01s/it] 17%|█▋        | 29/174 [00:29<02:25,  1.01s/it] 17%|█▋        | 30/174 [00:30<02:24,  1.00s/it] 18%|█▊        | 31/174 [00:31<02:30,  1.05s/it] 18%|█▊        | 32/174 [00:32<02:27,  1.04s/it] 19%|█▉        | 33/174 [00:33<02:25,  1.03s/it] 20%|█▉        | 34/174 [00:34<02:23,  1.02s/it] 20%|██        | 35/174 [00:35<02:21,  1.02s/it] 21%|██        | 36/174 [00:36<02:20,  1.01s/it] 21%|██▏       | 37/174 [00:37<02:18,  1.01s/it] 22%|██▏       | 38/174 [00:38<02:17,  1.01s/it] 22%|██▏       | 39/174 [00:39<02:16,  1.01s/it] 23%|██▎       | 40/174 [00:40<02:14,  1.01s/it] 24%|██▎       | 41/174 [00:41<02:13,  1.01s/it] 24%|██▍       | 42/174 [00:42<02:12,  1.01s/it] 25%|██▍       | 43/174 [00:43<02:11,  1.01s/it] 25%|██▌       | 44/174 [00:44<02:10,  1.01s/it] 26%|██▌       | 45/174 [00:45<02:09,  1.01s/it] 26%|██▋       | 46/174 [00:46<02:08,  1.01s/it] 27%|██▋       | 47/174 [00:47<02:07,  1.01s/it] 28%|██▊       | 48/174 [00:48<02:07,  1.01s/it] 28%|██▊       | 49/174 [00:49<02:05,  1.01s/it] 29%|██▊       | 50/174 [00:50<02:05,  1.01s/it] 29%|██▉       | 51/174 [00:51<02:03,  1.01s/it] 30%|██▉       | 52/174 [00:52<02:02,  1.01s/it] 30%|███       | 53/174 [00:53<02:01,  1.01s/it] 31%|███       | 54/174 [00:54<02:00,  1.00s/it] 32%|███▏      | 55/174 [00:55<01:59,  1.00s/it] 32%|███▏      | 56/174 [00:56<01:58,  1.00s/it] 33%|███▎      | 57/174 [00:57<02:02,  1.05s/it] 33%|███▎      | 58/174 [00:58<01:58,  1.02s/it]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.75it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.76it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.57it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 33%|███▎      | 58/174 [01:00<01:58,  1.02s/it]
100%|██████████| 4/4 [00:01<00:00,  2.57it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 34%|███▍      | 59/174 [01:05<05:32,  2.89s/it] 34%|███▍      | 60/174 [01:06<04:24,  2.32s/it] 35%|███▌      | 61/174 [01:07<03:37,  1.93s/it] 36%|███▌      | 62/174 [01:08<03:04,  1.65s/it] 36%|███▌      | 63/174 [01:09<02:41,  1.46s/it] 37%|███▋      | 64/174 [01:10<02:25,  1.32s/it] 37%|███▋      | 65/174 [01:11<02:13,  1.23s/it] 38%|███▊      | 66/174 [01:12<02:05,  1.16s/it] 39%|███▊      | 67/174 [01:13<01:59,  1.11s/it] 39%|███▉      | 68/174 [01:14<01:54,  1.08s/it] 40%|███▉      | 69/174 [01:15<01:51,  1.06s/it] 40%|████      | 70/174 [01:16<01:48,  1.04s/it] 41%|████      | 71/174 [01:17<01:46,  1.03s/it] 41%|████▏     | 72/174 [01:18<01:44,  1.02s/it] 42%|████▏     | 73/174 [01:19<01:42,  1.02s/it] 43%|████▎     | 74/174 [01:20<01:41,  1.02s/it] 43%|████▎     | 75/174 [01:21<01:40,  1.01s/it] 44%|████▎     | 76/174 [01:22<01:39,  1.01s/it] 44%|████▍     | 77/174 [01:23<01:37,  1.01s/it] 45%|████▍     | 78/174 [01:24<01:36,  1.01s/it] 45%|████▌     | 79/174 [01:25<01:35,  1.01s/it] 46%|████▌     | 80/174 [01:26<01:34,  1.01s/it] 47%|████▋     | 81/174 [01:27<01:33,  1.01s/it] 47%|████▋     | 82/174 [01:28<01:32,  1.01s/it] 48%|████▊     | 83/174 [01:29<01:31,  1.01s/it] 48%|████▊     | 84/174 [01:30<01:30,  1.00s/it] 49%|████▉     | 85/174 [01:31<01:29,  1.00s/it] 49%|████▉     | 86/174 [01:33<01:28,  1.00s/it] 50%|█████     | 87/174 [01:34<01:27,  1.00s/it] 51%|█████     | 88/174 [01:35<01:26,  1.01s/it] 51%|█████     | 89/174 [01:36<01:25,  1.01s/it] 52%|█████▏    | 90/174 [01:37<01:24,  1.01s/it] 52%|█████▏    | 91/174 [01:38<01:23,  1.01s/it] 53%|█████▎    | 92/174 [01:39<01:22,  1.01s/it] 53%|█████▎    | 93/174 [01:40<01:21,  1.01s/it] 54%|█████▍    | 94/174 [01:41<01:20,  1.00s/it] 55%|█████▍    | 95/174 [01:42<01:19,  1.00s/it] 55%|█████▌    | 96/174 [01:43<01:18,  1.00s/it] 56%|█████▌    | 97/174 [01:44<01:17,  1.01s/it] 56%|█████▋    | 98/174 [01:45<01:16,  1.01s/it] 57%|█████▋    | 99/174 [01:46<01:15,  1.01s/it] 57%|█████▋    | 100/174 [01:47<01:17,  1.05s/it] 58%|█████▊    | 101/174 [01:48<01:15,  1.04s/it] 59%|█████▊    | 102/174 [01:49<01:14,  1.03s/it] 59%|█████▉    | 103/174 [01:50<01:12,  1.02s/it] 60%|█████▉    | 104/174 [01:51<01:11,  1.02s/it] 60%|██████    | 105/174 [01:52<01:10,  1.02s/it] 61%|██████    | 106/174 [01:53<01:08,  1.01s/it] 61%|██████▏   | 107/174 [01:54<01:07,  1.01s/it] 62%|██████▏   | 108/174 [01:55<01:06,  1.00s/it] 63%|██████▎   | 109/174 [01:56<01:05,  1.01s/it] 63%|██████▎   | 110/174 [01:57<01:04,  1.01s/it] 64%|██████▍   | 111/174 [01:58<01:03,  1.01s/it] 64%|██████▍   | 112/174 [01:59<01:02,  1.01s/it] 65%|██████▍   | 113/174 [02:00<01:01,  1.01s/it] 66%|██████▌   | 114/174 [02:01<01:00,  1.01s/it] 66%|██████▌   | 115/174 [02:02<00:59,  1.01s/it] 67%|██████▋   | 116/174 [02:03<00:57,  1.01it/s]{'eval_loss': 106.09235382080078, 'eval_precision': 0.004230118443316413, 'eval_recall': 0.03875968992248062, 'eval_f1': 0.007627765064836003, 'eval_accuracy': 0.5506058446186742, 'eval_runtime': 2.118, 'eval_samples_per_second': 48.631, 'eval_steps_per_second': 1.889, 'epoch': 1.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.86it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.73it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                 
                                             [A 67%|██████▋   | 116/174 [02:05<00:57,  1.01it/s]
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 67%|██████▋   | 117/174 [02:09<02:32,  2.68s/it] 68%|██████▊   | 118/174 [02:10<02:01,  2.18s/it] 68%|██████▊   | 119/174 [02:11<01:40,  1.83s/it] 69%|██████▉   | 120/174 [02:12<01:25,  1.58s/it] 70%|██████▉   | 121/174 [02:13<01:14,  1.41s/it] 70%|███████   | 122/174 [02:14<01:06,  1.29s/it] 71%|███████   | 123/174 [02:15<01:01,  1.20s/it] 71%|███████▏  | 124/174 [02:16<00:57,  1.15s/it] 72%|███████▏  | 125/174 [02:17<00:54,  1.10s/it] 72%|███████▏  | 126/174 [02:18<00:51,  1.08s/it] 73%|███████▎  | 127/174 [02:19<00:49,  1.05s/it] 74%|███████▎  | 128/174 [02:20<00:47,  1.04s/it] 74%|███████▍  | 129/174 [02:21<00:46,  1.03s/it] 75%|███████▍  | 130/174 [02:22<00:45,  1.02s/it] 75%|███████▌  | 131/174 [02:23<00:43,  1.02s/it] 76%|███████▌  | 132/174 [02:25<00:44,  1.06s/it] 76%|███████▋  | 133/174 [02:26<00:42,  1.04s/it] 77%|███████▋  | 134/174 [02:27<00:41,  1.03s/it] 78%|███████▊  | 135/174 [02:28<00:39,  1.03s/it] 78%|███████▊  | 136/174 [02:29<00:38,  1.02s/it] 79%|███████▊  | 137/174 [02:30<00:37,  1.02s/it] 79%|███████▉  | 138/174 [02:31<00:36,  1.01s/it] 80%|███████▉  | 139/174 [02:32<00:35,  1.01s/it] 80%|████████  | 140/174 [02:33<00:34,  1.01s/it] 81%|████████  | 141/174 [02:34<00:33,  1.01s/it] 82%|████████▏ | 142/174 [02:35<00:32,  1.01s/it] 82%|████████▏ | 143/174 [02:36<00:31,  1.01s/it] 83%|████████▎ | 144/174 [02:37<00:30,  1.01s/it] 83%|████████▎ | 145/174 [02:38<00:29,  1.01s/it] 84%|████████▍ | 146/174 [02:39<00:28,  1.01s/it] 84%|████████▍ | 147/174 [02:40<00:27,  1.01s/it] 85%|████████▌ | 148/174 [02:41<00:26,  1.01s/it] 86%|████████▌ | 149/174 [02:42<00:25,  1.01s/it] 86%|████████▌ | 150/174 [02:43<00:24,  1.01s/it] 87%|████████▋ | 151/174 [02:44<00:23,  1.01s/it] 87%|████████▋ | 152/174 [02:45<00:22,  1.01s/it] 88%|████████▊ | 153/174 [02:46<00:21,  1.01s/it] 89%|████████▊ | 154/174 [02:47<00:20,  1.01s/it] 89%|████████▉ | 155/174 [02:48<00:19,  1.01s/it] 90%|████████▉ | 156/174 [02:49<00:18,  1.01s/it] 90%|█████████ | 157/174 [02:50<00:17,  1.05s/it] 91%|█████████ | 158/174 [02:51<00:16,  1.04s/it] 91%|█████████▏| 159/174 [02:52<00:15,  1.03s/it] 92%|█████████▏| 160/174 [02:53<00:14,  1.02s/it] 93%|█████████▎| 161/174 [02:54<00:13,  1.01s/it] 93%|█████████▎| 162/174 [02:55<00:12,  1.01s/it] 94%|█████████▎| 163/174 [02:56<00:11,  1.01s/it] 94%|█████████▍| 164/174 [02:57<00:10,  1.01s/it] 95%|█████████▍| 165/174 [02:58<00:09,  1.01s/it] 95%|█████████▌| 166/174 [02:59<00:08,  1.01s/it] 96%|█████████▌| 167/174 [03:00<00:07,  1.01s/it] 97%|█████████▋| 168/174 [03:01<00:06,  1.01s/it] 97%|█████████▋| 169/174 [03:02<00:05,  1.01s/it] 98%|█████████▊| 170/174 [03:03<00:04,  1.01s/it] 98%|█████████▊| 171/174 [03:04<00:03,  1.01s/it] 99%|█████████▉| 172/174 [03:05<00:02,  1.01s/it] 99%|█████████▉| 173/174 [03:06<00:01,  1.01s/it]100%|██████████| 174/174 [03:07<00:00,  1.01it/s]{'eval_loss': 35.56211471557617, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9397719173200285, 'eval_runtime': 2.1092, 'eval_samples_per_second': 48.833, 'eval_steps_per_second': 1.896, 'epoch': 2.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.73it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.77it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.69it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                 
                                             [A100%|██████████| 174/174 [03:09<00:00,  1.01it/s]
100%|██████████| 4/4 [00:01<00:00,  2.69it/s][A
                                             [A                                                 100%|██████████| 174/174 [03:13<00:00,  1.01it/s]100%|██████████| 174/174 [03:13<00:00,  1.11s/it]
[I 2025-09-09 12:25:36,670] Trial 7 finished with value: 0.9397719173200285 and parameters: {'learning_rate': 2.569061303119879e-06, 'num_train_epochs': 3, 'per_device_train_batch_size': 2, 'weight_decay': 1.2484581989568438e-05, 'warmup_ratio': 0.27488664691116127, 'optimizer': 'Adafactor'}. Best is trial 1 with value: 3.319722221030952.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁██
wandb:                 eval/f1 █▁▁
wandb:               eval/loss █▂▁
wandb:          eval/precision █▁▁
wandb:             eval/recall █▁▁
wandb:            eval/runtime █▇▁
wandb: eval/samples_per_second ▁▂█
wandb:   eval/steps_per_second ▁▂█
wandb:             train/epoch ▁▅██
wandb:       train/global_step ▁▅██
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.93977
wandb:                  eval/f1 0
wandb:                eval/loss 24.37387
wandb:           eval/precision 0
wandb:              eval/recall 0
wandb:             eval/runtime 2.059
wandb:  eval/samples_per_second 50.025
wandb:    eval/steps_per_second 1.943
wandb:               total_flos 0
wandb:              train/epoch 3
wandb:        train/global_step 174
wandb:               train_loss 180.31353
wandb:            train_runtime 196.735
wandb: train_samples_per_second 14.09
wandb:   train_steps_per_second 0.884
wandb: 
wandb: 🚀 View run wobbly-snowflake-712 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/5a39fyo8
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250909_122221-5a39fyo8/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_122539-ygfutbi2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sun-713
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/ygfutbi2
{'eval_loss': 24.373868942260742, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9397719173200285, 'eval_runtime': 2.059, 'eval_samples_per_second': 50.025, 'eval_steps_per_second': 1.943, 'epoch': 3.0}
{'train_runtime': 196.735, 'train_samples_per_second': 14.09, 'train_steps_per_second': 0.884, 'train_loss': 180.3135326867816, 'epoch': 3.0}
  0%|          | 0/345 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/345 [00:01<08:23,  1.46s/it]  1%|          | 2/345 [00:02<08:18,  1.45s/it]  1%|          | 3/345 [00:04<08:16,  1.45s/it]  1%|          | 4/345 [00:05<08:14,  1.45s/it]  1%|▏         | 5/345 [00:07<08:12,  1.45s/it]  2%|▏         | 6/345 [00:08<08:11,  1.45s/it]  2%|▏         | 7/345 [00:10<08:09,  1.45s/it]  2%|▏         | 8/345 [00:11<08:07,  1.45s/it]  3%|▎         | 9/345 [00:13<08:06,  1.45s/it]  3%|▎         | 10/345 [00:14<08:04,  1.45s/it]  3%|▎         | 11/345 [00:15<08:03,  1.45s/it]  3%|▎         | 12/345 [00:17<08:01,  1.45s/it]  4%|▍         | 13/345 [00:18<07:59,  1.45s/it]  4%|▍         | 14/345 [00:20<07:58,  1.44s/it]  4%|▍         | 15/345 [00:20<06:38,  1.21s/it]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.86it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.79it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.65it/s][A                                                
                                             [A  4%|▍         | 15/345 [00:23<06:38,  1.21s/it]
100%|██████████| 4/4 [00:01<00:00,  2.65it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  5%|▍         | 16/345 [00:29<18:08,  3.31s/it]  5%|▍         | 17/345 [00:30<15:01,  2.75s/it]  5%|▌         | 18/345 [00:32<12:51,  2.36s/it]  6%|▌         | 19/345 [00:33<11:19,  2.09s/it]  6%|▌         | 20/345 [00:34<10:15,  1.89s/it]  6%|▌         | 21/345 [00:36<09:30,  1.76s/it]  6%|▋         | 22/345 [00:37<08:58,  1.67s/it]  7%|▋         | 23/345 [00:39<08:35,  1.60s/it]  7%|▋         | 24/345 [00:40<08:19,  1.56s/it]  7%|▋         | 25/345 [00:42<08:07,  1.52s/it]  8%|▊         | 26/345 [00:43<07:59,  1.50s/it]  8%|▊         | 27/345 [00:45<07:52,  1.49s/it]  8%|▊         | 28/345 [00:46<07:47,  1.48s/it]  8%|▊         | 29/345 [00:47<07:43,  1.47s/it]  9%|▊         | 30/345 [00:48<06:26,  1.23s/it]{'eval_loss': 142.3001251220703, 'eval_precision': 0.00518444666001994, 'eval_recall': 0.10077519379844961, 'eval_f1': 0.009861558884885265, 'eval_accuracy': 0.0921240199572345, 'eval_runtime': 2.0941, 'eval_samples_per_second': 49.185, 'eval_steps_per_second': 1.91, 'epoch': 1.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.88it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.25it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A  9%|▊         | 30/345 [00:50<06:26,  1.23s/it]
100%|██████████| 4/4 [00:01<00:00,  2.25it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  9%|▉         | 31/345 [00:56<16:57,  3.24s/it]  9%|▉         | 32/345 [00:58<14:06,  2.70s/it] 10%|▉         | 33/345 [00:59<12:05,  2.33s/it] 10%|▉         | 34/345 [01:00<10:41,  2.06s/it] 10%|█         | 35/345 [01:02<09:42,  1.88s/it] 10%|█         | 36/345 [01:03<09:00,  1.75s/it] 11%|█         | 37/345 [01:05<08:31,  1.66s/it] 11%|█         | 38/345 [01:06<08:09,  1.60s/it] 11%|█▏        | 39/345 [01:08<07:54,  1.55s/it] 12%|█▏        | 40/345 [01:09<07:43,  1.52s/it] 12%|█▏        | 41/345 [01:11<07:36,  1.50s/it] 12%|█▏        | 42/345 [01:12<07:29,  1.49s/it] 12%|█▏        | 43/345 [01:13<07:24,  1.47s/it] 13%|█▎        | 44/345 [01:15<07:20,  1.46s/it] 13%|█▎        | 45/345 [01:16<06:07,  1.22s/it]{'eval_loss': 112.49517059326172, 'eval_precision': 0.004940711462450593, 'eval_recall': 0.05813953488372093, 'eval_f1': 0.009107468123861566, 'eval_accuracy': 0.43709907341411264, 'eval_runtime': 2.2726, 'eval_samples_per_second': 45.322, 'eval_steps_per_second': 1.76, 'epoch': 2.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.87it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.72it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.54it/s][A                                                
                                             [A 13%|█▎        | 45/345 [01:18<06:07,  1.22s/it]
100%|██████████| 4/4 [00:01<00:00,  2.54it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 13%|█▎        | 46/345 [01:24<16:46,  3.37s/it] 14%|█▎        | 47/345 [01:25<13:52,  2.79s/it] 14%|█▍        | 48/345 [01:27<11:49,  2.39s/it] 14%|█▍        | 49/345 [01:28<10:23,  2.11s/it] 14%|█▍        | 50/345 [01:30<09:23,  1.91s/it] 15%|█▍        | 51/345 [01:31<08:40,  1.77s/it] 15%|█▌        | 52/345 [01:33<08:10,  1.67s/it] 15%|█▌        | 53/345 [01:34<07:49,  1.61s/it] 16%|█▌        | 54/345 [01:36<07:33,  1.56s/it] 16%|█▌        | 55/345 [01:37<07:22,  1.53s/it] 16%|█▌        | 56/345 [01:38<07:14,  1.50s/it] 17%|█▋        | 57/345 [01:40<07:08,  1.49s/it] 17%|█▋        | 58/345 [01:41<07:03,  1.47s/it] 17%|█▋        | 59/345 [01:43<06:59,  1.47s/it] 17%|█▋        | 60/345 [01:43<05:49,  1.22s/it]{'eval_loss': 83.86329650878906, 'eval_precision': 0.0035587188612099642, 'eval_recall': 0.007751937984496124, 'eval_f1': 0.004878048780487805, 'eval_accuracy': 0.8524590163934426, 'eval_runtime': 2.1416, 'eval_samples_per_second': 48.095, 'eval_steps_per_second': 1.868, 'epoch': 3.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.86it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.77it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.64it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 17%|█▋        | 60/345 [01:45<05:49,  1.22s/it]
100%|██████████| 4/4 [00:01<00:00,  2.64it/s][A
                                             [A                                                 17%|█▋        | 60/345 [01:50<05:49,  1.22s/it] 17%|█▋        | 60/345 [01:50<08:43,  1.84s/it]
[I 2025-09-09 12:27:30,847] Trial 8 finished with value: 0.9365645046329294 and parameters: {'learning_rate': 2.7427175202412384e-06, 'num_train_epochs': 23, 'per_device_train_batch_size': 8, 'weight_decay': 0.06286319967088291, 'warmup_ratio': 0.027600715771216023, 'optimizer': 'AdamW'}. Best is trial 1 with value: 3.319722221030952.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▄▇█
wandb:                 eval/f1 █▇▄▁
wandb:               eval/loss █▆▃▁
wandb:          eval/precision ██▆▁
wandb:             eval/recall █▅▂▁
wandb:            eval/runtime ▁█▃▁
wandb: eval/samples_per_second █▁▆█
wandb:   eval/steps_per_second █▁▆█
wandb:             train/epoch ▁▃▆██
wandb:       train/global_step ▁▃▆██
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.93656
wandb:                  eval/f1 0
wandb:                eval/loss 55.27277
wandb:           eval/precision 0
wandb:              eval/recall 0
wandb:             eval/runtime 2.0967
wandb:  eval/samples_per_second 49.125
wandb:    eval/steps_per_second 1.908
wandb:               total_flos 0
wandb:              train/epoch 4
wandb:        train/global_step 60
wandb:               train_loss 237.19206
wandb:            train_runtime 112.8906
wandb: train_samples_per_second 188.253
wandb:   train_steps_per_second 3.056
wandb: 
wandb: 🚀 View run laced-sun-713 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/ygfutbi2
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250909_122539-ygfutbi2/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_122733-cc24u07w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-fog-714
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/cc24u07w
{'eval_loss': 55.27276611328125, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9365645046329294, 'eval_runtime': 2.0967, 'eval_samples_per_second': 49.125, 'eval_steps_per_second': 1.908, 'epoch': 4.0}
{'train_runtime': 112.8906, 'train_samples_per_second': 188.253, 'train_steps_per_second': 3.056, 'train_loss': 237.19205729166666, 'epoch': 4.0}
  0%|          | 0/555 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/555 [00:01<13:29,  1.46s/it]  0%|          | 2/555 [00:02<13:21,  1.45s/it]  1%|          | 3/555 [00:04<13:19,  1.45s/it]  1%|          | 4/555 [00:05<13:16,  1.45s/it]  1%|          | 5/555 [00:07<13:15,  1.45s/it]  1%|          | 6/555 [00:08<13:14,  1.45s/it]  1%|▏         | 7/555 [00:10<13:12,  1.45s/it]  1%|▏         | 8/555 [00:11<13:10,  1.45s/it]  2%|▏         | 9/555 [00:13<13:09,  1.45s/it]  2%|▏         | 10/555 [00:14<13:07,  1.45s/it]  2%|▏         | 11/555 [00:15<13:06,  1.45s/it]  2%|▏         | 12/555 [00:17<13:04,  1.45s/it]  2%|▏         | 13/555 [00:18<13:03,  1.45s/it]  3%|▎         | 14/555 [00:20<13:01,  1.44s/it]  3%|▎         | 15/555 [00:20<10:52,  1.21s/it]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.70it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.76it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.63it/s][A                                                
                                             [A  3%|▎         | 15/555 [00:23<10:52,  1.21s/it]
100%|██████████| 4/4 [00:01<00:00,  2.63it/s][A
                                             [A  3%|▎         | 15/555 [00:23<13:49,  1.54s/it]
[I 2025-09-09 12:27:57,315] Trial 9 pruned. 
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁
wandb:                 eval/f1 ▁
wandb:               eval/loss ▁
wandb:          eval/precision ▁
wandb:             eval/recall ▁
wandb:            eval/runtime ▁
wandb: eval/samples_per_second ▁
wandb:   eval/steps_per_second ▁
wandb:             train/epoch ▁
wandb:       train/global_step ▁
wandb: 
wandb: Run summary:
wandb:           eval/accuracy 0.03813
wandb:                 eval/f1 0.01082
wandb:               eval/loss 156.657
wandb:          eval/precision 0.00567
wandb:             eval/recall 0.11628
wandb:            eval/runtime 2.1351
wandb: eval/samples_per_second 48.24
wandb:   eval/steps_per_second 1.873
wandb:             train/epoch 1
wandb:       train/global_step 15
wandb: 
wandb: 🚀 View run northern-fog-714 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/cc24u07w
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250909_122733-cc24u07w/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_122800-btl5vwqu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-dew-715
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/btl5vwqu
{'eval_loss': 156.65699768066406, 'eval_precision': 0.005672149744753261, 'eval_recall': 0.11627906976744186, 'eval_f1': 0.010816657652785288, 'eval_accuracy': 0.038132573057733425, 'eval_runtime': 2.1351, 'eval_samples_per_second': 48.24, 'eval_steps_per_second': 1.873, 'epoch': 1.0}
  0%|          | 0/1740 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/1740 [00:00<26:07,  1.11it/s]  0%|          | 2/1740 [00:01<25:59,  1.11it/s]  0%|          | 3/1740 [00:02<25:58,  1.11it/s]  0%|          | 4/1740 [00:03<25:59,  1.11it/s]  0%|          | 5/1740 [00:04<25:59,  1.11it/s]  0%|          | 6/1740 [00:05<25:57,  1.11it/s]  0%|          | 7/1740 [00:06<25:57,  1.11it/s]  0%|          | 8/1740 [00:07<25:56,  1.11it/s]  1%|          | 9/1740 [00:08<25:54,  1.11it/s]  1%|          | 10/1740 [00:08<25:54,  1.11it/s]  1%|          | 11/1740 [00:09<25:53,  1.11it/s]  1%|          | 12/1740 [00:10<25:53,  1.11it/s]  1%|          | 13/1740 [00:11<25:52,  1.11it/s]  1%|          | 14/1740 [00:12<25:51,  1.11it/s]  1%|          | 15/1740 [00:13<25:51,  1.11it/s]  1%|          | 16/1740 [00:14<25:50,  1.11it/s]  1%|          | 17/1740 [00:15<25:45,  1.11it/s]  1%|          | 18/1740 [00:16<25:40,  1.12it/s]  1%|          | 19/1740 [00:17<25:42,  1.12it/s]  1%|          | 20/1740 [00:17<25:43,  1.11it/s]  1%|          | 21/1740 [00:18<25:45,  1.11it/s]  1%|▏         | 22/1740 [00:19<25:45,  1.11it/s]  1%|▏         | 23/1740 [00:20<25:45,  1.11it/s]  1%|▏         | 24/1740 [00:21<25:45,  1.11it/s]  1%|▏         | 25/1740 [00:22<25:42,  1.11it/s]  1%|▏         | 26/1740 [00:23<25:42,  1.11it/s]  2%|▏         | 27/1740 [00:24<25:41,  1.11it/s]  2%|▏         | 28/1740 [00:25<25:40,  1.11it/s]  2%|▏         | 29/1740 [00:26<25:40,  1.11it/s]  2%|▏         | 30/1740 [00:26<25:38,  1.11it/s]  2%|▏         | 31/1740 [00:28<27:02,  1.05it/s]  2%|▏         | 32/1740 [00:28<26:37,  1.07it/s]  2%|▏         | 33/1740 [00:29<26:18,  1.08it/s]  2%|▏         | 34/1740 [00:30<26:06,  1.09it/s]  2%|▏         | 35/1740 [00:31<25:56,  1.10it/s]  2%|▏         | 36/1740 [00:32<25:47,  1.10it/s]  2%|▏         | 37/1740 [00:33<25:42,  1.10it/s]  2%|▏         | 38/1740 [00:34<25:38,  1.11it/s]  2%|▏         | 39/1740 [00:35<25:35,  1.11it/s]  2%|▏         | 40/1740 [00:36<25:33,  1.11it/s]  2%|▏         | 41/1740 [00:37<25:31,  1.11it/s]  2%|▏         | 42/1740 [00:37<25:29,  1.11it/s]  2%|▏         | 43/1740 [00:38<25:27,  1.11it/s]  3%|▎         | 44/1740 [00:39<25:26,  1.11it/s]  3%|▎         | 45/1740 [00:40<25:25,  1.11it/s]  3%|▎         | 46/1740 [00:41<25:24,  1.11it/s]  3%|▎         | 47/1740 [00:42<25:23,  1.11it/s]  3%|▎         | 48/1740 [00:43<25:22,  1.11it/s]  3%|▎         | 49/1740 [00:44<25:21,  1.11it/s]  3%|▎         | 50/1740 [00:45<25:20,  1.11it/s]  3%|▎         | 51/1740 [00:46<25:20,  1.11it/s]  3%|▎         | 52/1740 [00:46<25:19,  1.11it/s]  3%|▎         | 53/1740 [00:47<25:19,  1.11it/s]  3%|▎         | 54/1740 [00:48<25:18,  1.11it/s]  3%|▎         | 55/1740 [00:49<25:16,  1.11it/s]  3%|▎         | 56/1740 [00:50<25:09,  1.12it/s]  3%|▎         | 57/1740 [00:51<26:22,  1.06it/s]  3%|▎         | 58/1740 [00:52<26:00,  1.08it/s]  3%|▎         | 59/1740 [00:53<25:46,  1.09it/s]  3%|▎         | 60/1740 [00:54<25:34,  1.09it/s]  4%|▎         | 61/1740 [00:55<25:26,  1.10it/s]  4%|▎         | 62/1740 [00:56<25:22,  1.10it/s]  4%|▎         | 63/1740 [00:56<25:17,  1.10it/s]  4%|▎         | 64/1740 [00:57<25:14,  1.11it/s]  4%|▎         | 65/1740 [00:58<25:12,  1.11it/s]  4%|▍         | 66/1740 [00:59<25:09,  1.11it/s]  4%|▍         | 67/1740 [01:00<25:00,  1.11it/s]  4%|▍         | 68/1740 [01:01<24:59,  1.11it/s]  4%|▍         | 69/1740 [01:02<25:00,  1.11it/s]  4%|▍         | 70/1740 [01:03<25:00,  1.11it/s]  4%|▍         | 71/1740 [01:04<25:00,  1.11it/s]  4%|▍         | 72/1740 [01:05<25:00,  1.11it/s]  4%|▍         | 73/1740 [01:05<25:00,  1.11it/s]  4%|▍         | 74/1740 [01:06<24:59,  1.11it/s]  4%|▍         | 75/1740 [01:07<24:58,  1.11it/s]  4%|▍         | 76/1740 [01:08<24:58,  1.11it/s]  4%|▍         | 77/1740 [01:09<24:57,  1.11it/s]  4%|▍         | 78/1740 [01:10<24:50,  1.12it/s]  5%|▍         | 79/1740 [01:11<24:48,  1.12it/s]  5%|▍         | 80/1740 [01:12<24:49,  1.11it/s]  5%|▍         | 81/1740 [01:13<24:50,  1.11it/s]  5%|▍         | 82/1740 [01:14<26:02,  1.06it/s]  5%|▍         | 83/1740 [01:15<25:38,  1.08it/s]  5%|▍         | 84/1740 [01:15<25:17,  1.09it/s]  5%|▍         | 85/1740 [01:16<25:08,  1.10it/s]  5%|▍         | 86/1740 [01:17<25:02,  1.10it/s]  5%|▌         | 87/1740 [01:18<24:57,  1.10it/s]  5%|▌         | 88/1740 [01:19<24:54,  1.11it/s]  5%|▌         | 89/1740 [01:20<24:46,  1.11it/s]  5%|▌         | 90/1740 [01:21<24:43,  1.11it/s]  5%|▌         | 91/1740 [01:22<24:43,  1.11it/s]  5%|▌         | 92/1740 [01:23<24:42,  1.11it/s]  5%|▌         | 93/1740 [01:24<24:42,  1.11it/s]  5%|▌         | 94/1740 [01:24<24:40,  1.11it/s]  5%|▌         | 95/1740 [01:25<24:41,  1.11it/s]  6%|▌         | 96/1740 [01:26<24:39,  1.11it/s]  6%|▌         | 97/1740 [01:27<24:39,  1.11it/s]  6%|▌         | 98/1740 [01:28<24:38,  1.11it/s]  6%|▌         | 99/1740 [01:29<24:36,  1.11it/s]  6%|▌         | 100/1740 [01:30<24:36,  1.11it/s]  6%|▌         | 101/1740 [01:31<24:36,  1.11it/s]  6%|▌         | 102/1740 [01:32<24:34,  1.11it/s]  6%|▌         | 103/1740 [01:33<24:33,  1.11it/s]  6%|▌         | 104/1740 [01:33<24:32,  1.11it/s]  6%|▌         | 105/1740 [01:34<24:32,  1.11it/s]  6%|▌         | 106/1740 [01:35<24:30,  1.11it/s]  6%|▌         | 107/1740 [01:36<24:29,  1.11it/s]  6%|▌         | 108/1740 [01:37<24:29,  1.11it/s]  6%|▋         | 109/1740 [01:38<24:28,  1.11it/s]  6%|▋         | 110/1740 [01:39<24:26,  1.11it/s]  6%|▋         | 111/1740 [01:40<24:26,  1.11it/s]  6%|▋         | 112/1740 [01:41<24:25,  1.11it/s]  6%|▋         | 113/1740 [01:42<24:24,  1.11it/s]  7%|▋         | 114/1740 [01:42<24:23,  1.11it/s]  7%|▋         | 115/1740 [01:43<24:21,  1.11it/s]  7%|▋         | 116/1740 [01:44<20:45,  1.30it/s]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.82it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.81it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                  
                                             [A  7%|▋         | 116/1740 [01:46<20:45,  1.30it/s]
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  7%|▋         | 117/1740 [01:51<1:08:53,  2.55s/it]  7%|▋         | 118/1740 [01:51<55:27,  2.05s/it]    7%|▋         | 119/1740 [01:52<46:05,  1.71s/it]  7%|▋         | 120/1740 [01:53<39:31,  1.46s/it]  7%|▋         | 121/1740 [01:54<34:55,  1.29s/it]  7%|▋         | 122/1740 [01:55<31:41,  1.18s/it]  7%|▋         | 123/1740 [01:56<30:37,  1.14s/it]  7%|▋         | 124/1740 [01:57<28:41,  1.07s/it]  7%|▋         | 125/1740 [01:58<27:21,  1.02s/it]  7%|▋         | 126/1740 [01:59<26:24,  1.02it/s]  7%|▋         | 127/1740 [02:00<25:40,  1.05it/s]  7%|▋         | 128/1740 [02:01<25:06,  1.07it/s]  7%|▋         | 129/1740 [02:01<24:48,  1.08it/s]  7%|▋         | 130/1740 [02:02<24:36,  1.09it/s]  8%|▊         | 131/1740 [02:03<24:26,  1.10it/s]  8%|▊         | 132/1740 [02:04<24:19,  1.10it/s]  8%|▊         | 133/1740 [02:05<24:15,  1.10it/s]  8%|▊         | 134/1740 [02:06<24:11,  1.11it/s]  8%|▊         | 135/1740 [02:07<24:08,  1.11it/s]  8%|▊         | 136/1740 [02:08<24:06,  1.11it/s]  8%|▊         | 137/1740 [02:09<24:04,  1.11it/s]  8%|▊         | 138/1740 [02:10<24:00,  1.11it/s]  8%|▊         | 139/1740 [02:10<23:52,  1.12it/s]  8%|▊         | 140/1740 [02:11<23:53,  1.12it/s]  8%|▊         | 141/1740 [02:12<23:54,  1.11it/s]  8%|▊         | 142/1740 [02:13<23:55,  1.11it/s]  8%|▊         | 143/1740 [02:14<23:55,  1.11it/s]  8%|▊         | 144/1740 [02:15<23:50,  1.12it/s]  8%|▊         | 145/1740 [02:16<23:47,  1.12it/s]  8%|▊         | 146/1740 [02:17<23:48,  1.12it/s]  8%|▊         | 147/1740 [02:18<23:49,  1.11it/s]  9%|▊         | 148/1740 [02:18<23:50,  1.11it/s]  9%|▊         | 149/1740 [02:19<23:49,  1.11it/s]  9%|▊         | 150/1740 [02:20<23:49,  1.11it/s]  9%|▊         | 151/1740 [02:21<23:49,  1.11it/s]  9%|▊         | 152/1740 [02:22<23:50,  1.11it/s]  9%|▉         | 153/1740 [02:23<23:50,  1.11it/s]  9%|▉         | 154/1740 [02:24<23:48,  1.11it/s]  9%|▉         | 155/1740 [02:25<23:48,  1.11it/s]  9%|▉         | 156/1740 [02:26<23:47,  1.11it/s]  9%|▉         | 157/1740 [02:27<23:46,  1.11it/s]  9%|▉         | 158/1740 [02:28<23:44,  1.11it/s]  9%|▉         | 159/1740 [02:28<23:42,  1.11it/s]  9%|▉         | 160/1740 [02:29<23:42,  1.11it/s]  9%|▉         | 161/1740 [02:30<23:42,  1.11it/s]  9%|▉         | 162/1740 [02:31<23:41,  1.11it/s]  9%|▉         | 163/1740 [02:32<23:40,  1.11it/s]  9%|▉         | 164/1740 [02:33<23:39,  1.11it/s]  9%|▉         | 165/1740 [02:34<23:37,  1.11it/s] 10%|▉         | 166/1740 [02:35<23:37,  1.11it/s] 10%|▉         | 167/1740 [02:36<23:37,  1.11it/s] 10%|▉         | 168/1740 [02:37<23:35,  1.11it/s] 10%|▉         | 169/1740 [02:37<23:35,  1.11it/s] 10%|▉         | 170/1740 [02:38<23:34,  1.11it/s] 10%|▉         | 171/1740 [02:39<23:33,  1.11it/s] 10%|▉         | 172/1740 [02:40<23:33,  1.11it/s] 10%|▉         | 173/1740 [02:41<23:32,  1.11it/s] 10%|█         | 174/1740 [02:42<24:40,  1.06it/s] 10%|█         | 175/1740 [02:43<24:19,  1.07it/s] 10%|█         | 176/1740 [02:44<24:03,  1.08it/s] 10%|█         | 177/1740 [02:45<23:53,  1.09it/s] 10%|█         | 178/1740 [02:46<23:44,  1.10it/s] 10%|█         | 179/1740 [02:47<23:39,  1.10it/s] 10%|█         | 180/1740 [02:47<23:35,  1.10it/s] 10%|█         | 181/1740 [02:48<23:30,  1.11it/s] 10%|█         | 182/1740 [02:49<23:28,  1.11it/s] 11%|█         | 183/1740 [02:50<23:26,  1.11it/s] 11%|█         | 184/1740 [02:51<23:24,  1.11it/s] 11%|█         | 185/1740 [02:52<23:23,  1.11it/s] 11%|█         | 186/1740 [02:53<23:21,  1.11it/s] 11%|█         | 187/1740 [02:54<23:20,  1.11it/s] 11%|█         | 188/1740 [02:55<23:19,  1.11it/s] 11%|█         | 189/1740 [02:56<23:17,  1.11it/s] 11%|█         | 190/1740 [02:56<23:16,  1.11it/s] 11%|█         | 191/1740 [02:57<23:16,  1.11it/s] 11%|█         | 192/1740 [02:58<23:14,  1.11it/s] 11%|█         | 193/1740 [02:59<23:14,  1.11it/s] 11%|█         | 194/1740 [03:00<23:14,  1.11it/s] 11%|█         | 195/1740 [03:01<23:13,  1.11it/s] 11%|█▏        | 196/1740 [03:02<23:11,  1.11it/s] 11%|█▏        | 197/1740 [03:03<23:11,  1.11it/s] 11%|█▏        | 198/1740 [03:04<23:09,  1.11it/s] 11%|█▏        | 199/1740 [03:05<23:08,  1.11it/s] 11%|█▏        | 200/1740 [03:06<23:06,  1.11it/s] 12%|█▏        | 201/1740 [03:06<23:05,  1.11it/s] 12%|█▏        | 202/1740 [03:07<23:04,  1.11it/s] 12%|█▏        | 203/1740 [03:08<23:03,  1.11it/s] 12%|█▏        | 204/1740 [03:09<23:03,  1.11it/s] 12%|█▏        | 205/1740 [03:10<22:56,  1.11it/s] 12%|█▏        | 206/1740 [03:11<22:54,  1.12it/s] 12%|█▏        | 207/1740 [03:12<22:56,  1.11it/s] 12%|█▏        | 208/1740 [03:13<22:57,  1.11it/s] 12%|█▏        | 209/1740 [03:14<22:56,  1.11it/s] 12%|█▏        | 210/1740 [03:14<22:56,  1.11it/s] 12%|█▏        | 211/1740 [03:15<22:49,  1.12it/s] 12%|█▏        | 212/1740 [03:16<22:50,  1.12it/s] 12%|█▏        | 213/1740 [03:17<23:58,  1.06it/s] 12%|█▏        | 214/1740 [03:18<23:37,  1.08it/s] 12%|█▏        | 215/1740 [03:19<23:24,  1.09it/s] 12%|█▏        | 216/1740 [03:20<23:08,  1.10it/s] 12%|█▏        | 217/1740 [03:21<23:00,  1.10it/s] 13%|█▎        | 218/1740 [03:22<22:57,  1.10it/s] 13%|█▎        | 219/1740 [03:23<22:54,  1.11it/s] 13%|█▎        | 220/1740 [03:24<22:51,  1.11it/s] 13%|█▎        | 221/1740 [03:25<22:50,  1.11it/s] 13%|█▎        | 222/1740 [03:25<22:49,  1.11it/s] 13%|█▎        | 223/1740 [03:26<22:48,  1.11it/s] 13%|█▎        | 224/1740 [03:27<22:47,  1.11it/s] 13%|█▎        | 225/1740 [03:28<22:45,  1.11it/s] 13%|█▎        | 226/1740 [03:29<22:44,  1.11it/s] 13%|█▎        | 227/1740 [03:30<22:43,  1.11it/s] 13%|█▎        | 228/1740 [03:31<22:42,  1.11it/s] 13%|█▎        | 229/1740 [03:32<22:42,  1.11it/s] 13%|█▎        | 230/1740 [03:33<22:41,  1.11it/s] 13%|█▎        | 231/1740 [03:34<22:39,  1.11it/s] 13%|█▎        | 232/1740 [03:34<19:18,  1.30it/s]{'eval_loss': 14.486785888671875, 'eval_precision': 0.4642857142857143, 'eval_recall': 0.1511627906976744, 'eval_f1': 0.2280701754385965, 'eval_accuracy': 0.9447612259444048, 'eval_runtime': 2.0877, 'eval_samples_per_second': 49.337, 'eval_steps_per_second': 1.916, 'epoch': 1.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.70it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.66it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                  
                                             [A 13%|█▎        | 232/1740 [03:36<19:18,  1.30it/s]
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 13%|█▎        | 233/1740 [03:41<1:04:17,  2.56s/it] 13%|█▎        | 234/1740 [03:42<51:45,  2.06s/it]   14%|█▎        | 235/1740 [03:43<42:59,  1.71s/it] 14%|█▎        | 236/1740 [03:43<36:51,  1.47s/it] 14%|█▎        | 237/1740 [03:44<32:33,  1.30s/it] 14%|█▎        | 238/1740 [03:45<29:32,  1.18s/it] 14%|█▎        | 239/1740 [03:46<27:25,  1.10s/it] 14%|█▍        | 240/1740 [03:47<25:57,  1.04s/it] 14%|█▍        | 241/1740 [03:48<24:54,  1.00it/s] 14%|█▍        | 242/1740 [03:49<24:10,  1.03it/s] 14%|█▍        | 243/1740 [03:50<24:47,  1.01it/s] 14%|█▍        | 244/1740 [03:51<24:04,  1.04it/s] 14%|█▍        | 245/1740 [03:52<23:35,  1.06it/s] 14%|█▍        | 246/1740 [03:53<23:13,  1.07it/s] 14%|█▍        | 247/1740 [03:53<22:58,  1.08it/s] 14%|█▍        | 248/1740 [03:54<22:47,  1.09it/s] 14%|█▍        | 249/1740 [03:55<22:40,  1.10it/s] 14%|█▍        | 250/1740 [03:56<22:34,  1.10it/s] 14%|█▍        | 251/1740 [03:57<22:30,  1.10it/s] 14%|█▍        | 252/1740 [03:58<22:27,  1.10it/s] 15%|█▍        | 253/1740 [03:59<22:24,  1.11it/s] 15%|█▍        | 254/1740 [04:00<22:22,  1.11it/s] 15%|█▍        | 255/1740 [04:01<22:20,  1.11it/s] 15%|█▍        | 256/1740 [04:02<22:19,  1.11it/s] 15%|█▍        | 257/1740 [04:03<22:18,  1.11it/s] 15%|█▍        | 258/1740 [04:03<22:17,  1.11it/s] 15%|█▍        | 259/1740 [04:04<22:16,  1.11it/s] 15%|█▍        | 260/1740 [04:05<22:15,  1.11it/s] 15%|█▌        | 261/1740 [04:06<22:13,  1.11it/s] 15%|█▌        | 262/1740 [04:07<22:13,  1.11it/s] 15%|█▌        | 263/1740 [04:08<22:11,  1.11it/s] 15%|█▌        | 264/1740 [04:09<22:11,  1.11it/s] 15%|█▌        | 265/1740 [04:10<22:10,  1.11it/s] 15%|█▌        | 266/1740 [04:11<22:09,  1.11it/s] 15%|█▌        | 267/1740 [04:12<22:08,  1.11it/s] 15%|█▌        | 268/1740 [04:12<22:09,  1.11it/s] 15%|█▌        | 269/1740 [04:13<23:12,  1.06it/s] 16%|█▌        | 270/1740 [04:14<22:52,  1.07it/s] 16%|█▌        | 271/1740 [04:15<22:28,  1.09it/s] 16%|█▌        | 272/1740 [04:16<22:20,  1.10it/s] 16%|█▌        | 273/1740 [04:17<22:13,  1.10it/s] 16%|█▌        | 274/1740 [04:18<22:09,  1.10it/s] 16%|█▌        | 275/1740 [04:19<22:06,  1.10it/s] 16%|█▌        | 276/1740 [04:20<22:03,  1.11it/s] 16%|█▌        | 277/1740 [04:21<22:02,  1.11it/s] 16%|█▌        | 278/1740 [04:22<22:00,  1.11it/s] 16%|█▌        | 279/1740 [04:22<21:58,  1.11it/s] 16%|█▌        | 280/1740 [04:23<21:57,  1.11it/s] 16%|█▌        | 281/1740 [04:24<21:56,  1.11it/s] 16%|█▌        | 282/1740 [04:25<21:55,  1.11it/s] 16%|█▋        | 283/1740 [04:26<21:54,  1.11it/s] 16%|█▋        | 284/1740 [04:27<21:53,  1.11it/s] 16%|█▋        | 285/1740 [04:28<21:51,  1.11it/s] 16%|█▋        | 286/1740 [04:29<21:52,  1.11it/s] 16%|█▋        | 287/1740 [04:30<21:50,  1.11it/s] 17%|█▋        | 288/1740 [04:31<21:50,  1.11it/s] 17%|█▋        | 289/1740 [04:32<21:49,  1.11it/s] 17%|█▋        | 290/1740 [04:32<21:48,  1.11it/s] 17%|█▋        | 291/1740 [04:33<21:47,  1.11it/s] 17%|█▋        | 292/1740 [04:34<21:46,  1.11it/s] 17%|█▋        | 293/1740 [04:35<21:44,  1.11it/s] 17%|█▋        | 294/1740 [04:36<22:48,  1.06it/s] 17%|█▋        | 295/1740 [04:37<22:28,  1.07it/s] 17%|█▋        | 296/1740 [04:38<22:13,  1.08it/s] 17%|█▋        | 297/1740 [04:39<22:02,  1.09it/s] 17%|█▋        | 298/1740 [04:40<21:55,  1.10it/s] 17%|█▋        | 299/1740 [04:41<21:49,  1.10it/s] 17%|█▋        | 300/1740 [04:42<21:45,  1.10it/s] 17%|█▋        | 301/1740 [04:42<21:42,  1.10it/s] 17%|█▋        | 302/1740 [04:43<21:40,  1.11it/s] 17%|█▋        | 303/1740 [04:44<21:37,  1.11it/s] 17%|█▋        | 304/1740 [04:45<21:35,  1.11it/s] 18%|█▊        | 305/1740 [04:46<21:35,  1.11it/s] 18%|█▊        | 306/1740 [04:47<21:33,  1.11it/s] 18%|█▊        | 307/1740 [04:48<21:32,  1.11it/s] 18%|█▊        | 308/1740 [04:49<21:30,  1.11it/s] 18%|█▊        | 309/1740 [04:50<21:29,  1.11it/s] 18%|█▊        | 310/1740 [04:51<21:28,  1.11it/s] 18%|█▊        | 311/1740 [04:51<21:27,  1.11it/s] 18%|█▊        | 312/1740 [04:52<21:26,  1.11it/s] 18%|█▊        | 313/1740 [04:53<21:26,  1.11it/s] 18%|█▊        | 314/1740 [04:54<21:25,  1.11it/s] 18%|█▊        | 315/1740 [04:55<21:24,  1.11it/s] 18%|█▊        | 316/1740 [04:56<21:23,  1.11it/s] 18%|█▊        | 317/1740 [04:57<21:23,  1.11it/s] 18%|█▊        | 318/1740 [04:58<21:21,  1.11it/s] 18%|█▊        | 319/1740 [04:59<21:21,  1.11it/s] 18%|█▊        | 320/1740 [05:00<21:17,  1.11it/s] 18%|█▊        | 321/1740 [05:00<21:12,  1.11it/s] 19%|█▊        | 322/1740 [05:01<21:14,  1.11it/s] 19%|█▊        | 323/1740 [05:02<21:14,  1.11it/s] 19%|█▊        | 324/1740 [05:03<21:15,  1.11it/s] 19%|█▊        | 325/1740 [05:04<21:15,  1.11it/s] 19%|█▊        | 326/1740 [05:05<21:14,  1.11it/s] 19%|█▉        | 327/1740 [05:06<21:14,  1.11it/s] 19%|█▉        | 328/1740 [05:07<21:13,  1.11it/s] 19%|█▉        | 329/1740 [05:08<21:12,  1.11it/s] 19%|█▉        | 330/1740 [05:09<21:12,  1.11it/s] 19%|█▉        | 331/1740 [05:10<21:10,  1.11it/s] 19%|█▉        | 332/1740 [05:10<21:10,  1.11it/s] 19%|█▉        | 333/1740 [05:11<21:09,  1.11it/s] 19%|█▉        | 334/1740 [05:12<21:08,  1.11it/s] 19%|█▉        | 335/1740 [05:13<21:07,  1.11it/s] 19%|█▉        | 336/1740 [05:14<21:07,  1.11it/s] 19%|█▉        | 337/1740 [05:15<21:01,  1.11it/s] 19%|█▉        | 338/1740 [05:16<20:58,  1.11it/s] 19%|█▉        | 339/1740 [05:17<20:58,  1.11it/s] 20%|█▉        | 340/1740 [05:18<20:58,  1.11it/s] 20%|█▉        | 341/1740 [05:19<20:59,  1.11it/s] 20%|█▉        | 342/1740 [05:19<20:59,  1.11it/s] 20%|█▉        | 343/1740 [05:20<20:58,  1.11it/s] 20%|█▉        | 344/1740 [05:21<20:58,  1.11it/s] 20%|█▉        | 345/1740 [05:22<20:56,  1.11it/s] 20%|█▉        | 346/1740 [05:23<21:58,  1.06it/s] 20%|█▉        | 347/1740 [05:24<21:39,  1.07it/s] 20%|██        | 348/1740 [05:25<18:19,  1.27it/s]{'eval_loss': 13.02392578125, 'eval_precision': 0.487012987012987, 'eval_recall': 0.29069767441860467, 'eval_f1': 0.3640776699029126, 'eval_accuracy': 0.9545616535994298, 'eval_runtime': 2.1032, 'eval_samples_per_second': 48.972, 'eval_steps_per_second': 1.902, 'epoch': 2.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.73it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.69it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.55it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                  
                                             [A 20%|██        | 348/1740 [05:27<18:19,  1.27it/s]
100%|██████████| 4/4 [00:01<00:00,  2.55it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 20%|██        | 349/1740 [05:31<57:51,  2.50s/it] 20%|██        | 350/1740 [05:32<46:43,  2.02s/it] 20%|██        | 351/1740 [05:33<38:57,  1.68s/it] 20%|██        | 352/1740 [05:34<33:30,  1.45s/it] 20%|██        | 353/1740 [05:35<29:41,  1.28s/it] 20%|██        | 354/1740 [05:36<27:01,  1.17s/it] 20%|██        | 355/1740 [05:36<25:09,  1.09s/it] 20%|██        | 356/1740 [05:37<23:50,  1.03s/it] 21%|██        | 357/1740 [05:38<22:55,  1.01it/s] 21%|██        | 358/1740 [05:39<22:16,  1.03it/s] 21%|██        | 359/1740 [05:40<21:43,  1.06it/s] 21%|██        | 360/1740 [05:41<21:23,  1.08it/s] 21%|██        | 361/1740 [05:42<21:10,  1.09it/s] 21%|██        | 362/1740 [05:43<21:01,  1.09it/s] 21%|██        | 363/1740 [05:44<20:55,  1.10it/s] 21%|██        | 364/1740 [05:45<20:49,  1.10it/s] 21%|██        | 365/1740 [05:45<20:46,  1.10it/s] 21%|██        | 366/1740 [05:46<20:43,  1.10it/s] 21%|██        | 367/1740 [05:47<20:41,  1.11it/s] 21%|██        | 368/1740 [05:48<20:39,  1.11it/s] 21%|██        | 369/1740 [05:49<20:38,  1.11it/s] 21%|██▏       | 370/1740 [05:50<20:31,  1.11it/s] 21%|██▏       | 371/1740 [05:51<20:29,  1.11it/s] 21%|██▏       | 372/1740 [05:52<20:29,  1.11it/s] 21%|██▏       | 373/1740 [05:53<20:30,  1.11it/s] 21%|██▏       | 374/1740 [05:54<20:30,  1.11it/s] 22%|██▏       | 375/1740 [05:54<20:30,  1.11it/s] 22%|██▏       | 376/1740 [05:55<20:29,  1.11it/s] 22%|██▏       | 377/1740 [05:56<20:29,  1.11it/s] 22%|██▏       | 378/1740 [05:57<20:28,  1.11it/s] 22%|██▏       | 379/1740 [05:58<20:29,  1.11it/s] 22%|██▏       | 380/1740 [05:59<20:27,  1.11it/s] 22%|██▏       | 381/1740 [06:00<20:26,  1.11it/s] 22%|██▏       | 382/1740 [06:01<21:24,  1.06it/s] 22%|██▏       | 383/1740 [06:02<21:05,  1.07it/s] 22%|██▏       | 384/1740 [06:03<20:53,  1.08it/s] 22%|██▏       | 385/1740 [06:04<20:44,  1.09it/s] 22%|██▏       | 386/1740 [06:04<20:36,  1.10it/s] 22%|██▏       | 387/1740 [06:05<20:31,  1.10it/s] 22%|██▏       | 388/1740 [06:06<20:26,  1.10it/s] 22%|██▏       | 389/1740 [06:07<20:23,  1.10it/s] 22%|██▏       | 390/1740 [06:08<20:21,  1.11it/s] 22%|██▏       | 391/1740 [06:09<20:19,  1.11it/s] 23%|██▎       | 392/1740 [06:10<20:17,  1.11it/s] 23%|██▎       | 393/1740 [06:11<20:16,  1.11it/s] 23%|██▎       | 394/1740 [06:12<20:15,  1.11it/s] 23%|██▎       | 395/1740 [06:13<20:13,  1.11it/s] 23%|██▎       | 396/1740 [06:14<20:12,  1.11it/s] 23%|██▎       | 397/1740 [06:14<20:11,  1.11it/s] 23%|██▎       | 398/1740 [06:15<20:10,  1.11it/s] 23%|██▎       | 399/1740 [06:16<20:09,  1.11it/s] 23%|██▎       | 400/1740 [06:17<20:07,  1.11it/s] 23%|██▎       | 401/1740 [06:18<20:07,  1.11it/s] 23%|██▎       | 402/1740 [06:19<20:06,  1.11it/s] 23%|██▎       | 403/1740 [06:20<20:07,  1.11it/s] 23%|██▎       | 404/1740 [06:21<20:05,  1.11it/s] 23%|██▎       | 405/1740 [06:22<20:04,  1.11it/s] 23%|██▎       | 406/1740 [06:23<20:04,  1.11it/s] 23%|██▎       | 407/1740 [06:23<20:03,  1.11it/s] 23%|██▎       | 408/1740 [06:24<20:01,  1.11it/s] 24%|██▎       | 409/1740 [06:25<20:00,  1.11it/s] 24%|██▎       | 410/1740 [06:26<19:59,  1.11it/s] 24%|██▎       | 411/1740 [06:27<19:58,  1.11it/s] 24%|██▎       | 412/1740 [06:28<19:57,  1.11it/s] 24%|██▎       | 413/1740 [06:29<19:56,  1.11it/s] 24%|██▍       | 414/1740 [06:30<19:57,  1.11it/s] 24%|██▍       | 415/1740 [06:31<19:52,  1.11it/s] 24%|██▍       | 416/1740 [06:32<19:51,  1.11it/s] 24%|██▍       | 417/1740 [06:32<19:52,  1.11it/s] 24%|██▍       | 418/1740 [06:33<19:52,  1.11it/s] 24%|██▍       | 419/1740 [06:34<19:51,  1.11it/s] 24%|██▍       | 420/1740 [06:35<19:50,  1.11it/s] 24%|██▍       | 421/1740 [06:36<19:50,  1.11it/s] 24%|██▍       | 422/1740 [06:37<20:47,  1.06it/s] 24%|██▍       | 423/1740 [06:38<20:30,  1.07it/s] 24%|██▍       | 424/1740 [06:39<20:16,  1.08it/s] 24%|██▍       | 425/1740 [06:40<20:08,  1.09it/s] 24%|██▍       | 426/1740 [06:41<20:01,  1.09it/s] 25%|██▍       | 427/1740 [06:42<19:54,  1.10it/s] 25%|██▍       | 428/1740 [06:43<19:50,  1.10it/s] 25%|██▍       | 429/1740 [06:43<19:47,  1.10it/s] 25%|██▍       | 430/1740 [06:44<19:45,  1.11it/s] 25%|██▍       | 431/1740 [06:45<19:43,  1.11it/s] 25%|██▍       | 432/1740 [06:46<19:41,  1.11it/s] 25%|██▍       | 433/1740 [06:47<19:40,  1.11it/s] 25%|██▍       | 434/1740 [06:48<19:40,  1.11it/s] 25%|██▌       | 435/1740 [06:49<19:38,  1.11it/s] 25%|██▌       | 436/1740 [06:50<19:36,  1.11it/s] 25%|██▌       | 437/1740 [06:51<19:35,  1.11it/s] 25%|██▌       | 438/1740 [06:52<19:34,  1.11it/s] 25%|██▌       | 439/1740 [06:52<19:34,  1.11it/s] 25%|██▌       | 440/1740 [06:53<19:32,  1.11it/s] 25%|██▌       | 441/1740 [06:54<19:31,  1.11it/s] 25%|██▌       | 442/1740 [06:55<19:32,  1.11it/s] 25%|██▌       | 443/1740 [06:56<19:31,  1.11it/s] 26%|██▌       | 444/1740 [06:57<19:30,  1.11it/s] 26%|██▌       | 445/1740 [06:58<19:30,  1.11it/s] 26%|██▌       | 446/1740 [06:59<19:29,  1.11it/s] 26%|██▌       | 447/1740 [07:00<19:28,  1.11it/s] 26%|██▌       | 448/1740 [07:01<19:27,  1.11it/s] 26%|██▌       | 449/1740 [07:01<19:25,  1.11it/s] 26%|██▌       | 450/1740 [07:02<19:24,  1.11it/s] 26%|██▌       | 451/1740 [07:03<19:23,  1.11it/s] 26%|██▌       | 452/1740 [07:04<19:22,  1.11it/s] 26%|██▌       | 453/1740 [07:05<20:19,  1.06it/s] 26%|██▌       | 454/1740 [07:06<20:00,  1.07it/s] 26%|██▌       | 455/1740 [07:07<19:47,  1.08it/s] 26%|██▌       | 456/1740 [07:08<19:38,  1.09it/s] 26%|██▋       | 457/1740 [07:09<19:32,  1.09it/s] 26%|██▋       | 458/1740 [07:10<19:27,  1.10it/s] 26%|██▋       | 459/1740 [07:11<19:23,  1.10it/s] 26%|██▋       | 460/1740 [07:12<19:19,  1.10it/s] 26%|██▋       | 461/1740 [07:12<19:18,  1.10it/s] 27%|██▋       | 462/1740 [07:13<19:16,  1.11it/s] 27%|██▋       | 463/1740 [07:14<19:14,  1.11it/s] 27%|██▋       | 464/1740 [07:15<16:20,  1.30it/s]{'eval_loss': 10.137076377868652, 'eval_precision': 0.6629213483146067, 'eval_recall': 0.4573643410852713, 'eval_f1': 0.5412844036697247, 'eval_accuracy': 0.9647184604419102, 'eval_runtime': 2.1203, 'eval_samples_per_second': 48.579, 'eval_steps_per_second': 1.887, 'epoch': 3.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.73it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.74it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.56it/s][A                                                  
                                             [A 27%|██▋       | 464/1740 [07:17<16:20,  1.30it/s]
100%|██████████| 4/4 [00:01<00:00,  2.56it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 27%|██▋       | 465/1740 [07:21<52:37,  2.48s/it] 27%|██▋       | 466/1740 [07:22<42:32,  2.00s/it] 27%|██▋       | 467/1740 [07:23<35:30,  1.67s/it] 27%|██▋       | 468/1740 [07:24<30:34,  1.44s/it] 27%|██▋       | 469/1740 [07:25<27:07,  1.28s/it] 27%|██▋       | 470/1740 [07:26<24:42,  1.17s/it] 27%|██▋       | 471/1740 [07:27<22:59,  1.09s/it] 27%|██▋       | 472/1740 [07:28<21:48,  1.03s/it] 27%|██▋       | 473/1740 [07:28<20:57,  1.01it/s] 27%|██▋       | 474/1740 [07:29<20:22,  1.04it/s] 27%|██▋       | 475/1740 [07:30<19:58,  1.06it/s] 27%|██▋       | 476/1740 [07:31<20:36,  1.02it/s] 27%|██▋       | 477/1740 [07:32<20:07,  1.05it/s] 27%|██▋       | 478/1740 [07:33<19:45,  1.06it/s] 28%|██▊       | 479/1740 [07:34<19:30,  1.08it/s] 28%|██▊       | 480/1740 [07:35<19:20,  1.09it/s] 28%|██▊       | 481/1740 [07:36<19:12,  1.09it/s] 28%|██▊       | 482/1740 [07:37<19:07,  1.10it/s] 28%|██▊       | 483/1740 [07:38<19:03,  1.10it/s] 28%|██▊       | 484/1740 [07:38<18:59,  1.10it/s] 28%|██▊       | 485/1740 [07:39<18:57,  1.10it/s] 28%|██▊       | 486/1740 [07:40<18:55,  1.10it/s] 28%|██▊       | 487/1740 [07:41<18:53,  1.11it/s] 28%|██▊       | 488/1740 [07:42<18:51,  1.11it/s] 28%|██▊       | 489/1740 [07:43<18:49,  1.11it/s] 28%|██▊       | 490/1740 [07:44<18:48,  1.11it/s] 28%|██▊       | 491/1740 [07:45<18:48,  1.11it/s] 28%|██▊       | 492/1740 [07:46<18:46,  1.11it/s] 28%|██▊       | 493/1740 [07:47<18:45,  1.11it/s] 28%|██▊       | 494/1740 [07:48<18:44,  1.11it/s] 28%|██▊       | 495/1740 [07:48<18:44,  1.11it/s] 29%|██▊       | 496/1740 [07:49<18:43,  1.11it/s] 29%|██▊       | 497/1740 [07:50<18:37,  1.11it/s] 29%|██▊       | 498/1740 [07:51<18:36,  1.11it/s] 29%|██▊       | 499/1740 [07:52<18:37,  1.11it/s] 29%|██▊       | 500/1740 [07:53<18:36,  1.11it/s]                                                   29%|██▊       | 500/1740 [07:53<18:36,  1.11it/s] 29%|██▉       | 501/1740 [07:54<18:38,  1.11it/s] 29%|██▉       | 502/1740 [07:55<18:37,  1.11it/s] 29%|██▉       | 503/1740 [07:56<18:36,  1.11it/s] 29%|██▉       | 504/1740 [07:57<18:34,  1.11it/s] 29%|██▉       | 505/1740 [07:57<18:33,  1.11it/s] 29%|██▉       | 506/1740 [07:58<18:32,  1.11it/s] 29%|██▉       | 507/1740 [07:59<18:31,  1.11it/s] 29%|██▉       | 508/1740 [08:00<18:31,  1.11it/s] 29%|██▉       | 509/1740 [08:01<18:30,  1.11it/s] 29%|██▉       | 510/1740 [08:02<18:30,  1.11it/s] 29%|██▉       | 511/1740 [08:03<18:29,  1.11it/s] 29%|██▉       | 512/1740 [08:04<18:28,  1.11it/s] 29%|██▉       | 513/1740 [08:05<18:28,  1.11it/s] 30%|██▉       | 514/1740 [08:06<18:26,  1.11it/s] 30%|██▉       | 515/1740 [08:06<18:26,  1.11it/s] 30%|██▉       | 516/1740 [08:07<18:25,  1.11it/s] 30%|██▉       | 517/1740 [08:08<18:23,  1.11it/s] 30%|██▉       | 518/1740 [08:09<18:22,  1.11it/s] 30%|██▉       | 519/1740 [08:10<18:17,  1.11it/s] 30%|██▉       | 520/1740 [08:11<18:15,  1.11it/s] 30%|██▉       | 521/1740 [08:12<18:16,  1.11it/s] 30%|███       | 522/1740 [08:13<18:15,  1.11it/s] 30%|███       | 523/1740 [08:14<18:16,  1.11it/s] 30%|███       | 524/1740 [08:15<18:15,  1.11it/s] 30%|███       | 525/1740 [08:15<18:09,  1.12it/s] 30%|███       | 526/1740 [08:16<18:10,  1.11it/s] 30%|███       | 527/1740 [08:17<18:10,  1.11it/s] 30%|███       | 528/1740 [08:18<19:04,  1.06it/s] 30%|███       | 529/1740 [08:19<18:47,  1.07it/s] 30%|███       | 530/1740 [08:20<18:36,  1.08it/s] 31%|███       | 531/1740 [08:21<18:28,  1.09it/s] 31%|███       | 532/1740 [08:22<18:22,  1.10it/s] 31%|███       | 533/1740 [08:23<18:17,  1.10it/s] 31%|███       | 534/1740 [08:24<18:13,  1.10it/s] 31%|███       | 535/1740 [08:25<18:11,  1.10it/s] 31%|███       | 536/1740 [08:26<18:09,  1.11it/s] 31%|███       | 537/1740 [08:26<18:07,  1.11it/s] 31%|███       | 538/1740 [08:27<18:06,  1.11it/s] 31%|███       | 539/1740 [08:28<18:04,  1.11it/s] 31%|███       | 540/1740 [08:29<18:03,  1.11it/s] 31%|███       | 541/1740 [08:30<17:57,  1.11it/s] 31%|███       | 542/1740 [08:31<17:55,  1.11it/s] 31%|███       | 543/1740 [08:32<17:56,  1.11it/s] 31%|███▏      | 544/1740 [08:33<17:56,  1.11it/s] 31%|███▏      | 545/1740 [08:34<17:55,  1.11it/s] 31%|███▏      | 546/1740 [08:35<17:55,  1.11it/s] 31%|███▏      | 547/1740 [08:35<17:54,  1.11it/s] 31%|███▏      | 548/1740 [08:36<17:53,  1.11it/s] 32%|███▏      | 549/1740 [08:37<17:52,  1.11it/s] 32%|███▏      | 550/1740 [08:38<17:51,  1.11it/s] 32%|███▏      | 551/1740 [08:39<17:50,  1.11it/s] 32%|███▏      | 552/1740 [08:40<17:50,  1.11it/s] 32%|███▏      | 553/1740 [08:41<17:49,  1.11it/s] 32%|███▏      | 554/1740 [08:42<17:49,  1.11it/s] 32%|███▏      | 555/1740 [08:43<17:48,  1.11it/s] 32%|███▏      | 556/1740 [08:44<17:47,  1.11it/s] 32%|███▏      | 557/1740 [08:44<17:47,  1.11it/s] 32%|███▏      | 558/1740 [08:45<17:47,  1.11it/s] 32%|███▏      | 559/1740 [08:46<17:46,  1.11it/s] 32%|███▏      | 560/1740 [08:47<17:45,  1.11it/s] 32%|███▏      | 561/1740 [08:48<17:43,  1.11it/s] 32%|███▏      | 562/1740 [08:49<17:42,  1.11it/s] 32%|███▏      | 563/1740 [08:50<17:41,  1.11it/s] 32%|███▏      | 564/1740 [08:51<17:40,  1.11it/s] 32%|███▏      | 565/1740 [08:52<17:39,  1.11it/s] 33%|███▎      | 566/1740 [08:53<17:38,  1.11it/s] 33%|███▎      | 567/1740 [08:53<17:36,  1.11it/s] 33%|███▎      | 568/1740 [08:55<18:28,  1.06it/s] 33%|███▎      | 569/1740 [08:55<18:11,  1.07it/s] 33%|███▎      | 570/1740 [08:56<17:59,  1.08it/s] 33%|███▎      | 571/1740 [08:57<17:51,  1.09it/s] 33%|███▎      | 572/1740 [08:58<17:45,  1.10it/s] 33%|███▎      | 573/1740 [08:59<17:40,  1.10it/s] 33%|███▎      | 574/1740 [09:00<17:37,  1.10it/s] 33%|███▎      | 575/1740 [09:01<17:34,  1.11it/s] 33%|███▎      | 576/1740 [09:02<17:32,  1.11it/s] 33%|███▎      | 577/1740 [09:03<17:30,  1.11it/s] 33%|███▎      | 578/1740 [09:04<17:28,  1.11it/s] 33%|███▎      | 579/1740 [09:04<17:27,  1.11it/s] 33%|███▎      | 580/1740 [09:05<14:52,  1.30it/s]{'eval_loss': 6.85012674331665, 'eval_precision': 0.6258741258741258, 'eval_recall': 0.6937984496124031, 'eval_f1': 0.6580882352941176, 'eval_accuracy': 0.9684604419101924, 'eval_runtime': 2.142, 'eval_samples_per_second': 48.085, 'eval_steps_per_second': 1.867, 'epoch': 4.0}
{'loss': 40.2605, 'grad_norm': 77920064.0, 'learning_rate': 6.453752255644988e-05, 'epoch': 4.31}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.87it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.73it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.51it/s][A                                                  
                                             [A 33%|███▎      | 580/1740 [09:07<14:52,  1.30it/s]
100%|██████████| 4/4 [00:01<00:00,  2.51it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 33%|███▎      | 581/1740 [09:11<46:49,  2.42s/it] 33%|███▎      | 582/1740 [09:12<37:56,  1.97s/it] 34%|███▎      | 583/1740 [09:13<31:44,  1.65s/it] 34%|███▎      | 584/1740 [09:14<27:24,  1.42s/it] 34%|███▎      | 585/1740 [09:15<24:19,  1.26s/it] 34%|███▎      | 586/1740 [09:16<22:08,  1.15s/it] 34%|███▎      | 587/1740 [09:17<20:41,  1.08s/it] 34%|███▍      | 588/1740 [09:17<19:39,  1.02s/it] 34%|███▍      | 589/1740 [09:18<18:56,  1.01it/s] 34%|███▍      | 590/1740 [09:19<18:25,  1.04it/s] 34%|███▍      | 591/1740 [09:20<18:03,  1.06it/s] 34%|███▍      | 592/1740 [09:21<17:47,  1.08it/s] 34%|███▍      | 593/1740 [09:22<17:36,  1.09it/s] 34%|███▍      | 594/1740 [09:23<17:28,  1.09it/s] 34%|███▍      | 595/1740 [09:24<17:24,  1.10it/s] 34%|███▍      | 596/1740 [09:25<17:19,  1.10it/s] 34%|███▍      | 597/1740 [09:26<18:06,  1.05it/s] 34%|███▍      | 598/1740 [09:27<17:49,  1.07it/s] 34%|███▍      | 599/1740 [09:28<17:36,  1.08it/s] 34%|███▍      | 600/1740 [09:28<17:27,  1.09it/s] 35%|███▍      | 601/1740 [09:29<17:21,  1.09it/s] 35%|███▍      | 602/1740 [09:30<17:15,  1.10it/s] 35%|███▍      | 603/1740 [09:31<17:12,  1.10it/s] 35%|███▍      | 604/1740 [09:32<17:08,  1.10it/s] 35%|███▍      | 605/1740 [09:33<17:06,  1.11it/s] 35%|███▍      | 606/1740 [09:34<17:04,  1.11it/s] 35%|███▍      | 607/1740 [09:35<17:03,  1.11it/s] 35%|███▍      | 608/1740 [09:36<17:01,  1.11it/s] 35%|███▌      | 609/1740 [09:37<17:01,  1.11it/s] 35%|███▌      | 610/1740 [09:37<16:59,  1.11it/s] 35%|███▌      | 611/1740 [09:38<16:59,  1.11it/s] 35%|███▌      | 612/1740 [09:39<16:57,  1.11it/s] 35%|███▌      | 613/1740 [09:40<16:56,  1.11it/s] 35%|███▌      | 614/1740 [09:41<16:55,  1.11it/s] 35%|███▌      | 615/1740 [09:42<16:55,  1.11it/s] 35%|███▌      | 616/1740 [09:43<16:54,  1.11it/s] 35%|███▌      | 617/1740 [09:44<16:53,  1.11it/s] 36%|███▌      | 618/1740 [09:45<16:52,  1.11it/s] 36%|███▌      | 619/1740 [09:46<16:51,  1.11it/s] 36%|███▌      | 620/1740 [09:46<16:50,  1.11it/s] 36%|███▌      | 621/1740 [09:47<16:49,  1.11it/s] 36%|███▌      | 622/1740 [09:48<17:38,  1.06it/s] 36%|███▌      | 623/1740 [09:49<17:23,  1.07it/s] 36%|███▌      | 624/1740 [09:50<17:11,  1.08it/s] 36%|███▌      | 625/1740 [09:51<17:03,  1.09it/s] 36%|███▌      | 626/1740 [09:52<16:57,  1.09it/s] 36%|███▌      | 627/1740 [09:53<16:52,  1.10it/s] 36%|███▌      | 628/1740 [09:54<16:49,  1.10it/s] 36%|███▌      | 629/1740 [09:55<16:46,  1.10it/s] 36%|███▌      | 630/1740 [09:56<16:44,  1.11it/s] 36%|███▋      | 631/1740 [09:57<16:42,  1.11it/s] 36%|███▋      | 632/1740 [09:57<16:40,  1.11it/s] 36%|███▋      | 633/1740 [09:58<16:39,  1.11it/s] 36%|███▋      | 634/1740 [09:59<16:38,  1.11it/s] 36%|███▋      | 635/1740 [10:00<16:37,  1.11it/s] 37%|███▋      | 636/1740 [10:01<16:37,  1.11it/s] 37%|███▋      | 637/1740 [10:02<16:35,  1.11it/s] 37%|███▋      | 638/1740 [10:03<16:34,  1.11it/s] 37%|███▋      | 639/1740 [10:04<16:34,  1.11it/s] 37%|███▋      | 640/1740 [10:05<16:32,  1.11it/s] 37%|███▋      | 641/1740 [10:06<16:31,  1.11it/s] 37%|███▋      | 642/1740 [10:06<16:31,  1.11it/s] 37%|███▋      | 643/1740 [10:07<16:29,  1.11it/s] 37%|███▋      | 644/1740 [10:08<16:28,  1.11it/s] 37%|███▋      | 645/1740 [10:09<16:27,  1.11it/s] 37%|███▋      | 646/1740 [10:10<16:22,  1.11it/s] 37%|███▋      | 647/1740 [10:11<17:09,  1.06it/s] 37%|███▋      | 648/1740 [10:12<16:55,  1.08it/s] 37%|███▋      | 649/1740 [10:13<16:45,  1.09it/s] 37%|███▋      | 650/1740 [10:14<16:37,  1.09it/s] 37%|███▋      | 651/1740 [10:15<16:30,  1.10it/s] 37%|███▋      | 652/1740 [10:16<16:23,  1.11it/s] 38%|███▊      | 653/1740 [10:16<16:22,  1.11it/s] 38%|███▊      | 654/1740 [10:17<16:20,  1.11it/s] 38%|███▊      | 655/1740 [10:18<16:19,  1.11it/s] 38%|███▊      | 656/1740 [10:19<16:18,  1.11it/s] 38%|███▊      | 657/1740 [10:20<16:17,  1.11it/s] 38%|███▊      | 658/1740 [10:21<16:16,  1.11it/s] 38%|███▊      | 659/1740 [10:22<16:14,  1.11it/s] 38%|███▊      | 660/1740 [10:23<16:13,  1.11it/s] 38%|███▊      | 661/1740 [10:24<16:12,  1.11it/s] 38%|███▊      | 662/1740 [10:25<16:11,  1.11it/s] 38%|███▊      | 663/1740 [10:26<16:11,  1.11it/s] 38%|███▊      | 664/1740 [10:26<16:09,  1.11it/s] 38%|███▊      | 665/1740 [10:27<16:08,  1.11it/s] 38%|███▊      | 666/1740 [10:28<16:07,  1.11it/s] 38%|███▊      | 667/1740 [10:29<16:06,  1.11it/s] 38%|███▊      | 668/1740 [10:30<16:01,  1.11it/s] 38%|███▊      | 669/1740 [10:31<16:00,  1.12it/s] 39%|███▊      | 670/1740 [10:32<16:00,  1.11it/s] 39%|███▊      | 671/1740 [10:33<16:01,  1.11it/s] 39%|███▊      | 672/1740 [10:34<16:00,  1.11it/s] 39%|███▊      | 673/1740 [10:34<16:00,  1.11it/s] 39%|███▊      | 674/1740 [10:35<15:59,  1.11it/s] 39%|███▉      | 675/1740 [10:36<15:59,  1.11it/s] 39%|███▉      | 676/1740 [10:37<15:58,  1.11it/s] 39%|███▉      | 677/1740 [10:38<15:57,  1.11it/s] 39%|███▉      | 678/1740 [10:39<15:56,  1.11it/s] 39%|███▉      | 679/1740 [10:40<15:56,  1.11it/s] 39%|███▉      | 680/1740 [10:41<15:55,  1.11it/s] 39%|███▉      | 681/1740 [10:42<15:54,  1.11it/s] 39%|███▉      | 682/1740 [10:43<15:53,  1.11it/s] 39%|███▉      | 683/1740 [10:44<15:52,  1.11it/s] 39%|███▉      | 684/1740 [10:44<15:51,  1.11it/s] 39%|███▉      | 685/1740 [10:45<15:51,  1.11it/s] 39%|███▉      | 686/1740 [10:46<15:50,  1.11it/s] 39%|███▉      | 687/1740 [10:47<15:48,  1.11it/s] 40%|███▉      | 688/1740 [10:48<15:47,  1.11it/s] 40%|███▉      | 689/1740 [10:49<15:47,  1.11it/s] 40%|███▉      | 690/1740 [10:50<15:46,  1.11it/s] 40%|███▉      | 691/1740 [10:51<15:46,  1.11it/s] 40%|███▉      | 692/1740 [10:52<15:45,  1.11it/s] 40%|███▉      | 693/1740 [10:53<15:44,  1.11it/s] 40%|███▉      | 694/1740 [10:53<15:43,  1.11it/s] 40%|███▉      | 695/1740 [10:54<15:42,  1.11it/s] 40%|████      | 696/1740 [10:55<13:23,  1.30it/s]{'eval_loss': 8.119136810302734, 'eval_precision': 0.64, 'eval_recall': 0.6821705426356589, 'eval_f1': 0.6604127579737336, 'eval_accuracy': 0.9672131147540983, 'eval_runtime': 2.1488, 'eval_samples_per_second': 47.935, 'eval_steps_per_second': 1.862, 'epoch': 5.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.89it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.45it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.47it/s][A                                                  
                                             [A 40%|████      | 696/1740 [10:57<13:23,  1.30it/s]
100%|██████████| 4/4 [00:01<00:00,  2.47it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 40%|████      | 697/1740 [11:02<44:27,  2.56s/it] 40%|████      | 698/1740 [11:02<35:46,  2.06s/it] 40%|████      | 699/1740 [11:03<29:42,  1.71s/it] 40%|████      | 700/1740 [11:04<25:27,  1.47s/it] 40%|████      | 701/1740 [11:05<22:29,  1.30s/it] 40%|████      | 702/1740 [11:06<20:24,  1.18s/it] 40%|████      | 703/1740 [11:07<18:56,  1.10s/it] 40%|████      | 704/1740 [11:08<17:54,  1.04s/it] 41%|████      | 705/1740 [11:09<17:12,  1.00it/s] 41%|████      | 706/1740 [11:10<16:39,  1.03it/s] 41%|████      | 707/1740 [11:11<16:15,  1.06it/s] 41%|████      | 708/1740 [11:11<16:01,  1.07it/s] 41%|████      | 709/1740 [11:12<15:51,  1.08it/s] 41%|████      | 710/1740 [11:13<15:44,  1.09it/s] 41%|████      | 711/1740 [11:14<15:38,  1.10it/s] 41%|████      | 712/1740 [11:15<15:30,  1.10it/s] 41%|████      | 713/1740 [11:16<15:26,  1.11it/s] 41%|████      | 714/1740 [11:17<15:24,  1.11it/s] 41%|████      | 715/1740 [11:18<15:24,  1.11it/s] 41%|████      | 716/1740 [11:19<15:23,  1.11it/s] 41%|████      | 717/1740 [11:20<15:22,  1.11it/s] 41%|████▏     | 718/1740 [11:20<15:22,  1.11it/s] 41%|████▏     | 719/1740 [11:21<15:21,  1.11it/s] 41%|████▏     | 720/1740 [11:22<15:20,  1.11it/s] 41%|████▏     | 721/1740 [11:23<15:19,  1.11it/s] 41%|████▏     | 722/1740 [11:24<15:18,  1.11it/s] 42%|████▏     | 723/1740 [11:25<15:18,  1.11it/s] 42%|████▏     | 724/1740 [11:26<15:16,  1.11it/s] 42%|████▏     | 725/1740 [11:27<15:15,  1.11it/s] 42%|████▏     | 726/1740 [11:28<15:15,  1.11it/s] 42%|████▏     | 727/1740 [11:29<15:14,  1.11it/s] 42%|████▏     | 728/1740 [11:29<15:13,  1.11it/s] 42%|████▏     | 729/1740 [11:30<15:13,  1.11it/s] 42%|████▏     | 730/1740 [11:31<15:11,  1.11it/s] 42%|████▏     | 731/1740 [11:32<15:11,  1.11it/s] 42%|████▏     | 732/1740 [11:33<15:09,  1.11it/s] 42%|████▏     | 733/1740 [11:34<15:10,  1.11it/s] 42%|████▏     | 734/1740 [11:35<15:09,  1.11it/s] 42%|████▏     | 735/1740 [11:36<15:53,  1.05it/s] 42%|████▏     | 736/1740 [11:37<15:38,  1.07it/s] 42%|████▏     | 737/1740 [11:38<15:28,  1.08it/s] 42%|████▏     | 738/1740 [11:39<15:20,  1.09it/s] 42%|████▏     | 739/1740 [11:40<15:13,  1.10it/s] 43%|████▎     | 740/1740 [11:40<15:05,  1.10it/s] 43%|████▎     | 741/1740 [11:41<15:03,  1.11it/s] 43%|████▎     | 742/1740 [11:42<15:02,  1.11it/s] 43%|████▎     | 743/1740 [11:43<15:01,  1.11it/s] 43%|████▎     | 744/1740 [11:44<14:59,  1.11it/s] 43%|████▎     | 745/1740 [11:45<14:58,  1.11it/s] 43%|████▎     | 746/1740 [11:46<14:57,  1.11it/s] 43%|████▎     | 747/1740 [11:47<14:56,  1.11it/s] 43%|████▎     | 748/1740 [11:48<14:55,  1.11it/s] 43%|████▎     | 749/1740 [11:49<14:53,  1.11it/s] 43%|████▎     | 750/1740 [11:49<14:52,  1.11it/s] 43%|████▎     | 751/1740 [11:50<14:52,  1.11it/s] 43%|████▎     | 752/1740 [11:51<14:51,  1.11it/s] 43%|████▎     | 753/1740 [11:52<14:50,  1.11it/s] 43%|████▎     | 754/1740 [11:53<14:49,  1.11it/s] 43%|████▎     | 755/1740 [11:54<14:48,  1.11it/s] 43%|████▎     | 756/1740 [11:55<14:47,  1.11it/s] 44%|████▎     | 757/1740 [11:56<14:46,  1.11it/s] 44%|████▎     | 758/1740 [11:57<14:45,  1.11it/s] 44%|████▎     | 759/1740 [11:58<14:45,  1.11it/s] 44%|████▎     | 760/1740 [11:58<14:43,  1.11it/s] 44%|████▎     | 761/1740 [11:59<14:42,  1.11it/s] 44%|████▍     | 762/1740 [12:00<14:42,  1.11it/s] 44%|████▍     | 763/1740 [12:01<14:41,  1.11it/s] 44%|████▍     | 764/1740 [12:02<14:40,  1.11it/s] 44%|████▍     | 765/1740 [12:03<15:23,  1.06it/s] 44%|████▍     | 766/1740 [12:04<15:09,  1.07it/s] 44%|████▍     | 767/1740 [12:05<14:59,  1.08it/s] 44%|████▍     | 768/1740 [12:06<14:52,  1.09it/s] 44%|████▍     | 769/1740 [12:07<14:46,  1.10it/s] 44%|████▍     | 770/1740 [12:08<14:42,  1.10it/s] 44%|████▍     | 771/1740 [12:09<14:39,  1.10it/s] 44%|████▍     | 772/1740 [12:09<14:36,  1.10it/s] 44%|████▍     | 773/1740 [12:10<14:35,  1.10it/s] 44%|████▍     | 774/1740 [12:11<14:33,  1.11it/s] 45%|████▍     | 775/1740 [12:12<14:32,  1.11it/s] 45%|████▍     | 776/1740 [12:13<14:31,  1.11it/s] 45%|████▍     | 777/1740 [12:14<14:29,  1.11it/s] 45%|████▍     | 778/1740 [12:15<14:25,  1.11it/s] 45%|████▍     | 779/1740 [12:16<14:23,  1.11it/s] 45%|████▍     | 780/1740 [12:17<14:23,  1.11it/s] 45%|████▍     | 781/1740 [12:18<14:23,  1.11it/s] 45%|████▍     | 782/1740 [12:18<14:22,  1.11it/s] 45%|████▌     | 783/1740 [12:19<14:22,  1.11it/s] 45%|████▌     | 784/1740 [12:20<14:22,  1.11it/s] 45%|████▌     | 785/1740 [12:21<14:21,  1.11it/s] 45%|████▌     | 786/1740 [12:22<14:20,  1.11it/s] 45%|████▌     | 787/1740 [12:23<14:19,  1.11it/s] 45%|████▌     | 788/1740 [12:24<14:18,  1.11it/s] 45%|████▌     | 789/1740 [12:25<14:18,  1.11it/s] 45%|████▌     | 790/1740 [12:26<14:17,  1.11it/s] 45%|████▌     | 791/1740 [12:27<14:16,  1.11it/s] 46%|████▌     | 792/1740 [12:27<14:16,  1.11it/s] 46%|████▌     | 793/1740 [12:28<14:14,  1.11it/s] 46%|████▌     | 794/1740 [12:29<14:14,  1.11it/s] 46%|████▌     | 795/1740 [12:30<14:13,  1.11it/s] 46%|████▌     | 796/1740 [12:31<14:12,  1.11it/s] 46%|████▌     | 797/1740 [12:32<14:54,  1.05it/s] 46%|████▌     | 798/1740 [12:33<14:40,  1.07it/s] 46%|████▌     | 799/1740 [12:34<14:30,  1.08it/s] 46%|████▌     | 800/1740 [12:35<14:24,  1.09it/s] 46%|████▌     | 801/1740 [12:36<14:18,  1.09it/s] 46%|████▌     | 802/1740 [12:37<14:14,  1.10it/s] 46%|████▌     | 803/1740 [12:38<14:10,  1.10it/s] 46%|████▌     | 804/1740 [12:38<14:08,  1.10it/s] 46%|████▋     | 805/1740 [12:39<14:06,  1.11it/s] 46%|████▋     | 806/1740 [12:40<14:04,  1.11it/s] 46%|████▋     | 807/1740 [12:41<14:02,  1.11it/s] 46%|████▋     | 808/1740 [12:42<14:01,  1.11it/s] 46%|████▋     | 809/1740 [12:43<14:00,  1.11it/s] 47%|████▋     | 810/1740 [12:44<13:59,  1.11it/s] 47%|████▋     | 811/1740 [12:45<13:58,  1.11it/s] 47%|████▋     | 812/1740 [12:45<11:54,  1.30it/s]{'eval_loss': 6.854203224182129, 'eval_precision': 0.8622448979591837, 'eval_recall': 0.6550387596899225, 'eval_f1': 0.7444933920704846, 'eval_accuracy': 0.9789736279401283, 'eval_runtime': 2.2017, 'eval_samples_per_second': 46.782, 'eval_steps_per_second': 1.817, 'epoch': 6.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.69it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.72it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.66it/s][A                                                  
                                             [A 47%|████▋     | 812/1740 [12:47<11:54,  1.30it/s]
100%|██████████| 4/4 [00:01<00:00,  2.66it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 47%|████▋     | 813/1740 [12:52<37:37,  2.44s/it] 47%|████▋     | 814/1740 [12:52<30:29,  1.98s/it] 47%|████▋     | 815/1740 [12:53<25:29,  1.65s/it] 47%|████▋     | 816/1740 [12:54<21:59,  1.43s/it] 47%|████▋     | 817/1740 [12:55<19:32,  1.27s/it] 47%|████▋     | 818/1740 [12:56<17:49,  1.16s/it] 47%|████▋     | 819/1740 [12:57<16:37,  1.08s/it] 47%|████▋     | 820/1740 [12:58<15:46,  1.03s/it] 47%|████▋     | 821/1740 [12:59<15:10,  1.01it/s] 47%|████▋     | 822/1740 [13:00<15:27,  1.01s/it] 47%|████▋     | 823/1740 [13:01<14:56,  1.02it/s] 47%|████▋     | 824/1740 [13:02<14:34,  1.05it/s] 47%|████▋     | 825/1740 [13:03<14:19,  1.06it/s] 47%|████▋     | 826/1740 [13:03<14:08,  1.08it/s] 48%|████▊     | 827/1740 [13:04<14:00,  1.09it/s] 48%|████▊     | 828/1740 [13:05<13:54,  1.09it/s] 48%|████▊     | 829/1740 [13:06<13:50,  1.10it/s] 48%|████▊     | 830/1740 [13:07<13:47,  1.10it/s] 48%|████▊     | 831/1740 [13:08<13:44,  1.10it/s] 48%|████▊     | 832/1740 [13:09<13:42,  1.10it/s] 48%|████▊     | 833/1740 [13:10<13:40,  1.10it/s] 48%|████▊     | 834/1740 [13:11<13:39,  1.11it/s] 48%|████▊     | 835/1740 [13:12<13:37,  1.11it/s] 48%|████▊     | 836/1740 [13:12<13:37,  1.11it/s] 48%|████▊     | 837/1740 [13:13<13:35,  1.11it/s] 48%|████▊     | 838/1740 [13:14<13:34,  1.11it/s] 48%|████▊     | 839/1740 [13:15<13:29,  1.11it/s] 48%|████▊     | 840/1740 [13:16<13:28,  1.11it/s] 48%|████▊     | 841/1740 [13:17<13:29,  1.11it/s] 48%|████▊     | 842/1740 [13:18<13:28,  1.11it/s] 48%|████▊     | 843/1740 [13:19<13:28,  1.11it/s] 49%|████▊     | 844/1740 [13:20<13:28,  1.11it/s] 49%|████▊     | 845/1740 [13:21<13:27,  1.11it/s] 49%|████▊     | 846/1740 [13:21<13:26,  1.11it/s] 49%|████▊     | 847/1740 [13:23<14:05,  1.06it/s] 49%|████▊     | 848/1740 [13:23<13:53,  1.07it/s] 49%|████▉     | 849/1740 [13:24<13:44,  1.08it/s] 49%|████▉     | 850/1740 [13:25<13:37,  1.09it/s] 49%|████▉     | 851/1740 [13:26<13:32,  1.09it/s] 49%|████▉     | 852/1740 [13:27<13:29,  1.10it/s] 49%|████▉     | 853/1740 [13:28<13:25,  1.10it/s] 49%|████▉     | 854/1740 [13:29<13:23,  1.10it/s] 49%|████▉     | 855/1740 [13:30<13:21,  1.10it/s] 49%|████▉     | 856/1740 [13:31<13:19,  1.11it/s] 49%|████▉     | 857/1740 [13:32<13:18,  1.11it/s] 49%|████▉     | 858/1740 [13:32<13:17,  1.11it/s] 49%|████▉     | 859/1740 [13:33<13:16,  1.11it/s] 49%|████▉     | 860/1740 [13:34<13:15,  1.11it/s] 49%|████▉     | 861/1740 [13:35<13:14,  1.11it/s] 50%|████▉     | 862/1740 [13:36<13:13,  1.11it/s] 50%|████▉     | 863/1740 [13:37<13:12,  1.11it/s] 50%|████▉     | 864/1740 [13:38<13:11,  1.11it/s] 50%|████▉     | 865/1740 [13:39<13:10,  1.11it/s] 50%|████▉     | 866/1740 [13:40<13:09,  1.11it/s] 50%|████▉     | 867/1740 [13:41<13:08,  1.11it/s] 50%|████▉     | 868/1740 [13:42<13:07,  1.11it/s] 50%|████▉     | 869/1740 [13:42<13:06,  1.11it/s] 50%|█████     | 870/1740 [13:43<13:05,  1.11it/s] 50%|█████     | 871/1740 [13:44<13:04,  1.11it/s] 50%|█████     | 872/1740 [13:45<13:04,  1.11it/s] 50%|█████     | 873/1740 [13:46<13:02,  1.11it/s] 50%|█████     | 874/1740 [13:47<13:02,  1.11it/s] 50%|█████     | 875/1740 [13:48<13:00,  1.11it/s] 50%|█████     | 876/1740 [13:49<12:59,  1.11it/s] 50%|█████     | 877/1740 [13:50<12:57,  1.11it/s] 50%|█████     | 878/1740 [13:51<12:53,  1.11it/s] 51%|█████     | 879/1740 [13:51<12:53,  1.11it/s] 51%|█████     | 880/1740 [13:52<12:54,  1.11it/s] 51%|█████     | 881/1740 [13:53<12:53,  1.11it/s] 51%|█████     | 882/1740 [13:54<12:53,  1.11it/s] 51%|█████     | 883/1740 [13:55<12:52,  1.11it/s] 51%|█████     | 884/1740 [13:56<12:51,  1.11it/s] 51%|█████     | 885/1740 [13:57<12:51,  1.11it/s] 51%|█████     | 886/1740 [13:58<12:50,  1.11it/s] 51%|█████     | 887/1740 [13:59<12:49,  1.11it/s] 51%|█████     | 888/1740 [14:00<12:47,  1.11it/s] 51%|█████     | 889/1740 [14:00<12:43,  1.11it/s] 51%|█████     | 890/1740 [14:01<12:43,  1.11it/s] 51%|█████     | 891/1740 [14:02<12:44,  1.11it/s] 51%|█████▏    | 892/1740 [14:03<12:43,  1.11it/s] 51%|█████▏    | 893/1740 [14:04<12:43,  1.11it/s] 51%|█████▏    | 894/1740 [14:05<12:43,  1.11it/s] 51%|█████▏    | 895/1740 [14:06<12:41,  1.11it/s] 51%|█████▏    | 896/1740 [14:07<12:41,  1.11it/s] 52%|█████▏    | 897/1740 [14:08<12:40,  1.11it/s] 52%|█████▏    | 898/1740 [14:09<12:39,  1.11it/s] 52%|█████▏    | 899/1740 [14:10<13:14,  1.06it/s] 52%|█████▏    | 900/1740 [14:10<12:59,  1.08it/s] 52%|█████▏    | 901/1740 [14:11<12:52,  1.09it/s] 52%|█████▏    | 902/1740 [14:12<12:47,  1.09it/s] 52%|█████▏    | 903/1740 [14:13<12:42,  1.10it/s] 52%|█████▏    | 904/1740 [14:14<12:39,  1.10it/s] 52%|█████▏    | 905/1740 [14:15<12:34,  1.11it/s] 52%|█████▏    | 906/1740 [14:16<12:31,  1.11it/s] 52%|█████▏    | 907/1740 [14:17<12:31,  1.11it/s] 52%|█████▏    | 908/1740 [14:18<12:30,  1.11it/s] 52%|█████▏    | 909/1740 [14:19<12:29,  1.11it/s] 52%|█████▏    | 910/1740 [14:19<12:29,  1.11it/s] 52%|█████▏    | 911/1740 [14:20<12:28,  1.11it/s] 52%|█████▏    | 912/1740 [14:21<12:27,  1.11it/s] 52%|█████▏    | 913/1740 [14:22<12:26,  1.11it/s] 53%|█████▎    | 914/1740 [14:23<12:25,  1.11it/s] 53%|█████▎    | 915/1740 [14:24<12:24,  1.11it/s] 53%|█████▎    | 916/1740 [14:25<12:23,  1.11it/s] 53%|█████▎    | 917/1740 [14:26<12:22,  1.11it/s] 53%|█████▎    | 918/1740 [14:27<12:22,  1.11it/s] 53%|█████▎    | 919/1740 [14:28<12:20,  1.11it/s] 53%|█████▎    | 920/1740 [14:29<12:20,  1.11it/s] 53%|█████▎    | 921/1740 [14:29<12:19,  1.11it/s] 53%|█████▎    | 922/1740 [14:30<12:18,  1.11it/s] 53%|█████▎    | 923/1740 [14:31<12:17,  1.11it/s] 53%|█████▎    | 924/1740 [14:32<12:16,  1.11it/s] 53%|█████▎    | 925/1740 [14:33<12:15,  1.11it/s] 53%|█████▎    | 926/1740 [14:34<12:14,  1.11it/s] 53%|█████▎    | 927/1740 [14:35<12:13,  1.11it/s] 53%|█████▎    | 928/1740 [14:35<10:24,  1.30it/s]{'eval_loss': 5.26989221572876, 'eval_precision': 0.7428571428571429, 'eval_recall': 0.7054263565891473, 'eval_f1': 0.7236580516898609, 'eval_accuracy': 0.9789736279401283, 'eval_runtime': 2.0999, 'eval_samples_per_second': 49.051, 'eval_steps_per_second': 1.905, 'epoch': 7.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.85it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.73it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A                                                  
                                             [A 53%|█████▎    | 928/1740 [14:37<10:24,  1.30it/s]
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 53%|█████▎    | 929/1740 [14:42<33:46,  2.50s/it] 53%|█████▎    | 930/1740 [14:43<27:15,  2.02s/it] 54%|█████▎    | 931/1740 [14:44<22:42,  1.68s/it] 54%|█████▎    | 932/1740 [14:45<19:31,  1.45s/it] 54%|█████▎    | 933/1740 [14:45<17:17,  1.29s/it] 54%|█████▎    | 934/1740 [14:46<15:43,  1.17s/it] 54%|█████▎    | 935/1740 [14:47<15:12,  1.13s/it] 54%|█████▍    | 936/1740 [14:48<14:16,  1.07s/it] 54%|█████▍    | 937/1740 [14:49<13:35,  1.02s/it] 54%|█████▍    | 938/1740 [14:50<13:07,  1.02it/s] 54%|█████▍    | 939/1740 [14:51<12:47,  1.04it/s] 54%|█████▍    | 940/1740 [14:52<12:32,  1.06it/s] 54%|█████▍    | 941/1740 [14:53<12:23,  1.07it/s] 54%|█████▍    | 942/1740 [14:54<12:15,  1.08it/s] 54%|█████▍    | 943/1740 [14:55<12:10,  1.09it/s] 54%|█████▍    | 944/1740 [14:56<12:07,  1.09it/s] 54%|█████▍    | 945/1740 [14:56<12:04,  1.10it/s] 54%|█████▍    | 946/1740 [14:57<12:01,  1.10it/s] 54%|█████▍    | 947/1740 [14:58<11:59,  1.10it/s] 54%|█████▍    | 948/1740 [14:59<11:57,  1.10it/s] 55%|█████▍    | 949/1740 [15:00<11:53,  1.11it/s] 55%|█████▍    | 950/1740 [15:01<11:51,  1.11it/s] 55%|█████▍    | 951/1740 [15:02<11:51,  1.11it/s] 55%|█████▍    | 952/1740 [15:03<11:50,  1.11it/s] 55%|█████▍    | 953/1740 [15:04<11:50,  1.11it/s] 55%|█████▍    | 954/1740 [15:05<11:49,  1.11it/s] 55%|█████▍    | 955/1740 [15:05<11:49,  1.11it/s] 55%|█████▍    | 956/1740 [15:06<11:48,  1.11it/s] 55%|█████▌    | 957/1740 [15:07<11:47,  1.11it/s] 55%|█████▌    | 958/1740 [15:08<11:47,  1.11it/s] 55%|█████▌    | 959/1740 [15:09<11:46,  1.11it/s] 55%|█████▌    | 960/1740 [15:10<11:42,  1.11it/s] 55%|█████▌    | 961/1740 [15:11<11:40,  1.11it/s] 55%|█████▌    | 962/1740 [15:12<11:40,  1.11it/s] 55%|█████▌    | 963/1740 [15:13<11:40,  1.11it/s] 55%|█████▌    | 964/1740 [15:14<11:39,  1.11it/s] 55%|█████▌    | 965/1740 [15:14<11:39,  1.11it/s] 56%|█████▌    | 966/1740 [15:15<11:34,  1.11it/s] 56%|█████▌    | 967/1740 [15:16<11:35,  1.11it/s] 56%|█████▌    | 968/1740 [15:17<11:34,  1.11it/s] 56%|█████▌    | 969/1740 [15:18<11:34,  1.11it/s] 56%|█████▌    | 970/1740 [15:19<11:33,  1.11it/s] 56%|█████▌    | 971/1740 [15:20<11:33,  1.11it/s] 56%|█████▌    | 972/1740 [15:21<11:33,  1.11it/s] 56%|█████▌    | 973/1740 [15:22<11:32,  1.11it/s] 56%|█████▌    | 974/1740 [15:23<11:31,  1.11it/s] 56%|█████▌    | 975/1740 [15:24<12:04,  1.06it/s] 56%|█████▌    | 976/1740 [15:25<11:53,  1.07it/s] 56%|█████▌    | 977/1740 [15:25<11:45,  1.08it/s] 56%|█████▌    | 978/1740 [15:26<11:39,  1.09it/s] 56%|█████▋    | 979/1740 [15:27<11:35,  1.09it/s] 56%|█████▋    | 980/1740 [15:28<11:32,  1.10it/s] 56%|█████▋    | 981/1740 [15:29<11:29,  1.10it/s] 56%|█████▋    | 982/1740 [15:30<11:27,  1.10it/s] 56%|█████▋    | 983/1740 [15:31<11:26,  1.10it/s] 57%|█████▋    | 984/1740 [15:32<11:24,  1.10it/s] 57%|█████▋    | 985/1740 [15:33<11:23,  1.11it/s] 57%|█████▋    | 986/1740 [15:34<11:21,  1.11it/s] 57%|█████▋    | 987/1740 [15:34<11:20,  1.11it/s] 57%|█████▋    | 988/1740 [15:35<11:20,  1.11it/s] 57%|█████▋    | 989/1740 [15:36<11:19,  1.11it/s] 57%|█████▋    | 990/1740 [15:37<11:17,  1.11it/s] 57%|█████▋    | 991/1740 [15:38<11:16,  1.11it/s] 57%|█████▋    | 992/1740 [15:39<11:15,  1.11it/s] 57%|█████▋    | 993/1740 [15:40<11:14,  1.11it/s] 57%|█████▋    | 994/1740 [15:41<11:13,  1.11it/s] 57%|█████▋    | 995/1740 [15:42<11:13,  1.11it/s] 57%|█████▋    | 996/1740 [15:43<11:12,  1.11it/s] 57%|█████▋    | 997/1740 [15:44<11:11,  1.11it/s] 57%|█████▋    | 998/1740 [15:44<11:10,  1.11it/s] 57%|█████▋    | 999/1740 [15:45<11:09,  1.11it/s] 57%|█████▋    | 1000/1740 [15:46<11:08,  1.11it/s]                                                    57%|█████▋    | 1000/1740 [15:46<11:08,  1.11it/s] 58%|█████▊    | 1001/1740 [15:47<11:07,  1.11it/s] 58%|█████▊    | 1002/1740 [15:48<11:06,  1.11it/s] 58%|█████▊    | 1003/1740 [15:49<11:06,  1.11it/s] 58%|█████▊    | 1004/1740 [15:50<11:05,  1.11it/s] 58%|█████▊    | 1005/1740 [15:51<11:04,  1.11it/s] 58%|█████▊    | 1006/1740 [15:52<11:36,  1.05it/s] 58%|█████▊    | 1007/1740 [15:53<11:25,  1.07it/s] 58%|█████▊    | 1008/1740 [15:54<11:18,  1.08it/s] 58%|█████▊    | 1009/1740 [15:55<11:11,  1.09it/s] 58%|█████▊    | 1010/1740 [15:55<11:07,  1.09it/s] 58%|█████▊    | 1011/1740 [15:56<11:04,  1.10it/s] 58%|█████▊    | 1012/1740 [15:57<11:01,  1.10it/s] 58%|█████▊    | 1013/1740 [15:58<10:59,  1.10it/s] 58%|█████▊    | 1014/1740 [15:59<10:58,  1.10it/s] 58%|█████▊    | 1015/1740 [16:00<10:57,  1.10it/s] 58%|█████▊    | 1016/1740 [16:01<10:56,  1.10it/s] 58%|█████▊    | 1017/1740 [16:02<10:54,  1.10it/s] 59%|█████▊    | 1018/1740 [16:03<10:54,  1.10it/s] 59%|█████▊    | 1019/1740 [16:04<10:53,  1.10it/s] 59%|█████▊    | 1020/1740 [16:04<10:51,  1.10it/s] 59%|█████▊    | 1021/1740 [16:05<10:50,  1.10it/s] 59%|█████▊    | 1022/1740 [16:06<10:49,  1.10it/s] 59%|█████▉    | 1023/1740 [16:07<10:48,  1.11it/s] 59%|█████▉    | 1024/1740 [16:08<10:47,  1.11it/s] 59%|█████▉    | 1025/1740 [16:09<10:46,  1.11it/s] 59%|█████▉    | 1026/1740 [16:10<10:45,  1.11it/s] 59%|█████▉    | 1027/1740 [16:11<10:45,  1.11it/s] 59%|█████▉    | 1028/1740 [16:12<10:44,  1.11it/s] 59%|█████▉    | 1029/1740 [16:13<10:43,  1.11it/s] 59%|█████▉    | 1030/1740 [16:14<10:42,  1.11it/s] 59%|█████▉    | 1031/1740 [16:14<10:40,  1.11it/s] 59%|█████▉    | 1032/1740 [16:15<11:08,  1.06it/s] 59%|█████▉    | 1033/1740 [16:16<10:59,  1.07it/s] 59%|█████▉    | 1034/1740 [16:17<10:52,  1.08it/s] 59%|█████▉    | 1035/1740 [16:18<10:47,  1.09it/s] 60%|█████▉    | 1036/1740 [16:19<10:43,  1.09it/s] 60%|█████▉    | 1037/1740 [16:20<10:37,  1.10it/s] 60%|█████▉    | 1038/1740 [16:21<10:34,  1.11it/s] 60%|█████▉    | 1039/1740 [16:22<10:34,  1.11it/s] 60%|█████▉    | 1040/1740 [16:23<10:33,  1.11it/s] 60%|█████▉    | 1041/1740 [16:24<10:32,  1.11it/s] 60%|█████▉    | 1042/1740 [16:24<10:31,  1.11it/s] 60%|█████▉    | 1043/1740 [16:25<10:30,  1.11it/s] 60%|██████    | 1044/1740 [16:26<08:56,  1.30it/s]{'eval_loss': 7.402132987976074, 'eval_precision': 0.7773109243697479, 'eval_recall': 0.7170542635658915, 'eval_f1': 0.745967741935484, 'eval_accuracy': 0.9763007840342124, 'eval_runtime': 2.0847, 'eval_samples_per_second': 49.408, 'eval_steps_per_second': 1.919, 'epoch': 8.0}
{'loss': 11.9247, 'grad_norm': 17134.009765625, 'learning_rate': 3.8535297513561126e-05, 'epoch': 8.62}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.85it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.77it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.63it/s][A                                                   
                                             [A 60%|██████    | 1044/1740 [16:28<08:56,  1.30it/s]
100%|██████████| 4/4 [00:01<00:00,  2.63it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 60%|██████    | 1045/1740 [16:32<28:43,  2.48s/it] 60%|██████    | 1046/1740 [16:33<23:12,  2.01s/it] 60%|██████    | 1047/1740 [16:34<19:21,  1.68s/it] 60%|██████    | 1048/1740 [16:35<16:39,  1.44s/it] 60%|██████    | 1049/1740 [16:36<14:45,  1.28s/it] 60%|██████    | 1050/1740 [16:37<13:26,  1.17s/it] 60%|██████    | 1051/1740 [16:38<12:30,  1.09s/it] 60%|██████    | 1052/1740 [16:39<11:51,  1.03s/it] 61%|██████    | 1053/1740 [16:40<11:22,  1.01it/s] 61%|██████    | 1054/1740 [16:40<10:59,  1.04it/s] 61%|██████    | 1055/1740 [16:41<11:17,  1.01it/s] 61%|██████    | 1056/1740 [16:42<10:59,  1.04it/s] 61%|██████    | 1057/1740 [16:43<10:46,  1.06it/s] 61%|██████    | 1058/1740 [16:44<10:36,  1.07it/s] 61%|██████    | 1059/1740 [16:45<10:30,  1.08it/s] 61%|██████    | 1060/1740 [16:46<10:25,  1.09it/s] 61%|██████    | 1061/1740 [16:47<10:21,  1.09it/s] 61%|██████    | 1062/1740 [16:48<10:18,  1.10it/s] 61%|██████    | 1063/1740 [16:49<10:15,  1.10it/s] 61%|██████    | 1064/1740 [16:50<10:12,  1.10it/s] 61%|██████    | 1065/1740 [16:50<10:08,  1.11it/s] 61%|██████▏   | 1066/1740 [16:51<10:08,  1.11it/s] 61%|██████▏   | 1067/1740 [16:52<10:08,  1.11it/s] 61%|██████▏   | 1068/1740 [16:53<10:07,  1.11it/s] 61%|██████▏   | 1069/1740 [16:54<10:07,  1.10it/s] 61%|██████▏   | 1070/1740 [16:55<10:06,  1.10it/s] 62%|██████▏   | 1071/1740 [16:56<10:05,  1.10it/s] 62%|██████▏   | 1072/1740 [16:57<10:04,  1.10it/s] 62%|██████▏   | 1073/1740 [16:58<10:03,  1.10it/s] 62%|██████▏   | 1074/1740 [16:59<10:02,  1.11it/s] 62%|██████▏   | 1075/1740 [17:00<10:01,  1.11it/s] 62%|██████▏   | 1076/1740 [17:00<10:00,  1.11it/s] 62%|██████▏   | 1077/1740 [17:01<09:59,  1.11it/s] 62%|██████▏   | 1078/1740 [17:02<09:58,  1.11it/s] 62%|██████▏   | 1079/1740 [17:03<09:58,  1.10it/s] 62%|██████▏   | 1080/1740 [17:04<10:26,  1.05it/s] 62%|██████▏   | 1081/1740 [17:05<10:17,  1.07it/s] 62%|██████▏   | 1082/1740 [17:06<10:09,  1.08it/s] 62%|██████▏   | 1083/1740 [17:07<10:04,  1.09it/s] 62%|██████▏   | 1084/1740 [17:08<10:00,  1.09it/s] 62%|██████▏   | 1085/1740 [17:09<09:57,  1.10it/s] 62%|██████▏   | 1086/1740 [17:10<09:53,  1.10it/s] 62%|██████▏   | 1087/1740 [17:11<09:49,  1.11it/s] 63%|██████▎   | 1088/1740 [17:11<09:48,  1.11it/s] 63%|██████▎   | 1089/1740 [17:12<09:47,  1.11it/s] 63%|██████▎   | 1090/1740 [17:13<09:47,  1.11it/s] 63%|██████▎   | 1091/1740 [17:14<09:46,  1.11it/s] 63%|██████▎   | 1092/1740 [17:15<09:43,  1.11it/s] 63%|██████▎   | 1093/1740 [17:16<09:41,  1.11it/s] 63%|██████▎   | 1094/1740 [17:17<09:41,  1.11it/s] 63%|██████▎   | 1095/1740 [17:18<09:41,  1.11it/s] 63%|██████▎   | 1096/1740 [17:19<09:41,  1.11it/s] 63%|██████▎   | 1097/1740 [17:20<09:40,  1.11it/s] 63%|██████▎   | 1098/1740 [17:20<09:40,  1.11it/s] 63%|██████▎   | 1099/1740 [17:21<09:39,  1.11it/s] 63%|██████▎   | 1100/1740 [17:22<09:38,  1.11it/s] 63%|██████▎   | 1101/1740 [17:23<09:38,  1.11it/s] 63%|██████▎   | 1102/1740 [17:24<09:36,  1.11it/s] 63%|██████▎   | 1103/1740 [17:25<09:36,  1.10it/s] 63%|██████▎   | 1104/1740 [17:26<09:34,  1.11it/s] 64%|██████▎   | 1105/1740 [17:27<09:33,  1.11it/s] 64%|██████▎   | 1106/1740 [17:28<09:33,  1.11it/s] 64%|██████▎   | 1107/1740 [17:29<09:32,  1.11it/s] 64%|██████▎   | 1108/1740 [17:29<09:31,  1.11it/s] 64%|██████▎   | 1109/1740 [17:30<09:30,  1.11it/s] 64%|██████▍   | 1110/1740 [17:31<09:29,  1.11it/s] 64%|██████▍   | 1111/1740 [17:32<09:28,  1.11it/s] 64%|██████▍   | 1112/1740 [17:33<09:27,  1.11it/s] 64%|██████▍   | 1113/1740 [17:34<09:26,  1.11it/s] 64%|██████▍   | 1114/1740 [17:35<09:26,  1.11it/s] 64%|██████▍   | 1115/1740 [17:36<09:25,  1.11it/s] 64%|██████▍   | 1116/1740 [17:37<09:24,  1.11it/s] 64%|██████▍   | 1117/1740 [17:38<09:23,  1.10it/s] 64%|██████▍   | 1118/1740 [17:39<09:23,  1.10it/s] 64%|██████▍   | 1119/1740 [17:39<09:22,  1.10it/s] 64%|██████▍   | 1120/1740 [17:40<09:21,  1.10it/s] 64%|██████▍   | 1121/1740 [17:41<09:20,  1.10it/s] 64%|██████▍   | 1122/1740 [17:42<09:19,  1.11it/s] 65%|██████▍   | 1123/1740 [17:43<09:18,  1.11it/s] 65%|██████▍   | 1124/1740 [17:44<09:17,  1.11it/s] 65%|██████▍   | 1125/1740 [17:45<09:16,  1.11it/s] 65%|██████▍   | 1126/1740 [17:46<09:15,  1.10it/s] 65%|██████▍   | 1127/1740 [17:47<09:14,  1.11it/s] 65%|██████▍   | 1128/1740 [17:48<09:13,  1.11it/s] 65%|██████▍   | 1129/1740 [17:48<09:12,  1.11it/s] 65%|██████▍   | 1130/1740 [17:49<09:11,  1.11it/s] 65%|██████▌   | 1131/1740 [17:50<09:11,  1.10it/s] 65%|██████▌   | 1132/1740 [17:51<09:37,  1.05it/s] 65%|██████▌   | 1133/1740 [17:52<09:28,  1.07it/s] 65%|██████▌   | 1134/1740 [17:53<09:21,  1.08it/s] 65%|██████▌   | 1135/1740 [17:54<09:16,  1.09it/s] 65%|██████▌   | 1136/1740 [17:55<09:13,  1.09it/s] 65%|██████▌   | 1137/1740 [17:56<09:10,  1.10it/s] 65%|██████▌   | 1138/1740 [17:57<09:07,  1.10it/s] 65%|██████▌   | 1139/1740 [17:58<09:05,  1.10it/s] 66%|██████▌   | 1140/1740 [17:59<09:04,  1.10it/s] 66%|██████▌   | 1141/1740 [18:00<09:02,  1.10it/s] 66%|██████▌   | 1142/1740 [18:00<09:01,  1.10it/s] 66%|██████▌   | 1143/1740 [18:01<09:00,  1.11it/s] 66%|██████▌   | 1144/1740 [18:02<08:58,  1.11it/s] 66%|██████▌   | 1145/1740 [18:03<08:58,  1.11it/s] 66%|██████▌   | 1146/1740 [18:04<08:57,  1.11it/s] 66%|██████▌   | 1147/1740 [18:05<08:56,  1.11it/s] 66%|██████▌   | 1148/1740 [18:06<08:55,  1.11it/s] 66%|██████▌   | 1149/1740 [18:07<08:53,  1.11it/s] 66%|██████▌   | 1150/1740 [18:08<08:52,  1.11it/s] 66%|██████▌   | 1151/1740 [18:09<08:52,  1.11it/s] 66%|██████▌   | 1152/1740 [18:09<08:51,  1.11it/s] 66%|██████▋   | 1153/1740 [18:10<08:50,  1.11it/s] 66%|██████▋   | 1154/1740 [18:11<08:50,  1.11it/s] 66%|██████▋   | 1155/1740 [18:12<08:49,  1.11it/s] 66%|██████▋   | 1156/1740 [18:13<08:48,  1.11it/s] 66%|██████▋   | 1157/1740 [18:14<08:47,  1.11it/s] 67%|██████▋   | 1158/1740 [18:15<08:44,  1.11it/s] 67%|██████▋   | 1159/1740 [18:16<08:42,  1.11it/s] 67%|██████▋   | 1160/1740 [18:16<07:24,  1.30it/s]{'eval_loss': 5.72153902053833, 'eval_precision': 0.7955390334572491, 'eval_recall': 0.8294573643410853, 'eval_f1': 0.8121442125237192, 'eval_accuracy': 0.9816464718460441, 'eval_runtime': 2.0823, 'eval_samples_per_second': 49.464, 'eval_steps_per_second': 1.921, 'epoch': 9.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.84it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.77it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.65it/s][A                                                   
                                             [A 67%|██████▋   | 1160/1740 [18:18<07:24,  1.30it/s]
100%|██████████| 4/4 [00:01<00:00,  2.65it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 67%|██████▋   | 1161/1740 [18:22<22:50,  2.37s/it] 67%|██████▋   | 1162/1740 [18:23<18:34,  1.93s/it] 67%|██████▋   | 1163/1740 [18:24<15:35,  1.62s/it] 67%|██████▋   | 1164/1740 [18:25<13:30,  1.41s/it] 67%|██████▋   | 1165/1740 [18:26<12:01,  1.26s/it] 67%|██████▋   | 1166/1740 [18:27<11:00,  1.15s/it] 67%|██████▋   | 1167/1740 [18:28<10:17,  1.08s/it] 67%|██████▋   | 1168/1740 [18:29<10:11,  1.07s/it] 67%|██████▋   | 1169/1740 [18:30<09:42,  1.02s/it] 67%|██████▋   | 1170/1740 [18:31<09:21,  1.01it/s] 67%|██████▋   | 1171/1740 [18:32<09:06,  1.04it/s] 67%|██████▋   | 1172/1740 [18:32<08:55,  1.06it/s] 67%|██████▋   | 1173/1740 [18:33<08:48,  1.07it/s] 67%|██████▋   | 1174/1740 [18:34<08:42,  1.08it/s] 68%|██████▊   | 1175/1740 [18:35<08:38,  1.09it/s] 68%|██████▊   | 1176/1740 [18:36<08:35,  1.09it/s] 68%|██████▊   | 1177/1740 [18:37<08:32,  1.10it/s] 68%|██████▊   | 1178/1740 [18:38<08:30,  1.10it/s] 68%|██████▊   | 1179/1740 [18:39<08:29,  1.10it/s] 68%|██████▊   | 1180/1740 [18:40<08:26,  1.11it/s] 68%|██████▊   | 1181/1740 [18:41<08:23,  1.11it/s] 68%|██████▊   | 1182/1740 [18:41<08:23,  1.11it/s] 68%|██████▊   | 1183/1740 [18:42<08:23,  1.11it/s] 68%|██████▊   | 1184/1740 [18:43<08:22,  1.11it/s] 68%|██████▊   | 1185/1740 [18:44<08:21,  1.11it/s] 68%|██████▊   | 1186/1740 [18:45<08:20,  1.11it/s] 68%|██████▊   | 1187/1740 [18:46<08:19,  1.11it/s] 68%|██████▊   | 1188/1740 [18:47<08:18,  1.11it/s] 68%|██████▊   | 1189/1740 [18:48<08:17,  1.11it/s] 68%|██████▊   | 1190/1740 [18:49<08:17,  1.11it/s] 68%|██████▊   | 1191/1740 [18:50<08:16,  1.11it/s] 69%|██████▊   | 1192/1740 [18:50<08:15,  1.11it/s] 69%|██████▊   | 1193/1740 [18:51<08:14,  1.11it/s] 69%|██████▊   | 1194/1740 [18:52<08:13,  1.11it/s] 69%|██████▊   | 1195/1740 [18:53<08:12,  1.11it/s] 69%|██████▊   | 1196/1740 [18:54<08:11,  1.11it/s] 69%|██████▉   | 1197/1740 [18:55<08:11,  1.10it/s] 69%|██████▉   | 1198/1740 [18:56<08:10,  1.10it/s] 69%|██████▉   | 1199/1740 [18:57<08:09,  1.10it/s] 69%|██████▉   | 1200/1740 [18:58<08:08,  1.11it/s] 69%|██████▉   | 1201/1740 [18:59<08:07,  1.10it/s] 69%|██████▉   | 1202/1740 [19:00<08:06,  1.11it/s] 69%|██████▉   | 1203/1740 [19:00<08:03,  1.11it/s] 69%|██████▉   | 1204/1740 [19:01<08:03,  1.11it/s] 69%|██████▉   | 1205/1740 [19:02<08:02,  1.11it/s] 69%|██████▉   | 1206/1740 [19:03<08:02,  1.11it/s] 69%|██████▉   | 1207/1740 [19:04<08:01,  1.11it/s] 69%|██████▉   | 1208/1740 [19:05<08:24,  1.05it/s] 69%|██████▉   | 1209/1740 [19:06<08:17,  1.07it/s] 70%|██████▉   | 1210/1740 [19:07<08:11,  1.08it/s] 70%|██████▉   | 1211/1740 [19:08<08:06,  1.09it/s] 70%|██████▉   | 1212/1740 [19:09<08:03,  1.09it/s] 70%|██████▉   | 1213/1740 [19:10<08:00,  1.10it/s] 70%|██████▉   | 1214/1740 [19:11<07:56,  1.10it/s] 70%|██████▉   | 1215/1740 [19:11<07:55,  1.10it/s] 70%|██████▉   | 1216/1740 [19:12<07:54,  1.10it/s] 70%|██████▉   | 1217/1740 [19:13<07:53,  1.10it/s] 70%|███████   | 1218/1740 [19:14<07:52,  1.10it/s] 70%|███████   | 1219/1740 [19:15<07:49,  1.11it/s] 70%|███████   | 1220/1740 [19:16<07:48,  1.11it/s] 70%|███████   | 1221/1740 [19:17<07:48,  1.11it/s] 70%|███████   | 1222/1740 [19:18<07:47,  1.11it/s] 70%|███████   | 1223/1740 [19:19<07:47,  1.11it/s] 70%|███████   | 1224/1740 [19:20<07:46,  1.11it/s] 70%|███████   | 1225/1740 [19:20<07:43,  1.11it/s] 70%|███████   | 1226/1740 [19:21<07:43,  1.11it/s] 71%|███████   | 1227/1740 [19:22<07:42,  1.11it/s] 71%|███████   | 1228/1740 [19:23<07:42,  1.11it/s] 71%|███████   | 1229/1740 [19:24<07:41,  1.11it/s] 71%|███████   | 1230/1740 [19:25<07:40,  1.11it/s] 71%|███████   | 1231/1740 [19:26<07:40,  1.11it/s] 71%|███████   | 1232/1740 [19:27<07:39,  1.11it/s] 71%|███████   | 1233/1740 [19:28<07:38,  1.11it/s] 71%|███████   | 1234/1740 [19:29<07:37,  1.11it/s] 71%|███████   | 1235/1740 [19:29<07:36,  1.11it/s] 71%|███████   | 1236/1740 [19:30<07:35,  1.11it/s] 71%|███████   | 1237/1740 [19:31<07:35,  1.10it/s] 71%|███████   | 1238/1740 [19:32<07:34,  1.11it/s] 71%|███████   | 1239/1740 [19:33<07:56,  1.05it/s] 71%|███████▏  | 1240/1740 [19:34<07:48,  1.07it/s] 71%|███████▏  | 1241/1740 [19:35<07:42,  1.08it/s] 71%|███████▏  | 1242/1740 [19:36<07:38,  1.09it/s] 71%|███████▏  | 1243/1740 [19:37<07:35,  1.09it/s] 71%|███████▏  | 1244/1740 [19:38<07:32,  1.10it/s] 72%|███████▏  | 1245/1740 [19:39<07:30,  1.10it/s] 72%|███████▏  | 1246/1740 [19:40<07:28,  1.10it/s] 72%|███████▏  | 1247/1740 [19:40<07:27,  1.10it/s] 72%|███████▏  | 1248/1740 [19:41<07:26,  1.10it/s] 72%|███████▏  | 1249/1740 [19:42<07:25,  1.10it/s] 72%|███████▏  | 1250/1740 [19:43<07:23,  1.10it/s] 72%|███████▏  | 1251/1740 [19:44<07:22,  1.10it/s] 72%|███████▏  | 1252/1740 [19:45<07:21,  1.10it/s] 72%|███████▏  | 1253/1740 [19:46<07:21,  1.10it/s] 72%|███████▏  | 1254/1740 [19:47<07:20,  1.10it/s] 72%|███████▏  | 1255/1740 [19:48<07:19,  1.10it/s] 72%|███████▏  | 1256/1740 [19:49<07:17,  1.11it/s] 72%|███████▏  | 1257/1740 [19:50<07:16,  1.11it/s] 72%|███████▏  | 1258/1740 [19:50<07:13,  1.11it/s] 72%|███████▏  | 1259/1740 [19:51<07:13,  1.11it/s] 72%|███████▏  | 1260/1740 [19:52<07:12,  1.11it/s] 72%|███████▏  | 1261/1740 [19:53<07:12,  1.11it/s] 73%|███████▎  | 1262/1740 [19:54<07:12,  1.11it/s] 73%|███████▎  | 1263/1740 [19:55<07:11,  1.11it/s] 73%|███████▎  | 1264/1740 [19:56<07:10,  1.11it/s] 73%|███████▎  | 1265/1740 [19:57<07:30,  1.05it/s] 73%|███████▎  | 1266/1740 [19:58<07:23,  1.07it/s] 73%|███████▎  | 1267/1740 [19:59<07:18,  1.08it/s] 73%|███████▎  | 1268/1740 [20:00<07:13,  1.09it/s] 73%|███████▎  | 1269/1740 [20:01<07:08,  1.10it/s] 73%|███████▎  | 1270/1740 [20:01<07:07,  1.10it/s] 73%|███████▎  | 1271/1740 [20:02<07:05,  1.10it/s] 73%|███████▎  | 1272/1740 [20:03<07:04,  1.10it/s] 73%|███████▎  | 1273/1740 [20:04<07:03,  1.10it/s] 73%|███████▎  | 1274/1740 [20:05<07:02,  1.10it/s] 73%|███████▎  | 1275/1740 [20:06<07:01,  1.10it/s] 73%|███████▎  | 1276/1740 [20:06<05:58,  1.29it/s]{'eval_loss': 5.329878807067871, 'eval_precision': 0.7655172413793103, 'eval_recall': 0.8604651162790697, 'eval_f1': 0.8102189781021898, 'eval_accuracy': 0.9818246614397719, 'eval_runtime': 2.0851, 'eval_samples_per_second': 49.397, 'eval_steps_per_second': 1.918, 'epoch': 10.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.84it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.79it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A                                                   
                                             [A 73%|███████▎  | 1276/1740 [20:09<05:58,  1.29it/s]
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 73%|███████▎  | 1277/1740 [20:13<18:23,  2.38s/it] 73%|███████▎  | 1278/1740 [20:13<14:56,  1.94s/it] 74%|███████▎  | 1279/1740 [20:14<12:31,  1.63s/it] 74%|███████▎  | 1280/1740 [20:15<10:47,  1.41s/it] 74%|███████▎  | 1281/1740 [20:16<09:36,  1.26s/it] 74%|███████▎  | 1282/1740 [20:17<08:46,  1.15s/it] 74%|███████▎  | 1283/1740 [20:18<08:11,  1.08s/it] 74%|███████▍  | 1284/1740 [20:19<07:47,  1.02s/it] 74%|███████▍  | 1285/1740 [20:20<07:29,  1.01it/s] 74%|███████▍  | 1286/1740 [20:21<07:17,  1.04it/s] 74%|███████▍  | 1287/1740 [20:22<07:08,  1.06it/s] 74%|███████▍  | 1288/1740 [20:23<07:21,  1.02it/s] 74%|███████▍  | 1289/1740 [20:24<07:11,  1.05it/s] 74%|███████▍  | 1290/1740 [20:24<07:03,  1.06it/s] 74%|███████▍  | 1291/1740 [20:25<06:57,  1.07it/s] 74%|███████▍  | 1292/1740 [20:26<06:53,  1.08it/s] 74%|███████▍  | 1293/1740 [20:27<06:50,  1.09it/s] 74%|███████▍  | 1294/1740 [20:28<06:47,  1.09it/s] 74%|███████▍  | 1295/1740 [20:29<06:45,  1.10it/s] 74%|███████▍  | 1296/1740 [20:30<06:43,  1.10it/s] 75%|███████▍  | 1297/1740 [20:31<06:42,  1.10it/s] 75%|███████▍  | 1298/1740 [20:32<06:41,  1.10it/s] 75%|███████▍  | 1299/1740 [20:33<06:39,  1.10it/s] 75%|███████▍  | 1300/1740 [20:33<06:38,  1.10it/s] 75%|███████▍  | 1301/1740 [20:34<06:37,  1.10it/s] 75%|███████▍  | 1302/1740 [20:35<06:36,  1.10it/s] 75%|███████▍  | 1303/1740 [20:36<06:35,  1.10it/s] 75%|███████▍  | 1304/1740 [20:37<06:34,  1.10it/s] 75%|███████▌  | 1305/1740 [20:38<06:33,  1.10it/s] 75%|███████▌  | 1306/1740 [20:39<06:32,  1.10it/s] 75%|███████▌  | 1307/1740 [20:40<06:31,  1.11it/s] 75%|███████▌  | 1308/1740 [20:41<06:29,  1.11it/s] 75%|███████▌  | 1309/1740 [20:42<06:29,  1.11it/s] 75%|███████▌  | 1310/1740 [20:43<06:28,  1.11it/s] 75%|███████▌  | 1311/1740 [20:43<06:27,  1.11it/s] 75%|███████▌  | 1312/1740 [20:44<06:26,  1.11it/s] 75%|███████▌  | 1313/1740 [20:45<06:45,  1.05it/s] 76%|███████▌  | 1314/1740 [20:46<06:39,  1.07it/s] 76%|███████▌  | 1315/1740 [20:47<06:34,  1.08it/s] 76%|███████▌  | 1316/1740 [20:48<06:30,  1.09it/s] 76%|███████▌  | 1317/1740 [20:49<06:27,  1.09it/s] 76%|███████▌  | 1318/1740 [20:50<06:25,  1.10it/s] 76%|███████▌  | 1319/1740 [20:51<06:23,  1.10it/s] 76%|███████▌  | 1320/1740 [20:52<06:21,  1.10it/s] 76%|███████▌  | 1321/1740 [20:53<06:20,  1.10it/s] 76%|███████▌  | 1322/1740 [20:54<06:18,  1.10it/s] 76%|███████▌  | 1323/1740 [20:54<06:17,  1.10it/s] 76%|███████▌  | 1324/1740 [20:55<06:17,  1.10it/s] 76%|███████▌  | 1325/1740 [20:56<06:16,  1.10it/s] 76%|███████▌  | 1326/1740 [20:57<06:15,  1.10it/s] 76%|███████▋  | 1327/1740 [20:58<06:14,  1.10it/s] 76%|███████▋  | 1328/1740 [20:59<06:13,  1.10it/s] 76%|███████▋  | 1329/1740 [21:00<06:12,  1.10it/s] 76%|███████▋  | 1330/1740 [21:01<06:11,  1.10it/s] 76%|███████▋  | 1331/1740 [21:02<06:10,  1.10it/s] 77%|███████▋  | 1332/1740 [21:03<06:09,  1.10it/s] 77%|███████▋  | 1333/1740 [21:04<06:08,  1.10it/s] 77%|███████▋  | 1334/1740 [21:04<06:07,  1.10it/s] 77%|███████▋  | 1335/1740 [21:05<06:06,  1.10it/s] 77%|███████▋  | 1336/1740 [21:06<06:05,  1.10it/s] 77%|███████▋  | 1337/1740 [21:07<06:04,  1.10it/s] 77%|███████▋  | 1338/1740 [21:08<06:03,  1.10it/s] 77%|███████▋  | 1339/1740 [21:09<06:03,  1.10it/s] 77%|███████▋  | 1340/1740 [21:10<06:02,  1.10it/s] 77%|███████▋  | 1341/1740 [21:11<06:01,  1.10it/s] 77%|███████▋  | 1342/1740 [21:12<06:00,  1.10it/s] 77%|███████▋  | 1343/1740 [21:13<05:59,  1.10it/s] 77%|███████▋  | 1344/1740 [21:13<05:58,  1.10it/s] 77%|███████▋  | 1345/1740 [21:14<05:58,  1.10it/s] 77%|███████▋  | 1346/1740 [21:15<05:55,  1.11it/s] 77%|███████▋  | 1347/1740 [21:16<05:54,  1.11it/s] 77%|███████▋  | 1348/1740 [21:17<05:53,  1.11it/s] 78%|███████▊  | 1349/1740 [21:18<05:53,  1.11it/s] 78%|███████▊  | 1350/1740 [21:19<05:52,  1.11it/s] 78%|███████▊  | 1351/1740 [21:20<05:51,  1.11it/s] 78%|███████▊  | 1352/1740 [21:21<05:50,  1.11it/s] 78%|███████▊  | 1353/1740 [21:22<05:49,  1.11it/s] 78%|███████▊  | 1354/1740 [21:22<05:49,  1.11it/s] 78%|███████▊  | 1355/1740 [21:23<05:48,  1.11it/s] 78%|███████▊  | 1356/1740 [21:24<05:47,  1.11it/s] 78%|███████▊  | 1357/1740 [21:25<05:46,  1.10it/s] 78%|███████▊  | 1358/1740 [21:26<05:45,  1.10it/s] 78%|███████▊  | 1359/1740 [21:27<05:44,  1.10it/s] 78%|███████▊  | 1360/1740 [21:28<05:44,  1.10it/s] 78%|███████▊  | 1361/1740 [21:29<05:43,  1.10it/s] 78%|███████▊  | 1362/1740 [21:30<05:42,  1.10it/s] 78%|███████▊  | 1363/1740 [21:31<05:41,  1.10it/s] 78%|███████▊  | 1364/1740 [21:32<05:40,  1.10it/s] 78%|███████▊  | 1365/1740 [21:33<05:56,  1.05it/s] 79%|███████▊  | 1366/1740 [21:34<05:50,  1.07it/s] 79%|███████▊  | 1367/1740 [21:34<05:46,  1.08it/s] 79%|███████▊  | 1368/1740 [21:35<05:42,  1.09it/s] 79%|███████▊  | 1369/1740 [21:36<05:40,  1.09it/s] 79%|███████▊  | 1370/1740 [21:37<05:38,  1.09it/s] 79%|███████▉  | 1371/1740 [21:38<05:36,  1.10it/s] 79%|███████▉  | 1372/1740 [21:39<05:34,  1.10it/s] 79%|███████▉  | 1373/1740 [21:40<05:33,  1.10it/s] 79%|███████▉  | 1374/1740 [21:41<05:32,  1.10it/s] 79%|███████▉  | 1375/1740 [21:42<05:30,  1.10it/s] 79%|███████▉  | 1376/1740 [21:43<05:29,  1.10it/s] 79%|███████▉  | 1377/1740 [21:43<05:29,  1.10it/s] 79%|███████▉  | 1378/1740 [21:44<05:28,  1.10it/s] 79%|███████▉  | 1379/1740 [21:45<05:27,  1.10it/s] 79%|███████▉  | 1380/1740 [21:46<05:26,  1.10it/s] 79%|███████▉  | 1381/1740 [21:47<05:25,  1.10it/s] 79%|███████▉  | 1382/1740 [21:48<05:24,  1.10it/s] 79%|███████▉  | 1383/1740 [21:49<05:23,  1.10it/s] 80%|███████▉  | 1384/1740 [21:50<05:22,  1.10it/s] 80%|███████▉  | 1385/1740 [21:51<05:21,  1.10it/s] 80%|███████▉  | 1386/1740 [21:52<05:20,  1.10it/s] 80%|███████▉  | 1387/1740 [21:53<05:19,  1.10it/s] 80%|███████▉  | 1388/1740 [21:53<05:18,  1.10it/s] 80%|███████▉  | 1389/1740 [21:54<05:17,  1.10it/s] 80%|███████▉  | 1390/1740 [21:55<05:16,  1.10it/s] 80%|███████▉  | 1391/1740 [21:56<05:16,  1.10it/s] 80%|████████  | 1392/1740 [21:57<04:28,  1.30it/s]{'eval_loss': 4.721287250518799, 'eval_precision': 0.8286852589641435, 'eval_recall': 0.8062015503875969, 'eval_f1': 0.8172888015717092, 'eval_accuracy': 0.9836065573770492, 'eval_runtime': 2.106, 'eval_samples_per_second': 48.907, 'eval_steps_per_second': 1.899, 'epoch': 11.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.85it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.74it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.57it/s][A                                                   
                                             [A 80%|████████  | 1392/1740 [21:59<04:28,  1.30it/s]
100%|██████████| 4/4 [00:01<00:00,  2.57it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 80%|████████  | 1393/1740 [22:03<13:40,  2.37s/it] 80%|████████  | 1394/1740 [22:04<11:06,  1.93s/it] 80%|████████  | 1395/1740 [22:05<09:19,  1.62s/it] 80%|████████  | 1396/1740 [22:05<08:03,  1.41s/it] 80%|████████  | 1397/1740 [22:06<07:10,  1.26s/it] 80%|████████  | 1398/1740 [22:07<06:33,  1.15s/it] 80%|████████  | 1399/1740 [22:08<06:07,  1.08s/it] 80%|████████  | 1400/1740 [22:09<05:48,  1.03s/it] 81%|████████  | 1401/1740 [22:10<05:49,  1.03s/it] 81%|████████  | 1402/1740 [22:11<05:35,  1.01it/s] 81%|████████  | 1403/1740 [22:12<05:25,  1.03it/s] 81%|████████  | 1404/1740 [22:13<05:18,  1.06it/s] 81%|████████  | 1405/1740 [22:14<05:13,  1.07it/s] 81%|████████  | 1406/1740 [22:15<05:09,  1.08it/s] 81%|████████  | 1407/1740 [22:16<05:04,  1.09it/s] 81%|████████  | 1408/1740 [22:16<05:02,  1.10it/s] 81%|████████  | 1409/1740 [22:17<05:01,  1.10it/s] 81%|████████  | 1410/1740 [22:18<04:59,  1.10it/s] 81%|████████  | 1411/1740 [22:19<04:58,  1.10it/s] 81%|████████  | 1412/1740 [22:20<04:56,  1.11it/s] 81%|████████  | 1413/1740 [22:21<04:55,  1.11it/s] 81%|████████▏ | 1414/1740 [22:22<04:54,  1.11it/s] 81%|████████▏ | 1415/1740 [22:23<04:53,  1.11it/s] 81%|████████▏ | 1416/1740 [22:24<04:53,  1.10it/s] 81%|████████▏ | 1417/1740 [22:25<04:52,  1.10it/s] 81%|████████▏ | 1418/1740 [22:25<04:51,  1.10it/s] 82%|████████▏ | 1419/1740 [22:26<04:50,  1.10it/s] 82%|████████▏ | 1420/1740 [22:27<04:49,  1.10it/s] 82%|████████▏ | 1421/1740 [22:28<04:49,  1.10it/s] 82%|████████▏ | 1422/1740 [22:29<04:48,  1.10it/s] 82%|████████▏ | 1423/1740 [22:30<04:46,  1.11it/s] 82%|████████▏ | 1424/1740 [22:31<04:44,  1.11it/s] 82%|████████▏ | 1425/1740 [22:32<04:44,  1.11it/s] 82%|████████▏ | 1426/1740 [22:33<04:43,  1.11it/s] 82%|████████▏ | 1427/1740 [22:34<04:43,  1.11it/s] 82%|████████▏ | 1428/1740 [22:34<04:42,  1.11it/s] 82%|████████▏ | 1429/1740 [22:35<04:41,  1.10it/s] 82%|████████▏ | 1430/1740 [22:36<04:40,  1.10it/s] 82%|████████▏ | 1431/1740 [22:37<04:39,  1.10it/s] 82%|████████▏ | 1432/1740 [22:38<04:38,  1.10it/s] 82%|████████▏ | 1433/1740 [22:39<04:38,  1.10it/s] 82%|████████▏ | 1434/1740 [22:40<04:36,  1.11it/s] 82%|████████▏ | 1435/1740 [22:41<04:34,  1.11it/s] 83%|████████▎ | 1436/1740 [22:42<04:34,  1.11it/s] 83%|████████▎ | 1437/1740 [22:43<04:34,  1.11it/s] 83%|████████▎ | 1438/1740 [22:44<04:33,  1.11it/s] 83%|████████▎ | 1439/1740 [22:44<04:32,  1.10it/s] 83%|████████▎ | 1440/1740 [22:45<04:31,  1.10it/s] 83%|████████▎ | 1441/1740 [22:46<04:44,  1.05it/s] 83%|████████▎ | 1442/1740 [22:47<04:39,  1.07it/s] 83%|████████▎ | 1443/1740 [22:48<04:35,  1.08it/s] 83%|████████▎ | 1444/1740 [22:49<04:32,  1.09it/s] 83%|████████▎ | 1445/1740 [22:50<04:29,  1.10it/s] 83%|████████▎ | 1446/1740 [22:51<04:27,  1.10it/s] 83%|████████▎ | 1447/1740 [22:52<04:26,  1.10it/s] 83%|████████▎ | 1448/1740 [22:53<04:25,  1.10it/s] 83%|████████▎ | 1449/1740 [22:54<04:23,  1.10it/s] 83%|████████▎ | 1450/1740 [22:55<04:22,  1.10it/s] 83%|████████▎ | 1451/1740 [22:55<04:22,  1.10it/s] 83%|████████▎ | 1452/1740 [22:56<04:21,  1.10it/s] 84%|████████▎ | 1453/1740 [22:57<04:20,  1.10it/s] 84%|████████▎ | 1454/1740 [22:58<04:19,  1.10it/s] 84%|████████▎ | 1455/1740 [22:59<04:18,  1.10it/s] 84%|████████▎ | 1456/1740 [23:00<04:17,  1.10it/s] 84%|████████▎ | 1457/1740 [23:01<04:16,  1.10it/s] 84%|████████▍ | 1458/1740 [23:02<04:15,  1.10it/s] 84%|████████▍ | 1459/1740 [23:03<04:14,  1.10it/s] 84%|████████▍ | 1460/1740 [23:04<04:13,  1.10it/s] 84%|████████▍ | 1461/1740 [23:05<04:12,  1.10it/s] 84%|████████▍ | 1462/1740 [23:05<04:11,  1.10it/s] 84%|████████▍ | 1463/1740 [23:06<04:10,  1.10it/s] 84%|████████▍ | 1464/1740 [23:07<04:10,  1.10it/s] 84%|████████▍ | 1465/1740 [23:08<04:09,  1.10it/s] 84%|████████▍ | 1466/1740 [23:09<04:08,  1.10it/s] 84%|████████▍ | 1467/1740 [23:10<04:06,  1.11it/s] 84%|████████▍ | 1468/1740 [23:11<04:05,  1.11it/s] 84%|████████▍ | 1469/1740 [23:12<04:04,  1.11it/s] 84%|████████▍ | 1470/1740 [23:13<04:03,  1.11it/s] 85%|████████▍ | 1471/1740 [23:14<04:03,  1.11it/s] 85%|████████▍ | 1472/1740 [23:15<04:14,  1.05it/s] 85%|████████▍ | 1473/1740 [23:15<04:08,  1.07it/s] 85%|████████▍ | 1474/1740 [23:16<04:05,  1.08it/s] 85%|████████▍ | 1475/1740 [23:17<04:03,  1.09it/s] 85%|████████▍ | 1476/1740 [23:18<04:01,  1.09it/s] 85%|████████▍ | 1477/1740 [23:19<04:00,  1.10it/s] 85%|████████▍ | 1478/1740 [23:20<03:58,  1.10it/s] 85%|████████▌ | 1479/1740 [23:21<03:57,  1.10it/s] 85%|████████▌ | 1480/1740 [23:22<03:56,  1.10it/s] 85%|████████▌ | 1481/1740 [23:23<03:55,  1.10it/s] 85%|████████▌ | 1482/1740 [23:24<03:54,  1.10it/s] 85%|████████▌ | 1483/1740 [23:25<03:53,  1.10it/s] 85%|████████▌ | 1484/1740 [23:25<03:52,  1.10it/s] 85%|████████▌ | 1485/1740 [23:26<03:51,  1.10it/s] 85%|████████▌ | 1486/1740 [23:27<03:50,  1.10it/s] 85%|████████▌ | 1487/1740 [23:28<03:49,  1.10it/s] 86%|████████▌ | 1488/1740 [23:29<03:48,  1.10it/s] 86%|████████▌ | 1489/1740 [23:30<03:46,  1.11it/s] 86%|████████▌ | 1490/1740 [23:31<03:45,  1.11it/s] 86%|████████▌ | 1491/1740 [23:32<03:44,  1.11it/s] 86%|████████▌ | 1492/1740 [23:33<03:44,  1.11it/s] 86%|████████▌ | 1493/1740 [23:34<03:43,  1.11it/s] 86%|████████▌ | 1494/1740 [23:35<03:42,  1.11it/s] 86%|████████▌ | 1495/1740 [23:35<03:41,  1.10it/s] 86%|████████▌ | 1496/1740 [23:36<03:40,  1.10it/s] 86%|████████▌ | 1497/1740 [23:37<03:39,  1.10it/s] 86%|████████▌ | 1498/1740 [23:38<03:49,  1.05it/s] 86%|████████▌ | 1499/1740 [23:39<03:45,  1.07it/s] 86%|████████▌ | 1500/1740 [23:40<03:41,  1.08it/s]                                                    86%|████████▌ | 1500/1740 [23:40<03:41,  1.08it/s] 86%|████████▋ | 1501/1740 [23:41<03:39,  1.09it/s] 86%|████████▋ | 1502/1740 [23:42<03:37,  1.09it/s] 86%|████████▋ | 1503/1740 [23:43<03:35,  1.10it/s] 86%|████████▋ | 1504/1740 [23:44<03:34,  1.10it/s] 86%|████████▋ | 1505/1740 [23:45<03:33,  1.10it/s] 87%|████████▋ | 1506/1740 [23:46<03:32,  1.10it/s] 87%|████████▋ | 1507/1740 [23:46<03:31,  1.10it/s] 87%|████████▋ | 1508/1740 [23:47<02:59,  1.29it/s]{'eval_loss': 4.7837066650390625, 'eval_precision': 0.8007246376811594, 'eval_recall': 0.8565891472868217, 'eval_f1': 0.8277153558052435, 'eval_accuracy': 0.9834283677833214, 'eval_runtime': 2.1079, 'eval_samples_per_second': 48.863, 'eval_steps_per_second': 1.898, 'epoch': 12.0}
{'loss': 9.9804, 'grad_norm': 284287.34375, 'learning_rate': 1.2533072470672377e-05, 'epoch': 12.94}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.82it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.77it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.57it/s][A                                                   
                                             [A 87%|████████▋ | 1508/1740 [23:49<02:59,  1.29it/s]
100%|██████████| 4/4 [00:01<00:00,  2.57it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 87%|████████▋ | 1509/1740 [23:53<09:27,  2.46s/it] 87%|████████▋ | 1510/1740 [23:54<07:37,  1.99s/it] 87%|████████▋ | 1511/1740 [23:55<06:21,  1.66s/it] 87%|████████▋ | 1512/1740 [23:56<05:27,  1.44s/it] 87%|████████▋ | 1513/1740 [23:57<04:50,  1.28s/it] 87%|████████▋ | 1514/1740 [23:58<04:23,  1.17s/it] 87%|████████▋ | 1515/1740 [23:59<04:04,  1.09s/it] 87%|████████▋ | 1516/1740 [24:00<03:51,  1.03s/it] 87%|████████▋ | 1517/1740 [24:00<03:40,  1.01it/s] 87%|████████▋ | 1518/1740 [24:01<03:34,  1.04it/s] 87%|████████▋ | 1519/1740 [24:02<03:29,  1.06it/s] 87%|████████▋ | 1520/1740 [24:03<03:25,  1.07it/s] 87%|████████▋ | 1521/1740 [24:04<03:22,  1.08it/s] 87%|████████▋ | 1522/1740 [24:05<03:30,  1.04it/s] 88%|████████▊ | 1523/1740 [24:06<03:25,  1.06it/s] 88%|████████▊ | 1524/1740 [24:07<03:21,  1.07it/s] 88%|████████▊ | 1525/1740 [24:08<03:19,  1.08it/s] 88%|████████▊ | 1526/1740 [24:09<03:16,  1.09it/s] 88%|████████▊ | 1527/1740 [24:10<03:15,  1.09it/s] 88%|████████▊ | 1528/1740 [24:11<03:13,  1.10it/s] 88%|████████▊ | 1529/1740 [24:12<03:12,  1.10it/s] 88%|████████▊ | 1530/1740 [24:12<03:10,  1.10it/s] 88%|████████▊ | 1531/1740 [24:13<03:09,  1.10it/s] 88%|████████▊ | 1532/1740 [24:14<03:08,  1.10it/s] 88%|████████▊ | 1533/1740 [24:15<03:06,  1.11it/s] 88%|████████▊ | 1534/1740 [24:16<03:05,  1.11it/s] 88%|████████▊ | 1535/1740 [24:17<03:05,  1.11it/s] 88%|████████▊ | 1536/1740 [24:18<03:04,  1.11it/s] 88%|████████▊ | 1537/1740 [24:19<03:03,  1.11it/s] 88%|████████▊ | 1538/1740 [24:20<03:02,  1.11it/s] 88%|████████▊ | 1539/1740 [24:21<03:01,  1.11it/s] 89%|████████▊ | 1540/1740 [24:21<03:00,  1.11it/s] 89%|████████▊ | 1541/1740 [24:22<02:59,  1.11it/s] 89%|████████▊ | 1542/1740 [24:23<02:59,  1.11it/s] 89%|████████▊ | 1543/1740 [24:24<02:58,  1.10it/s] 89%|████████▊ | 1544/1740 [24:25<02:57,  1.10it/s] 89%|████████▉ | 1545/1740 [24:26<02:56,  1.10it/s] 89%|████████▉ | 1546/1740 [24:27<02:55,  1.10it/s] 89%|████████▉ | 1547/1740 [24:28<02:54,  1.10it/s] 89%|████████▉ | 1548/1740 [24:29<02:54,  1.10it/s] 89%|████████▉ | 1549/1740 [24:30<02:52,  1.11it/s] 89%|████████▉ | 1550/1740 [24:30<02:51,  1.11it/s] 89%|████████▉ | 1551/1740 [24:31<02:50,  1.11it/s] 89%|████████▉ | 1552/1740 [24:32<02:49,  1.11it/s] 89%|████████▉ | 1553/1740 [24:33<02:49,  1.11it/s] 89%|████████▉ | 1554/1740 [24:34<02:48,  1.11it/s] 89%|████████▉ | 1555/1740 [24:35<02:47,  1.10it/s] 89%|████████▉ | 1556/1740 [24:36<02:46,  1.11it/s] 89%|████████▉ | 1557/1740 [24:37<02:45,  1.10it/s] 90%|████████▉ | 1558/1740 [24:38<02:44,  1.10it/s] 90%|████████▉ | 1559/1740 [24:39<02:43,  1.10it/s] 90%|████████▉ | 1560/1740 [24:40<02:42,  1.11it/s] 90%|████████▉ | 1561/1740 [24:40<02:41,  1.11it/s] 90%|████████▉ | 1562/1740 [24:41<02:40,  1.11it/s] 90%|████████▉ | 1563/1740 [24:42<02:39,  1.11it/s] 90%|████████▉ | 1564/1740 [24:43<02:39,  1.11it/s] 90%|████████▉ | 1565/1740 [24:44<02:38,  1.11it/s] 90%|█████████ | 1566/1740 [24:45<02:37,  1.10it/s] 90%|█████████ | 1567/1740 [24:46<02:36,  1.10it/s] 90%|█████████ | 1568/1740 [24:47<02:35,  1.10it/s] 90%|█████████ | 1569/1740 [24:48<02:34,  1.10it/s] 90%|█████████ | 1570/1740 [24:49<02:33,  1.10it/s] 90%|█████████ | 1571/1740 [24:49<02:33,  1.10it/s] 90%|█████████ | 1572/1740 [24:50<02:32,  1.10it/s] 90%|█████████ | 1573/1740 [24:51<02:31,  1.10it/s] 90%|█████████ | 1574/1740 [24:52<02:37,  1.05it/s] 91%|█████████ | 1575/1740 [24:53<02:34,  1.07it/s] 91%|█████████ | 1576/1740 [24:54<02:32,  1.08it/s] 91%|█████████ | 1577/1740 [24:55<02:30,  1.09it/s] 91%|█████████ | 1578/1740 [24:56<02:28,  1.09it/s] 91%|█████████ | 1579/1740 [24:57<02:27,  1.09it/s] 91%|█████████ | 1580/1740 [24:58<02:25,  1.10it/s] 91%|█████████ | 1581/1740 [24:59<02:24,  1.10it/s] 91%|█████████ | 1582/1740 [25:00<02:23,  1.10it/s] 91%|█████████ | 1583/1740 [25:00<02:21,  1.11it/s] 91%|█████████ | 1584/1740 [25:01<02:20,  1.11it/s] 91%|█████████ | 1585/1740 [25:02<02:20,  1.11it/s] 91%|█████████ | 1586/1740 [25:03<02:19,  1.11it/s] 91%|█████████ | 1587/1740 [25:04<02:18,  1.11it/s] 91%|█████████▏| 1588/1740 [25:05<02:17,  1.11it/s] 91%|█████████▏| 1589/1740 [25:06<02:16,  1.11it/s] 91%|█████████▏| 1590/1740 [25:07<02:15,  1.10it/s] 91%|█████████▏| 1591/1740 [25:08<02:14,  1.10it/s] 91%|█████████▏| 1592/1740 [25:09<02:14,  1.10it/s] 92%|█████████▏| 1593/1740 [25:10<02:13,  1.10it/s] 92%|█████████▏| 1594/1740 [25:10<02:12,  1.10it/s] 92%|█████████▏| 1595/1740 [25:11<02:11,  1.10it/s] 92%|█████████▏| 1596/1740 [25:12<02:10,  1.10it/s] 92%|█████████▏| 1597/1740 [25:13<02:09,  1.10it/s] 92%|█████████▏| 1598/1740 [25:14<02:08,  1.10it/s] 92%|█████████▏| 1599/1740 [25:15<02:07,  1.11it/s] 92%|█████████▏| 1600/1740 [25:16<02:06,  1.11it/s] 92%|█████████▏| 1601/1740 [25:17<02:05,  1.11it/s] 92%|█████████▏| 1602/1740 [25:18<02:04,  1.11it/s] 92%|█████████▏| 1603/1740 [25:19<02:03,  1.11it/s] 92%|█████████▏| 1604/1740 [25:20<02:03,  1.11it/s] 92%|█████████▏| 1605/1740 [25:20<02:02,  1.10it/s] 92%|█████████▏| 1606/1740 [25:21<02:01,  1.10it/s] 92%|█████████▏| 1607/1740 [25:22<02:00,  1.10it/s] 92%|█████████▏| 1608/1740 [25:23<01:59,  1.10it/s] 92%|█████████▏| 1609/1740 [25:24<01:58,  1.10it/s] 93%|█████████▎| 1610/1740 [25:25<01:57,  1.10it/s] 93%|█████████▎| 1611/1740 [25:26<01:56,  1.10it/s] 93%|█████████▎| 1612/1740 [25:27<01:55,  1.10it/s] 93%|█████████▎| 1613/1740 [25:28<01:55,  1.10it/s] 93%|█████████▎| 1614/1740 [25:29<01:59,  1.05it/s] 93%|█████████▎| 1615/1740 [25:30<01:56,  1.07it/s] 93%|█████████▎| 1616/1740 [25:31<01:54,  1.08it/s] 93%|█████████▎| 1617/1740 [25:31<01:52,  1.09it/s] 93%|█████████▎| 1618/1740 [25:32<01:51,  1.09it/s] 93%|█████████▎| 1619/1740 [25:33<01:50,  1.10it/s] 93%|█████████▎| 1620/1740 [25:34<01:49,  1.10it/s] 93%|█████████▎| 1621/1740 [25:35<01:48,  1.10it/s] 93%|█████████▎| 1622/1740 [25:36<01:47,  1.10it/s] 93%|█████████▎| 1623/1740 [25:37<01:46,  1.10it/s] 93%|█████████▎| 1624/1740 [25:37<01:29,  1.29it/s]{'eval_loss': 4.345605850219727, 'eval_precision': 0.859375, 'eval_recall': 0.8527131782945736, 'eval_f1': 0.8560311284046692, 'eval_accuracy': 0.9862794012829651, 'eval_runtime': 2.1288, 'eval_samples_per_second': 48.385, 'eval_steps_per_second': 1.879, 'epoch': 13.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.79it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.57it/s][A                                                   
                                             [A 93%|█████████▎| 1624/1740 [25:39<01:29,  1.29it/s]
100%|██████████| 4/4 [00:01<00:00,  2.57it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 93%|█████████▎| 1625/1740 [25:43<04:35,  2.39s/it] 93%|█████████▎| 1626/1740 [25:44<03:41,  1.94s/it] 94%|█████████▎| 1627/1740 [25:45<03:04,  1.63s/it] 94%|█████████▎| 1628/1740 [25:46<02:38,  1.42s/it] 94%|█████████▎| 1629/1740 [25:47<02:20,  1.26s/it] 94%|█████████▎| 1630/1740 [25:48<02:07,  1.16s/it] 94%|█████████▎| 1631/1740 [25:49<01:57,  1.08s/it] 94%|█████████▍| 1632/1740 [25:50<01:51,  1.03s/it] 94%|█████████▍| 1633/1740 [25:51<01:46,  1.01it/s] 94%|█████████▍| 1634/1740 [25:52<01:42,  1.03it/s] 94%|█████████▍| 1635/1740 [25:53<01:39,  1.05it/s] 94%|█████████▍| 1636/1740 [25:53<01:37,  1.07it/s] 94%|█████████▍| 1637/1740 [25:54<01:35,  1.08it/s] 94%|█████████▍| 1638/1740 [25:55<01:33,  1.09it/s] 94%|█████████▍| 1639/1740 [25:56<01:32,  1.09it/s] 94%|█████████▍| 1640/1740 [25:57<01:31,  1.10it/s] 94%|█████████▍| 1641/1740 [25:58<01:30,  1.10it/s] 94%|█████████▍| 1642/1740 [25:59<01:33,  1.05it/s] 94%|█████████▍| 1643/1740 [26:00<01:30,  1.07it/s] 94%|█████████▍| 1644/1740 [26:01<01:28,  1.08it/s] 95%|█████████▍| 1645/1740 [26:02<01:27,  1.09it/s] 95%|█████████▍| 1646/1740 [26:03<01:26,  1.09it/s] 95%|█████████▍| 1647/1740 [26:04<01:24,  1.10it/s] 95%|█████████▍| 1648/1740 [26:04<01:23,  1.10it/s] 95%|█████████▍| 1649/1740 [26:05<01:22,  1.10it/s] 95%|█████████▍| 1650/1740 [26:06<01:21,  1.10it/s] 95%|█████████▍| 1651/1740 [26:07<01:20,  1.10it/s] 95%|█████████▍| 1652/1740 [26:08<01:19,  1.10it/s] 95%|█████████▌| 1653/1740 [26:09<01:18,  1.10it/s] 95%|█████████▌| 1654/1740 [26:10<01:18,  1.10it/s] 95%|█████████▌| 1655/1740 [26:11<01:17,  1.10it/s] 95%|█████████▌| 1656/1740 [26:12<01:16,  1.10it/s] 95%|█████████▌| 1657/1740 [26:13<01:15,  1.10it/s] 95%|█████████▌| 1658/1740 [26:14<01:14,  1.10it/s] 95%|█████████▌| 1659/1740 [26:14<01:13,  1.10it/s] 95%|█████████▌| 1660/1740 [26:15<01:12,  1.11it/s] 95%|█████████▌| 1661/1740 [26:16<01:11,  1.11it/s] 96%|█████████▌| 1662/1740 [26:17<01:10,  1.11it/s] 96%|█████████▌| 1663/1740 [26:18<01:09,  1.10it/s] 96%|█████████▌| 1664/1740 [26:19<01:08,  1.10it/s] 96%|█████████▌| 1665/1740 [26:20<01:07,  1.10it/s] 96%|█████████▌| 1666/1740 [26:21<01:07,  1.10it/s] 96%|█████████▌| 1667/1740 [26:22<01:06,  1.10it/s] 96%|█████████▌| 1668/1740 [26:23<01:08,  1.05it/s] 96%|█████████▌| 1669/1740 [26:24<01:06,  1.07it/s] 96%|█████████▌| 1670/1740 [26:25<01:05,  1.08it/s] 96%|█████████▌| 1671/1740 [26:25<01:03,  1.08it/s] 96%|█████████▌| 1672/1740 [26:26<01:02,  1.09it/s] 96%|█████████▌| 1673/1740 [26:27<01:01,  1.09it/s] 96%|█████████▌| 1674/1740 [26:28<01:00,  1.10it/s] 96%|█████████▋| 1675/1740 [26:29<00:59,  1.10it/s] 96%|█████████▋| 1676/1740 [26:30<00:58,  1.10it/s] 96%|█████████▋| 1677/1740 [26:31<00:57,  1.10it/s] 96%|█████████▋| 1678/1740 [26:32<00:56,  1.10it/s] 96%|█████████▋| 1679/1740 [26:33<00:55,  1.10it/s] 97%|█████████▋| 1680/1740 [26:34<00:54,  1.10it/s] 97%|█████████▋| 1681/1740 [26:35<00:53,  1.10it/s] 97%|█████████▋| 1682/1740 [26:35<00:52,  1.10it/s] 97%|█████████▋| 1683/1740 [26:36<00:51,  1.10it/s] 97%|█████████▋| 1684/1740 [26:37<00:50,  1.10it/s] 97%|█████████▋| 1685/1740 [26:38<00:49,  1.10it/s] 97%|█████████▋| 1686/1740 [26:39<00:48,  1.10it/s] 97%|█████████▋| 1687/1740 [26:40<00:47,  1.11it/s] 97%|█████████▋| 1688/1740 [26:41<00:46,  1.11it/s] 97%|█████████▋| 1689/1740 [26:42<00:46,  1.11it/s] 97%|█████████▋| 1690/1740 [26:43<00:45,  1.11it/s] 97%|█████████▋| 1691/1740 [26:44<00:44,  1.10it/s] 97%|█████████▋| 1692/1740 [26:44<00:43,  1.10it/s] 97%|█████████▋| 1693/1740 [26:46<00:44,  1.05it/s] 97%|█████████▋| 1694/1740 [26:46<00:43,  1.07it/s] 97%|█████████▋| 1695/1740 [26:47<00:41,  1.08it/s] 97%|█████████▋| 1696/1740 [26:48<00:40,  1.09it/s] 98%|█████████▊| 1697/1740 [26:49<00:39,  1.09it/s] 98%|█████████▊| 1698/1740 [26:50<00:38,  1.10it/s] 98%|█████████▊| 1699/1740 [26:51<00:37,  1.10it/s] 98%|█████████▊| 1700/1740 [26:52<00:36,  1.10it/s] 98%|█████████▊| 1701/1740 [26:53<00:35,  1.10it/s] 98%|█████████▊| 1702/1740 [26:54<00:34,  1.10it/s] 98%|█████████▊| 1703/1740 [26:55<00:33,  1.10it/s] 98%|█████████▊| 1704/1740 [26:55<00:32,  1.10it/s] 98%|█████████▊| 1705/1740 [26:56<00:31,  1.10it/s] 98%|█████████▊| 1706/1740 [26:57<00:30,  1.10it/s] 98%|█████████▊| 1707/1740 [26:58<00:29,  1.10it/s] 98%|█████████▊| 1708/1740 [26:59<00:28,  1.10it/s] 98%|█████████▊| 1709/1740 [27:00<00:27,  1.11it/s] 98%|█████████▊| 1710/1740 [27:01<00:27,  1.11it/s] 98%|█████████▊| 1711/1740 [27:02<00:26,  1.11it/s] 98%|█████████▊| 1712/1740 [27:03<00:25,  1.11it/s] 98%|█████████▊| 1713/1740 [27:04<00:24,  1.10it/s] 99%|█████████▊| 1714/1740 [27:05<00:23,  1.10it/s] 99%|█████████▊| 1715/1740 [27:05<00:22,  1.10it/s] 99%|█████████▊| 1716/1740 [27:06<00:21,  1.10it/s] 99%|█████████▊| 1717/1740 [27:07<00:20,  1.10it/s] 99%|█████████▊| 1718/1740 [27:08<00:19,  1.10it/s] 99%|█████████▉| 1719/1740 [27:09<00:19,  1.10it/s] 99%|█████████▉| 1720/1740 [27:10<00:18,  1.10it/s] 99%|█████████▉| 1721/1740 [27:11<00:17,  1.10it/s] 99%|█████████▉| 1722/1740 [27:12<00:16,  1.10it/s] 99%|█████████▉| 1723/1740 [27:13<00:15,  1.10it/s] 99%|█████████▉| 1724/1740 [27:14<00:14,  1.10it/s] 99%|█████████▉| 1725/1740 [27:15<00:13,  1.10it/s] 99%|█████████▉| 1726/1740 [27:15<00:12,  1.11it/s] 99%|█████████▉| 1727/1740 [27:16<00:11,  1.11it/s] 99%|█████████▉| 1728/1740 [27:17<00:10,  1.11it/s] 99%|█████████▉| 1729/1740 [27:18<00:09,  1.10it/s] 99%|█████████▉| 1730/1740 [27:19<00:09,  1.10it/s] 99%|█████████▉| 1731/1740 [27:20<00:08,  1.10it/s]100%|█████████▉| 1732/1740 [27:21<00:07,  1.10it/s]100%|█████████▉| 1733/1740 [27:22<00:06,  1.10it/s]100%|█████████▉| 1734/1740 [27:23<00:05,  1.10it/s]100%|█████████▉| 1735/1740 [27:24<00:04,  1.10it/s]100%|█████████▉| 1736/1740 [27:24<00:03,  1.10it/s]100%|█████████▉| 1737/1740 [27:25<00:02,  1.10it/s]100%|█████████▉| 1738/1740 [27:26<00:01,  1.10it/s]100%|█████████▉| 1739/1740 [27:27<00:00,  1.10it/s]100%|██████████| 1740/1740 [27:28<00:00,  1.29it/s]{'eval_loss': 4.2596306800842285, 'eval_precision': 0.8599221789883269, 'eval_recall': 0.8565891472868217, 'eval_f1': 0.8582524271844659, 'eval_accuracy': 0.9866357804704206, 'eval_runtime': 2.1334, 'eval_samples_per_second': 48.281, 'eval_steps_per_second': 1.875, 'epoch': 14.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.87it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.80it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.61it/s][A                                                   
                                             [A100%|██████████| 1740/1740 [27:30<00:00,  1.29it/s]
100%|██████████| 4/4 [00:01<00:00,  2.61it/s][A
                                             [A                                                   100%|██████████| 1740/1740 [27:34<00:00,  1.29it/s]100%|██████████| 1740/1740 [27:34<00:00,  1.05it/s]
[I 2025-09-09 12:55:36,109] Trial 10 finished with value: 3.554755087169663 and parameters: {'learning_rate': 7.915077303055335e-05, 'num_train_epochs': 15, 'per_device_train_batch_size': 1, 'weight_decay': 0.0010718374645443155, 'warmup_ratio': 0.12514311847073786, 'optimizer': 'Adam'}. Best is trial 10 with value: 3.554755087169663.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb: uploading history steps 17-18, summary, console lines 53-59
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▃▄▅▅▇▇▆▇▇▇▇███
wandb:                 eval/f1 ▁▃▄▆▆▇▇▇▇▇█████
wandb:               eval/loss █▇▅▃▄▃▂▃▂▂▁▁▁▁▁
wandb:          eval/precision ▁▁▄▄▄█▆▇▇▆▇▇███
wandb:             eval/recall ▁▂▄▆▆▆▆▇██▇████
wandb:            eval/runtime ▁▂▃▅▅█▂▁▁▁▂▃▄▄▁
wandb: eval/samples_per_second █▇▆▄▄▁▇███▇▆▅▅▇
wandb:   eval/steps_per_second █▇▆▄▄▁▇███▇▆▅▅▇
wandb:             train/epoch ▁▁▂▃▃▃▃▄▅▅▅▅▆▇▇▇▇██
wandb:       train/global_step ▁▁▂▃▃▃▃▄▅▅▅▅▆▇▇▇▇██
wandb:         train/grad_norm █▁▁
wandb:     train/learning_rate █▄▁
wandb:              train/loss █▁▁
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.98664
wandb:                  eval/f1 0.85603
wandb:                eval/loss 4.27837
wandb:           eval/precision 0.85938
wandb:              eval/recall 0.85271
wandb:             eval/runtime 2.0906
wandb:  eval/samples_per_second 49.268
wandb:    eval/steps_per_second 1.913
wandb:               total_flos 0
wandb:              train/epoch 15
wandb:        train/global_step 1740
wandb:          train/grad_norm 284287.34375
wandb:      train/learning_rate 1e-05
wandb:               train/loss 9.9804
wandb:               train_loss 18.77802
wandb:            train_runtime 1657.3703
wandb: train_samples_per_second 8.363
wandb:   train_steps_per_second 1.05
wandb: 
wandb: 🚀 View run decent-dew-715 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/btl5vwqu
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250909_122800-btl5vwqu/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_125539-0clzkshb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-silence-716
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/0clzkshb
{'eval_loss': 4.278367042541504, 'eval_precision': 0.859375, 'eval_recall': 0.8527131782945736, 'eval_f1': 0.8560311284046692, 'eval_accuracy': 0.9866357804704206, 'eval_runtime': 2.0906, 'eval_samples_per_second': 49.268, 'eval_steps_per_second': 1.913, 'epoch': 15.0}
{'train_runtime': 1657.3703, 'train_samples_per_second': 8.363, 'train_steps_per_second': 1.05, 'train_loss': 18.77802348520564, 'epoch': 15.0}
  0%|          | 0/1740 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/1740 [00:00<26:22,  1.10it/s]  0%|          | 2/1740 [00:01<26:13,  1.10it/s]  0%|          | 3/1740 [00:02<26:09,  1.11it/s]  0%|          | 4/1740 [00:03<26:09,  1.11it/s]  0%|          | 5/1740 [00:04<26:09,  1.11it/s]  0%|          | 6/1740 [00:05<26:09,  1.10it/s]  0%|          | 7/1740 [00:06<26:07,  1.11it/s]  0%|          | 8/1740 [00:07<26:06,  1.11it/s]  1%|          | 9/1740 [00:08<26:05,  1.11it/s]  1%|          | 10/1740 [00:09<26:04,  1.11it/s]  1%|          | 11/1740 [00:09<26:04,  1.10it/s]  1%|          | 12/1740 [00:10<26:04,  1.10it/s]  1%|          | 13/1740 [00:11<26:04,  1.10it/s]  1%|          | 14/1740 [00:12<26:02,  1.10it/s]  1%|          | 15/1740 [00:13<26:02,  1.10it/s]  1%|          | 16/1740 [00:14<26:00,  1.10it/s]  1%|          | 17/1740 [00:15<26:00,  1.10it/s]  1%|          | 18/1740 [00:16<25:59,  1.10it/s]  1%|          | 19/1740 [00:17<25:58,  1.10it/s]  1%|          | 20/1740 [00:18<25:57,  1.10it/s]  1%|          | 21/1740 [00:19<25:57,  1.10it/s]  1%|▏         | 22/1740 [00:19<25:54,  1.11it/s]  1%|▏         | 23/1740 [00:20<25:53,  1.11it/s]  1%|▏         | 24/1740 [00:21<25:52,  1.11it/s]  1%|▏         | 25/1740 [00:22<25:51,  1.11it/s]  1%|▏         | 26/1740 [00:23<25:49,  1.11it/s]  2%|▏         | 27/1740 [00:24<25:50,  1.10it/s]  2%|▏         | 28/1740 [00:25<25:48,  1.11it/s]  2%|▏         | 29/1740 [00:26<25:49,  1.10it/s]  2%|▏         | 30/1740 [00:27<25:48,  1.10it/s]  2%|▏         | 31/1740 [00:28<27:15,  1.05it/s]  2%|▏         | 32/1740 [00:29<26:49,  1.06it/s]  2%|▏         | 33/1740 [00:30<26:26,  1.08it/s]  2%|▏         | 34/1740 [00:30<26:07,  1.09it/s]  2%|▏         | 35/1740 [00:31<25:59,  1.09it/s]  2%|▏         | 36/1740 [00:32<25:52,  1.10it/s]  2%|▏         | 37/1740 [00:33<25:49,  1.10it/s]  2%|▏         | 38/1740 [00:34<25:47,  1.10it/s]  2%|▏         | 39/1740 [00:35<25:44,  1.10it/s]  2%|▏         | 40/1740 [00:36<25:41,  1.10it/s]  2%|▏         | 41/1740 [00:37<25:32,  1.11it/s]  2%|▏         | 42/1740 [00:38<25:32,  1.11it/s]  2%|▏         | 43/1740 [00:39<25:34,  1.11it/s]  3%|▎         | 44/1740 [00:39<25:32,  1.11it/s]  3%|▎         | 45/1740 [00:40<25:24,  1.11it/s]  3%|▎         | 46/1740 [00:41<25:28,  1.11it/s]  3%|▎         | 47/1740 [00:42<25:28,  1.11it/s]  3%|▎         | 48/1740 [00:43<25:30,  1.11it/s]  3%|▎         | 49/1740 [00:44<25:30,  1.10it/s]  3%|▎         | 50/1740 [00:45<25:29,  1.10it/s]  3%|▎         | 51/1740 [00:46<25:29,  1.10it/s]  3%|▎         | 52/1740 [00:47<25:29,  1.10it/s]  3%|▎         | 53/1740 [00:48<25:27,  1.10it/s]  3%|▎         | 54/1740 [00:49<25:27,  1.10it/s]  3%|▎         | 55/1740 [00:49<25:27,  1.10it/s]  3%|▎         | 56/1740 [00:50<25:25,  1.10it/s]  3%|▎         | 57/1740 [00:51<26:39,  1.05it/s]  3%|▎         | 58/1740 [00:52<26:15,  1.07it/s]  3%|▎         | 59/1740 [00:53<25:59,  1.08it/s]  3%|▎         | 60/1740 [00:54<25:46,  1.09it/s]  4%|▎         | 61/1740 [00:55<25:38,  1.09it/s]  4%|▎         | 62/1740 [00:56<25:32,  1.09it/s]  4%|▎         | 63/1740 [00:57<25:27,  1.10it/s]  4%|▎         | 64/1740 [00:58<25:24,  1.10it/s]  4%|▎         | 65/1740 [00:59<25:21,  1.10it/s]  4%|▍         | 66/1740 [01:00<25:19,  1.10it/s]  4%|▍         | 67/1740 [01:00<25:16,  1.10it/s]  4%|▍         | 68/1740 [01:01<25:15,  1.10it/s]  4%|▍         | 69/1740 [01:02<25:13,  1.10it/s]  4%|▍         | 70/1740 [01:03<25:12,  1.10it/s]  4%|▍         | 71/1740 [01:04<25:11,  1.10it/s]  4%|▍         | 72/1740 [01:05<25:09,  1.11it/s]  4%|▍         | 73/1740 [01:06<25:09,  1.10it/s]  4%|▍         | 74/1740 [01:07<25:07,  1.10it/s]  4%|▍         | 75/1740 [01:08<25:07,  1.10it/s]  4%|▍         | 76/1740 [01:09<25:06,  1.10it/s]  4%|▍         | 77/1740 [01:09<25:04,  1.11it/s]  4%|▍         | 78/1740 [01:10<24:56,  1.11it/s]  5%|▍         | 79/1740 [01:11<24:58,  1.11it/s]  5%|▍         | 80/1740 [01:12<24:59,  1.11it/s]  5%|▍         | 81/1740 [01:13<24:58,  1.11it/s]  5%|▍         | 82/1740 [01:14<26:10,  1.06it/s]  5%|▍         | 83/1740 [01:15<25:49,  1.07it/s]  5%|▍         | 84/1740 [01:16<25:33,  1.08it/s]  5%|▍         | 85/1740 [01:17<25:22,  1.09it/s]  5%|▍         | 86/1740 [01:18<25:14,  1.09it/s]  5%|▌         | 87/1740 [01:19<25:08,  1.10it/s]  5%|▌         | 88/1740 [01:20<25:01,  1.10it/s]  5%|▌         | 89/1740 [01:20<24:53,  1.11it/s]  5%|▌         | 90/1740 [01:21<24:53,  1.10it/s]  5%|▌         | 91/1740 [01:22<24:51,  1.11it/s]  5%|▌         | 92/1740 [01:23<24:52,  1.10it/s]  5%|▌         | 93/1740 [01:24<24:51,  1.10it/s]  5%|▌         | 94/1740 [01:25<24:50,  1.10it/s]  5%|▌         | 95/1740 [01:26<24:48,  1.10it/s]  6%|▌         | 96/1740 [01:27<24:48,  1.10it/s]  6%|▌         | 97/1740 [01:28<24:47,  1.10it/s]  6%|▌         | 98/1740 [01:29<24:46,  1.10it/s]  6%|▌         | 99/1740 [01:30<24:42,  1.11it/s]  6%|▌         | 100/1740 [01:30<24:36,  1.11it/s]  6%|▌         | 101/1740 [01:31<24:38,  1.11it/s]  6%|▌         | 102/1740 [01:32<24:39,  1.11it/s]  6%|▌         | 103/1740 [01:33<24:39,  1.11it/s]  6%|▌         | 104/1740 [01:34<24:38,  1.11it/s]  6%|▌         | 105/1740 [01:35<24:38,  1.11it/s]  6%|▌         | 106/1740 [01:36<24:38,  1.11it/s]  6%|▌         | 107/1740 [01:37<24:29,  1.11it/s]  6%|▌         | 108/1740 [01:38<24:30,  1.11it/s]  6%|▋         | 109/1740 [01:39<24:32,  1.11it/s]  6%|▋         | 110/1740 [01:39<24:31,  1.11it/s]  6%|▋         | 111/1740 [01:40<24:33,  1.11it/s]  6%|▋         | 112/1740 [01:41<24:32,  1.11it/s]  6%|▋         | 113/1740 [01:42<24:31,  1.11it/s]  7%|▋         | 114/1740 [01:43<24:32,  1.10it/s]  7%|▋         | 115/1740 [01:44<24:30,  1.10it/s]  7%|▋         | 116/1740 [01:44<20:53,  1.30it/s]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.87it/s][A
 75%|███████▌  | 3/4 [00:00<00:00,  2.89it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.68it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                  
                                             [A  7%|▋         | 116/1740 [01:47<20:53,  1.30it/s]
100%|██████████| 4/4 [00:01<00:00,  2.68it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  7%|▋         | 117/1740 [01:51<1:03:55,  2.36s/it]  7%|▋         | 118/1740 [01:51<52:02,  1.93s/it]    7%|▋         | 119/1740 [01:52<43:45,  1.62s/it]  7%|▋         | 120/1740 [01:53<37:55,  1.40s/it]  7%|▋         | 121/1740 [01:54<33:50,  1.25s/it]  7%|▋         | 122/1740 [01:55<30:59,  1.15s/it]  7%|▋         | 123/1740 [01:56<30:11,  1.12s/it]  7%|▋         | 124/1740 [01:57<28:26,  1.06s/it]  7%|▋         | 125/1740 [01:58<27:12,  1.01s/it]  7%|▋         | 126/1740 [01:59<26:19,  1.02it/s]  7%|▋         | 127/1740 [02:00<25:43,  1.05it/s]  7%|▋         | 128/1740 [02:01<25:17,  1.06it/s]  7%|▋         | 129/1740 [02:02<24:58,  1.08it/s]  7%|▋         | 130/1740 [02:02<24:46,  1.08it/s]  8%|▊         | 131/1740 [02:03<24:37,  1.09it/s]  8%|▊         | 132/1740 [02:04<24:28,  1.09it/s]  8%|▊         | 133/1740 [02:05<24:24,  1.10it/s]  8%|▊         | 134/1740 [02:06<24:21,  1.10it/s]  8%|▊         | 135/1740 [02:07<24:17,  1.10it/s]  8%|▊         | 136/1740 [02:08<24:14,  1.10it/s]  8%|▊         | 137/1740 [02:09<24:12,  1.10it/s]  8%|▊         | 138/1740 [02:10<24:10,  1.10it/s]  8%|▊         | 139/1740 [02:11<24:09,  1.10it/s]  8%|▊         | 140/1740 [02:11<24:07,  1.11it/s]  8%|▊         | 141/1740 [02:12<24:06,  1.11it/s]  8%|▊         | 142/1740 [02:13<24:05,  1.11it/s]  8%|▊         | 143/1740 [02:14<24:03,  1.11it/s]  8%|▊         | 144/1740 [02:15<24:03,  1.11it/s]  8%|▊         | 145/1740 [02:16<24:02,  1.11it/s]  8%|▊         | 146/1740 [02:17<24:01,  1.11it/s]  8%|▊         | 147/1740 [02:18<24:00,  1.11it/s]  9%|▊         | 148/1740 [02:19<24:00,  1.11it/s]  9%|▊         | 149/1740 [02:20<23:57,  1.11it/s]  9%|▊         | 150/1740 [02:20<23:52,  1.11it/s]  9%|▊         | 151/1740 [02:21<23:53,  1.11it/s]  9%|▊         | 152/1740 [02:22<23:54,  1.11it/s]  9%|▉         | 153/1740 [02:23<23:54,  1.11it/s]  9%|▉         | 154/1740 [02:24<23:54,  1.11it/s]  9%|▉         | 155/1740 [02:25<23:53,  1.11it/s]  9%|▉         | 156/1740 [02:26<23:52,  1.11it/s]  9%|▉         | 157/1740 [02:27<23:52,  1.11it/s]  9%|▉         | 158/1740 [02:28<23:51,  1.10it/s]  9%|▉         | 159/1740 [02:29<23:51,  1.10it/s]  9%|▉         | 160/1740 [02:30<23:50,  1.10it/s]  9%|▉         | 161/1740 [02:30<23:50,  1.10it/s]  9%|▉         | 162/1740 [02:31<23:47,  1.11it/s]  9%|▉         | 163/1740 [02:32<23:47,  1.10it/s]  9%|▉         | 164/1740 [02:33<23:46,  1.10it/s]  9%|▉         | 165/1740 [02:34<23:45,  1.10it/s] 10%|▉         | 166/1740 [02:35<23:44,  1.10it/s] 10%|▉         | 167/1740 [02:36<23:43,  1.10it/s] 10%|▉         | 168/1740 [02:37<23:34,  1.11it/s] 10%|▉         | 169/1740 [02:38<23:37,  1.11it/s] 10%|▉         | 170/1740 [02:39<23:38,  1.11it/s] 10%|▉         | 171/1740 [02:39<23:38,  1.11it/s] 10%|▉         | 172/1740 [02:40<23:38,  1.11it/s] 10%|▉         | 173/1740 [02:41<23:37,  1.11it/s] 10%|█         | 174/1740 [02:42<24:45,  1.05it/s] 10%|█         | 175/1740 [02:43<24:24,  1.07it/s] 10%|█         | 176/1740 [02:44<24:09,  1.08it/s] 10%|█         | 177/1740 [02:45<23:58,  1.09it/s] 10%|█         | 178/1740 [02:46<23:51,  1.09it/s] 10%|█         | 179/1740 [02:47<23:46,  1.09it/s] 10%|█         | 180/1740 [02:48<23:41,  1.10it/s] 10%|█         | 181/1740 [02:49<23:38,  1.10it/s] 10%|█         | 182/1740 [02:50<23:32,  1.10it/s] 11%|█         | 183/1740 [02:50<23:26,  1.11it/s] 11%|█         | 184/1740 [02:51<23:26,  1.11it/s] 11%|█         | 185/1740 [02:52<23:27,  1.10it/s] 11%|█         | 186/1740 [02:53<23:26,  1.10it/s] 11%|█         | 187/1740 [02:54<23:25,  1.10it/s] 11%|█         | 188/1740 [02:55<23:27,  1.10it/s] 11%|█         | 189/1740 [02:56<23:25,  1.10it/s] 11%|█         | 190/1740 [02:57<23:24,  1.10it/s] 11%|█         | 191/1740 [02:58<23:24,  1.10it/s] 11%|█         | 192/1740 [02:59<23:23,  1.10it/s] 11%|█         | 193/1740 [03:00<23:21,  1.10it/s] 11%|█         | 194/1740 [03:00<23:20,  1.10it/s] 11%|█         | 195/1740 [03:01<23:18,  1.10it/s] 11%|█▏        | 196/1740 [03:02<23:17,  1.10it/s] 11%|█▏        | 197/1740 [03:03<23:16,  1.10it/s] 11%|█▏        | 198/1740 [03:04<23:16,  1.10it/s] 11%|█▏        | 199/1740 [03:05<23:15,  1.10it/s] 11%|█▏        | 200/1740 [03:06<23:13,  1.11it/s] 12%|█▏        | 201/1740 [03:07<23:12,  1.11it/s] 12%|█▏        | 202/1740 [03:08<23:12,  1.10it/s] 12%|█▏        | 203/1740 [03:09<23:11,  1.10it/s] 12%|█▏        | 204/1740 [03:10<23:10,  1.10it/s] 12%|█▏        | 205/1740 [03:10<23:10,  1.10it/s] 12%|█▏        | 206/1740 [03:11<23:09,  1.10it/s] 12%|█▏        | 207/1740 [03:12<23:08,  1.10it/s] 12%|█▏        | 208/1740 [03:13<23:07,  1.10it/s] 12%|█▏        | 209/1740 [03:14<23:07,  1.10it/s] 12%|█▏        | 210/1740 [03:15<23:07,  1.10it/s] 12%|█▏        | 211/1740 [03:16<23:05,  1.10it/s] 12%|█▏        | 212/1740 [03:17<23:04,  1.10it/s] 12%|█▏        | 213/1740 [03:18<24:11,  1.05it/s] 12%|█▏        | 214/1740 [03:19<23:48,  1.07it/s] 12%|█▏        | 215/1740 [03:20<23:34,  1.08it/s] 12%|█▏        | 216/1740 [03:21<23:23,  1.09it/s] 12%|█▏        | 217/1740 [03:21<23:15,  1.09it/s] 13%|█▎        | 218/1740 [03:22<23:10,  1.09it/s] 13%|█▎        | 219/1740 [03:23<23:05,  1.10it/s] 13%|█▎        | 220/1740 [03:24<23:02,  1.10it/s] 13%|█▎        | 221/1740 [03:25<23:00,  1.10it/s] 13%|█▎        | 222/1740 [03:26<22:58,  1.10it/s] 13%|█▎        | 223/1740 [03:27<22:56,  1.10it/s] 13%|█▎        | 224/1740 [03:28<22:54,  1.10it/s] 13%|█▎        | 225/1740 [03:29<22:52,  1.10it/s] 13%|█▎        | 226/1740 [03:30<22:50,  1.10it/s] 13%|█▎        | 227/1740 [03:30<22:44,  1.11it/s] 13%|█▎        | 228/1740 [03:31<22:44,  1.11it/s] 13%|█▎        | 229/1740 [03:32<22:45,  1.11it/s] 13%|█▎        | 230/1740 [03:33<22:45,  1.11it/s] 13%|█▎        | 231/1740 [03:34<22:45,  1.10it/s] 13%|█▎        | 232/1740 [03:35<19:23,  1.30it/s]{'eval_loss': 14.07596492767334, 'eval_precision': 0.4690265486725664, 'eval_recall': 0.2054263565891473, 'eval_f1': 0.28571428571428575, 'eval_accuracy': 0.9463649322879544, 'eval_runtime': 2.0751, 'eval_samples_per_second': 49.636, 'eval_steps_per_second': 1.928, 'epoch': 1.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.93it/s][A
 75%|███████▌  | 3/4 [00:00<00:00,  2.84it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                  
                                             [A 13%|█▎        | 232/1740 [03:37<19:23,  1.30it/s]
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 13%|█▎        | 233/1740 [03:41<59:01,  2.35s/it] 13%|█▎        | 234/1740 [03:41<48:04,  1.92s/it] 14%|█▎        | 235/1740 [03:42<40:27,  1.61s/it] 14%|█▎        | 236/1740 [03:43<35:05,  1.40s/it] 14%|█▎        | 237/1740 [03:44<31:21,  1.25s/it] 14%|█▎        | 238/1740 [03:45<28:44,  1.15s/it] 14%|█▎        | 239/1740 [03:46<26:53,  1.07s/it] 14%|█▍        | 240/1740 [03:47<25:35,  1.02s/it] 14%|█▍        | 241/1740 [03:48<24:40,  1.01it/s] 14%|█▍        | 242/1740 [03:49<24:02,  1.04it/s] 14%|█▍        | 243/1740 [03:50<24:42,  1.01it/s] 14%|█▍        | 244/1740 [03:51<24:03,  1.04it/s] 14%|█▍        | 245/1740 [03:52<23:35,  1.06it/s] 14%|█▍        | 246/1740 [03:53<23:16,  1.07it/s] 14%|█▍        | 247/1740 [03:53<23:02,  1.08it/s] 14%|█▍        | 248/1740 [03:54<22:52,  1.09it/s] 14%|█▍        | 249/1740 [03:55<22:43,  1.09it/s] 14%|█▍        | 250/1740 [03:56<22:38,  1.10it/s] 14%|█▍        | 251/1740 [03:57<22:34,  1.10it/s] 14%|█▍        | 252/1740 [03:58<22:31,  1.10it/s] 15%|█▍        | 253/1740 [03:59<22:29,  1.10it/s] 15%|█▍        | 254/1740 [04:00<22:28,  1.10it/s] 15%|█▍        | 255/1740 [04:01<22:25,  1.10it/s] 15%|█▍        | 256/1740 [04:02<22:24,  1.10it/s] 15%|█▍        | 257/1740 [04:02<22:23,  1.10it/s] 15%|█▍        | 258/1740 [04:03<22:22,  1.10it/s] 15%|█▍        | 259/1740 [04:04<22:22,  1.10it/s] 15%|█▍        | 260/1740 [04:05<22:20,  1.10it/s] 15%|█▌        | 261/1740 [04:06<22:18,  1.10it/s] 15%|█▌        | 262/1740 [04:07<22:16,  1.11it/s] 15%|█▌        | 263/1740 [04:08<22:17,  1.10it/s] 15%|█▌        | 264/1740 [04:09<22:15,  1.10it/s] 15%|█▌        | 265/1740 [04:10<22:15,  1.10it/s] 15%|█▌        | 266/1740 [04:11<22:13,  1.11it/s] 15%|█▌        | 267/1740 [04:12<22:12,  1.11it/s] 15%|█▌        | 268/1740 [04:12<22:12,  1.11it/s] 15%|█▌        | 269/1740 [04:13<23:23,  1.05it/s] 16%|█▌        | 270/1740 [04:14<23:02,  1.06it/s] 16%|█▌        | 271/1740 [04:15<22:46,  1.08it/s] 16%|█▌        | 272/1740 [04:16<22:33,  1.08it/s] 16%|█▌        | 273/1740 [04:17<22:25,  1.09it/s] 16%|█▌        | 274/1740 [04:18<22:19,  1.09it/s] 16%|█▌        | 275/1740 [04:19<22:15,  1.10it/s] 16%|█▌        | 276/1740 [04:20<22:12,  1.10it/s] 16%|█▌        | 277/1740 [04:21<22:09,  1.10it/s] 16%|█▌        | 278/1740 [04:22<22:07,  1.10it/s] 16%|█▌        | 279/1740 [04:23<22:05,  1.10it/s] 16%|█▌        | 280/1740 [04:23<22:03,  1.10it/s] 16%|█▌        | 281/1740 [04:24<22:02,  1.10it/s] 16%|█▌        | 282/1740 [04:25<22:01,  1.10it/s] 16%|█▋        | 283/1740 [04:26<22:01,  1.10it/s] 16%|█▋        | 284/1740 [04:27<21:59,  1.10it/s] 16%|█▋        | 285/1740 [04:28<21:58,  1.10it/s] 16%|█▋        | 286/1740 [04:29<21:58,  1.10it/s] 16%|█▋        | 287/1740 [04:30<21:57,  1.10it/s] 17%|█▋        | 288/1740 [04:31<21:56,  1.10it/s] 17%|█▋        | 289/1740 [04:32<21:55,  1.10it/s] 17%|█▋        | 290/1740 [04:33<21:53,  1.10it/s] 17%|█▋        | 291/1740 [04:33<21:51,  1.10it/s] 17%|█▋        | 292/1740 [04:34<21:51,  1.10it/s] 17%|█▋        | 293/1740 [04:35<21:50,  1.10it/s] 17%|█▋        | 294/1740 [04:36<22:49,  1.06it/s] 17%|█▋        | 295/1740 [04:37<22:26,  1.07it/s] 17%|█▋        | 296/1740 [04:38<22:13,  1.08it/s] 17%|█▋        | 297/1740 [04:39<22:05,  1.09it/s] 17%|█▋        | 298/1740 [04:40<21:58,  1.09it/s] 17%|█▋        | 299/1740 [04:41<21:54,  1.10it/s] 17%|█▋        | 300/1740 [04:42<21:51,  1.10it/s] 17%|█▋        | 301/1740 [04:43<21:48,  1.10it/s] 17%|█▋        | 302/1740 [04:44<21:47,  1.10it/s] 17%|█▋        | 303/1740 [04:44<21:45,  1.10it/s] 17%|█▋        | 304/1740 [04:45<21:43,  1.10it/s] 18%|█▊        | 305/1740 [04:46<21:42,  1.10it/s] 18%|█▊        | 306/1740 [04:47<21:40,  1.10it/s] 18%|█▊        | 307/1740 [04:48<21:38,  1.10it/s] 18%|█▊        | 308/1740 [04:49<21:38,  1.10it/s] 18%|█▊        | 309/1740 [04:50<21:36,  1.10it/s] 18%|█▊        | 310/1740 [04:51<21:35,  1.10it/s] 18%|█▊        | 311/1740 [04:52<21:33,  1.10it/s] 18%|█▊        | 312/1740 [04:53<21:31,  1.11it/s] 18%|█▊        | 313/1740 [04:53<21:31,  1.10it/s] 18%|█▊        | 314/1740 [04:54<21:30,  1.11it/s] 18%|█▊        | 315/1740 [04:55<21:29,  1.10it/s] 18%|█▊        | 316/1740 [04:56<21:28,  1.10it/s] 18%|█▊        | 317/1740 [04:57<21:27,  1.10it/s] 18%|█▊        | 318/1740 [04:58<21:26,  1.10it/s] 18%|█▊        | 319/1740 [04:59<21:26,  1.10it/s] 18%|█▊        | 320/1740 [05:00<21:25,  1.10it/s] 18%|█▊        | 321/1740 [05:01<21:25,  1.10it/s] 19%|█▊        | 322/1740 [05:02<21:24,  1.10it/s] 19%|█▊        | 323/1740 [05:03<21:23,  1.10it/s] 19%|█▊        | 324/1740 [05:03<21:23,  1.10it/s] 19%|█▊        | 325/1740 [05:04<21:21,  1.10it/s] 19%|█▊        | 326/1740 [05:05<21:20,  1.10it/s] 19%|█▉        | 327/1740 [05:06<21:19,  1.10it/s] 19%|█▉        | 328/1740 [05:07<21:17,  1.10it/s] 19%|█▉        | 329/1740 [05:08<21:16,  1.11it/s] 19%|█▉        | 330/1740 [05:09<21:16,  1.10it/s] 19%|█▉        | 331/1740 [05:10<21:14,  1.11it/s] 19%|█▉        | 332/1740 [05:11<21:14,  1.10it/s] 19%|█▉        | 333/1740 [05:12<21:15,  1.10it/s] 19%|█▉        | 334/1740 [05:12<21:15,  1.10it/s] 19%|█▉        | 335/1740 [05:13<21:14,  1.10it/s] 19%|█▉        | 336/1740 [05:14<21:12,  1.10it/s] 19%|█▉        | 337/1740 [05:15<21:11,  1.10it/s] 19%|█▉        | 338/1740 [05:16<21:10,  1.10it/s] 19%|█▉        | 339/1740 [05:17<21:09,  1.10it/s] 20%|█▉        | 340/1740 [05:18<21:08,  1.10it/s] 20%|█▉        | 341/1740 [05:19<21:07,  1.10it/s] 20%|█▉        | 342/1740 [05:20<21:06,  1.10it/s] 20%|█▉        | 343/1740 [05:21<21:04,  1.10it/s] 20%|█▉        | 344/1740 [05:22<21:04,  1.10it/s] 20%|█▉        | 345/1740 [05:22<21:03,  1.10it/s] 20%|█▉        | 346/1740 [05:24<22:04,  1.05it/s] 20%|█▉        | 347/1740 [05:24<21:45,  1.07it/s] 20%|██        | 348/1740 [05:25<18:25,  1.26it/s]{'eval_loss': 13.95577621459961, 'eval_precision': 0.4702702702702703, 'eval_recall': 0.3372093023255814, 'eval_f1': 0.39277652370203164, 'eval_accuracy': 0.9518888096935139, 'eval_runtime': 2.079, 'eval_samples_per_second': 49.543, 'eval_steps_per_second': 1.924, 'epoch': 2.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.85it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.79it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.70it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                  
                                             [A 20%|██        | 348/1740 [05:27<18:25,  1.26it/s]
100%|██████████| 4/4 [00:01<00:00,  2.70it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 20%|██        | 349/1740 [05:31<54:31,  2.35s/it] 20%|██        | 350/1740 [05:32<44:24,  1.92s/it] 20%|██        | 351/1740 [05:33<37:21,  1.61s/it] 20%|██        | 352/1740 [05:34<32:24,  1.40s/it] 20%|██        | 353/1740 [05:34<28:56,  1.25s/it] 20%|██        | 354/1740 [05:35<26:30,  1.15s/it] 20%|██        | 355/1740 [05:36<24:45,  1.07s/it] 20%|██        | 356/1740 [05:37<23:32,  1.02s/it] 21%|██        | 357/1740 [05:38<22:43,  1.01it/s] 21%|██        | 358/1740 [05:39<22:09,  1.04it/s] 21%|██        | 359/1740 [05:40<21:44,  1.06it/s] 21%|██        | 360/1740 [05:41<21:28,  1.07it/s] 21%|██        | 361/1740 [05:42<21:16,  1.08it/s] 21%|██        | 362/1740 [05:43<21:09,  1.09it/s] 21%|██        | 363/1740 [05:44<21:01,  1.09it/s] 21%|██        | 364/1740 [05:44<20:56,  1.10it/s] 21%|██        | 365/1740 [05:45<20:53,  1.10it/s] 21%|██        | 366/1740 [05:46<20:49,  1.10it/s] 21%|██        | 367/1740 [05:47<20:46,  1.10it/s] 21%|██        | 368/1740 [05:48<20:45,  1.10it/s] 21%|██        | 369/1740 [05:49<20:44,  1.10it/s] 21%|██▏       | 370/1740 [05:50<20:42,  1.10it/s] 21%|██▏       | 371/1740 [05:51<20:41,  1.10it/s] 21%|██▏       | 372/1740 [05:52<20:38,  1.10it/s] 21%|██▏       | 373/1740 [05:53<20:38,  1.10it/s] 21%|██▏       | 374/1740 [05:53<20:37,  1.10it/s] 22%|██▏       | 375/1740 [05:54<20:36,  1.10it/s] 22%|██▏       | 376/1740 [05:55<20:36,  1.10it/s] 22%|██▏       | 377/1740 [05:56<20:35,  1.10it/s] 22%|██▏       | 378/1740 [05:57<20:34,  1.10it/s] 22%|██▏       | 379/1740 [05:58<20:33,  1.10it/s] 22%|██▏       | 380/1740 [05:59<20:30,  1.10it/s] 22%|██▏       | 381/1740 [06:00<20:31,  1.10it/s] 22%|██▏       | 382/1740 [06:01<21:30,  1.05it/s] 22%|██▏       | 383/1740 [06:02<21:11,  1.07it/s] 22%|██▏       | 384/1740 [06:03<20:57,  1.08it/s] 22%|██▏       | 385/1740 [06:04<20:48,  1.09it/s] 22%|██▏       | 386/1740 [06:05<20:40,  1.09it/s] 22%|██▏       | 387/1740 [06:05<20:35,  1.10it/s] 22%|██▏       | 388/1740 [06:06<20:30,  1.10it/s] 22%|██▏       | 389/1740 [06:07<20:27,  1.10it/s] 22%|██▏       | 390/1740 [06:08<20:25,  1.10it/s] 22%|██▏       | 391/1740 [06:09<20:23,  1.10it/s] 23%|██▎       | 392/1740 [06:10<20:21,  1.10it/s] 23%|██▎       | 393/1740 [06:11<20:20,  1.10it/s] 23%|██▎       | 394/1740 [06:12<20:19,  1.10it/s] 23%|██▎       | 395/1740 [06:13<20:18,  1.10it/s] 23%|██▎       | 396/1740 [06:14<20:17,  1.10it/s] 23%|██▎       | 397/1740 [06:14<20:15,  1.10it/s] 23%|██▎       | 398/1740 [06:15<20:15,  1.10it/s] 23%|██▎       | 399/1740 [06:16<20:13,  1.10it/s] 23%|██▎       | 400/1740 [06:17<20:13,  1.10it/s] 23%|██▎       | 401/1740 [06:18<20:11,  1.10it/s] 23%|██▎       | 402/1740 [06:19<20:11,  1.10it/s] 23%|██▎       | 403/1740 [06:20<20:05,  1.11it/s] 23%|██▎       | 404/1740 [06:21<20:03,  1.11it/s] 23%|██▎       | 405/1740 [06:22<20:04,  1.11it/s] 23%|██▎       | 406/1740 [06:23<20:05,  1.11it/s] 23%|██▎       | 407/1740 [06:24<20:04,  1.11it/s] 23%|██▎       | 408/1740 [06:24<20:04,  1.11it/s] 24%|██▎       | 409/1740 [06:25<20:05,  1.10it/s] 24%|██▎       | 410/1740 [06:26<20:03,  1.10it/s] 24%|██▎       | 411/1740 [06:27<20:03,  1.10it/s] 24%|██▎       | 412/1740 [06:28<20:03,  1.10it/s] 24%|██▎       | 413/1740 [06:29<20:02,  1.10it/s] 24%|██▍       | 414/1740 [06:30<20:01,  1.10it/s] 24%|██▍       | 415/1740 [06:31<19:59,  1.10it/s] 24%|██▍       | 416/1740 [06:32<19:58,  1.10it/s] 24%|██▍       | 417/1740 [06:33<19:57,  1.10it/s] 24%|██▍       | 418/1740 [06:33<19:56,  1.10it/s] 24%|██▍       | 419/1740 [06:34<19:56,  1.10it/s] 24%|██▍       | 420/1740 [06:35<19:55,  1.10it/s] 24%|██▍       | 421/1740 [06:36<19:51,  1.11it/s] 24%|██▍       | 422/1740 [06:37<20:46,  1.06it/s] 24%|██▍       | 423/1740 [06:38<20:30,  1.07it/s] 24%|██▍       | 424/1740 [06:39<20:18,  1.08it/s] 24%|██▍       | 425/1740 [06:40<20:10,  1.09it/s] 24%|██▍       | 426/1740 [06:41<20:03,  1.09it/s] 25%|██▍       | 427/1740 [06:42<19:59,  1.09it/s] 25%|██▍       | 428/1740 [06:43<19:55,  1.10it/s] 25%|██▍       | 429/1740 [06:44<19:53,  1.10it/s] 25%|██▍       | 430/1740 [06:44<19:50,  1.10it/s] 25%|██▍       | 431/1740 [06:45<19:49,  1.10it/s] 25%|██▍       | 432/1740 [06:46<19:47,  1.10it/s] 25%|██▍       | 433/1740 [06:47<19:45,  1.10it/s] 25%|██▍       | 434/1740 [06:48<19:45,  1.10it/s] 25%|██▌       | 435/1740 [06:49<19:43,  1.10it/s] 25%|██▌       | 436/1740 [06:50<19:43,  1.10it/s] 25%|██▌       | 437/1740 [06:51<19:42,  1.10it/s] 25%|██▌       | 438/1740 [06:52<19:41,  1.10it/s] 25%|██▌       | 439/1740 [06:53<19:40,  1.10it/s] 25%|██▌       | 440/1740 [06:54<19:38,  1.10it/s] 25%|██▌       | 441/1740 [06:54<19:37,  1.10it/s] 25%|██▌       | 442/1740 [06:55<19:37,  1.10it/s] 25%|██▌       | 443/1740 [06:56<19:36,  1.10it/s] 26%|██▌       | 444/1740 [06:57<19:36,  1.10it/s] 26%|██▌       | 445/1740 [06:58<19:35,  1.10it/s] 26%|██▌       | 446/1740 [06:59<19:33,  1.10it/s] 26%|██▌       | 447/1740 [07:00<19:29,  1.11it/s] 26%|██▌       | 448/1740 [07:01<19:26,  1.11it/s] 26%|██▌       | 449/1740 [07:02<19:26,  1.11it/s] 26%|██▌       | 450/1740 [07:03<19:26,  1.11it/s] 26%|██▌       | 451/1740 [07:04<19:25,  1.11it/s] 26%|██▌       | 452/1740 [07:04<19:25,  1.10it/s] 26%|██▌       | 453/1740 [07:05<20:23,  1.05it/s] 26%|██▌       | 454/1740 [07:06<20:04,  1.07it/s] 26%|██▌       | 455/1740 [07:07<19:52,  1.08it/s] 26%|██▌       | 456/1740 [07:08<19:43,  1.09it/s] 26%|██▋       | 457/1740 [07:09<19:37,  1.09it/s] 26%|██▋       | 458/1740 [07:10<19:26,  1.10it/s] 26%|██▋       | 459/1740 [07:11<19:22,  1.10it/s] 26%|██▋       | 460/1740 [07:12<19:20,  1.10it/s] 26%|██▋       | 461/1740 [07:13<19:19,  1.10it/s] 27%|██▋       | 462/1740 [07:14<19:17,  1.10it/s] 27%|██▋       | 463/1740 [07:15<19:18,  1.10it/s] 27%|██▋       | 464/1740 [07:15<16:26,  1.29it/s]{'eval_loss': 11.2039155960083, 'eval_precision': 0.6818181818181818, 'eval_recall': 0.5232558139534884, 'eval_f1': 0.5921052631578948, 'eval_accuracy': 0.9654312188168211, 'eval_runtime': 2.053, 'eval_samples_per_second': 50.171, 'eval_steps_per_second': 1.948, 'epoch': 3.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.92it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.80it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A                                                  
                                             [A 27%|██▋       | 464/1740 [07:17<16:26,  1.29it/s]
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A
                                             [A 27%|██▋       | 464/1740 [07:17<20:03,  1.06it/s]
[I 2025-09-09 13:02:57,414] Trial 11 pruned. 
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▃█▇
wandb:                 eval/f1 ▁▃██
wandb:               eval/loss ██▅▁
wandb:          eval/precision ▁▁█▄
wandb:             eval/recall ▁▃▆█
wandb:            eval/runtime ▇█▁▇
wandb: eval/samples_per_second ▂▁█▂
wandb:   eval/steps_per_second ▂▁█▂
wandb:             train/epoch ▁▃▆█
wandb:       train/global_step ▁▃▆█
wandb: 
wandb: Run summary:
wandb:           eval/accuracy 0.96222
wandb:                 eval/f1 0.59717
wandb:               eval/loss 8.11686
wandb:          eval/precision 0.5487
wandb:             eval/recall 0.65504
wandb:            eval/runtime 2.0749
wandb: eval/samples_per_second 49.642
wandb:   eval/steps_per_second 1.928
wandb:             train/epoch 4
wandb:       train/global_step 464
wandb: 
wandb: 🚀 View run sparkling-silence-716 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/0clzkshb
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250909_125539-0clzkshb/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_130300-5m2fo2a3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-serenity-717
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/5m2fo2a3
{'eval_loss': 8.11685848236084, 'eval_precision': 0.5487012987012987, 'eval_recall': 0.6550387596899225, 'eval_f1': 0.5971731448763251, 'eval_accuracy': 0.962223806129722, 'eval_runtime': 2.0749, 'eval_samples_per_second': 49.642, 'eval_steps_per_second': 1.928, 'epoch': 4.0}
  0%|          | 0/1740 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/1740 [00:00<26:38,  1.09it/s]  0%|          | 2/1740 [00:01<26:22,  1.10it/s]  0%|          | 3/1740 [00:02<26:19,  1.10it/s]  0%|          | 4/1740 [00:03<26:19,  1.10it/s]  0%|          | 5/1740 [00:04<26:19,  1.10it/s]  0%|          | 6/1740 [00:05<26:17,  1.10it/s]  0%|          | 7/1740 [00:06<26:18,  1.10it/s]  0%|          | 8/1740 [00:07<26:16,  1.10it/s]  1%|          | 9/1740 [00:08<26:15,  1.10it/s]  1%|          | 10/1740 [00:09<26:15,  1.10it/s]  1%|          | 11/1740 [00:10<26:11,  1.10it/s]  1%|          | 12/1740 [00:10<26:03,  1.11it/s]  1%|          | 13/1740 [00:11<26:05,  1.10it/s]  1%|          | 14/1740 [00:12<26:06,  1.10it/s]  1%|          | 15/1740 [00:13<26:06,  1.10it/s]  1%|          | 16/1740 [00:14<26:06,  1.10it/s]  1%|          | 17/1740 [00:15<26:01,  1.10it/s]  1%|          | 18/1740 [00:16<25:57,  1.11it/s]  1%|          | 19/1740 [00:17<25:58,  1.10it/s]  1%|          | 20/1740 [00:18<26:00,  1.10it/s]  1%|          | 21/1740 [00:19<26:00,  1.10it/s]  1%|▏         | 22/1740 [00:19<25:58,  1.10it/s]  1%|▏         | 23/1740 [00:20<25:51,  1.11it/s]  1%|▏         | 24/1740 [00:21<25:54,  1.10it/s]  1%|▏         | 25/1740 [00:22<25:54,  1.10it/s]  1%|▏         | 26/1740 [00:23<25:55,  1.10it/s]  2%|▏         | 27/1740 [00:24<25:55,  1.10it/s]  2%|▏         | 28/1740 [00:25<25:55,  1.10it/s]  2%|▏         | 29/1740 [00:26<25:55,  1.10it/s]  2%|▏         | 30/1740 [00:27<25:54,  1.10it/s]  2%|▏         | 31/1740 [00:28<27:20,  1.04it/s]  2%|▏         | 32/1740 [00:29<26:54,  1.06it/s]  2%|▏         | 33/1740 [00:30<26:34,  1.07it/s]  2%|▏         | 34/1740 [00:31<26:21,  1.08it/s]  2%|▏         | 35/1740 [00:31<26:10,  1.09it/s]  2%|▏         | 36/1740 [00:32<26:04,  1.09it/s]  2%|▏         | 37/1740 [00:33<25:59,  1.09it/s]  2%|▏         | 38/1740 [00:34<25:55,  1.09it/s]  2%|▏         | 39/1740 [00:35<25:52,  1.10it/s]  2%|▏         | 40/1740 [00:36<25:49,  1.10it/s]  2%|▏         | 41/1740 [00:37<25:46,  1.10it/s]  2%|▏         | 42/1740 [00:38<25:45,  1.10it/s]  2%|▏         | 43/1740 [00:39<25:44,  1.10it/s]  3%|▎         | 44/1740 [00:40<25:42,  1.10it/s]  3%|▎         | 45/1740 [00:41<25:42,  1.10it/s]  3%|▎         | 46/1740 [00:41<25:39,  1.10it/s]  3%|▎         | 47/1740 [00:42<25:38,  1.10it/s]  3%|▎         | 48/1740 [00:43<25:38,  1.10it/s]  3%|▎         | 49/1740 [00:44<25:37,  1.10it/s]  3%|▎         | 50/1740 [00:45<25:37,  1.10it/s]  3%|▎         | 51/1740 [00:46<25:36,  1.10it/s]  3%|▎         | 52/1740 [00:47<25:34,  1.10it/s]  3%|▎         | 53/1740 [00:48<25:35,  1.10it/s]  3%|▎         | 54/1740 [00:49<25:33,  1.10it/s]  3%|▎         | 55/1740 [00:50<25:31,  1.10it/s]  3%|▎         | 56/1740 [00:51<25:32,  1.10it/s]  3%|▎         | 57/1740 [00:52<26:45,  1.05it/s]  3%|▎         | 58/1740 [00:53<26:21,  1.06it/s]  3%|▎         | 59/1740 [00:53<26:05,  1.07it/s]  3%|▎         | 60/1740 [00:54<25:53,  1.08it/s]  4%|▎         | 61/1740 [00:55<25:44,  1.09it/s]  4%|▎         | 62/1740 [00:56<25:38,  1.09it/s]  4%|▎         | 63/1740 [00:57<25:33,  1.09it/s]  4%|▎         | 64/1740 [00:58<25:30,  1.10it/s]  4%|▎         | 65/1740 [00:59<25:26,  1.10it/s]  4%|▍         | 66/1740 [01:00<25:25,  1.10it/s]  4%|▍         | 67/1740 [01:01<25:23,  1.10it/s]  4%|▍         | 68/1740 [01:02<25:21,  1.10it/s]  4%|▍         | 69/1740 [01:03<25:19,  1.10it/s]  4%|▍         | 70/1740 [01:03<25:18,  1.10it/s]  4%|▍         | 71/1740 [01:04<25:18,  1.10it/s]  4%|▍         | 72/1740 [01:05<25:18,  1.10it/s]  4%|▍         | 73/1740 [01:06<25:15,  1.10it/s]  4%|▍         | 74/1740 [01:07<25:16,  1.10it/s]  4%|▍         | 75/1740 [01:08<25:15,  1.10it/s]  4%|▍         | 76/1740 [01:09<25:13,  1.10it/s]  4%|▍         | 77/1740 [01:10<25:09,  1.10it/s]  4%|▍         | 78/1740 [01:11<25:05,  1.10it/s]  5%|▍         | 79/1740 [01:12<25:06,  1.10it/s]  5%|▍         | 80/1740 [01:13<25:07,  1.10it/s]  5%|▍         | 81/1740 [01:13<25:06,  1.10it/s]  5%|▍         | 82/1740 [01:14<26:20,  1.05it/s]  5%|▍         | 83/1740 [01:15<25:50,  1.07it/s]  5%|▍         | 84/1740 [01:16<25:34,  1.08it/s]  5%|▍         | 85/1740 [01:17<25:25,  1.08it/s]  5%|▍         | 86/1740 [01:18<25:18,  1.09it/s]  5%|▌         | 87/1740 [01:19<25:12,  1.09it/s]  5%|▌         | 88/1740 [01:20<25:03,  1.10it/s]  5%|▌         | 89/1740 [01:21<24:59,  1.10it/s]  5%|▌         | 90/1740 [01:22<24:59,  1.10it/s]  5%|▌         | 91/1740 [01:23<24:59,  1.10it/s]  5%|▌         | 92/1740 [01:24<24:58,  1.10it/s]  5%|▌         | 93/1740 [01:24<24:57,  1.10it/s]  5%|▌         | 94/1740 [01:25<24:58,  1.10it/s]  5%|▌         | 95/1740 [01:26<24:57,  1.10it/s]  6%|▌         | 96/1740 [01:27<24:56,  1.10it/s]  6%|▌         | 97/1740 [01:28<24:53,  1.10it/s]  6%|▌         | 98/1740 [01:29<24:52,  1.10it/s]  6%|▌         | 99/1740 [01:30<24:47,  1.10it/s]  6%|▌         | 100/1740 [01:31<24:44,  1.10it/s]  6%|▌         | 101/1740 [01:32<24:45,  1.10it/s]  6%|▌         | 102/1740 [01:33<24:46,  1.10it/s]  6%|▌         | 103/1740 [01:34<24:45,  1.10it/s]  6%|▌         | 104/1740 [01:34<24:45,  1.10it/s]  6%|▌         | 105/1740 [01:35<24:45,  1.10it/s]  6%|▌         | 106/1740 [01:36<24:44,  1.10it/s]  6%|▌         | 107/1740 [01:37<24:44,  1.10it/s]  6%|▌         | 108/1740 [01:38<24:43,  1.10it/s]  6%|▋         | 109/1740 [01:39<24:40,  1.10it/s]  6%|▋         | 110/1740 [01:40<24:41,  1.10it/s]  6%|▋         | 111/1740 [01:41<24:41,  1.10it/s]  6%|▋         | 112/1740 [01:42<24:40,  1.10it/s]  6%|▋         | 113/1740 [01:43<24:40,  1.10it/s]  7%|▋         | 114/1740 [01:44<24:38,  1.10it/s]  7%|▋         | 115/1740 [01:44<24:37,  1.10it/s]  7%|▋         | 116/1740 [01:45<21:00,  1.29it/s]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.71it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.69it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.51it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                  
                                             [A  7%|▋         | 116/1740 [01:47<21:00,  1.29it/s]
100%|██████████| 4/4 [00:01<00:00,  2.51it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  7%|▋         | 117/1740 [01:51<1:05:50,  2.43s/it]  7%|▋         | 118/1740 [01:52<53:26,  1.98s/it]    7%|▋         | 119/1740 [01:53<44:47,  1.66s/it]  7%|▋         | 120/1740 [01:54<38:41,  1.43s/it]  7%|▋         | 121/1740 [01:55<34:28,  1.28s/it]  7%|▋         | 122/1740 [01:56<31:27,  1.17s/it]  7%|▋         | 123/1740 [01:57<30:35,  1.13s/it]  7%|▋         | 124/1740 [01:58<28:45,  1.07s/it]  7%|▋         | 125/1740 [01:59<27:27,  1.02s/it]  7%|▋         | 126/1740 [02:00<26:31,  1.01it/s]  7%|▋         | 127/1740 [02:00<25:47,  1.04it/s]  7%|▋         | 128/1740 [02:01<25:22,  1.06it/s]  7%|▋         | 129/1740 [02:02<25:04,  1.07it/s]  7%|▋         | 130/1740 [02:03<24:51,  1.08it/s]  8%|▊         | 131/1740 [02:04<24:42,  1.09it/s]  8%|▊         | 132/1740 [02:05<24:35,  1.09it/s]  8%|▊         | 133/1740 [02:06<24:30,  1.09it/s]  8%|▊         | 134/1740 [02:07<24:27,  1.09it/s]  8%|▊         | 135/1740 [02:08<24:24,  1.10it/s]  8%|▊         | 136/1740 [02:09<24:21,  1.10it/s]  8%|▊         | 137/1740 [02:10<24:18,  1.10it/s]  8%|▊         | 138/1740 [02:10<24:10,  1.10it/s]  8%|▊         | 139/1740 [02:11<24:11,  1.10it/s]  8%|▊         | 140/1740 [02:12<24:13,  1.10it/s]  8%|▊         | 141/1740 [02:13<24:11,  1.10it/s]  8%|▊         | 142/1740 [02:14<24:12,  1.10it/s]  8%|▊         | 143/1740 [02:15<24:07,  1.10it/s]  8%|▊         | 144/1740 [02:16<24:01,  1.11it/s]  8%|▊         | 145/1740 [02:17<24:03,  1.10it/s]  8%|▊         | 146/1740 [02:18<24:03,  1.10it/s]  8%|▊         | 147/1740 [02:19<24:05,  1.10it/s]  9%|▊         | 148/1740 [02:20<24:06,  1.10it/s]  9%|▊         | 149/1740 [02:20<24:05,  1.10it/s]  9%|▊         | 150/1740 [02:21<24:03,  1.10it/s]  9%|▊         | 151/1740 [02:22<24:03,  1.10it/s]  9%|▊         | 152/1740 [02:23<24:03,  1.10it/s]  9%|▉         | 153/1740 [02:24<24:03,  1.10it/s]  9%|▉         | 154/1740 [02:25<24:03,  1.10it/s]  9%|▉         | 155/1740 [02:26<24:01,  1.10it/s]  9%|▉         | 156/1740 [02:27<24:00,  1.10it/s]  9%|▉         | 157/1740 [02:28<24:00,  1.10it/s]  9%|▉         | 158/1740 [02:29<23:59,  1.10it/s]  9%|▉         | 159/1740 [02:30<23:56,  1.10it/s]  9%|▉         | 160/1740 [02:30<23:50,  1.10it/s]  9%|▉         | 161/1740 [02:31<23:51,  1.10it/s]  9%|▉         | 162/1740 [02:32<23:51,  1.10it/s]  9%|▉         | 163/1740 [02:33<23:51,  1.10it/s]  9%|▉         | 164/1740 [02:34<23:50,  1.10it/s]  9%|▉         | 165/1740 [02:35<23:50,  1.10it/s] 10%|▉         | 166/1740 [02:36<23:50,  1.10it/s] 10%|▉         | 167/1740 [02:37<23:50,  1.10it/s] 10%|▉         | 168/1740 [02:38<23:49,  1.10it/s] 10%|▉         | 169/1740 [02:39<23:48,  1.10it/s] 10%|▉         | 170/1740 [02:40<23:46,  1.10it/s] 10%|▉         | 171/1740 [02:40<23:38,  1.11it/s] 10%|▉         | 172/1740 [02:41<23:40,  1.10it/s] 10%|▉         | 173/1740 [02:42<23:41,  1.10it/s] 10%|█         | 174/1740 [02:43<24:51,  1.05it/s] 10%|█         | 175/1740 [02:44<24:30,  1.06it/s] 10%|█         | 176/1740 [02:45<24:14,  1.07it/s] 10%|█         | 177/1740 [02:46<24:03,  1.08it/s] 10%|█         | 178/1740 [02:47<23:56,  1.09it/s] 10%|█         | 179/1740 [02:48<23:50,  1.09it/s] 10%|█         | 180/1740 [02:49<23:46,  1.09it/s] 10%|█         | 181/1740 [02:50<23:43,  1.10it/s] 10%|█         | 182/1740 [02:51<23:40,  1.10it/s] 11%|█         | 183/1740 [02:51<23:38,  1.10it/s] 11%|█         | 184/1740 [02:52<23:37,  1.10it/s] 11%|█         | 185/1740 [02:53<23:35,  1.10it/s] 11%|█         | 186/1740 [02:54<23:34,  1.10it/s] 11%|█         | 187/1740 [02:55<23:32,  1.10it/s] 11%|█         | 188/1740 [02:56<23:32,  1.10it/s] 11%|█         | 189/1740 [02:57<23:31,  1.10it/s] 11%|█         | 190/1740 [02:58<23:30,  1.10it/s] 11%|█         | 191/1740 [02:59<23:30,  1.10it/s] 11%|█         | 192/1740 [03:00<23:29,  1.10it/s] 11%|█         | 193/1740 [03:01<23:27,  1.10it/s] 11%|█         | 194/1740 [03:01<23:27,  1.10it/s] 11%|█         | 195/1740 [03:02<23:25,  1.10it/s] 11%|█▏        | 196/1740 [03:03<23:23,  1.10it/s] 11%|█▏        | 197/1740 [03:04<23:23,  1.10it/s] 11%|█▏        | 198/1740 [03:05<23:20,  1.10it/s] 11%|█▏        | 199/1740 [03:06<23:19,  1.10it/s] 11%|█▏        | 200/1740 [03:07<23:19,  1.10it/s] 12%|█▏        | 201/1740 [03:08<23:18,  1.10it/s] 12%|█▏        | 202/1740 [03:09<23:18,  1.10it/s] 12%|█▏        | 203/1740 [03:10<23:16,  1.10it/s] 12%|█▏        | 204/1740 [03:11<23:15,  1.10it/s] 12%|█▏        | 205/1740 [03:11<23:15,  1.10it/s] 12%|█▏        | 206/1740 [03:12<23:15,  1.10it/s] 12%|█▏        | 207/1740 [03:13<23:13,  1.10it/s] 12%|█▏        | 208/1740 [03:14<23:13,  1.10it/s] 12%|█▏        | 209/1740 [03:15<23:07,  1.10it/s] 12%|█▏        | 210/1740 [03:16<23:04,  1.10it/s] 12%|█▏        | 211/1740 [03:17<23:05,  1.10it/s] 12%|█▏        | 212/1740 [03:18<23:05,  1.10it/s] 12%|█▏        | 213/1740 [03:19<24:13,  1.05it/s] 12%|█▏        | 214/1740 [03:20<23:53,  1.06it/s] 12%|█▏        | 215/1740 [03:21<23:38,  1.08it/s] 12%|█▏        | 216/1740 [03:22<23:28,  1.08it/s] 12%|█▏        | 217/1740 [03:23<23:21,  1.09it/s] 13%|█▎        | 218/1740 [03:23<23:15,  1.09it/s] 13%|█▎        | 219/1740 [03:24<23:11,  1.09it/s] 13%|█▎        | 220/1740 [03:25<23:06,  1.10it/s] 13%|█▎        | 221/1740 [03:26<23:06,  1.10it/s] 13%|█▎        | 222/1740 [03:27<23:03,  1.10it/s] 13%|█▎        | 223/1740 [03:28<23:01,  1.10it/s] 13%|█▎        | 224/1740 [03:29<23:00,  1.10it/s] 13%|█▎        | 225/1740 [03:30<22:58,  1.10it/s] 13%|█▎        | 226/1740 [03:31<22:56,  1.10it/s] 13%|█▎        | 227/1740 [03:32<22:57,  1.10it/s] 13%|█▎        | 228/1740 [03:33<22:56,  1.10it/s] 13%|█▎        | 229/1740 [03:33<22:54,  1.10it/s] 13%|█▎        | 230/1740 [03:34<22:53,  1.10it/s] 13%|█▎        | 231/1740 [03:35<22:52,  1.10it/s] 13%|█▎        | 232/1740 [03:36<19:29,  1.29it/s]{'eval_loss': 14.515652656555176, 'eval_precision': 0.37579617834394907, 'eval_recall': 0.22868217054263565, 'eval_f1': 0.28433734939759037, 'eval_accuracy': 0.9445830363506771, 'eval_runtime': 2.1455, 'eval_samples_per_second': 48.007, 'eval_steps_per_second': 1.864, 'epoch': 1.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.82it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.71it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.54it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                  
                                             [A 13%|█▎        | 232/1740 [03:38<19:29,  1.29it/s]
100%|██████████| 4/4 [00:01<00:00,  2.54it/s][A
                                             [A 13%|█▎        | 232/1740 [03:38<23:39,  1.06it/s]
[I 2025-09-09 13:06:39,435] Trial 12 pruned. 
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁█
wandb:                 eval/f1 ▁█
wandb:               eval/loss █▁
wandb:          eval/precision █▁
wandb:             eval/recall ▁█
wandb:            eval/runtime █▁
wandb: eval/samples_per_second ▁█
wandb:   eval/steps_per_second ▁█
wandb:             train/epoch ▁█
wandb:       train/global_step ▁█
wandb: 
wandb: Run summary:
wandb:           eval/accuracy 0.94886
wandb:                 eval/f1 0.31556
wandb:               eval/loss 13.91521
wandb:          eval/precision 0.36979
wandb:             eval/recall 0.27519
wandb:            eval/runtime 2.1307
wandb: eval/samples_per_second 48.342
wandb:   eval/steps_per_second 1.877
wandb:             train/epoch 2
wandb:       train/global_step 232
wandb: 
wandb: 🚀 View run vital-serenity-717 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/5m2fo2a3
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250909_130300-5m2fo2a3/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_130642-rx02njyv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-plasma-718
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/rx02njyv
{'eval_loss': 13.915210723876953, 'eval_precision': 0.3697916666666667, 'eval_recall': 0.2751937984496124, 'eval_f1': 0.31555555555555553, 'eval_accuracy': 0.9488595866001426, 'eval_runtime': 2.1307, 'eval_samples_per_second': 48.342, 'eval_steps_per_second': 1.877, 'epoch': 2.0}
  0%|          | 0/522 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/522 [00:01<10:02,  1.16s/it]  0%|          | 2/522 [00:02<09:59,  1.15s/it]  1%|          | 3/522 [00:03<09:56,  1.15s/it]  1%|          | 4/522 [00:04<09:55,  1.15s/it]  1%|          | 5/522 [00:05<09:53,  1.15s/it]  1%|          | 6/522 [00:06<09:52,  1.15s/it]  1%|▏         | 7/522 [00:08<09:50,  1.15s/it]  2%|▏         | 8/522 [00:09<09:49,  1.15s/it]  2%|▏         | 9/522 [00:10<09:48,  1.15s/it]  2%|▏         | 10/522 [00:11<09:47,  1.15s/it]  2%|▏         | 11/522 [00:12<09:46,  1.15s/it]  2%|▏         | 12/522 [00:13<09:44,  1.15s/it]  2%|▏         | 13/522 [00:14<09:43,  1.15s/it]  3%|▎         | 14/522 [00:16<09:42,  1.15s/it]  3%|▎         | 15/522 [00:17<09:41,  1.15s/it]  3%|▎         | 16/522 [00:18<09:40,  1.15s/it]  3%|▎         | 17/522 [00:19<09:39,  1.15s/it]  3%|▎         | 18/522 [00:20<09:38,  1.15s/it]  4%|▎         | 19/522 [00:21<09:37,  1.15s/it]  4%|▍         | 20/522 [00:22<09:36,  1.15s/it]  4%|▍         | 21/522 [00:24<09:34,  1.15s/it]  4%|▍         | 22/522 [00:25<09:33,  1.15s/it]  4%|▍         | 23/522 [00:26<09:32,  1.15s/it]  5%|▍         | 24/522 [00:27<09:31,  1.15s/it]  5%|▍         | 25/522 [00:28<09:30,  1.15s/it]  5%|▍         | 26/522 [00:29<09:28,  1.15s/it]  5%|▌         | 27/522 [00:30<09:27,  1.15s/it]  5%|▌         | 28/522 [00:32<09:26,  1.15s/it]  6%|▌         | 29/522 [00:33<09:16,  1.13s/it]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.74it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.71it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.61it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A  6%|▌         | 29/522 [00:35<09:16,  1.13s/it]
100%|██████████| 4/4 [00:01<00:00,  2.61it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  6%|▌         | 30/522 [00:41<26:27,  3.23s/it]  6%|▌         | 31/522 [00:42<21:17,  2.60s/it]  6%|▌         | 32/522 [00:43<17:40,  2.16s/it]  6%|▋         | 33/522 [00:44<15:09,  1.86s/it]  7%|▋         | 34/522 [00:45<13:22,  1.64s/it]  7%|▋         | 35/522 [00:47<12:08,  1.50s/it]  7%|▋         | 36/522 [00:48<11:15,  1.39s/it]  7%|▋         | 37/522 [00:49<10:38,  1.32s/it]  7%|▋         | 38/522 [00:50<10:12,  1.27s/it]  7%|▋         | 39/522 [00:51<09:54,  1.23s/it]  8%|▊         | 40/522 [00:52<09:40,  1.21s/it]  8%|▊         | 41/522 [00:53<09:31,  1.19s/it]  8%|▊         | 42/522 [00:55<09:23,  1.17s/it]  8%|▊         | 43/522 [00:56<09:18,  1.17s/it]  8%|▊         | 44/522 [00:57<09:14,  1.16s/it]  9%|▊         | 45/522 [00:58<09:11,  1.16s/it]  9%|▉         | 46/522 [00:59<09:08,  1.15s/it]  9%|▉         | 47/522 [01:00<09:06,  1.15s/it]  9%|▉         | 48/522 [01:01<09:05,  1.15s/it]  9%|▉         | 49/522 [01:03<09:03,  1.15s/it] 10%|▉         | 50/522 [01:04<09:02,  1.15s/it] 10%|▉         | 51/522 [01:05<09:00,  1.15s/it] 10%|▉         | 52/522 [01:06<08:59,  1.15s/it] 10%|█         | 53/522 [01:07<08:57,  1.15s/it] 10%|█         | 54/522 [01:08<08:56,  1.15s/it] 11%|█         | 55/522 [01:09<08:55,  1.15s/it] 11%|█         | 56/522 [01:11<08:54,  1.15s/it] 11%|█         | 57/522 [01:12<08:53,  1.15s/it] 11%|█         | 58/522 [01:13<08:44,  1.13s/it]{'eval_loss': 30.488483428955078, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9397719173200285, 'eval_runtime': 2.115, 'eval_samples_per_second': 48.701, 'eval_steps_per_second': 1.891, 'epoch': 1.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.86it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.79it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.31it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 11%|█         | 58/522 [01:15<08:44,  1.13s/it]
100%|██████████| 4/4 [00:01<00:00,  2.31it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 11%|█▏        | 59/522 [01:21<24:57,  3.23s/it] 11%|█▏        | 60/522 [01:22<20:04,  2.61s/it] 12%|█▏        | 61/522 [01:23<16:39,  2.17s/it] 12%|█▏        | 62/522 [01:24<14:16,  1.86s/it] 12%|█▏        | 63/522 [01:26<12:35,  1.65s/it] 12%|█▏        | 64/522 [01:27<11:24,  1.50s/it] 12%|█▏        | 65/522 [01:28<10:35,  1.39s/it] 13%|█▎        | 66/522 [01:29<10:00,  1.32s/it] 13%|█▎        | 67/522 [01:30<09:35,  1.27s/it] 13%|█▎        | 68/522 [01:31<09:17,  1.23s/it] 13%|█▎        | 69/522 [01:32<09:05,  1.20s/it] 13%|█▎        | 70/522 [01:34<08:56,  1.19s/it] 14%|█▎        | 71/522 [01:35<08:48,  1.17s/it] 14%|█▍        | 72/522 [01:36<08:43,  1.16s/it] 14%|█▍        | 73/522 [01:37<08:40,  1.16s/it] 14%|█▍        | 74/522 [01:38<08:37,  1.15s/it] 14%|█▍        | 75/522 [01:39<08:34,  1.15s/it] 15%|█▍        | 76/522 [01:40<08:32,  1.15s/it] 15%|█▍        | 77/522 [01:42<08:31,  1.15s/it] 15%|█▍        | 78/522 [01:43<08:29,  1.15s/it] 15%|█▌        | 79/522 [01:44<08:27,  1.15s/it] 15%|█▌        | 80/522 [01:45<08:26,  1.15s/it] 16%|█▌        | 81/522 [01:46<08:25,  1.15s/it] 16%|█▌        | 82/522 [01:47<08:24,  1.15s/it] 16%|█▌        | 83/522 [01:48<08:22,  1.15s/it] 16%|█▌        | 84/522 [01:50<08:21,  1.15s/it] 16%|█▋        | 85/522 [01:51<08:20,  1.15s/it] 16%|█▋        | 86/522 [01:52<08:19,  1.15s/it] 17%|█▋        | 87/522 [01:53<08:11,  1.13s/it]{'eval_loss': 15.686797142028809, 'eval_precision': 1.0, 'eval_recall': 0.011627906976744186, 'eval_f1': 0.022988505747126436, 'eval_accuracy': 0.9403064861012117, 'eval_runtime': 2.2188, 'eval_samples_per_second': 46.422, 'eval_steps_per_second': 1.803, 'epoch': 2.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.84it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.73it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.61it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 17%|█▋        | 87/522 [01:55<08:11,  1.13s/it]
100%|██████████| 4/4 [00:01<00:00,  2.61it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 17%|█▋        | 88/522 [02:01<21:59,  3.04s/it] 17%|█▋        | 89/522 [02:02<17:50,  2.47s/it] 17%|█▋        | 90/522 [02:03<14:55,  2.07s/it] 17%|█▋        | 91/522 [02:04<12:53,  1.79s/it] 18%|█▊        | 92/522 [02:05<11:28,  1.60s/it] 18%|█▊        | 93/522 [02:06<10:27,  1.46s/it] 18%|█▊        | 94/522 [02:07<09:45,  1.37s/it] 18%|█▊        | 95/522 [02:09<09:15,  1.30s/it] 18%|█▊        | 96/522 [02:10<08:54,  1.25s/it] 19%|█▊        | 97/522 [02:11<08:39,  1.22s/it] 19%|█▉        | 98/522 [02:12<08:28,  1.20s/it] 19%|█▉        | 99/522 [02:13<08:39,  1.23s/it] 19%|█▉        | 100/522 [02:14<08:27,  1.20s/it] 19%|█▉        | 101/522 [02:16<08:19,  1.19s/it] 20%|█▉        | 102/522 [02:17<08:12,  1.17s/it] 20%|█▉        | 103/522 [02:18<08:07,  1.16s/it] 20%|█▉        | 104/522 [02:19<08:04,  1.16s/it] 20%|██        | 105/522 [02:20<08:01,  1.15s/it] 20%|██        | 106/522 [02:21<07:58,  1.15s/it] 20%|██        | 107/522 [02:22<07:56,  1.15s/it] 21%|██        | 108/522 [02:24<07:55,  1.15s/it] 21%|██        | 109/522 [02:25<07:53,  1.15s/it] 21%|██        | 110/522 [02:26<07:52,  1.15s/it] 21%|██▏       | 111/522 [02:27<07:51,  1.15s/it] 21%|██▏       | 112/522 [02:28<07:49,  1.15s/it] 22%|██▏       | 113/522 [02:29<07:48,  1.15s/it] 22%|██▏       | 114/522 [02:30<07:47,  1.15s/it] 22%|██▏       | 115/522 [02:32<07:46,  1.15s/it] 22%|██▏       | 116/522 [02:33<07:38,  1.13s/it]{'eval_loss': 11.696290969848633, 'eval_precision': 0.5048543689320388, 'eval_recall': 0.20155038759689922, 'eval_f1': 0.2880886426592798, 'eval_accuracy': 0.9483250178189594, 'eval_runtime': 2.0854, 'eval_samples_per_second': 49.391, 'eval_steps_per_second': 1.918, 'epoch': 3.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.86it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.71it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.61it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                 
                                             [A 22%|██▏       | 116/522 [02:35<07:38,  1.13s/it]
100%|██████████| 4/4 [00:01<00:00,  2.61it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 22%|██▏       | 117/522 [02:40<20:57,  3.10s/it] 23%|██▎       | 118/522 [02:42<16:56,  2.52s/it] 23%|██▎       | 119/522 [02:43<14:08,  2.11s/it] 23%|██▎       | 120/522 [02:44<12:10,  1.82s/it] 23%|██▎       | 121/522 [02:45<10:48,  1.62s/it] 23%|██▎       | 122/522 [02:46<09:49,  1.47s/it] 24%|██▎       | 123/522 [02:47<09:08,  1.38s/it] 24%|██▍       | 124/522 [02:48<08:39,  1.31s/it] 24%|██▍       | 125/522 [02:50<08:19,  1.26s/it] 24%|██▍       | 126/522 [02:51<08:22,  1.27s/it] 24%|██▍       | 127/522 [02:52<08:06,  1.23s/it] 25%|██▍       | 128/522 [02:53<07:55,  1.21s/it] 25%|██▍       | 129/522 [02:54<07:46,  1.19s/it] 25%|██▍       | 130/522 [02:55<07:40,  1.17s/it] 25%|██▌       | 131/522 [02:57<07:35,  1.17s/it] 25%|██▌       | 132/522 [02:58<07:32,  1.16s/it] 25%|██▌       | 133/522 [02:59<07:29,  1.16s/it] 26%|██▌       | 134/522 [03:00<07:27,  1.15s/it] 26%|██▌       | 135/522 [03:01<07:25,  1.15s/it] 26%|██▌       | 136/522 [03:02<07:23,  1.15s/it] 26%|██▌       | 137/522 [03:03<07:22,  1.15s/it] 26%|██▋       | 138/522 [03:05<07:20,  1.15s/it] 27%|██▋       | 139/522 [03:06<07:19,  1.15s/it] 27%|██▋       | 140/522 [03:07<07:18,  1.15s/it] 27%|██▋       | 141/522 [03:08<07:16,  1.15s/it] 27%|██▋       | 142/522 [03:09<07:15,  1.15s/it] 27%|██▋       | 143/522 [03:10<07:14,  1.15s/it] 28%|██▊       | 144/522 [03:11<07:13,  1.15s/it] 28%|██▊       | 145/522 [03:13<07:05,  1.13s/it]{'eval_loss': 8.843897819519043, 'eval_precision': 0.35986159169550175, 'eval_recall': 0.40310077519379844, 'eval_f1': 0.3802559414990859, 'eval_accuracy': 0.952423378474697, 'eval_runtime': 2.1132, 'eval_samples_per_second': 48.742, 'eval_steps_per_second': 1.893, 'epoch': 4.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.85it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.78it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.71it/s][A                                                 
                                             [A 28%|██▊       | 145/522 [03:15<07:05,  1.13s/it]
100%|██████████| 4/4 [00:01<00:00,  2.71it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 28%|██▊       | 146/522 [03:20<19:40,  3.14s/it] 28%|██▊       | 147/522 [03:22<15:53,  2.54s/it] 28%|██▊       | 148/522 [03:23<13:13,  2.12s/it] 29%|██▊       | 149/522 [03:24<11:22,  1.83s/it] 29%|██▊       | 150/522 [03:25<10:04,  1.62s/it] 29%|██▉       | 151/522 [03:26<09:09,  1.48s/it] 29%|██▉       | 152/522 [03:27<08:30,  1.38s/it] 29%|██▉       | 153/522 [03:28<08:02,  1.31s/it] 30%|██▉       | 154/522 [03:30<07:43,  1.26s/it] 30%|██▉       | 155/522 [03:31<07:29,  1.23s/it] 30%|██▉       | 156/522 [03:32<07:19,  1.20s/it] 30%|███       | 157/522 [03:33<07:12,  1.18s/it] 30%|███       | 158/522 [03:34<07:06,  1.17s/it] 30%|███       | 159/522 [03:35<07:18,  1.21s/it] 31%|███       | 160/522 [03:37<07:10,  1.19s/it] 31%|███       | 161/522 [03:38<07:04,  1.18s/it] 31%|███       | 162/522 [03:39<07:00,  1.17s/it] 31%|███       | 163/522 [03:40<06:56,  1.16s/it] 31%|███▏      | 164/522 [03:41<06:53,  1.16s/it] 32%|███▏      | 165/522 [03:42<06:51,  1.15s/it] 32%|███▏      | 166/522 [03:43<06:49,  1.15s/it] 32%|███▏      | 167/522 [03:45<06:47,  1.15s/it] 32%|███▏      | 168/522 [03:46<06:46,  1.15s/it] 32%|███▏      | 169/522 [03:47<06:45,  1.15s/it] 33%|███▎      | 170/522 [03:48<06:43,  1.15s/it] 33%|███▎      | 171/522 [03:49<06:42,  1.15s/it] 33%|███▎      | 172/522 [03:50<06:41,  1.15s/it] 33%|███▎      | 173/522 [03:51<06:40,  1.15s/it] 33%|███▎      | 174/522 [03:53<06:33,  1.13s/it]{'eval_loss': 8.03744888305664, 'eval_precision': 0.6363636363636364, 'eval_recall': 0.5155038759689923, 'eval_f1': 0.5695931477516061, 'eval_accuracy': 0.964896650035638, 'eval_runtime': 2.0578, 'eval_samples_per_second': 50.052, 'eval_steps_per_second': 1.944, 'epoch': 5.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.87it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.72it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.54it/s][A                                                 
                                             [A 33%|███▎      | 174/522 [03:55<06:33,  1.13s/it]
100%|██████████| 4/4 [00:01<00:00,  2.54it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 34%|███▎      | 175/522 [04:00<17:37,  3.05s/it] 34%|███▎      | 176/522 [04:01<14:17,  2.48s/it] 34%|███▍      | 177/522 [04:02<11:57,  2.08s/it] 34%|███▍      | 178/522 [04:04<10:18,  1.80s/it] 34%|███▍      | 179/522 [04:05<09:09,  1.60s/it] 34%|███▍      | 180/522 [04:06<08:20,  1.46s/it] 35%|███▍      | 181/522 [04:07<07:46,  1.37s/it] 35%|███▍      | 182/522 [04:08<07:22,  1.30s/it] 35%|███▌      | 183/522 [04:09<07:05,  1.25s/it] 35%|███▌      | 184/522 [04:10<06:52,  1.22s/it] 35%|███▌      | 185/522 [04:12<06:43,  1.20s/it] 36%|███▌      | 186/522 [04:13<06:37,  1.18s/it] 36%|███▌      | 187/522 [04:14<06:32,  1.17s/it] 36%|███▌      | 188/522 [04:15<06:28,  1.16s/it] 36%|███▌      | 189/522 [04:16<06:40,  1.20s/it] 36%|███▋      | 190/522 [04:17<06:33,  1.19s/it] 37%|███▋      | 191/522 [04:19<06:28,  1.17s/it] 37%|███▋      | 192/522 [04:20<06:24,  1.17s/it] 37%|███▋      | 193/522 [04:21<06:21,  1.16s/it] 37%|███▋      | 194/522 [04:22<06:18,  1.16s/it] 37%|███▋      | 195/522 [04:23<06:16,  1.15s/it] 38%|███▊      | 196/522 [04:24<06:15,  1.15s/it] 38%|███▊      | 197/522 [04:25<06:13,  1.15s/it] 38%|███▊      | 198/522 [04:27<06:12,  1.15s/it] 38%|███▊      | 199/522 [04:28<06:10,  1.15s/it] 38%|███▊      | 200/522 [04:29<06:09,  1.15s/it] 39%|███▊      | 201/522 [04:30<06:09,  1.15s/it] 39%|███▊      | 202/522 [04:31<06:09,  1.15s/it] 39%|███▉      | 203/522 [04:32<06:02,  1.14s/it]{'eval_loss': 7.013094902038574, 'eval_precision': 0.5214521452145214, 'eval_recall': 0.6124031007751938, 'eval_f1': 0.5632798573975044, 'eval_accuracy': 0.9654312188168211, 'eval_runtime': 2.1452, 'eval_samples_per_second': 48.014, 'eval_steps_per_second': 1.865, 'epoch': 6.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.83it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.77it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.56it/s][A                                                 
                                             [A 39%|███▉      | 203/522 [04:34<06:02,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.56it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 39%|███▉      | 204/522 [04:40<16:38,  3.14s/it] 39%|███▉      | 205/522 [04:41<13:26,  2.54s/it] 39%|███▉      | 206/522 [04:42<11:11,  2.13s/it] 40%|███▉      | 207/522 [04:44<09:37,  1.83s/it] 40%|███▉      | 208/522 [04:45<08:31,  1.63s/it] 40%|████      | 209/522 [04:46<07:45,  1.49s/it] 40%|████      | 210/522 [04:47<07:12,  1.39s/it] 40%|████      | 211/522 [04:48<06:49,  1.32s/it] 41%|████      | 212/522 [04:49<06:33,  1.27s/it] 41%|████      | 213/522 [04:50<06:20,  1.23s/it] 41%|████      | 214/522 [04:52<06:12,  1.21s/it] 41%|████      | 215/522 [04:53<06:06,  1.19s/it] 41%|████▏     | 216/522 [04:54<06:01,  1.18s/it] 42%|████▏     | 217/522 [04:55<05:57,  1.17s/it] 42%|████▏     | 218/522 [04:56<05:54,  1.17s/it] 42%|████▏     | 219/522 [04:57<05:52,  1.16s/it] 42%|████▏     | 220/522 [04:59<05:50,  1.16s/it] 42%|████▏     | 221/522 [05:00<05:48,  1.16s/it] 43%|████▎     | 222/522 [05:01<05:46,  1.16s/it] 43%|████▎     | 223/522 [05:02<05:45,  1.16s/it] 43%|████▎     | 224/522 [05:03<05:44,  1.15s/it] 43%|████▎     | 225/522 [05:04<05:42,  1.15s/it] 43%|████▎     | 226/522 [05:05<05:41,  1.15s/it] 43%|████▎     | 227/522 [05:07<05:40,  1.15s/it] 44%|████▎     | 228/522 [05:08<05:39,  1.15s/it] 44%|████▍     | 229/522 [05:09<05:50,  1.20s/it] 44%|████▍     | 230/522 [05:10<05:45,  1.18s/it] 44%|████▍     | 231/522 [05:11<05:41,  1.18s/it] 44%|████▍     | 232/522 [05:12<05:33,  1.15s/it]{'eval_loss': 5.390573024749756, 'eval_precision': 0.5864406779661017, 'eval_recall': 0.6705426356589147, 'eval_f1': 0.6256781193490054, 'eval_accuracy': 0.9722024233784747, 'eval_runtime': 2.1092, 'eval_samples_per_second': 48.833, 'eval_steps_per_second': 1.896, 'epoch': 7.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.71it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.73it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.56it/s][A                                                 
                                             [A 44%|████▍     | 232/522 [05:15<05:33,  1.15s/it]
100%|██████████| 4/4 [00:01<00:00,  2.56it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 45%|████▍     | 233/522 [05:20<15:12,  3.16s/it] 45%|████▍     | 234/522 [05:21<12:16,  2.56s/it] 45%|████▌     | 235/522 [05:23<10:12,  2.14s/it] 45%|████▌     | 236/522 [05:24<08:46,  1.84s/it] 45%|████▌     | 237/522 [05:25<07:45,  1.63s/it] 46%|████▌     | 238/522 [05:26<07:02,  1.49s/it] 46%|████▌     | 239/522 [05:27<06:32,  1.39s/it] 46%|████▌     | 240/522 [05:28<06:11,  1.32s/it] 46%|████▌     | 241/522 [05:30<05:56,  1.27s/it] 46%|████▋     | 242/522 [05:31<05:45,  1.23s/it] 47%|████▋     | 243/522 [05:32<05:37,  1.21s/it] 47%|████▋     | 244/522 [05:33<05:31,  1.19s/it] 47%|████▋     | 245/522 [05:34<05:27,  1.18s/it] 47%|████▋     | 246/522 [05:35<05:23,  1.17s/it] 47%|████▋     | 247/522 [05:36<05:20,  1.17s/it] 48%|████▊     | 248/522 [05:38<05:40,  1.24s/it] 48%|████▊     | 249/522 [05:39<05:32,  1.22s/it] 48%|████▊     | 250/522 [05:40<05:25,  1.20s/it] 48%|████▊     | 251/522 [05:41<05:21,  1.18s/it] 48%|████▊     | 252/522 [05:42<05:17,  1.18s/it] 48%|████▊     | 253/522 [05:44<05:26,  1.21s/it] 49%|████▊     | 254/522 [05:45<05:20,  1.20s/it] 49%|████▉     | 255/522 [05:46<05:16,  1.18s/it] 49%|████▉     | 256/522 [05:47<05:12,  1.17s/it] 49%|████▉     | 257/522 [05:48<05:09,  1.17s/it] 49%|████▉     | 258/522 [05:50<05:06,  1.16s/it] 50%|████▉     | 259/522 [05:51<05:04,  1.16s/it] 50%|████▉     | 260/522 [05:52<05:03,  1.16s/it] 50%|█████     | 261/522 [05:53<04:57,  1.14s/it]{'eval_loss': 4.939727783203125, 'eval_precision': 0.6678445229681979, 'eval_recall': 0.7325581395348837, 'eval_f1': 0.6987060998151571, 'eval_accuracy': 0.9764789736279401, 'eval_runtime': 2.1093, 'eval_samples_per_second': 48.832, 'eval_steps_per_second': 1.896, 'epoch': 8.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.88it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.80it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A                                                 
                                             [A 50%|█████     | 261/522 [05:55<04:57,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 50%|█████     | 262/522 [06:00<12:45,  2.94s/it] 50%|█████     | 263/522 [06:01<10:23,  2.41s/it] 51%|█████     | 264/522 [06:02<08:43,  2.03s/it] 51%|█████     | 265/522 [06:04<07:34,  1.77s/it] 51%|█████     | 266/522 [06:05<06:45,  1.58s/it] 51%|█████     | 267/522 [06:06<06:10,  1.45s/it] 51%|█████▏    | 268/522 [06:07<05:46,  1.36s/it] 52%|█████▏    | 269/522 [06:08<05:29,  1.30s/it] 52%|█████▏    | 270/522 [06:09<05:16,  1.26s/it] 52%|█████▏    | 271/522 [06:10<05:07,  1.23s/it] 52%|█████▏    | 272/522 [06:12<05:00,  1.20s/it] 52%|█████▏    | 273/522 [06:13<04:56,  1.19s/it] 52%|█████▏    | 274/522 [06:14<04:52,  1.18s/it] 53%|█████▎    | 275/522 [06:15<04:49,  1.17s/it] 53%|█████▎    | 276/522 [06:16<04:46,  1.17s/it] 53%|█████▎    | 277/522 [06:17<04:44,  1.16s/it] 53%|█████▎    | 278/522 [06:19<04:42,  1.16s/it] 53%|█████▎    | 279/522 [06:20<04:41,  1.16s/it] 54%|█████▎    | 280/522 [06:21<04:39,  1.16s/it] 54%|█████▍    | 281/522 [06:22<04:38,  1.15s/it] 54%|█████▍    | 282/522 [06:23<04:36,  1.15s/it] 54%|█████▍    | 283/522 [06:24<04:35,  1.15s/it] 54%|█████▍    | 284/522 [06:25<04:34,  1.15s/it] 55%|█████▍    | 285/522 [06:27<04:33,  1.15s/it] 55%|█████▍    | 286/522 [06:28<04:32,  1.15s/it] 55%|█████▍    | 287/522 [06:29<04:31,  1.15s/it] 55%|█████▌    | 288/522 [06:30<04:29,  1.15s/it] 55%|█████▌    | 289/522 [06:31<04:28,  1.15s/it] 56%|█████▌    | 290/522 [06:32<04:23,  1.14s/it]{'eval_loss': 4.63135290145874, 'eval_precision': 0.6770833333333334, 'eval_recall': 0.7558139534883721, 'eval_f1': 0.7142857142857142, 'eval_accuracy': 0.9768353528153956, 'eval_runtime': 2.0785, 'eval_samples_per_second': 49.554, 'eval_steps_per_second': 1.924, 'epoch': 9.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.85it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.42it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.35it/s][A                                                 
                                             [A 56%|█████▌    | 290/522 [06:35<04:23,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.35it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 56%|█████▌    | 291/522 [06:39<10:59,  2.86s/it] 56%|█████▌    | 292/522 [06:40<08:59,  2.34s/it] 56%|█████▌    | 293/522 [06:42<07:35,  1.99s/it] 56%|█████▋    | 294/522 [06:43<06:36,  1.74s/it] 57%|█████▋    | 295/522 [06:44<05:54,  1.56s/it] 57%|█████▋    | 296/522 [06:45<05:25,  1.44s/it] 57%|█████▋    | 297/522 [06:46<05:04,  1.35s/it] 57%|█████▋    | 298/522 [06:47<04:49,  1.29s/it] 57%|█████▋    | 299/522 [06:48<04:39,  1.25s/it] 57%|█████▋    | 300/522 [06:50<04:31,  1.22s/it] 58%|█████▊    | 301/522 [06:51<04:25,  1.20s/it] 58%|█████▊    | 302/522 [06:52<04:21,  1.19s/it] 58%|█████▊    | 303/522 [06:53<04:17,  1.18s/it] 58%|█████▊    | 304/522 [06:54<04:14,  1.17s/it] 58%|█████▊    | 305/522 [06:55<04:12,  1.16s/it] 59%|█████▊    | 306/522 [06:56<04:10,  1.16s/it] 59%|█████▉    | 307/522 [06:58<04:09,  1.16s/it] 59%|█████▉    | 308/522 [06:59<04:07,  1.16s/it] 59%|█████▉    | 309/522 [07:00<04:06,  1.16s/it] 59%|█████▉    | 310/522 [07:01<04:04,  1.15s/it] 60%|█████▉    | 311/522 [07:02<04:03,  1.15s/it] 60%|█████▉    | 312/522 [07:03<04:02,  1.15s/it] 60%|█████▉    | 313/522 [07:05<04:01,  1.15s/it] 60%|██████    | 314/522 [07:06<03:59,  1.15s/it] 60%|██████    | 315/522 [07:07<03:58,  1.15s/it] 61%|██████    | 316/522 [07:08<03:57,  1.15s/it] 61%|██████    | 317/522 [07:09<03:56,  1.15s/it] 61%|██████    | 318/522 [07:10<03:55,  1.15s/it] 61%|██████    | 319/522 [07:11<03:50,  1.14s/it]{'eval_loss': 4.168488025665283, 'eval_precision': 0.7381818181818182, 'eval_recall': 0.7868217054263565, 'eval_f1': 0.7617260787992496, 'eval_accuracy': 0.9803991446899502, 'eval_runtime': 2.2201, 'eval_samples_per_second': 46.394, 'eval_steps_per_second': 1.802, 'epoch': 10.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.90it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.80it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.63it/s][A                                                 
                                             [A 61%|██████    | 319/522 [07:14<03:50,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.63it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 61%|██████▏   | 320/522 [07:19<10:01,  2.98s/it] 61%|██████▏   | 321/522 [07:20<08:08,  2.43s/it] 62%|██████▏   | 322/522 [07:21<06:49,  2.05s/it] 62%|██████▏   | 323/522 [07:22<05:53,  1.78s/it] 62%|██████▏   | 324/522 [07:23<05:14,  1.59s/it] 62%|██████▏   | 325/522 [07:24<04:47,  1.46s/it] 62%|██████▏   | 326/522 [07:26<04:28,  1.37s/it] 63%|██████▎   | 327/522 [07:27<04:14,  1.30s/it] 63%|██████▎   | 328/522 [07:28<04:04,  1.26s/it] 63%|██████▎   | 329/522 [07:29<03:56,  1.23s/it] 63%|██████▎   | 330/522 [07:30<03:51,  1.20s/it] 63%|██████▎   | 331/522 [07:31<03:47,  1.19s/it] 64%|██████▎   | 332/522 [07:33<03:44,  1.18s/it] 64%|██████▍   | 333/522 [07:34<03:41,  1.17s/it] 64%|██████▍   | 334/522 [07:35<03:39,  1.17s/it] 64%|██████▍   | 335/522 [07:36<03:37,  1.16s/it] 64%|██████▍   | 336/522 [07:37<03:35,  1.16s/it] 65%|██████▍   | 337/522 [07:38<03:34,  1.16s/it] 65%|██████▍   | 338/522 [07:39<03:32,  1.16s/it] 65%|██████▍   | 339/522 [07:41<03:31,  1.16s/it] 65%|██████▌   | 340/522 [07:42<03:30,  1.15s/it] 65%|██████▌   | 341/522 [07:43<03:28,  1.15s/it] 66%|██████▌   | 342/522 [07:44<03:27,  1.15s/it] 66%|██████▌   | 343/522 [07:45<03:26,  1.15s/it] 66%|██████▌   | 344/522 [07:46<03:25,  1.15s/it] 66%|██████▌   | 345/522 [07:48<03:24,  1.15s/it] 66%|██████▋   | 346/522 [07:49<03:23,  1.15s/it] 66%|██████▋   | 347/522 [07:50<03:22,  1.15s/it] 67%|██████▋   | 348/522 [07:51<03:17,  1.14s/it]{'eval_loss': 3.957627058029175, 'eval_precision': 0.7683397683397684, 'eval_recall': 0.7713178294573644, 'eval_f1': 0.769825918762089, 'eval_accuracy': 0.9821810406272273, 'eval_runtime': 2.2228, 'eval_samples_per_second': 46.339, 'eval_steps_per_second': 1.8, 'epoch': 11.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.87it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.80it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.64it/s][A                                                 
                                             [A 67%|██████▋   | 348/522 [07:53<03:17,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.64it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 67%|██████▋   | 349/522 [07:59<08:50,  3.07s/it] 67%|██████▋   | 350/522 [08:00<07:08,  2.49s/it] 67%|██████▋   | 351/522 [08:01<05:57,  2.09s/it] 67%|██████▋   | 352/522 [08:02<05:07,  1.81s/it] 68%|██████▊   | 353/522 [08:03<04:32,  1.61s/it] 68%|██████▊   | 354/522 [08:04<04:07,  1.47s/it] 68%|██████▊   | 355/522 [08:05<03:50,  1.38s/it] 68%|██████▊   | 356/522 [08:07<03:44,  1.36s/it] 68%|██████▊   | 357/522 [08:08<03:33,  1.29s/it] 69%|██████▊   | 358/522 [08:09<03:25,  1.25s/it] 69%|██████▉   | 359/522 [08:10<03:19,  1.22s/it] 69%|██████▉   | 360/522 [08:11<03:14,  1.20s/it] 69%|██████▉   | 361/522 [08:13<03:11,  1.19s/it] 69%|██████▉   | 362/522 [08:14<03:08,  1.18s/it] 70%|██████▉   | 363/522 [08:15<03:06,  1.17s/it] 70%|██████▉   | 364/522 [08:16<03:04,  1.17s/it] 70%|██████▉   | 365/522 [08:17<03:02,  1.16s/it] 70%|███████   | 366/522 [08:18<03:00,  1.16s/it] 70%|███████   | 367/522 [08:19<02:59,  1.16s/it] 70%|███████   | 368/522 [08:21<02:58,  1.16s/it] 71%|███████   | 369/522 [08:22<02:56,  1.16s/it] 71%|███████   | 370/522 [08:23<02:55,  1.16s/it] 71%|███████   | 371/522 [08:24<02:54,  1.15s/it] 71%|███████▏  | 372/522 [08:25<02:53,  1.15s/it] 71%|███████▏  | 373/522 [08:26<02:51,  1.15s/it] 72%|███████▏  | 374/522 [08:28<02:50,  1.15s/it] 72%|███████▏  | 375/522 [08:29<02:49,  1.15s/it] 72%|███████▏  | 376/522 [08:30<02:48,  1.16s/it] 72%|███████▏  | 377/522 [08:31<02:44,  1.14s/it]{'eval_loss': 4.405450820922852, 'eval_precision': 0.75, 'eval_recall': 0.8255813953488372, 'eval_f1': 0.7859778597785977, 'eval_accuracy': 0.9803991446899502, 'eval_runtime': 2.0911, 'eval_samples_per_second': 49.257, 'eval_steps_per_second': 1.913, 'epoch': 12.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.85it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.73it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A                                                 
                                             [A 72%|███████▏  | 377/522 [08:33<02:44,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 72%|███████▏  | 378/522 [08:39<07:27,  3.11s/it] 73%|███████▎  | 379/522 [08:40<06:00,  2.52s/it] 73%|███████▎  | 380/522 [08:41<05:06,  2.16s/it] 73%|███████▎  | 381/522 [08:42<04:21,  1.86s/it] 73%|███████▎  | 382/522 [08:43<03:50,  1.64s/it] 73%|███████▎  | 383/522 [08:45<03:28,  1.50s/it] 74%|███████▎  | 384/522 [08:46<03:12,  1.39s/it] 74%|███████▍  | 385/522 [08:47<03:01,  1.32s/it] 74%|███████▍  | 386/522 [08:48<02:52,  1.27s/it] 74%|███████▍  | 387/522 [08:49<02:46,  1.24s/it] 74%|███████▍  | 388/522 [08:50<02:42,  1.21s/it] 75%|███████▍  | 389/522 [08:51<02:38,  1.19s/it] 75%|███████▍  | 390/522 [08:53<02:35,  1.18s/it] 75%|███████▍  | 391/522 [08:54<02:33,  1.17s/it] 75%|███████▌  | 392/522 [08:55<02:31,  1.17s/it] 75%|███████▌  | 393/522 [08:56<02:29,  1.16s/it] 75%|███████▌  | 394/522 [08:57<02:28,  1.16s/it] 76%|███████▌  | 395/522 [08:58<02:26,  1.16s/it] 76%|███████▌  | 396/522 [09:00<02:25,  1.16s/it] 76%|███████▌  | 397/522 [09:01<02:24,  1.15s/it] 76%|███████▌  | 398/522 [09:02<02:23,  1.15s/it] 76%|███████▋  | 399/522 [09:03<02:21,  1.15s/it] 77%|███████▋  | 400/522 [09:04<02:20,  1.15s/it] 77%|███████▋  | 401/522 [09:05<02:19,  1.15s/it] 77%|███████▋  | 402/522 [09:06<02:18,  1.15s/it] 77%|███████▋  | 403/522 [09:08<02:17,  1.15s/it] 77%|███████▋  | 404/522 [09:09<02:16,  1.15s/it] 78%|███████▊  | 405/522 [09:10<02:14,  1.15s/it] 78%|███████▊  | 406/522 [09:11<02:11,  1.14s/it]{'eval_loss': 3.763050079345703, 'eval_precision': 0.803088803088803, 'eval_recall': 0.8062015503875969, 'eval_f1': 0.8046421663442941, 'eval_accuracy': 0.9836065573770492, 'eval_runtime': 2.1192, 'eval_samples_per_second': 48.603, 'eval_steps_per_second': 1.887, 'epoch': 13.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.83it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.77it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.61it/s][A                                                 
                                             [A 78%|███████▊  | 406/522 [09:13<02:11,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.61it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 78%|███████▊  | 407/522 [09:19<06:11,  3.23s/it] 78%|███████▊  | 408/522 [09:20<04:56,  2.60s/it] 78%|███████▊  | 409/522 [09:21<04:05,  2.17s/it] 79%|███████▊  | 410/522 [09:23<03:28,  1.86s/it] 79%|███████▊  | 411/522 [09:24<03:03,  1.65s/it] 79%|███████▉  | 412/522 [09:25<02:45,  1.50s/it] 79%|███████▉  | 413/522 [09:26<02:32,  1.40s/it] 79%|███████▉  | 414/522 [09:27<02:22,  1.32s/it] 80%|███████▉  | 415/522 [09:28<02:16,  1.27s/it] 80%|███████▉  | 416/522 [09:29<02:11,  1.24s/it] 80%|███████▉  | 417/522 [09:31<02:07,  1.21s/it] 80%|████████  | 418/522 [09:32<02:04,  1.19s/it] 80%|████████  | 419/522 [09:33<02:01,  1.18s/it] 80%|████████  | 420/522 [09:34<01:59,  1.17s/it] 81%|████████  | 421/522 [09:35<01:57,  1.17s/it] 81%|████████  | 422/522 [09:36<01:56,  1.16s/it] 81%|████████  | 423/522 [09:38<01:54,  1.16s/it] 81%|████████  | 424/522 [09:39<01:57,  1.20s/it] 81%|████████▏ | 425/522 [09:40<01:55,  1.19s/it] 82%|████████▏ | 426/522 [09:41<01:53,  1.18s/it] 82%|████████▏ | 427/522 [09:42<01:51,  1.17s/it] 82%|████████▏ | 428/522 [09:43<01:49,  1.17s/it] 82%|████████▏ | 429/522 [09:45<01:48,  1.16s/it] 82%|████████▏ | 430/522 [09:46<01:46,  1.16s/it] 83%|████████▎ | 431/522 [09:47<01:45,  1.16s/it] 83%|████████▎ | 432/522 [09:48<01:44,  1.16s/it] 83%|████████▎ | 433/522 [09:49<01:42,  1.16s/it] 83%|████████▎ | 434/522 [09:50<01:41,  1.16s/it] 83%|████████▎ | 435/522 [09:51<01:39,  1.14s/it]{'eval_loss': 3.616715431213379, 'eval_precision': 0.7978339350180506, 'eval_recall': 0.8565891472868217, 'eval_f1': 0.8261682242990653, 'eval_accuracy': 0.9841411261582323, 'eval_runtime': 2.1035, 'eval_samples_per_second': 48.965, 'eval_steps_per_second': 1.902, 'epoch': 14.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.70it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.67it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.54it/s][A                                                 
                                             [A 83%|████████▎ | 435/522 [09:54<01:39,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.54it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 84%|████████▎ | 436/522 [09:59<04:20,  3.03s/it] 84%|████████▎ | 437/522 [10:00<03:29,  2.47s/it] 84%|████████▍ | 438/522 [10:01<02:54,  2.07s/it] 84%|████████▍ | 439/522 [10:02<02:29,  1.80s/it] 84%|████████▍ | 440/522 [10:04<02:11,  1.60s/it] 84%|████████▍ | 441/522 [10:05<01:58,  1.47s/it] 85%|████████▍ | 442/522 [10:06<01:49,  1.37s/it] 85%|████████▍ | 443/522 [10:07<01:43,  1.31s/it] 85%|████████▌ | 444/522 [10:08<01:38,  1.26s/it] 85%|████████▌ | 445/522 [10:09<01:34,  1.23s/it] 85%|████████▌ | 446/522 [10:10<01:31,  1.21s/it] 86%|████████▌ | 447/522 [10:12<01:29,  1.19s/it] 86%|████████▌ | 448/522 [10:13<01:27,  1.18s/it] 86%|████████▌ | 449/522 [10:14<01:25,  1.17s/it] 86%|████████▌ | 450/522 [10:15<01:27,  1.21s/it] 86%|████████▋ | 451/522 [10:16<01:24,  1.19s/it] 87%|████████▋ | 452/522 [10:18<01:22,  1.18s/it] 87%|████████▋ | 453/522 [10:19<01:20,  1.17s/it] 87%|████████▋ | 454/522 [10:20<01:19,  1.17s/it] 87%|████████▋ | 455/522 [10:21<01:17,  1.16s/it] 87%|████████▋ | 456/522 [10:22<01:16,  1.16s/it] 88%|████████▊ | 457/522 [10:23<01:15,  1.16s/it] 88%|████████▊ | 458/522 [10:24<01:14,  1.16s/it] 88%|████████▊ | 459/522 [10:26<01:12,  1.16s/it] 88%|████████▊ | 460/522 [10:27<01:11,  1.16s/it] 88%|████████▊ | 461/522 [10:28<01:10,  1.16s/it] 89%|████████▊ | 462/522 [10:29<01:09,  1.15s/it] 89%|████████▊ | 463/522 [10:30<01:08,  1.15s/it] 89%|████████▉ | 464/522 [10:31<01:05,  1.14s/it]{'eval_loss': 3.5381386280059814, 'eval_precision': 0.8426966292134831, 'eval_recall': 0.872093023255814, 'eval_f1': 0.8571428571428571, 'eval_accuracy': 0.986992159657876, 'eval_runtime': 2.1401, 'eval_samples_per_second': 48.129, 'eval_steps_per_second': 1.869, 'epoch': 15.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.84it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.82it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.65it/s][A                                                 
                                             [A 89%|████████▉ | 464/522 [10:33<01:05,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.65it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 89%|████████▉ | 465/522 [10:39<02:51,  3.00s/it] 89%|████████▉ | 466/522 [10:40<02:17,  2.45s/it] 89%|████████▉ | 467/522 [10:41<01:53,  2.06s/it] 90%|████████▉ | 468/522 [10:42<01:36,  1.79s/it] 90%|████████▉ | 469/522 [10:43<01:24,  1.60s/it] 90%|█████████ | 470/522 [10:44<01:16,  1.46s/it] 90%|█████████ | 471/522 [10:46<01:09,  1.37s/it] 90%|█████████ | 472/522 [10:47<01:05,  1.31s/it] 91%|█████████ | 473/522 [10:48<01:01,  1.26s/it] 91%|█████████ | 474/522 [10:49<00:58,  1.23s/it] 91%|█████████ | 475/522 [10:50<00:56,  1.20s/it] 91%|█████████ | 476/522 [10:51<00:54,  1.19s/it] 91%|█████████▏| 477/522 [10:53<00:53,  1.18s/it] 92%|█████████▏| 478/522 [10:54<00:51,  1.17s/it] 92%|█████████▏| 479/522 [10:55<00:50,  1.17s/it] 92%|█████████▏| 480/522 [10:56<00:48,  1.16s/it] 92%|█████████▏| 481/522 [10:57<00:47,  1.16s/it] 92%|█████████▏| 482/522 [10:58<00:48,  1.20s/it] 93%|█████████▎| 483/522 [11:00<00:46,  1.19s/it] 93%|█████████▎| 484/522 [11:01<00:44,  1.18s/it] 93%|█████████▎| 485/522 [11:02<00:43,  1.17s/it] 93%|█████████▎| 486/522 [11:03<00:41,  1.17s/it] 93%|█████████▎| 487/522 [11:04<00:40,  1.16s/it] 93%|█████████▎| 488/522 [11:05<00:39,  1.16s/it] 94%|█████████▎| 489/522 [11:07<00:38,  1.16s/it] 94%|█████████▍| 490/522 [11:08<00:36,  1.16s/it] 94%|█████████▍| 491/522 [11:09<00:35,  1.16s/it] 94%|█████████▍| 492/522 [11:10<00:34,  1.16s/it] 94%|█████████▍| 493/522 [11:11<00:33,  1.14s/it]{'eval_loss': 3.6816930770874023, 'eval_precision': 0.7964285714285714, 'eval_recall': 0.8643410852713178, 'eval_f1': 0.828996282527881, 'eval_accuracy': 0.9848538845331433, 'eval_runtime': 2.0673, 'eval_samples_per_second': 49.824, 'eval_steps_per_second': 1.935, 'epoch': 16.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.73it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.63it/s][A                                                 
                                             [A 94%|█████████▍| 493/522 [11:13<00:33,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.63it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 95%|█████████▍| 494/522 [11:18<01:22,  2.96s/it] 95%|█████████▍| 495/522 [11:19<01:05,  2.42s/it] 95%|█████████▌| 496/522 [11:21<00:53,  2.04s/it] 95%|█████████▌| 497/522 [11:22<00:44,  1.78s/it] 95%|█████████▌| 498/522 [11:23<00:38,  1.59s/it] 96%|█████████▌| 499/522 [11:24<00:33,  1.46s/it] 96%|█████████▌| 500/522 [11:25<00:30,  1.37s/it]                                                  96%|█████████▌| 500/522 [11:25<00:30,  1.37s/it] 96%|█████████▌| 501/522 [11:26<00:27,  1.30s/it] 96%|█████████▌| 502/522 [11:28<00:25,  1.26s/it] 96%|█████████▋| 503/522 [11:29<00:23,  1.23s/it] 97%|█████████▋| 504/522 [11:30<00:21,  1.21s/it] 97%|█████████▋| 505/522 [11:31<00:20,  1.19s/it] 97%|█████████▋| 506/522 [11:32<00:18,  1.18s/it] 97%|█████████▋| 507/522 [11:33<00:17,  1.17s/it] 97%|█████████▋| 508/522 [11:34<00:16,  1.17s/it] 98%|█████████▊| 509/522 [11:36<00:15,  1.16s/it] 98%|█████████▊| 510/522 [11:37<00:13,  1.16s/it] 98%|█████████▊| 511/522 [11:38<00:12,  1.16s/it] 98%|█████████▊| 512/522 [11:39<00:11,  1.16s/it] 98%|█████████▊| 513/522 [11:40<00:10,  1.20s/it] 98%|█████████▊| 514/522 [11:42<00:09,  1.19s/it] 99%|█████████▊| 515/522 [11:43<00:08,  1.18s/it] 99%|█████████▉| 516/522 [11:44<00:07,  1.17s/it] 99%|█████████▉| 517/522 [11:45<00:05,  1.17s/it] 99%|█████████▉| 518/522 [11:46<00:04,  1.17s/it] 99%|█████████▉| 519/522 [11:47<00:03,  1.16s/it]100%|█████████▉| 520/522 [11:49<00:02,  1.16s/it]100%|█████████▉| 521/522 [11:50<00:01,  1.16s/it]100%|██████████| 522/522 [11:51<00:00,  1.14s/it]{'eval_loss': 3.516580581665039, 'eval_precision': 0.8198529411764706, 'eval_recall': 0.8643410852713178, 'eval_f1': 0.8415094339622641, 'eval_accuracy': 0.9862794012829651, 'eval_runtime': 2.0876, 'eval_samples_per_second': 49.34, 'eval_steps_per_second': 1.916, 'epoch': 17.0}
{'loss': 28.3122, 'grad_norm': 2754122.0, 'learning_rate': 1.8211548197046096e-06, 'epoch': 17.24}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.85it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.72it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A                                                 
                                             [A100%|██████████| 522/522 [11:53<00:00,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A
                                             [A                                                 100%|██████████| 522/522 [11:58<00:00,  1.14s/it]100%|██████████| 522/522 [11:58<00:00,  1.38s/it]
[I 2025-09-09 13:18:41,763] Trial 13 finished with value: 3.5054303697371143 and parameters: {'learning_rate': 3.602719317241728e-05, 'num_train_epochs': 18, 'per_device_train_batch_size': 4, 'weight_decay': 0.004547832771294793, 'warmup_ratio': 0.12769735973851307, 'optimizer': 'Adam'}. Best is trial 10 with value: 3.554755087169663.
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▁▂▃▅▅▆▆▆▇▇▇▇█████
wandb:                 eval/f1 ▁▁▃▄▆▆▆▇▇▇▇▇██████
wandb:               eval/loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          eval/precision ▁█▅▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇
wandb:             eval/recall ▁▁▃▄▅▆▆▇▇▇▇█▇█████
wandb:            eval/runtime ▃█▂▃▁▅▃▃▂██▂▄▃▄▁▂▃
wandb: eval/samples_per_second ▅▁▇▆█▄▆▆▇▁▁▇▅▆▄█▇▆
wandb:   eval/steps_per_second ▅▁▇▆█▄▆▆▇▁▁▆▅▆▄█▇▆
wandb:             train/epoch ▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇████
wandb:       train/global_step ▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇████
wandb:         train/grad_norm ▁
wandb:     train/learning_rate ▁
wandb:              train/loss ▁
wandb: 
wandb: Run summary:
wandb:            eval/accuracy 0.98646
wandb:                  eval/f1 0.83932
wandb:                eval/loss 3.52009
wandb:           eval/precision 0.81919
wandb:              eval/recall 0.86047
wandb:             eval/runtime 2.0988
wandb:  eval/samples_per_second 49.075
wandb:    eval/steps_per_second 1.906
wandb:               total_flos 0
wandb:              train/epoch 18
wandb:        train/global_step 522
wandb:          train/grad_norm 2754122.0
wandb:      train/learning_rate 0.0
wandb:               train/loss 28.3122
wandb:               train_loss 27.39097
wandb:            train_runtime 721.047
wandb: train_samples_per_second 23.066
wandb:   train_steps_per_second 0.724
wandb: 
wandb: 🚀 View run legendary-plasma-718 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/rx02njyv
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250909_130642-rx02njyv/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_131844-s2j20k5t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sponge-719
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/s2j20k5t
{'eval_loss': 3.5200932025909424, 'eval_precision': 0.8191881918819188, 'eval_recall': 0.8604651162790697, 'eval_f1': 0.8393194706994329, 'eval_accuracy': 0.9864575908766928, 'eval_runtime': 2.0988, 'eval_samples_per_second': 49.075, 'eval_steps_per_second': 1.906, 'epoch': 18.0}
{'train_runtime': 721.047, 'train_samples_per_second': 23.066, 'train_steps_per_second': 0.724, 'train_loss': 27.390966831952674, 'epoch': 18.0}
  0%|          | 0/1305 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/1305 [00:01<25:19,  1.17s/it]  0%|          | 2/1305 [00:02<25:11,  1.16s/it]  0%|          | 3/1305 [00:03<25:05,  1.16s/it]  0%|          | 4/1305 [00:04<25:03,  1.16s/it]  0%|          | 5/1305 [00:05<25:01,  1.15s/it]  0%|          | 6/1305 [00:06<24:59,  1.15s/it]  1%|          | 7/1305 [00:08<24:57,  1.15s/it]  1%|          | 8/1305 [00:09<24:55,  1.15s/it]  1%|          | 9/1305 [00:10<24:54,  1.15s/it]  1%|          | 10/1305 [00:11<24:52,  1.15s/it]  1%|          | 11/1305 [00:12<24:52,  1.15s/it]  1%|          | 12/1305 [00:13<24:50,  1.15s/it]  1%|          | 13/1305 [00:15<24:49,  1.15s/it]  1%|          | 14/1305 [00:16<24:50,  1.15s/it]  1%|          | 15/1305 [00:17<24:50,  1.16s/it]  1%|          | 16/1305 [00:18<24:48,  1.16s/it]  1%|▏         | 17/1305 [00:19<24:46,  1.15s/it]  1%|▏         | 18/1305 [00:20<24:45,  1.15s/it]  1%|▏         | 19/1305 [00:21<24:44,  1.15s/it]  2%|▏         | 20/1305 [00:23<24:42,  1.15s/it]  2%|▏         | 21/1305 [00:24<24:41,  1.15s/it]  2%|▏         | 22/1305 [00:25<24:41,  1.15s/it]  2%|▏         | 23/1305 [00:26<24:39,  1.15s/it]  2%|▏         | 24/1305 [00:27<24:38,  1.15s/it]  2%|▏         | 25/1305 [00:28<24:36,  1.15s/it]  2%|▏         | 26/1305 [00:30<24:36,  1.15s/it]  2%|▏         | 27/1305 [00:31<24:35,  1.15s/it]  2%|▏         | 28/1305 [00:32<24:34,  1.15s/it]  2%|▏         | 29/1305 [00:33<24:11,  1.14s/it]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.84it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.72it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                 
                                             [A  2%|▏         | 29/1305 [00:35<24:11,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A
                                             [A  2%|▏         | 29/1305 [00:35<26:03,  1.23s/it]
[I 2025-09-09 13:19:21,419] Trial 14 pruned. 
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁
wandb:                 eval/f1 ▁
wandb:               eval/loss ▁
wandb:          eval/precision ▁
wandb:             eval/recall ▁
wandb:            eval/runtime ▁
wandb: eval/samples_per_second ▁
wandb:   eval/steps_per_second ▁
wandb:             train/epoch ▁
wandb:       train/global_step ▁
wandb: 
wandb: Run summary:
wandb:           eval/accuracy 0.5882
wandb:                 eval/f1 0.00913
wandb:               eval/loss 104.0556
wandb:          eval/precision 0.00511
wandb:             eval/recall 0.04264
wandb:            eval/runtime 2.1208
wandb: eval/samples_per_second 48.566
wandb:   eval/steps_per_second 1.886
wandb:             train/epoch 1
wandb:       train/global_step 29
wandb: 
wandb: 🚀 View run zany-sponge-719 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/s2j20k5t
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250909_131844-s2j20k5t/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_131929-pdmmgscu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-pyramid-720
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/pdmmgscu
{'eval_loss': 104.05559539794922, 'eval_precision': 0.005111524163568773, 'eval_recall': 0.04263565891472868, 'eval_f1': 0.009128630705394191, 'eval_accuracy': 0.5882038488952245, 'eval_runtime': 2.1208, 'eval_samples_per_second': 48.566, 'eval_steps_per_second': 1.886, 'epoch': 1.0}
  0%|          | 0/377 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/377 [00:01<07:17,  1.16s/it]  1%|          | 2/377 [00:02<07:14,  1.16s/it]  1%|          | 3/377 [00:03<07:12,  1.16s/it]  1%|          | 4/377 [00:04<07:11,  1.16s/it]  1%|▏         | 5/377 [00:05<07:09,  1.15s/it]  2%|▏         | 6/377 [00:06<07:08,  1.15s/it]  2%|▏         | 7/377 [00:08<07:07,  1.16s/it]  2%|▏         | 8/377 [00:09<07:06,  1.15s/it]  2%|▏         | 9/377 [00:10<07:05,  1.16s/it]  3%|▎         | 10/377 [00:11<07:03,  1.15s/it]  3%|▎         | 11/377 [00:12<07:02,  1.15s/it]  3%|▎         | 12/377 [00:13<07:01,  1.15s/it]  3%|▎         | 13/377 [00:15<07:00,  1.15s/it]  4%|▎         | 14/377 [00:16<06:58,  1.15s/it]  4%|▍         | 15/377 [00:17<06:57,  1.15s/it]  4%|▍         | 16/377 [00:18<06:56,  1.15s/it]  5%|▍         | 17/377 [00:19<06:55,  1.15s/it]  5%|▍         | 18/377 [00:20<06:54,  1.15s/it]  5%|▌         | 19/377 [00:21<06:53,  1.15s/it]  5%|▌         | 20/377 [00:23<06:51,  1.15s/it]  6%|▌         | 21/377 [00:24<06:50,  1.15s/it]  6%|▌         | 22/377 [00:25<06:49,  1.15s/it]  6%|▌         | 23/377 [00:26<06:48,  1.15s/it]  6%|▋         | 24/377 [00:27<06:47,  1.15s/it]  7%|▋         | 25/377 [00:28<06:46,  1.15s/it]  7%|▋         | 26/377 [00:30<06:45,  1.15s/it]  7%|▋         | 27/377 [00:31<06:44,  1.15s/it]  7%|▋         | 28/377 [00:32<06:42,  1.15s/it]  8%|▊         | 29/377 [00:33<06:36,  1.14s/it]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.92it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.77it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A  8%|▊         | 29/377 [00:35<06:36,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  8%|▊         | 30/377 [00:42<19:30,  3.37s/it]  8%|▊         | 31/377 [00:43<15:36,  2.71s/it]  8%|▊         | 32/377 [00:44<12:52,  2.24s/it]  9%|▉         | 33/377 [00:45<10:58,  1.91s/it]  9%|▉         | 34/377 [00:46<09:38,  1.69s/it]  9%|▉         | 35/377 [00:47<08:42,  1.53s/it] 10%|▉         | 36/377 [00:48<08:02,  1.42s/it] 10%|▉         | 37/377 [00:50<07:34,  1.34s/it] 10%|█         | 38/377 [00:51<07:14,  1.28s/it] 10%|█         | 39/377 [00:52<07:00,  1.24s/it] 11%|█         | 40/377 [00:53<06:50,  1.22s/it] 11%|█         | 41/377 [00:54<06:42,  1.20s/it] 11%|█         | 42/377 [00:55<06:36,  1.19s/it] 11%|█▏        | 43/377 [00:57<06:32,  1.18s/it] 12%|█▏        | 44/377 [00:58<06:29,  1.17s/it] 12%|█▏        | 45/377 [00:59<06:26,  1.16s/it] 12%|█▏        | 46/377 [01:00<06:24,  1.16s/it] 12%|█▏        | 47/377 [01:01<06:22,  1.16s/it] 13%|█▎        | 48/377 [01:02<06:20,  1.16s/it] 13%|█▎        | 49/377 [01:03<06:19,  1.16s/it] 13%|█▎        | 50/377 [01:05<06:17,  1.16s/it] 14%|█▎        | 51/377 [01:06<06:16,  1.16s/it] 14%|█▍        | 52/377 [01:07<06:15,  1.16s/it] 14%|█▍        | 53/377 [01:08<06:14,  1.15s/it] 14%|█▍        | 54/377 [01:09<06:13,  1.16s/it] 15%|█▍        | 55/377 [01:10<06:11,  1.15s/it] 15%|█▍        | 56/377 [01:12<06:10,  1.15s/it] 15%|█▌        | 57/377 [01:13<06:09,  1.15s/it] 15%|█▌        | 58/377 [01:14<06:02,  1.14s/it]{'eval_loss': 23.86873435974121, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9397719173200285, 'eval_runtime': 2.1048, 'eval_samples_per_second': 48.937, 'eval_steps_per_second': 1.9, 'epoch': 1.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.83it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.79it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.30it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 15%|█▌        | 58/377 [01:16<06:02,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.30it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 16%|█▌        | 59/377 [01:21<15:15,  2.88s/it] 16%|█▌        | 60/377 [01:22<12:29,  2.36s/it] 16%|█▌        | 61/377 [01:23<10:32,  2.00s/it] 16%|█▋        | 62/377 [01:24<09:10,  1.75s/it] 17%|█▋        | 63/377 [01:25<08:13,  1.57s/it] 17%|█▋        | 64/377 [01:27<07:33,  1.45s/it] 17%|█▋        | 65/377 [01:28<07:04,  1.36s/it] 18%|█▊        | 66/377 [01:29<06:44,  1.30s/it] 18%|█▊        | 67/377 [01:30<06:29,  1.26s/it] 18%|█▊        | 68/377 [01:31<06:19,  1.23s/it] 18%|█▊        | 69/377 [01:32<06:11,  1.21s/it] 19%|█▊        | 70/377 [01:33<06:06,  1.19s/it] 19%|█▉        | 71/377 [01:35<06:01,  1.18s/it] 19%|█▉        | 72/377 [01:36<05:58,  1.18s/it] 19%|█▉        | 73/377 [01:37<05:55,  1.17s/it] 20%|█▉        | 74/377 [01:38<05:53,  1.17s/it] 20%|█▉        | 75/377 [01:39<05:51,  1.16s/it] 20%|██        | 76/377 [01:40<05:49,  1.16s/it] 20%|██        | 77/377 [01:42<05:48,  1.16s/it] 21%|██        | 78/377 [01:43<05:46,  1.16s/it] 21%|██        | 79/377 [01:44<05:45,  1.16s/it] 21%|██        | 80/377 [01:45<05:44,  1.16s/it] 21%|██▏       | 81/377 [01:46<05:43,  1.16s/it] 22%|██▏       | 82/377 [01:47<05:41,  1.16s/it] 22%|██▏       | 83/377 [01:49<05:40,  1.16s/it] 22%|██▏       | 84/377 [01:50<05:39,  1.16s/it] 23%|██▎       | 85/377 [01:51<05:38,  1.16s/it] 23%|██▎       | 86/377 [01:52<05:37,  1.16s/it] 23%|██▎       | 87/377 [01:53<05:31,  1.14s/it]{'eval_loss': 16.063627243041992, 'eval_precision': 0.5, 'eval_recall': 0.003875968992248062, 'eval_f1': 0.007692307692307692, 'eval_accuracy': 0.9399501069137562, 'eval_runtime': 2.225, 'eval_samples_per_second': 46.293, 'eval_steps_per_second': 1.798, 'epoch': 2.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.85it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.77it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.68it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 23%|██▎       | 87/377 [01:55<05:31,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.68it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 23%|██▎       | 88/377 [02:00<13:51,  2.88s/it] 24%|██▎       | 89/377 [02:01<11:20,  2.36s/it] 24%|██▍       | 90/377 [02:02<09:34,  2.00s/it] 24%|██▍       | 91/377 [02:04<08:19,  1.75s/it] 24%|██▍       | 92/377 [02:05<07:27,  1.57s/it] 25%|██▍       | 93/377 [02:06<06:50,  1.45s/it] 25%|██▍       | 94/377 [02:07<06:24,  1.36s/it] 25%|██▌       | 95/377 [02:08<06:06,  1.30s/it] 25%|██▌       | 96/377 [02:09<05:53,  1.26s/it] 26%|██▌       | 97/377 [02:11<05:56,  1.27s/it] 26%|██▌       | 98/377 [02:12<05:45,  1.24s/it] 26%|██▋       | 99/377 [02:13<05:37,  1.21s/it] 27%|██▋       | 100/377 [02:14<05:31,  1.20s/it] 27%|██▋       | 101/377 [02:15<05:27,  1.19s/it] 27%|██▋       | 102/377 [02:16<05:24,  1.18s/it] 27%|██▋       | 103/377 [02:18<05:21,  1.17s/it] 28%|██▊       | 104/377 [02:19<05:19,  1.17s/it] 28%|██▊       | 105/377 [02:20<05:16,  1.17s/it] 28%|██▊       | 106/377 [02:21<05:15,  1.16s/it] 28%|██▊       | 107/377 [02:22<05:13,  1.16s/it] 29%|██▊       | 108/377 [02:23<05:12,  1.16s/it] 29%|██▉       | 109/377 [02:25<05:10,  1.16s/it] 29%|██▉       | 110/377 [02:26<05:09,  1.16s/it] 29%|██▉       | 111/377 [02:27<05:08,  1.16s/it] 30%|██▉       | 112/377 [02:28<05:07,  1.16s/it] 30%|██▉       | 113/377 [02:29<05:05,  1.16s/it] 30%|███       | 114/377 [02:30<05:04,  1.16s/it] 31%|███       | 115/377 [02:31<05:03,  1.16s/it] 31%|███       | 116/377 [02:33<04:57,  1.14s/it]{'eval_loss': 11.729780197143555, 'eval_precision': 0.33088235294117646, 'eval_recall': 0.3488372093023256, 'eval_f1': 0.33962264150943394, 'eval_accuracy': 0.9440484675694939, 'eval_runtime': 2.0787, 'eval_samples_per_second': 49.55, 'eval_steps_per_second': 1.924, 'epoch': 3.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.82it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.80it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.70it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                 
                                             [A 31%|███       | 116/377 [02:35<04:57,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.70it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 31%|███       | 117/377 [02:42<15:20,  3.54s/it] 31%|███▏      | 118/377 [02:43<12:12,  2.83s/it] 32%|███▏      | 119/377 [02:44<10:00,  2.33s/it] 32%|███▏      | 120/377 [02:45<08:27,  1.98s/it] 32%|███▏      | 121/377 [02:46<07:34,  1.78s/it] 32%|███▏      | 122/377 [02:48<06:45,  1.59s/it] 33%|███▎      | 123/377 [02:49<06:11,  1.46s/it] 33%|███▎      | 124/377 [02:50<05:47,  1.37s/it] 33%|███▎      | 125/377 [02:51<05:30,  1.31s/it] 33%|███▎      | 126/377 [02:52<05:17,  1.27s/it] 34%|███▎      | 127/377 [02:53<05:08,  1.23s/it] 34%|███▍      | 128/377 [02:55<05:01,  1.21s/it] 34%|███▍      | 129/377 [02:56<04:56,  1.19s/it] 34%|███▍      | 130/377 [02:57<04:52,  1.18s/it] 35%|███▍      | 131/377 [02:58<04:49,  1.18s/it] 35%|███▌      | 132/377 [02:59<04:46,  1.17s/it] 35%|███▌      | 133/377 [03:00<04:44,  1.17s/it] 36%|███▌      | 134/377 [03:02<04:42,  1.16s/it] 36%|███▌      | 135/377 [03:03<04:41,  1.16s/it] 36%|███▌      | 136/377 [03:04<04:39,  1.16s/it] 36%|███▋      | 137/377 [03:05<04:38,  1.16s/it] 37%|███▋      | 138/377 [03:06<04:37,  1.16s/it] 37%|███▋      | 139/377 [03:07<04:35,  1.16s/it] 37%|███▋      | 140/377 [03:09<04:34,  1.16s/it] 37%|███▋      | 141/377 [03:10<04:33,  1.16s/it] 38%|███▊      | 142/377 [03:11<04:32,  1.16s/it] 38%|███▊      | 143/377 [03:12<04:31,  1.16s/it] 38%|███▊      | 144/377 [03:13<04:30,  1.16s/it] 38%|███▊      | 145/377 [03:14<04:24,  1.14s/it]{'eval_loss': 8.884334564208984, 'eval_precision': 0.49029126213592233, 'eval_recall': 0.39147286821705424, 'eval_f1': 0.43534482758620685, 'eval_accuracy': 0.9554526015680684, 'eval_runtime': 2.0455, 'eval_samples_per_second': 50.355, 'eval_steps_per_second': 1.956, 'epoch': 4.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.87it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.80it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.63it/s][A                                                 
                                             [A 38%|███▊      | 145/377 [03:16<04:24,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.63it/s][A
                                             [A 38%|███▊      | 145/377 [03:16<05:14,  1.36s/it]
[I 2025-09-09 13:22:47,027] Trial 15 pruned. 
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▁▂▅█
wandb:                 eval/f1 ▁▁▅▆█
wandb:               eval/loss █▅▃▁▁
wandb:          eval/precision ▁▆▄▆█
wandb:             eval/recall ▁▁▆▇█
wandb:            eval/runtime ▃█▂▁▃
wandb: eval/samples_per_second ▆▁▇█▆
wandb:   eval/steps_per_second ▆▁▇█▆
wandb:             train/epoch ▁▃▅▆█
wandb:       train/global_step ▁▃▅▆█
wandb: 
wandb: Run summary:
wandb:           eval/accuracy 0.96525
wandb:                 eval/f1 0.55856
wandb:               eval/loss 7.87845
wandb:          eval/precision 0.66667
wandb:             eval/recall 0.48062
wandb:            eval/runtime 2.0937
wandb: eval/samples_per_second 49.195
wandb:   eval/steps_per_second 1.91
wandb:             train/epoch 5
wandb:       train/global_step 145
wandb: 
wandb: 🚀 View run radiant-pyramid-720 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/pdmmgscu
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250909_131929-pdmmgscu/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_132249-v4b1x697
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-wave-721
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/v4b1x697
{'eval_loss': 7.878449440002441, 'eval_precision': 0.6666666666666666, 'eval_recall': 0.4806201550387597, 'eval_f1': 0.5585585585585585, 'eval_accuracy': 0.9652530292230934, 'eval_runtime': 2.0937, 'eval_samples_per_second': 49.195, 'eval_steps_per_second': 1.91, 'epoch': 5.0}
  0%|          | 0/261 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/261 [00:01<05:03,  1.17s/it]  1%|          | 2/261 [00:02<05:00,  1.16s/it]  1%|          | 3/261 [00:03<04:58,  1.16s/it]  2%|▏         | 4/261 [00:04<04:57,  1.16s/it]  2%|▏         | 5/261 [00:05<04:56,  1.16s/it]  2%|▏         | 6/261 [00:06<04:54,  1.16s/it]  3%|▎         | 7/261 [00:08<04:54,  1.16s/it]  3%|▎         | 8/261 [00:09<04:52,  1.16s/it]  3%|▎         | 9/261 [00:10<04:51,  1.16s/it]  4%|▍         | 10/261 [00:11<04:50,  1.16s/it]  4%|▍         | 11/261 [00:12<04:49,  1.16s/it]  5%|▍         | 12/261 [00:13<04:47,  1.16s/it]  5%|▍         | 13/261 [00:15<04:46,  1.16s/it]  5%|▌         | 14/261 [00:16<04:45,  1.16s/it]  6%|▌         | 15/261 [00:17<04:44,  1.16s/it]  6%|▌         | 16/261 [00:18<04:43,  1.16s/it]  7%|▋         | 17/261 [00:19<04:42,  1.16s/it]  7%|▋         | 18/261 [00:20<04:40,  1.16s/it]  7%|▋         | 19/261 [00:21<04:39,  1.16s/it]  8%|▊         | 20/261 [00:23<04:38,  1.16s/it]  8%|▊         | 21/261 [00:24<04:37,  1.16s/it]  8%|▊         | 22/261 [00:25<04:36,  1.16s/it]  9%|▉         | 23/261 [00:26<04:35,  1.16s/it]  9%|▉         | 24/261 [00:27<04:33,  1.16s/it] 10%|▉         | 25/261 [00:28<04:32,  1.16s/it] 10%|▉         | 26/261 [00:30<04:31,  1.16s/it] 10%|█         | 27/261 [00:31<04:30,  1.16s/it] 11%|█         | 28/261 [00:32<04:29,  1.16s/it] 11%|█         | 29/261 [00:33<04:24,  1.14s/it]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.83it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.71it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.57it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 11%|█         | 29/261 [00:35<04:24,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.57it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 11%|█▏        | 30/261 [00:43<15:12,  3.95s/it] 12%|█▏        | 31/261 [00:45<11:55,  3.11s/it] 12%|█▏        | 32/261 [00:46<09:38,  2.52s/it] 13%|█▎        | 33/261 [00:47<08:02,  2.12s/it] 13%|█▎        | 34/261 [00:48<06:54,  1.83s/it] 13%|█▎        | 35/261 [00:49<06:07,  1.63s/it] 14%|█▍        | 36/261 [00:50<05:34,  1.49s/it] 14%|█▍        | 37/261 [00:52<05:10,  1.39s/it] 15%|█▍        | 38/261 [00:53<04:53,  1.32s/it] 15%|█▍        | 39/261 [00:54<04:41,  1.27s/it] 15%|█▌        | 40/261 [00:55<04:33,  1.24s/it] 16%|█▌        | 41/261 [00:56<04:26,  1.21s/it] 16%|█▌        | 42/261 [00:57<04:21,  1.20s/it] 16%|█▋        | 43/261 [00:59<04:18,  1.18s/it] 17%|█▋        | 44/261 [01:00<04:15,  1.18s/it] 17%|█▋        | 45/261 [01:01<04:12,  1.17s/it] 18%|█▊        | 46/261 [01:02<04:10,  1.17s/it] 18%|█▊        | 47/261 [01:03<04:09,  1.16s/it] 18%|█▊        | 48/261 [01:04<04:07,  1.16s/it] 19%|█▉        | 49/261 [01:05<04:06,  1.16s/it] 19%|█▉        | 50/261 [01:07<04:04,  1.16s/it] 20%|█▉        | 51/261 [01:08<04:03,  1.16s/it] 20%|█▉        | 52/261 [01:09<04:02,  1.16s/it] 20%|██        | 53/261 [01:10<04:00,  1.16s/it] 21%|██        | 54/261 [01:11<03:59,  1.16s/it] 21%|██        | 55/261 [01:12<03:58,  1.16s/it] 21%|██▏       | 56/261 [01:14<03:57,  1.16s/it] 22%|██▏       | 57/261 [01:15<03:56,  1.16s/it] 22%|██▏       | 58/261 [01:16<03:51,  1.14s/it]{'eval_loss': 19.37680435180664, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9397719173200285, 'eval_runtime': 2.1347, 'eval_samples_per_second': 48.25, 'eval_steps_per_second': 1.874, 'epoch': 1.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.90it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.80it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.30it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 22%|██▏       | 58/261 [01:18<03:51,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.30it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 23%|██▎       | 59/261 [01:29<16:28,  4.89s/it] 23%|██▎       | 60/261 [01:31<12:38,  3.77s/it] 23%|██▎       | 61/261 [01:32<09:57,  2.99s/it] 24%|██▍       | 62/261 [01:33<08:04,  2.44s/it] 24%|██▍       | 63/261 [01:34<06:46,  2.05s/it] 25%|██▍       | 64/261 [01:35<05:51,  1.78s/it] 25%|██▍       | 65/261 [01:36<05:12,  1.59s/it] 25%|██▌       | 66/261 [01:38<04:45,  1.46s/it] 26%|██▌       | 67/261 [01:39<04:25,  1.37s/it] 26%|██▌       | 68/261 [01:40<04:11,  1.31s/it] 26%|██▋       | 69/261 [01:41<04:01,  1.26s/it] 27%|██▋       | 70/261 [01:42<03:54,  1.23s/it] 27%|██▋       | 71/261 [01:43<03:49,  1.21s/it] 28%|██▊       | 72/261 [01:44<03:44,  1.19s/it] 28%|██▊       | 73/261 [01:46<03:41,  1.18s/it] 28%|██▊       | 74/261 [01:47<03:39,  1.17s/it] 29%|██▊       | 75/261 [01:48<03:36,  1.17s/it] 29%|██▉       | 76/261 [01:49<03:35,  1.16s/it] 30%|██▉       | 77/261 [01:50<03:33,  1.16s/it] 30%|██▉       | 78/261 [01:51<03:32,  1.16s/it] 30%|███       | 79/261 [01:53<03:30,  1.16s/it] 31%|███       | 80/261 [01:54<03:29,  1.16s/it] 31%|███       | 81/261 [01:55<03:28,  1.16s/it] 31%|███▏      | 82/261 [01:56<03:26,  1.16s/it] 32%|███▏      | 83/261 [01:57<03:25,  1.16s/it] 32%|███▏      | 84/261 [01:58<03:24,  1.16s/it] 33%|███▎      | 85/261 [02:00<03:23,  1.16s/it] 33%|███▎      | 86/261 [02:01<03:22,  1.16s/it] 33%|███▎      | 87/261 [02:02<03:18,  1.14s/it]{'eval_loss': 12.55379867553711, 'eval_precision': 0.5545454545454546, 'eval_recall': 0.2364341085271318, 'eval_f1': 0.3315217391304348, 'eval_accuracy': 0.949928724162509, 'eval_runtime': 2.2089, 'eval_samples_per_second': 46.63, 'eval_steps_per_second': 1.811, 'epoch': 2.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.85it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.73it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.61it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 33%|███▎      | 87/261 [02:04<03:18,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.61it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 34%|███▎      | 88/261 [02:12<11:07,  3.86s/it] 34%|███▍      | 89/261 [02:13<08:44,  3.05s/it] 34%|███▍      | 90/261 [02:14<07:04,  2.48s/it] 35%|███▍      | 91/261 [02:15<05:54,  2.08s/it] 35%|███▌      | 92/261 [02:17<05:04,  1.80s/it] 36%|███▌      | 93/261 [02:18<04:30,  1.61s/it] 36%|███▌      | 94/261 [02:19<04:06,  1.47s/it] 36%|███▋      | 95/261 [02:20<03:48,  1.38s/it] 37%|███▋      | 96/261 [02:21<03:36,  1.31s/it] 37%|███▋      | 97/261 [02:23<03:34,  1.31s/it] 38%|███▊      | 98/261 [02:24<03:26,  1.26s/it] 38%|███▊      | 99/261 [02:25<03:19,  1.23s/it] 38%|███▊      | 100/261 [02:26<03:14,  1.21s/it] 39%|███▊      | 101/261 [02:27<03:10,  1.19s/it] 39%|███▉      | 102/261 [02:28<03:07,  1.18s/it] 39%|███▉      | 103/261 [02:29<03:05,  1.17s/it] 40%|███▉      | 104/261 [02:31<03:03,  1.17s/it] 40%|████      | 105/261 [02:32<03:01,  1.16s/it] 41%|████      | 106/261 [02:33<03:00,  1.16s/it] 41%|████      | 107/261 [02:34<02:58,  1.16s/it] 41%|████▏     | 108/261 [02:35<02:57,  1.16s/it] 42%|████▏     | 109/261 [02:36<02:56,  1.16s/it] 42%|████▏     | 110/261 [02:38<02:54,  1.16s/it] 43%|████▎     | 111/261 [02:39<02:53,  1.16s/it] 43%|████▎     | 112/261 [02:40<02:52,  1.16s/it] 43%|████▎     | 113/261 [02:41<02:51,  1.16s/it] 44%|████▎     | 114/261 [02:42<02:49,  1.16s/it] 44%|████▍     | 115/261 [02:43<02:48,  1.16s/it] 44%|████▍     | 116/261 [02:44<02:45,  1.14s/it]{'eval_loss': 10.365120887756348, 'eval_precision': 0.3559870550161812, 'eval_recall': 0.4263565891472868, 'eval_f1': 0.3880070546737214, 'eval_accuracy': 0.9481468282252317, 'eval_runtime': 2.1128, 'eval_samples_per_second': 48.751, 'eval_steps_per_second': 1.893, 'epoch': 3.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.72it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.67it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                 
                                             [A 44%|████▍     | 116/261 [02:46<02:45,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.67it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 45%|████▍     | 117/261 [02:57<10:54,  4.55s/it] 45%|████▌     | 118/261 [02:58<08:24,  3.53s/it] 46%|████▌     | 119/261 [02:59<06:40,  2.82s/it] 46%|████▌     | 120/261 [03:00<05:26,  2.32s/it] 46%|████▋     | 121/261 [03:02<04:42,  2.02s/it] 47%|████▋     | 122/261 [03:03<04:04,  1.76s/it] 47%|████▋     | 123/261 [03:04<03:37,  1.58s/it] 48%|████▊     | 124/261 [03:05<03:18,  1.45s/it] 48%|████▊     | 125/261 [03:06<03:05,  1.36s/it] 48%|████▊     | 126/261 [03:07<02:55,  1.30s/it] 49%|████▊     | 127/261 [03:09<02:48,  1.26s/it] 49%|████▉     | 128/261 [03:10<02:43,  1.23s/it] 49%|████▉     | 129/261 [03:11<02:38,  1.20s/it] 50%|████▉     | 130/261 [03:12<02:35,  1.19s/it] 50%|█████     | 131/261 [03:13<02:33,  1.18s/it] 51%|█████     | 132/261 [03:14<02:31,  1.17s/it] 51%|█████     | 133/261 [03:16<02:29,  1.17s/it] 51%|█████▏    | 134/261 [03:17<02:27,  1.16s/it] 52%|█████▏    | 135/261 [03:18<02:26,  1.16s/it] 52%|█████▏    | 136/261 [03:19<02:25,  1.16s/it] 52%|█████▏    | 137/261 [03:20<02:23,  1.16s/it] 53%|█████▎    | 138/261 [03:21<02:22,  1.16s/it] 53%|█████▎    | 139/261 [03:22<02:21,  1.16s/it] 54%|█████▎    | 140/261 [03:24<02:20,  1.16s/it] 54%|█████▍    | 141/261 [03:25<02:18,  1.16s/it] 54%|█████▍    | 142/261 [03:26<02:17,  1.16s/it] 55%|█████▍    | 143/261 [03:27<02:16,  1.15s/it] 55%|█████▌    | 144/261 [03:28<02:15,  1.15s/it] 56%|█████▌    | 145/261 [03:29<02:11,  1.14s/it]{'eval_loss': 7.6989593505859375, 'eval_precision': 0.5781990521327014, 'eval_recall': 0.4728682170542636, 'eval_f1': 0.5202558635394456, 'eval_accuracy': 0.9640057020669993, 'eval_runtime': 2.0648, 'eval_samples_per_second': 49.883, 'eval_steps_per_second': 1.937, 'epoch': 4.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.92it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.83it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.64it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                 
                                             [A 56%|█████▌    | 145/261 [03:31<02:11,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.64it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 56%|█████▌    | 146/261 [03:41<08:03,  4.20s/it] 56%|█████▋    | 147/261 [03:42<06:14,  3.29s/it] 57%|█████▋    | 148/261 [03:43<04:59,  2.65s/it] 57%|█████▋    | 149/261 [03:44<04:06,  2.20s/it] 57%|█████▋    | 150/261 [03:45<03:29,  1.89s/it] 58%|█████▊    | 151/261 [03:46<03:03,  1.67s/it] 58%|█████▊    | 152/261 [03:48<02:44,  1.51s/it] 59%|█████▊    | 153/261 [03:49<02:31,  1.40s/it] 59%|█████▉    | 154/261 [03:50<02:22,  1.33s/it] 59%|█████▉    | 155/261 [03:51<02:15,  1.28s/it] 60%|█████▉    | 156/261 [03:52<02:10,  1.24s/it] 60%|██████    | 157/261 [03:53<02:06,  1.21s/it] 61%|██████    | 158/261 [03:55<02:03,  1.20s/it] 61%|██████    | 159/261 [03:56<02:00,  1.18s/it] 61%|██████▏   | 160/261 [03:57<01:58,  1.17s/it] 62%|██████▏   | 161/261 [03:58<01:56,  1.17s/it] 62%|██████▏   | 162/261 [03:59<01:55,  1.16s/it] 62%|██████▏   | 163/261 [04:00<01:53,  1.16s/it] 63%|██████▎   | 164/261 [04:02<01:55,  1.19s/it] 63%|██████▎   | 165/261 [04:03<01:53,  1.18s/it] 64%|██████▎   | 166/261 [04:04<01:51,  1.18s/it] 64%|██████▍   | 167/261 [04:05<01:49,  1.17s/it] 64%|██████▍   | 168/261 [04:06<01:48,  1.16s/it] 65%|██████▍   | 169/261 [04:07<01:46,  1.16s/it] 65%|██████▌   | 170/261 [04:09<01:45,  1.16s/it] 66%|██████▌   | 171/261 [04:10<01:44,  1.16s/it] 66%|██████▌   | 172/261 [04:11<01:43,  1.16s/it] 66%|██████▋   | 173/261 [04:12<01:41,  1.16s/it] 67%|██████▋   | 174/261 [04:13<01:39,  1.14s/it]{'eval_loss': 7.873721122741699, 'eval_precision': 0.7041420118343196, 'eval_recall': 0.46124031007751937, 'eval_f1': 0.5573770491803279, 'eval_accuracy': 0.9650748396293657, 'eval_runtime': 2.0665, 'eval_samples_per_second': 49.842, 'eval_steps_per_second': 1.936, 'epoch': 5.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.89it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.82it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.68it/s][A                                                 
                                             [A 67%|██████▋   | 174/261 [04:15<01:39,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.68it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 67%|██████▋   | 175/261 [04:26<06:34,  4.59s/it] 67%|██████▋   | 176/261 [04:27<05:02,  3.56s/it] 68%|██████▊   | 177/261 [04:28<03:58,  2.84s/it] 68%|██████▊   | 178/261 [04:29<03:13,  2.33s/it] 69%|██████▊   | 179/261 [04:30<02:42,  1.98s/it] 69%|██████▉   | 180/261 [04:32<02:20,  1.73s/it] 69%|██████▉   | 181/261 [04:33<02:04,  1.56s/it] 70%|██████▉   | 182/261 [04:34<01:53,  1.44s/it] 70%|███████   | 183/261 [04:35<01:45,  1.35s/it] 70%|███████   | 184/261 [04:36<01:39,  1.29s/it] 71%|███████   | 185/261 [04:37<01:35,  1.25s/it] 71%|███████▏  | 186/261 [04:38<01:31,  1.22s/it] 72%|███████▏  | 187/261 [04:40<01:29,  1.20s/it] 72%|███████▏  | 188/261 [04:41<01:26,  1.19s/it] 72%|███████▏  | 189/261 [04:42<01:24,  1.18s/it] 73%|███████▎  | 190/261 [04:43<01:23,  1.17s/it] 73%|███████▎  | 191/261 [04:44<01:21,  1.17s/it] 74%|███████▎  | 192/261 [04:45<01:20,  1.16s/it] 74%|███████▍  | 193/261 [04:47<01:18,  1.16s/it] 74%|███████▍  | 194/261 [04:48<01:20,  1.20s/it] 75%|███████▍  | 195/261 [04:49<01:18,  1.19s/it] 75%|███████▌  | 196/261 [04:50<01:16,  1.18s/it] 75%|███████▌  | 197/261 [04:51<01:14,  1.17s/it] 76%|███████▌  | 198/261 [04:52<01:13,  1.17s/it] 76%|███████▌  | 199/261 [04:54<01:12,  1.16s/it] 77%|███████▋  | 200/261 [04:55<01:10,  1.16s/it] 77%|███████▋  | 201/261 [04:56<01:09,  1.16s/it] 77%|███████▋  | 202/261 [04:57<01:08,  1.16s/it] 78%|███████▊  | 203/261 [04:58<01:06,  1.14s/it]{'eval_loss': 5.947094440460205, 'eval_precision': 0.673728813559322, 'eval_recall': 0.6162790697674418, 'eval_f1': 0.6437246963562753, 'eval_accuracy': 0.9738061297220242, 'eval_runtime': 2.0783, 'eval_samples_per_second': 49.559, 'eval_steps_per_second': 1.925, 'epoch': 6.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.79it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.69it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.50it/s][A                                                 
                                             [A 78%|███████▊  | 203/261 [05:00<01:06,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.50it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 78%|███████▊  | 204/261 [05:07<03:22,  3.54s/it] 79%|███████▊  | 205/261 [05:08<02:38,  2.83s/it] 79%|███████▉  | 206/261 [05:10<02:07,  2.33s/it] 79%|███████▉  | 207/261 [05:11<01:46,  1.97s/it] 80%|███████▉  | 208/261 [05:12<01:31,  1.73s/it] 80%|████████  | 209/261 [05:13<01:21,  1.56s/it] 80%|████████  | 210/261 [05:14<01:13,  1.44s/it] 81%|████████  | 211/261 [05:15<01:07,  1.35s/it] 81%|████████  | 212/261 [05:17<01:03,  1.30s/it] 82%|████████▏ | 213/261 [05:18<01:00,  1.25s/it] 82%|████████▏ | 214/261 [05:19<00:57,  1.23s/it] 82%|████████▏ | 215/261 [05:20<00:55,  1.20s/it] 83%|████████▎ | 216/261 [05:21<00:53,  1.19s/it] 83%|████████▎ | 217/261 [05:22<00:51,  1.18s/it] 84%|████████▎ | 218/261 [05:24<00:50,  1.17s/it] 84%|████████▍ | 219/261 [05:25<00:50,  1.21s/it] 84%|████████▍ | 220/261 [05:26<00:49,  1.20s/it] 85%|████████▍ | 221/261 [05:27<00:47,  1.18s/it] 85%|████████▌ | 222/261 [05:28<00:45,  1.18s/it] 85%|████████▌ | 223/261 [05:29<00:44,  1.17s/it] 86%|████████▌ | 224/261 [05:31<00:43,  1.17s/it] 86%|████████▌ | 225/261 [05:32<00:41,  1.16s/it] 87%|████████▋ | 226/261 [05:33<00:40,  1.16s/it] 87%|████████▋ | 227/261 [05:34<00:39,  1.16s/it] 87%|████████▋ | 228/261 [05:35<00:38,  1.16s/it] 88%|████████▊ | 229/261 [05:36<00:37,  1.16s/it] 88%|████████▊ | 230/261 [05:38<00:35,  1.16s/it] 89%|████████▊ | 231/261 [05:39<00:34,  1.16s/it] 89%|████████▉ | 232/261 [05:40<00:33,  1.14s/it]{'eval_loss': 5.2893571853637695, 'eval_precision': 0.6311787072243346, 'eval_recall': 0.6434108527131783, 'eval_f1': 0.637236084452975, 'eval_accuracy': 0.9750534568781183, 'eval_runtime': 2.1638, 'eval_samples_per_second': 47.602, 'eval_steps_per_second': 1.849, 'epoch': 7.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.83it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.79it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.68it/s][A                                                 
                                             [A 89%|████████▉ | 232/261 [05:42<00:33,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.68it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 89%|████████▉ | 233/261 [05:51<01:56,  4.17s/it] 90%|████████▉ | 234/261 [05:52<01:28,  3.27s/it] 90%|█████████ | 235/261 [05:53<01:08,  2.63s/it] 90%|█████████ | 236/261 [05:55<00:54,  2.19s/it] 91%|█████████ | 237/261 [05:56<00:45,  1.88s/it] 91%|█████████ | 238/261 [05:57<00:38,  1.66s/it] 92%|█████████▏| 239/261 [05:58<00:33,  1.51s/it] 92%|█████████▏| 240/261 [05:59<00:29,  1.40s/it] 92%|█████████▏| 241/261 [06:00<00:26,  1.33s/it] 93%|█████████▎| 242/261 [06:01<00:24,  1.28s/it] 93%|█████████▎| 243/261 [06:03<00:22,  1.24s/it] 93%|█████████▎| 244/261 [06:04<00:20,  1.22s/it] 94%|█████████▍| 245/261 [06:05<00:19,  1.20s/it] 94%|█████████▍| 246/261 [06:06<00:17,  1.19s/it] 95%|█████████▍| 247/261 [06:07<00:16,  1.18s/it] 95%|█████████▌| 248/261 [06:08<00:15,  1.17s/it] 95%|█████████▌| 249/261 [06:10<00:13,  1.17s/it] 96%|█████████▌| 250/261 [06:11<00:12,  1.16s/it] 96%|█████████▌| 251/261 [06:12<00:11,  1.16s/it] 97%|█████████▋| 252/261 [06:13<00:10,  1.16s/it] 97%|█████████▋| 253/261 [06:14<00:09,  1.21s/it] 97%|█████████▋| 254/261 [06:15<00:08,  1.19s/it] 98%|█████████▊| 255/261 [06:17<00:07,  1.18s/it] 98%|█████████▊| 256/261 [06:18<00:05,  1.17s/it] 98%|█████████▊| 257/261 [06:19<00:04,  1.17s/it] 99%|█████████▉| 258/261 [06:20<00:03,  1.17s/it] 99%|█████████▉| 259/261 [06:21<00:02,  1.16s/it]100%|█████████▉| 260/261 [06:22<00:01,  1.16s/it]100%|██████████| 261/261 [06:24<00:00,  1.14s/it]{'eval_loss': 5.016750812530518, 'eval_precision': 0.708, 'eval_recall': 0.686046511627907, 'eval_f1': 0.6968503937007874, 'eval_accuracy': 0.9787954383464006, 'eval_runtime': 2.0512, 'eval_samples_per_second': 50.214, 'eval_steps_per_second': 1.95, 'epoch': 8.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.82it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.80it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.64it/s][A                                                 
                                             [A100%|██████████| 261/261 [06:26<00:00,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.64it/s][A
                                             [A100%|██████████| 261/261 [06:26<00:00,  1.48s/it]
[I 2025-09-09 13:29:16,837] Trial 16 pruned. 
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▃▃▅▆▇▇██
wandb:                 eval/f1 ▁▄▅▆▇▇▇██
wandb:               eval/loss █▅▄▂▂▁▁▁▁
wandb:          eval/precision ▁▆▅▇██▇██
wandb:             eval/recall ▁▃▅▆▆▇███
wandb:            eval/runtime ▅█▄▂▂▂▆▁▃
wandb: eval/samples_per_second ▄▁▅▇▇▇▃█▆
wandb:   eval/steps_per_second ▄▁▅▇▇▇▃█▆
wandb:             train/epoch ▁▂▃▄▅▅▆▇█
wandb:       train/global_step ▁▂▃▄▅▅▆▇█
wandb: 
wandb: Run summary:
wandb:           eval/accuracy 0.9788
wandb:                 eval/f1 0.69444
wandb:               eval/loss 4.95913
wandb:          eval/precision 0.71138
wandb:             eval/recall 0.67829
wandb:            eval/runtime 2.0967
wandb: eval/samples_per_second 49.124
wandb:   eval/steps_per_second 1.908
wandb:             train/epoch 9
wandb:       train/global_step 261
wandb: 
wandb: 🚀 View run genial-wave-721 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/v4b1x697
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250909_132249-v4b1x697/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_132919-64hmlnqo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-dawn-722
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/64hmlnqo
{'eval_loss': 4.9591264724731445, 'eval_precision': 0.7113821138211383, 'eval_recall': 0.6782945736434108, 'eval_f1': 0.6944444444444445, 'eval_accuracy': 0.9787954383464006, 'eval_runtime': 2.0967, 'eval_samples_per_second': 49.124, 'eval_steps_per_second': 1.908, 'epoch': 9.0}
  0%|          | 0/2320 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/2320 [00:00<35:59,  1.07it/s]  0%|          | 2/2320 [00:01<35:28,  1.09it/s]  0%|          | 3/2320 [00:02<35:23,  1.09it/s]  0%|          | 4/2320 [00:03<35:23,  1.09it/s]  0%|          | 5/2320 [00:04<35:24,  1.09it/s]  0%|          | 6/2320 [00:05<35:23,  1.09it/s]  0%|          | 7/2320 [00:06<35:21,  1.09it/s]  0%|          | 8/2320 [00:07<35:21,  1.09it/s]  0%|          | 9/2320 [00:08<35:20,  1.09it/s]  0%|          | 10/2320 [00:09<35:17,  1.09it/s]  0%|          | 11/2320 [00:10<35:11,  1.09it/s]  1%|          | 12/2320 [00:10<35:03,  1.10it/s]  1%|          | 13/2320 [00:11<35:05,  1.10it/s]  1%|          | 14/2320 [00:12<35:07,  1.09it/s]  1%|          | 15/2320 [00:13<35:09,  1.09it/s]  1%|          | 16/2320 [00:14<35:10,  1.09it/s]  1%|          | 17/2320 [00:15<35:10,  1.09it/s]  1%|          | 18/2320 [00:16<35:09,  1.09it/s]  1%|          | 19/2320 [00:17<35:09,  1.09it/s]  1%|          | 20/2320 [00:18<35:09,  1.09it/s]  1%|          | 21/2320 [00:19<35:07,  1.09it/s]  1%|          | 22/2320 [00:20<35:06,  1.09it/s]  1%|          | 23/2320 [00:21<35:06,  1.09it/s]  1%|          | 24/2320 [00:21<35:05,  1.09it/s]  1%|          | 25/2320 [00:22<35:04,  1.09it/s]  1%|          | 26/2320 [00:23<35:05,  1.09it/s]  1%|          | 27/2320 [00:24<35:03,  1.09it/s]  1%|          | 28/2320 [00:25<35:02,  1.09it/s]  1%|▏         | 29/2320 [00:26<35:03,  1.09it/s]  1%|▏         | 30/2320 [00:27<35:01,  1.09it/s]  1%|▏         | 31/2320 [00:28<36:57,  1.03it/s]  1%|▏         | 32/2320 [00:29<36:21,  1.05it/s]  1%|▏         | 33/2320 [00:30<35:46,  1.07it/s]  1%|▏         | 34/2320 [00:31<35:26,  1.07it/s]  2%|▏         | 35/2320 [00:32<35:17,  1.08it/s]  2%|▏         | 36/2320 [00:33<35:10,  1.08it/s]  2%|▏         | 37/2320 [00:34<35:05,  1.08it/s]  2%|▏         | 38/2320 [00:34<35:00,  1.09it/s]  2%|▏         | 39/2320 [00:35<34:57,  1.09it/s]  2%|▏         | 40/2320 [00:36<34:56,  1.09it/s]  2%|▏         | 41/2320 [00:37<34:53,  1.09it/s]  2%|▏         | 42/2320 [00:38<34:52,  1.09it/s]  2%|▏         | 43/2320 [00:39<34:49,  1.09it/s]  2%|▏         | 44/2320 [00:40<34:40,  1.09it/s]  2%|▏         | 45/2320 [00:41<34:37,  1.09it/s]  2%|▏         | 46/2320 [00:42<34:40,  1.09it/s]  2%|▏         | 47/2320 [00:43<34:41,  1.09it/s]  2%|▏         | 48/2320 [00:44<34:42,  1.09it/s]  2%|▏         | 49/2320 [00:45<34:42,  1.09it/s]  2%|▏         | 50/2320 [00:45<34:41,  1.09it/s]  2%|▏         | 51/2320 [00:46<34:41,  1.09it/s]  2%|▏         | 52/2320 [00:47<34:39,  1.09it/s]  2%|▏         | 53/2320 [00:48<34:40,  1.09it/s]  2%|▏         | 54/2320 [00:49<34:38,  1.09it/s]  2%|▏         | 55/2320 [00:50<34:36,  1.09it/s]  2%|▏         | 56/2320 [00:51<34:36,  1.09it/s]  2%|▏         | 57/2320 [00:52<36:16,  1.04it/s]  2%|▎         | 58/2320 [00:53<35:45,  1.05it/s]  3%|▎         | 59/2320 [00:54<35:24,  1.06it/s]  3%|▎         | 60/2320 [00:55<35:09,  1.07it/s]  3%|▎         | 61/2320 [00:56<34:49,  1.08it/s]  3%|▎         | 62/2320 [00:57<34:38,  1.09it/s]  3%|▎         | 63/2320 [00:58<34:34,  1.09it/s]  3%|▎         | 64/2320 [00:58<34:33,  1.09it/s]  3%|▎         | 65/2320 [00:59<34:29,  1.09it/s]  3%|▎         | 66/2320 [01:00<34:28,  1.09it/s]  3%|▎         | 67/2320 [01:01<34:26,  1.09it/s]  3%|▎         | 68/2320 [01:02<34:26,  1.09it/s]  3%|▎         | 69/2320 [01:03<34:25,  1.09it/s]  3%|▎         | 70/2320 [01:04<34:24,  1.09it/s]  3%|▎         | 71/2320 [01:05<34:23,  1.09it/s]  3%|▎         | 72/2320 [01:06<34:22,  1.09it/s]  3%|▎         | 73/2320 [01:07<34:21,  1.09it/s]  3%|▎         | 74/2320 [01:08<34:18,  1.09it/s]  3%|▎         | 75/2320 [01:09<34:17,  1.09it/s]  3%|▎         | 76/2320 [01:09<34:15,  1.09it/s]  3%|▎         | 77/2320 [01:10<34:05,  1.10it/s]  3%|▎         | 78/2320 [01:11<34:08,  1.09it/s]  3%|▎         | 79/2320 [01:12<34:10,  1.09it/s]  3%|▎         | 80/2320 [01:13<34:11,  1.09it/s]  3%|▎         | 81/2320 [01:14<34:10,  1.09it/s]  4%|▎         | 82/2320 [01:15<35:51,  1.04it/s]  4%|▎         | 83/2320 [01:16<35:22,  1.05it/s]  4%|▎         | 84/2320 [01:17<35:00,  1.06it/s]  4%|▎         | 85/2320 [01:18<34:45,  1.07it/s]  4%|▎         | 86/2320 [01:19<34:35,  1.08it/s]  4%|▍         | 87/2320 [01:20<34:26,  1.08it/s]  4%|▍         | 88/2320 [01:21<34:20,  1.08it/s]  4%|▍         | 89/2320 [01:22<34:15,  1.09it/s]  4%|▍         | 90/2320 [01:22<34:11,  1.09it/s]  4%|▍         | 91/2320 [01:23<34:09,  1.09it/s]  4%|▍         | 92/2320 [01:24<34:08,  1.09it/s]  4%|▍         | 93/2320 [01:25<34:05,  1.09it/s]  4%|▍         | 94/2320 [01:26<34:03,  1.09it/s]  4%|▍         | 95/2320 [01:27<34:02,  1.09it/s]  4%|▍         | 96/2320 [01:28<34:01,  1.09it/s]  4%|▍         | 97/2320 [01:29<34:00,  1.09it/s]  4%|▍         | 98/2320 [01:30<33:59,  1.09it/s]  4%|▍         | 99/2320 [01:31<33:57,  1.09it/s]  4%|▍         | 100/2320 [01:32<33:55,  1.09it/s]  4%|▍         | 101/2320 [01:33<33:54,  1.09it/s]  4%|▍         | 102/2320 [01:33<33:51,  1.09it/s]  4%|▍         | 103/2320 [01:34<33:51,  1.09it/s]  4%|▍         | 104/2320 [01:35<33:51,  1.09it/s]  5%|▍         | 105/2320 [01:36<33:51,  1.09it/s]  5%|▍         | 106/2320 [01:37<33:50,  1.09it/s]  5%|▍         | 107/2320 [01:38<33:50,  1.09it/s]  5%|▍         | 108/2320 [01:39<33:49,  1.09it/s]  5%|▍         | 109/2320 [01:40<33:48,  1.09it/s]  5%|▍         | 110/2320 [01:41<33:45,  1.09it/s]  5%|▍         | 111/2320 [01:42<33:44,  1.09it/s]  5%|▍         | 112/2320 [01:43<33:43,  1.09it/s]  5%|▍         | 113/2320 [01:44<33:43,  1.09it/s]  5%|▍         | 114/2320 [01:44<33:41,  1.09it/s]  5%|▍         | 115/2320 [01:45<33:40,  1.09it/s]  5%|▌         | 116/2320 [01:46<28:42,  1.28it/s]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.87it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.80it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.65it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                  
                                             [A  5%|▌         | 116/2320 [01:48<28:42,  1.28it/s]
100%|██████████| 4/4 [00:01<00:00,  2.65it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  5%|▌         | 117/2320 [02:01<3:07:19,  5.10s/it]  5%|▌         | 118/2320 [02:02<2:21:08,  3.85s/it]  5%|▌         | 119/2320 [02:03<1:48:52,  2.97s/it]  5%|▌         | 120/2320 [02:04<1:26:16,  2.35s/it]  5%|▌         | 121/2320 [02:05<1:10:27,  1.92s/it]  5%|▌         | 122/2320 [02:06<59:22,  1.62s/it]    5%|▌         | 123/2320 [02:07<53:13,  1.45s/it]  5%|▌         | 124/2320 [02:08<47:20,  1.29s/it]  5%|▌         | 125/2320 [02:09<43:11,  1.18s/it]  5%|▌         | 126/2320 [02:09<40:16,  1.10s/it]  5%|▌         | 127/2320 [02:10<38:13,  1.05s/it]  6%|▌         | 128/2320 [02:11<36:44,  1.01s/it]  6%|▌         | 129/2320 [02:12<35:49,  1.02it/s]  6%|▌         | 130/2320 [02:13<35:07,  1.04it/s]  6%|▌         | 131/2320 [02:14<34:38,  1.05it/s]  6%|▌         | 132/2320 [02:15<34:16,  1.06it/s]  6%|▌         | 133/2320 [02:16<34:01,  1.07it/s]  6%|▌         | 134/2320 [02:17<33:51,  1.08it/s]  6%|▌         | 135/2320 [02:18<33:41,  1.08it/s]  6%|▌         | 136/2320 [02:19<33:38,  1.08it/s]  6%|▌         | 137/2320 [02:20<33:35,  1.08it/s]  6%|▌         | 138/2320 [02:20<33:30,  1.09it/s]  6%|▌         | 139/2320 [02:21<33:26,  1.09it/s]  6%|▌         | 140/2320 [02:22<33:23,  1.09it/s]  6%|▌         | 141/2320 [02:23<33:21,  1.09it/s]  6%|▌         | 142/2320 [02:24<33:19,  1.09it/s]  6%|▌         | 143/2320 [02:25<33:18,  1.09it/s]  6%|▌         | 144/2320 [02:26<33:17,  1.09it/s]  6%|▋         | 145/2320 [02:27<33:15,  1.09it/s]  6%|▋         | 146/2320 [02:28<33:15,  1.09it/s]  6%|▋         | 147/2320 [02:29<33:15,  1.09it/s]  6%|▋         | 148/2320 [02:30<33:18,  1.09it/s]  6%|▋         | 149/2320 [02:31<33:15,  1.09it/s]  6%|▋         | 150/2320 [02:31<33:13,  1.09it/s]  7%|▋         | 151/2320 [02:32<33:10,  1.09it/s]  7%|▋         | 152/2320 [02:33<33:11,  1.09it/s]  7%|▋         | 153/2320 [02:34<33:09,  1.09it/s]  7%|▋         | 154/2320 [02:35<33:10,  1.09it/s]  7%|▋         | 155/2320 [02:36<33:07,  1.09it/s]  7%|▋         | 156/2320 [02:37<33:06,  1.09it/s]  7%|▋         | 157/2320 [02:38<33:06,  1.09it/s]  7%|▋         | 158/2320 [02:39<33:07,  1.09it/s]  7%|▋         | 159/2320 [02:40<33:05,  1.09it/s]  7%|▋         | 160/2320 [02:41<33:04,  1.09it/s]  7%|▋         | 161/2320 [02:42<33:04,  1.09it/s]  7%|▋         | 162/2320 [02:42<33:03,  1.09it/s]  7%|▋         | 163/2320 [02:43<33:01,  1.09it/s]  7%|▋         | 164/2320 [02:44<33:00,  1.09it/s]  7%|▋         | 165/2320 [02:45<33:00,  1.09it/s]  7%|▋         | 166/2320 [02:46<32:57,  1.09it/s]  7%|▋         | 167/2320 [02:47<32:58,  1.09it/s]  7%|▋         | 168/2320 [02:48<32:57,  1.09it/s]  7%|▋         | 169/2320 [02:49<32:56,  1.09it/s]  7%|▋         | 170/2320 [02:50<32:55,  1.09it/s]  7%|▋         | 171/2320 [02:51<32:52,  1.09it/s]  7%|▋         | 172/2320 [02:52<32:52,  1.09it/s]  7%|▋         | 173/2320 [02:53<32:51,  1.09it/s]  8%|▊         | 174/2320 [02:54<34:27,  1.04it/s]  8%|▊         | 175/2320 [02:55<33:58,  1.05it/s]  8%|▊         | 176/2320 [02:55<33:32,  1.07it/s]  8%|▊         | 177/2320 [02:56<33:12,  1.08it/s]  8%|▊         | 178/2320 [02:57<33:05,  1.08it/s]  8%|▊         | 179/2320 [02:58<32:59,  1.08it/s]  8%|▊         | 180/2320 [02:59<32:54,  1.08it/s]  8%|▊         | 181/2320 [03:00<32:50,  1.09it/s]  8%|▊         | 182/2320 [03:01<32:49,  1.09it/s]  8%|▊         | 183/2320 [03:02<32:45,  1.09it/s]  8%|▊         | 184/2320 [03:03<32:42,  1.09it/s]  8%|▊         | 185/2320 [03:04<32:40,  1.09it/s]  8%|▊         | 186/2320 [03:05<32:38,  1.09it/s]  8%|▊         | 187/2320 [03:06<32:37,  1.09it/s]  8%|▊         | 188/2320 [03:06<32:35,  1.09it/s]  8%|▊         | 189/2320 [03:07<32:35,  1.09it/s]  8%|▊         | 190/2320 [03:08<32:34,  1.09it/s]  8%|▊         | 191/2320 [03:09<32:34,  1.09it/s]  8%|▊         | 192/2320 [03:10<32:32,  1.09it/s]  8%|▊         | 193/2320 [03:11<32:32,  1.09it/s]  8%|▊         | 194/2320 [03:12<32:31,  1.09it/s]  8%|▊         | 195/2320 [03:13<32:29,  1.09it/s]  8%|▊         | 196/2320 [03:14<32:29,  1.09it/s]  8%|▊         | 197/2320 [03:15<32:30,  1.09it/s]  9%|▊         | 198/2320 [03:16<32:29,  1.09it/s]  9%|▊         | 199/2320 [03:17<32:27,  1.09it/s]  9%|▊         | 200/2320 [03:18<32:26,  1.09it/s]  9%|▊         | 201/2320 [03:18<32:25,  1.09it/s]  9%|▊         | 202/2320 [03:19<32:24,  1.09it/s]  9%|▉         | 203/2320 [03:20<32:23,  1.09it/s]  9%|▉         | 204/2320 [03:21<32:22,  1.09it/s]  9%|▉         | 205/2320 [03:22<32:21,  1.09it/s]  9%|▉         | 206/2320 [03:23<32:20,  1.09it/s]  9%|▉         | 207/2320 [03:24<32:19,  1.09it/s]  9%|▉         | 208/2320 [03:25<32:19,  1.09it/s]  9%|▉         | 209/2320 [03:26<32:19,  1.09it/s]  9%|▉         | 210/2320 [03:27<32:17,  1.09it/s]  9%|▉         | 211/2320 [03:28<32:17,  1.09it/s]  9%|▉         | 212/2320 [03:29<32:16,  1.09it/s]  9%|▉         | 213/2320 [03:30<33:45,  1.04it/s]  9%|▉         | 214/2320 [03:31<33:10,  1.06it/s]  9%|▉         | 215/2320 [03:31<32:53,  1.07it/s]  9%|▉         | 216/2320 [03:32<32:40,  1.07it/s]  9%|▉         | 217/2320 [03:33<32:29,  1.08it/s]  9%|▉         | 218/2320 [03:34<32:24,  1.08it/s]  9%|▉         | 219/2320 [03:35<32:20,  1.08it/s]  9%|▉         | 220/2320 [03:36<32:13,  1.09it/s] 10%|▉         | 221/2320 [03:37<32:11,  1.09it/s] 10%|▉         | 222/2320 [03:38<32:09,  1.09it/s] 10%|▉         | 223/2320 [03:39<32:09,  1.09it/s] 10%|▉         | 224/2320 [03:40<32:06,  1.09it/s] 10%|▉         | 225/2320 [03:41<32:05,  1.09it/s] 10%|▉         | 226/2320 [03:42<32:04,  1.09it/s] 10%|▉         | 227/2320 [03:42<32:04,  1.09it/s] 10%|▉         | 228/2320 [03:43<32:02,  1.09it/s] 10%|▉         | 229/2320 [03:44<32:01,  1.09it/s] 10%|▉         | 230/2320 [03:45<31:59,  1.09it/s] 10%|▉         | 231/2320 [03:46<31:58,  1.09it/s] 10%|█         | 232/2320 [03:47<27:15,  1.28it/s]{'eval_loss': 12.409260749816895, 'eval_precision': 0.46808510638297873, 'eval_recall': 0.17054263565891473, 'eval_f1': 0.25, 'eval_accuracy': 0.9476122594440485, 'eval_runtime': 2.0899, 'eval_samples_per_second': 49.284, 'eval_steps_per_second': 1.914, 'epoch': 1.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.87it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.80it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.79it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                  
                                             [A 10%|█         | 232/2320 [03:49<27:15,  1.28it/s]
100%|██████████| 4/4 [00:01<00:00,  2.79it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 10%|█         | 233/2320 [03:58<2:16:54,  3.94s/it] 10%|█         | 234/2320 [03:59<1:45:19,  3.03s/it] 10%|█         | 235/2320 [04:00<1:23:15,  2.40s/it] 10%|█         | 236/2320 [04:01<1:07:48,  1.95s/it] 10%|█         | 237/2320 [04:02<56:59,  1.64s/it]   10%|█         | 238/2320 [04:02<49:25,  1.42s/it] 10%|█         | 239/2320 [04:03<44:08,  1.27s/it] 10%|█         | 240/2320 [04:04<40:25,  1.17s/it] 10%|█         | 241/2320 [04:05<37:49,  1.09s/it] 10%|█         | 242/2320 [04:06<35:59,  1.04s/it] 10%|█         | 243/2320 [04:07<36:19,  1.05s/it] 11%|█         | 244/2320 [04:08<34:57,  1.01s/it] 11%|█         | 245/2320 [04:09<33:59,  1.02it/s] 11%|█         | 246/2320 [04:10<33:10,  1.04it/s] 11%|█         | 247/2320 [04:11<32:40,  1.06it/s] 11%|█         | 248/2320 [04:12<32:22,  1.07it/s] 11%|█         | 249/2320 [04:13<32:10,  1.07it/s] 11%|█         | 250/2320 [04:14<32:01,  1.08it/s] 11%|█         | 251/2320 [04:15<31:54,  1.08it/s] 11%|█         | 252/2320 [04:15<31:49,  1.08it/s] 11%|█         | 253/2320 [04:16<31:45,  1.08it/s] 11%|█         | 254/2320 [04:17<31:42,  1.09it/s] 11%|█         | 255/2320 [04:18<31:39,  1.09it/s] 11%|█         | 256/2320 [04:19<31:37,  1.09it/s] 11%|█         | 257/2320 [04:20<31:25,  1.09it/s] 11%|█         | 258/2320 [04:21<31:25,  1.09it/s] 11%|█         | 259/2320 [04:22<31:27,  1.09it/s] 11%|█         | 260/2320 [04:23<31:27,  1.09it/s] 11%|█▏        | 261/2320 [04:24<31:28,  1.09it/s] 11%|█▏        | 262/2320 [04:25<31:26,  1.09it/s] 11%|█▏        | 263/2320 [04:26<31:27,  1.09it/s] 11%|█▏        | 264/2320 [04:26<31:25,  1.09it/s] 11%|█▏        | 265/2320 [04:27<31:26,  1.09it/s] 11%|█▏        | 266/2320 [04:28<31:25,  1.09it/s] 12%|█▏        | 267/2320 [04:29<31:25,  1.09it/s] 12%|█▏        | 268/2320 [04:30<31:25,  1.09it/s] 12%|█▏        | 269/2320 [04:31<32:54,  1.04it/s] 12%|█▏        | 270/2320 [04:32<32:27,  1.05it/s] 12%|█▏        | 271/2320 [04:33<32:05,  1.06it/s] 12%|█▏        | 272/2320 [04:34<31:51,  1.07it/s] 12%|█▏        | 273/2320 [04:35<31:40,  1.08it/s] 12%|█▏        | 274/2320 [04:36<31:33,  1.08it/s] 12%|█▏        | 275/2320 [04:37<31:28,  1.08it/s] 12%|█▏        | 276/2320 [04:38<31:22,  1.09it/s] 12%|█▏        | 277/2320 [04:39<31:20,  1.09it/s] 12%|█▏        | 278/2320 [04:39<31:16,  1.09it/s] 12%|█▏        | 279/2320 [04:40<31:05,  1.09it/s] 12%|█▏        | 280/2320 [04:41<31:08,  1.09it/s] 12%|█▏        | 281/2320 [04:42<31:07,  1.09it/s] 12%|█▏        | 282/2320 [04:43<31:07,  1.09it/s] 12%|█▏        | 283/2320 [04:44<31:08,  1.09it/s] 12%|█▏        | 284/2320 [04:45<31:08,  1.09it/s] 12%|█▏        | 285/2320 [04:46<31:08,  1.09it/s] 12%|█▏        | 286/2320 [04:47<31:06,  1.09it/s] 12%|█▏        | 287/2320 [04:48<31:07,  1.09it/s] 12%|█▏        | 288/2320 [04:49<31:06,  1.09it/s] 12%|█▏        | 289/2320 [04:50<31:02,  1.09it/s] 12%|█▎        | 290/2320 [04:50<30:53,  1.10it/s] 13%|█▎        | 291/2320 [04:51<30:55,  1.09it/s] 13%|█▎        | 292/2320 [04:52<30:56,  1.09it/s] 13%|█▎        | 293/2320 [04:53<30:58,  1.09it/s] 13%|█▎        | 294/2320 [04:54<32:28,  1.04it/s] 13%|█▎        | 295/2320 [04:55<32:00,  1.05it/s] 13%|█▎        | 296/2320 [04:56<31:31,  1.07it/s] 13%|█▎        | 297/2320 [04:57<31:20,  1.08it/s] 13%|█▎        | 298/2320 [04:58<31:11,  1.08it/s] 13%|█▎        | 299/2320 [04:59<31:05,  1.08it/s] 13%|█▎        | 300/2320 [05:00<31:02,  1.08it/s] 13%|█▎        | 301/2320 [05:01<30:59,  1.09it/s] 13%|█▎        | 302/2320 [05:02<30:57,  1.09it/s] 13%|█▎        | 303/2320 [05:03<30:56,  1.09it/s] 13%|█▎        | 304/2320 [05:03<30:52,  1.09it/s] 13%|█▎        | 305/2320 [05:04<30:51,  1.09it/s] 13%|█▎        | 306/2320 [05:05<30:48,  1.09it/s] 13%|█▎        | 307/2320 [05:06<30:48,  1.09it/s] 13%|█▎        | 308/2320 [05:07<30:46,  1.09it/s] 13%|█▎        | 309/2320 [05:08<30:43,  1.09it/s] 13%|█▎        | 310/2320 [05:09<30:42,  1.09it/s] 13%|█▎        | 311/2320 [05:10<30:43,  1.09it/s] 13%|█▎        | 312/2320 [05:11<30:42,  1.09it/s] 13%|█▎        | 313/2320 [05:12<30:42,  1.09it/s] 14%|█▎        | 314/2320 [05:13<30:40,  1.09it/s] 14%|█▎        | 315/2320 [05:14<30:40,  1.09it/s] 14%|█▎        | 316/2320 [05:14<30:39,  1.09it/s] 14%|█▎        | 317/2320 [05:15<30:39,  1.09it/s] 14%|█▎        | 318/2320 [05:16<30:36,  1.09it/s] 14%|█▍        | 319/2320 [05:17<30:35,  1.09it/s] 14%|█▍        | 320/2320 [05:18<30:33,  1.09it/s] 14%|█▍        | 321/2320 [05:19<30:33,  1.09it/s] 14%|█▍        | 322/2320 [05:20<30:24,  1.09it/s] 14%|█▍        | 323/2320 [05:21<30:23,  1.10it/s] 14%|█▍        | 324/2320 [05:22<30:25,  1.09it/s] 14%|█▍        | 325/2320 [05:23<30:26,  1.09it/s] 14%|█▍        | 326/2320 [05:24<30:26,  1.09it/s] 14%|█▍        | 327/2320 [05:25<30:26,  1.09it/s] 14%|█▍        | 328/2320 [05:25<30:25,  1.09it/s] 14%|█▍        | 329/2320 [05:26<30:24,  1.09it/s] 14%|█▍        | 330/2320 [05:27<30:23,  1.09it/s] 14%|█▍        | 331/2320 [05:28<30:24,  1.09it/s] 14%|█▍        | 332/2320 [05:29<30:24,  1.09it/s] 14%|█▍        | 333/2320 [05:30<30:15,  1.09it/s] 14%|█▍        | 334/2320 [05:31<30:14,  1.09it/s] 14%|█▍        | 335/2320 [05:32<30:17,  1.09it/s] 14%|█▍        | 336/2320 [05:33<30:17,  1.09it/s] 15%|█▍        | 337/2320 [05:34<30:17,  1.09it/s] 15%|█▍        | 338/2320 [05:35<30:17,  1.09it/s] 15%|█▍        | 339/2320 [05:36<30:16,  1.09it/s] 15%|█▍        | 340/2320 [05:36<30:16,  1.09it/s] 15%|█▍        | 341/2320 [05:37<30:15,  1.09it/s] 15%|█▍        | 342/2320 [05:38<30:14,  1.09it/s] 15%|█▍        | 343/2320 [05:39<30:13,  1.09it/s] 15%|█▍        | 344/2320 [05:40<30:13,  1.09it/s] 15%|█▍        | 345/2320 [05:41<30:12,  1.09it/s] 15%|█▍        | 346/2320 [05:42<31:41,  1.04it/s] 15%|█▍        | 347/2320 [05:43<31:14,  1.05it/s] 15%|█▌        | 348/2320 [05:43<26:28,  1.24it/s]{'eval_loss': 10.484824180603027, 'eval_precision': 0.7181208053691275, 'eval_recall': 0.41472868217054265, 'eval_f1': 0.5257985257985257, 'eval_accuracy': 0.9607982893799002, 'eval_runtime': 2.04, 'eval_samples_per_second': 50.491, 'eval_steps_per_second': 1.961, 'epoch': 2.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  4.08it/s][A
 75%|███████▌  | 3/4 [00:00<00:00,  2.89it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.68it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                  
                                             [A 15%|█▌        | 348/2320 [05:46<26:28,  1.24it/s]
100%|██████████| 4/4 [00:01<00:00,  2.68it/s][A
                                             [A 15%|█▌        | 348/2320 [05:46<32:40,  1.01it/s]
[I 2025-09-09 13:35:06,574] Trial 17 pruned. 
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁▆█
wandb:                 eval/f1 ▁▆█
wandb:               eval/loss █▂▁
wandb:          eval/precision ▁▆█
wandb:             eval/recall ▁▆█
wandb:            eval/runtime █▁▁
wandb: eval/samples_per_second ▁██
wandb:   eval/steps_per_second ▁██
wandb:             train/epoch ▁▅█
wandb:       train/global_step ▁▅█
wandb: 
wandb: Run summary:
wandb:           eval/accuracy 0.96721
wandb:                 eval/f1 0.63741
wandb:               eval/loss 10.01764
wandb:          eval/precision 0.78857
wandb:             eval/recall 0.53488
wandb:            eval/runtime 2.0396
wandb: eval/samples_per_second 50.499
wandb:   eval/steps_per_second 1.961
wandb:             train/epoch 3
wandb:       train/global_step 348
wandb: 
wandb: 🚀 View run stoic-dawn-722 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/64hmlnqo
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250909_132919-64hmlnqo/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_133509-ohzhins3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-field-723
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/ohzhins3
{'eval_loss': 10.017635345458984, 'eval_precision': 0.7885714285714286, 'eval_recall': 0.5348837209302325, 'eval_f1': 0.6374133949191686, 'eval_accuracy': 0.9672131147540983, 'eval_runtime': 2.0396, 'eval_samples_per_second': 50.499, 'eval_steps_per_second': 1.961, 'epoch': 3.0}
  0%|          | 0/1682 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/1682 [00:01<28:45,  1.03s/it]  0%|          | 2/1682 [00:02<28:21,  1.01s/it]  0%|          | 3/1682 [00:03<28:23,  1.01s/it]  0%|          | 4/1682 [00:04<28:23,  1.01s/it]  0%|          | 5/1682 [00:05<28:23,  1.02s/it]  0%|          | 6/1682 [00:06<28:20,  1.01s/it]  0%|          | 7/1682 [00:07<28:13,  1.01s/it]  0%|          | 8/1682 [00:08<28:16,  1.01s/it]  1%|          | 9/1682 [00:09<28:18,  1.02s/it]  1%|          | 10/1682 [00:10<28:19,  1.02s/it]  1%|          | 11/1682 [00:11<28:18,  1.02s/it]  1%|          | 12/1682 [00:12<28:17,  1.02s/it]  1%|          | 13/1682 [00:13<28:16,  1.02s/it]  1%|          | 14/1682 [00:14<28:16,  1.02s/it]  1%|          | 15/1682 [00:15<28:15,  1.02s/it]  1%|          | 16/1682 [00:16<28:14,  1.02s/it]  1%|          | 17/1682 [00:17<28:13,  1.02s/it]  1%|          | 18/1682 [00:18<28:12,  1.02s/it]  1%|          | 19/1682 [00:19<28:11,  1.02s/it]  1%|          | 20/1682 [00:20<28:10,  1.02s/it]  1%|          | 21/1682 [00:21<28:10,  1.02s/it]  1%|▏         | 22/1682 [00:22<28:09,  1.02s/it]  1%|▏         | 23/1682 [00:23<28:09,  1.02s/it]  1%|▏         | 24/1682 [00:24<28:08,  1.02s/it]  1%|▏         | 25/1682 [00:25<28:07,  1.02s/it]  2%|▏         | 26/1682 [00:26<28:05,  1.02s/it]  2%|▏         | 27/1682 [00:27<28:04,  1.02s/it]  2%|▏         | 28/1682 [00:28<28:03,  1.02s/it]  2%|▏         | 29/1682 [00:29<28:02,  1.02s/it]  2%|▏         | 30/1682 [00:30<28:01,  1.02s/it]  2%|▏         | 31/1682 [00:31<29:21,  1.07s/it]  2%|▏         | 32/1682 [00:32<28:56,  1.05s/it]  2%|▏         | 33/1682 [00:33<28:37,  1.04s/it]  2%|▏         | 34/1682 [00:34<28:25,  1.03s/it]  2%|▏         | 35/1682 [00:35<28:17,  1.03s/it]  2%|▏         | 36/1682 [00:36<28:10,  1.03s/it]  2%|▏         | 37/1682 [00:37<28:05,  1.02s/it]  2%|▏         | 38/1682 [00:38<28:00,  1.02s/it]  2%|▏         | 39/1682 [00:39<27:57,  1.02s/it]  2%|▏         | 40/1682 [00:40<27:56,  1.02s/it]  2%|▏         | 41/1682 [00:41<27:55,  1.02s/it]  2%|▏         | 42/1682 [00:42<27:53,  1.02s/it]  3%|▎         | 43/1682 [00:43<27:52,  1.02s/it]  3%|▎         | 44/1682 [00:44<27:52,  1.02s/it]  3%|▎         | 45/1682 [00:45<27:51,  1.02s/it]  3%|▎         | 46/1682 [00:46<27:51,  1.02s/it]  3%|▎         | 47/1682 [00:48<27:50,  1.02s/it]  3%|▎         | 48/1682 [00:49<27:50,  1.02s/it]  3%|▎         | 49/1682 [00:50<27:48,  1.02s/it]  3%|▎         | 50/1682 [00:51<27:47,  1.02s/it]  3%|▎         | 51/1682 [00:52<27:46,  1.02s/it]  3%|▎         | 52/1682 [00:53<27:44,  1.02s/it]  3%|▎         | 53/1682 [00:54<27:43,  1.02s/it]  3%|▎         | 54/1682 [00:55<27:41,  1.02s/it]  3%|▎         | 55/1682 [00:56<27:38,  1.02s/it]  3%|▎         | 56/1682 [00:57<27:37,  1.02s/it]  3%|▎         | 57/1682 [00:58<28:46,  1.06s/it]  3%|▎         | 58/1682 [00:59<27:54,  1.03s/it]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.84it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.70it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.54it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                 
                                             [A  3%|▎         | 58/1682 [01:01<27:54,  1.03s/it]
100%|██████████| 4/4 [00:01<00:00,  2.54it/s][A
                                             [A  3%|▎         | 58/1682 [01:01<28:41,  1.06s/it]
[I 2025-09-09 13:36:11,747] Trial 18 pruned. 
Trying to set optimizer in the hyperparameter search but there is no corresponding field in `TrainingArguments`.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁
wandb:                 eval/f1 ▁
wandb:               eval/loss ▁
wandb:          eval/precision ▁
wandb:             eval/recall ▁
wandb:            eval/runtime ▁
wandb: eval/samples_per_second ▁
wandb:   eval/steps_per_second ▁
wandb:             train/epoch ▁
wandb:       train/global_step ▁
wandb: 
wandb: Run summary:
wandb:           eval/accuracy 0.70848
wandb:                 eval/f1 0.00709
wandb:               eval/loss 97.06676
wandb:          eval/precision 0.00418
wandb:             eval/recall 0.02326
wandb:            eval/runtime 2.1508
wandb: eval/samples_per_second 47.889
wandb:   eval/steps_per_second 1.86
wandb:             train/epoch 1
wandb:       train/global_step 58
wandb: 
wandb: 🚀 View run vivid-field-723 at: https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/ohzhins3
wandb: ⭐️ View project at: https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250909_133509-ohzhins3/logs
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250909_133614-xuinhbyw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-bush-724
wandb: ⭐️ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: 🚀 View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/xuinhbyw
{'eval_loss': 97.06675720214844, 'eval_precision': 0.004181184668989547, 'eval_recall': 0.023255813953488372, 'eval_f1': 0.007088009450679267, 'eval_accuracy': 0.7084818246614397, 'eval_runtime': 2.1508, 'eval_samples_per_second': 47.889, 'eval_steps_per_second': 1.86, 'epoch': 1.0}
  0%|          | 0/261 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/261 [00:01<05:08,  1.19s/it]  1%|          | 2/261 [00:02<05:03,  1.17s/it]  1%|          | 3/261 [00:03<05:00,  1.16s/it]  2%|▏         | 4/261 [00:04<04:58,  1.16s/it]  2%|▏         | 5/261 [00:05<04:57,  1.16s/it]  2%|▏         | 6/261 [00:06<04:55,  1.16s/it]  3%|▎         | 7/261 [00:08<04:54,  1.16s/it]  3%|▎         | 8/261 [00:09<04:53,  1.16s/it]  3%|▎         | 9/261 [00:10<04:52,  1.16s/it]  4%|▍         | 10/261 [00:11<04:50,  1.16s/it]  4%|▍         | 11/261 [00:12<04:49,  1.16s/it]  5%|▍         | 12/261 [00:13<04:48,  1.16s/it]  5%|▍         | 13/261 [00:15<04:47,  1.16s/it]  5%|▌         | 14/261 [00:16<04:45,  1.16s/it]  6%|▌         | 15/261 [00:17<04:44,  1.16s/it]  6%|▌         | 16/261 [00:18<04:43,  1.16s/it]  7%|▋         | 17/261 [00:19<04:42,  1.16s/it]  7%|▋         | 18/261 [00:20<04:41,  1.16s/it]  7%|▋         | 19/261 [00:22<04:39,  1.16s/it]  8%|▊         | 20/261 [00:23<04:38,  1.16s/it]  8%|▊         | 21/261 [00:24<04:37,  1.16s/it]  8%|▊         | 22/261 [00:25<04:36,  1.16s/it]  9%|▉         | 23/261 [00:26<04:35,  1.16s/it]  9%|▉         | 24/261 [00:27<04:34,  1.16s/it] 10%|▉         | 25/261 [00:28<04:33,  1.16s/it] 10%|▉         | 26/261 [00:30<04:32,  1.16s/it] 10%|█         | 27/261 [00:31<04:30,  1.16s/it] 11%|█         | 28/261 [00:32<04:29,  1.16s/it] 11%|█         | 29/261 [00:33<04:24,  1.14s/it]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.83it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.78it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.71it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 11%|█         | 29/261 [00:35<04:24,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.71it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 11%|█▏        | 30/261 [00:44<15:27,  4.01s/it] 12%|█▏        | 31/261 [00:45<12:06,  3.16s/it] 12%|█▏        | 32/261 [00:46<09:45,  2.56s/it] 13%|█▎        | 33/261 [00:47<08:07,  2.14s/it] 13%|█▎        | 34/261 [00:48<06:58,  1.84s/it] 13%|█▎        | 35/261 [00:50<06:10,  1.64s/it] 14%|█▍        | 36/261 [00:51<05:35,  1.49s/it] 14%|█▍        | 37/261 [00:52<05:11,  1.39s/it] 15%|█▍        | 38/261 [00:53<04:54,  1.32s/it] 15%|█▍        | 39/261 [00:54<04:42,  1.27s/it] 15%|█▌        | 40/261 [00:55<04:33,  1.24s/it] 16%|█▌        | 41/261 [00:56<04:26,  1.21s/it] 16%|█▌        | 42/261 [00:58<04:21,  1.20s/it] 16%|█▋        | 43/261 [00:59<04:18,  1.18s/it] 17%|█▋        | 44/261 [01:00<04:15,  1.18s/it] 17%|█▋        | 45/261 [01:01<04:12,  1.17s/it] 18%|█▊        | 46/261 [01:02<04:10,  1.17s/it] 18%|█▊        | 47/261 [01:03<04:09,  1.16s/it] 18%|█▊        | 48/261 [01:05<04:07,  1.16s/it] 19%|█▉        | 49/261 [01:06<04:06,  1.16s/it] 19%|█▉        | 50/261 [01:07<04:04,  1.16s/it] 20%|█▉        | 51/261 [01:08<04:03,  1.16s/it] 20%|█▉        | 52/261 [01:09<04:02,  1.16s/it] 20%|██        | 53/261 [01:10<04:01,  1.16s/it] 21%|██        | 54/261 [01:12<03:59,  1.16s/it] 21%|██        | 55/261 [01:13<03:58,  1.16s/it] 21%|██▏       | 56/261 [01:14<03:57,  1.16s/it] 22%|██▏       | 57/261 [01:15<03:56,  1.16s/it] 22%|██▏       | 58/261 [01:16<03:51,  1.14s/it]{'eval_loss': 23.316253662109375, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9397719173200285, 'eval_runtime': 2.0614, 'eval_samples_per_second': 49.967, 'eval_steps_per_second': 1.94, 'epoch': 1.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.93it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.81it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.33it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 22%|██▏       | 58/261 [01:18<03:51,  1.14s/it]
100%|██████████| 4/4 [00:01<00:00,  2.33it/s][A
                                             [A 22%|██▏       | 58/261 [01:18<04:35,  1.36s/it]
[I 2025-09-09 13:37:34,325] Trial 19 pruned. 
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
/home/s27mhusa_hpc/Master-Thesis/Fine-tune/fine_tune_mdeberta-crf.py:376: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `DebertaCRFTrainer.__init__`. Use `processing_class` instead.
  final_trainer = DebertaCRFTrainer(
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'eval_loss': 16.405155181884766, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9397719173200285, 'eval_runtime': 2.1956, 'eval_samples_per_second': 46.912, 'eval_steps_per_second': 1.822, 'epoch': 2.0}
Best trial: BestRun(run_id='10', objective=3.554755087169663, hyperparameters={'learning_rate': 7.915077303055335e-05, 'num_train_epochs': 15, 'per_device_train_batch_size': 1, 'weight_decay': 0.0010718374645443155, 'warmup_ratio': 0.12514311847073786, 'optimizer': 'Adam'}, run_summary=None)
  0%|          | 0/1740 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/1740 [00:00<26:35,  1.09it/s]  0%|          | 2/1740 [00:01<26:08,  1.11it/s]  0%|          | 3/1740 [00:02<26:13,  1.10it/s]  0%|          | 4/1740 [00:03<26:18,  1.10it/s]  0%|          | 5/1740 [00:04<26:19,  1.10it/s]  0%|          | 6/1740 [00:05<26:20,  1.10it/s]  0%|          | 7/1740 [00:06<26:21,  1.10it/s]  0%|          | 8/1740 [00:07<26:20,  1.10it/s]  1%|          | 9/1740 [00:08<26:21,  1.09it/s]  1%|          | 10/1740 [00:09<26:20,  1.09it/s]  1%|          | 11/1740 [00:10<26:20,  1.09it/s]  1%|          | 12/1740 [00:10<26:20,  1.09it/s]  1%|          | 13/1740 [00:11<26:18,  1.09it/s]  1%|          | 14/1740 [00:12<26:16,  1.10it/s]  1%|          | 15/1740 [00:13<26:16,  1.09it/s]  1%|          | 16/1740 [00:14<26:14,  1.09it/s]  1%|          | 17/1740 [00:15<26:14,  1.09it/s]  1%|          | 18/1740 [00:16<26:13,  1.09it/s]  1%|          | 19/1740 [00:17<26:12,  1.09it/s]  1%|          | 20/1740 [00:18<26:10,  1.10it/s]  1%|          | 21/1740 [00:19<26:10,  1.09it/s]  1%|▏         | 22/1740 [00:20<26:09,  1.09it/s]  1%|▏         | 23/1740 [00:20<26:09,  1.09it/s]  1%|▏         | 24/1740 [00:21<26:07,  1.09it/s]  1%|▏         | 25/1740 [00:22<26:06,  1.09it/s]  1%|▏         | 26/1740 [00:23<26:07,  1.09it/s]  2%|▏         | 27/1740 [00:24<26:05,  1.09it/s]  2%|▏         | 28/1740 [00:25<26:06,  1.09it/s]  2%|▏         | 29/1740 [00:26<26:05,  1.09it/s]  2%|▏         | 30/1740 [00:27<26:03,  1.09it/s]  2%|▏         | 31/1740 [00:28<26:02,  1.09it/s]  2%|▏         | 32/1740 [00:29<26:01,  1.09it/s]  2%|▏         | 33/1740 [00:30<26:00,  1.09it/s]  2%|▏         | 34/1740 [00:31<26:00,  1.09it/s]  2%|▏         | 35/1740 [00:31<25:59,  1.09it/s]  2%|▏         | 36/1740 [00:32<25:57,  1.09it/s]  2%|▏         | 37/1740 [00:33<25:56,  1.09it/s]  2%|▏         | 38/1740 [00:34<25:55,  1.09it/s]  2%|▏         | 39/1740 [00:35<25:55,  1.09it/s]  2%|▏         | 40/1740 [00:36<25:55,  1.09it/s]  2%|▏         | 41/1740 [00:37<25:53,  1.09it/s]  2%|▏         | 42/1740 [00:38<25:54,  1.09it/s]  2%|▏         | 43/1740 [00:39<25:51,  1.09it/s]  3%|▎         | 44/1740 [00:40<25:49,  1.09it/s]  3%|▎         | 45/1740 [00:41<25:39,  1.10it/s]  3%|▎         | 46/1740 [00:42<25:41,  1.10it/s]  3%|▎         | 47/1740 [00:42<25:44,  1.10it/s]  3%|▎         | 48/1740 [00:43<25:45,  1.10it/s]  3%|▎         | 49/1740 [00:44<25:43,  1.10it/s]  3%|▎         | 50/1740 [00:45<25:41,  1.10it/s]  3%|▎         | 51/1740 [00:46<26:55,  1.05it/s]  3%|▎         | 52/1740 [00:47<26:32,  1.06it/s]  3%|▎         | 53/1740 [00:48<26:16,  1.07it/s]  3%|▎         | 54/1740 [00:49<26:02,  1.08it/s]  3%|▎         | 55/1740 [00:50<25:49,  1.09it/s]  3%|▎         | 56/1740 [00:51<25:44,  1.09it/s]  3%|▎         | 57/1740 [00:52<25:42,  1.09it/s]  3%|▎         | 58/1740 [00:53<25:39,  1.09it/s]  3%|▎         | 59/1740 [00:54<25:38,  1.09it/s]  3%|▎         | 60/1740 [00:54<25:38,  1.09it/s]  4%|▎         | 61/1740 [00:55<25:36,  1.09it/s]  4%|▎         | 62/1740 [00:56<25:34,  1.09it/s]  4%|▎         | 63/1740 [00:57<25:33,  1.09it/s]  4%|▎         | 64/1740 [00:58<25:32,  1.09it/s]  4%|▎         | 65/1740 [00:59<25:28,  1.10it/s]  4%|▍         | 66/1740 [01:00<25:22,  1.10it/s]  4%|▍         | 67/1740 [01:01<25:23,  1.10it/s]  4%|▍         | 68/1740 [01:02<25:23,  1.10it/s]  4%|▍         | 69/1740 [01:03<25:25,  1.10it/s]  4%|▍         | 70/1740 [01:04<25:25,  1.09it/s]  4%|▍         | 71/1740 [01:04<25:24,  1.09it/s]  4%|▍         | 72/1740 [01:05<25:25,  1.09it/s]  4%|▍         | 73/1740 [01:06<25:24,  1.09it/s]  4%|▍         | 74/1740 [01:07<25:24,  1.09it/s]  4%|▍         | 75/1740 [01:08<25:22,  1.09it/s]  4%|▍         | 76/1740 [01:09<25:17,  1.10it/s]  4%|▍         | 77/1740 [01:10<25:12,  1.10it/s]  4%|▍         | 78/1740 [01:11<25:13,  1.10it/s]  5%|▍         | 79/1740 [01:12<25:14,  1.10it/s]  5%|▍         | 80/1740 [01:13<25:15,  1.10it/s]  5%|▍         | 81/1740 [01:14<25:14,  1.10it/s]  5%|▍         | 82/1740 [01:15<25:14,  1.09it/s]  5%|▍         | 83/1740 [01:15<25:15,  1.09it/s]  5%|▍         | 84/1740 [01:16<25:13,  1.09it/s]  5%|▍         | 85/1740 [01:17<25:12,  1.09it/s]  5%|▍         | 86/1740 [01:18<25:11,  1.09it/s]  5%|▌         | 87/1740 [01:19<25:11,  1.09it/s]  5%|▌         | 88/1740 [01:20<25:10,  1.09it/s]  5%|▌         | 89/1740 [01:21<25:09,  1.09it/s]  5%|▌         | 90/1740 [01:22<25:08,  1.09it/s]  5%|▌         | 91/1740 [01:23<25:07,  1.09it/s]  5%|▌         | 92/1740 [01:24<25:06,  1.09it/s]  5%|▌         | 93/1740 [01:25<25:05,  1.09it/s]  5%|▌         | 94/1740 [01:25<25:05,  1.09it/s]  5%|▌         | 95/1740 [01:26<25:03,  1.09it/s]  6%|▌         | 96/1740 [01:27<25:02,  1.09it/s]  6%|▌         | 97/1740 [01:28<25:01,  1.09it/s]  6%|▌         | 98/1740 [01:29<25:00,  1.09it/s]  6%|▌         | 99/1740 [01:30<25:00,  1.09it/s]  6%|▌         | 100/1740 [01:31<24:58,  1.09it/s]  6%|▌         | 101/1740 [01:32<24:57,  1.09it/s]  6%|▌         | 102/1740 [01:33<24:57,  1.09it/s]  6%|▌         | 103/1740 [01:34<24:55,  1.09it/s]  6%|▌         | 104/1740 [01:35<26:09,  1.04it/s]  6%|▌         | 105/1740 [01:36<25:45,  1.06it/s]  6%|▌         | 106/1740 [01:37<25:28,  1.07it/s]  6%|▌         | 107/1740 [01:38<25:18,  1.08it/s]  6%|▌         | 108/1740 [01:38<25:09,  1.08it/s]  6%|▋         | 109/1740 [01:39<24:58,  1.09it/s]  6%|▋         | 110/1740 [01:40<24:51,  1.09it/s]  6%|▋         | 111/1740 [01:41<24:49,  1.09it/s]  6%|▋         | 112/1740 [01:42<24:48,  1.09it/s]  6%|▋         | 113/1740 [01:43<24:48,  1.09it/s]  7%|▋         | 114/1740 [01:44<24:47,  1.09it/s]  7%|▋         | 115/1740 [01:45<24:46,  1.09it/s]  7%|▋         | 116/1740 [01:45<21:06,  1.28it/s]
  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.89it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.80it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                  
                                             [A  7%|▋         | 116/1740 [01:47<21:06,  1.28it/s]
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  7%|▋         | 117/1740 [01:57<1:46:23,  3.93s/it]  7%|▋         | 118/1740 [01:57<1:21:50,  3.03s/it]  7%|▋         | 119/1740 [01:58<1:04:38,  2.39s/it]  7%|▋         | 120/1740 [01:59<52:37,  1.95s/it]    7%|▋         | 121/1740 [02:00<44:13,  1.64s/it]  7%|▋         | 122/1740 [02:01<38:18,  1.42s/it]  7%|▋         | 123/1740 [02:02<34:13,  1.27s/it]  7%|▋         | 124/1740 [02:03<31:18,  1.16s/it]  7%|▋         | 125/1740 [02:04<29:17,  1.09s/it]  7%|▋         | 126/1740 [02:05<27:52,  1.04s/it]  7%|▋         | 127/1740 [02:06<26:52,  1.00it/s]  7%|▋         | 128/1740 [02:07<26:10,  1.03it/s]  7%|▋         | 129/1740 [02:08<25:39,  1.05it/s]  7%|▋         | 130/1740 [02:08<25:17,  1.06it/s]  8%|▊         | 131/1740 [02:09<24:58,  1.07it/s]  8%|▊         | 132/1740 [02:10<24:46,  1.08it/s]  8%|▊         | 133/1740 [02:11<24:40,  1.09it/s]  8%|▊         | 134/1740 [02:12<24:37,  1.09it/s]  8%|▊         | 135/1740 [02:13<25:46,  1.04it/s]  8%|▊         | 136/1740 [02:14<25:21,  1.05it/s]  8%|▊         | 137/1740 [02:15<25:04,  1.07it/s]  8%|▊         | 138/1740 [02:16<24:52,  1.07it/s]  8%|▊         | 139/1740 [02:17<24:44,  1.08it/s]  8%|▊         | 140/1740 [02:18<24:37,  1.08it/s]  8%|▊         | 141/1740 [02:19<24:34,  1.08it/s]  8%|▊         | 142/1740 [02:20<24:30,  1.09it/s]  8%|▊         | 143/1740 [02:20<24:27,  1.09it/s]  8%|▊         | 144/1740 [02:21<24:24,  1.09it/s]  8%|▊         | 145/1740 [02:22<24:21,  1.09it/s]  8%|▊         | 146/1740 [02:23<24:20,  1.09it/s]  8%|▊         | 147/1740 [02:24<24:20,  1.09it/s]  9%|▊         | 148/1740 [02:25<24:19,  1.09it/s]  9%|▊         | 149/1740 [02:26<24:17,  1.09it/s]  9%|▊         | 150/1740 [02:27<24:17,  1.09it/s]  9%|▊         | 151/1740 [02:28<24:13,  1.09it/s]  9%|▊         | 152/1740 [02:29<24:13,  1.09it/s]  9%|▉         | 153/1740 [02:30<24:12,  1.09it/s]  9%|▉         | 154/1740 [02:31<24:10,  1.09it/s]  9%|▉         | 155/1740 [02:31<24:10,  1.09it/s]  9%|▉         | 156/1740 [02:32<24:09,  1.09it/s]  9%|▉         | 157/1740 [02:33<24:07,  1.09it/s]  9%|▉         | 158/1740 [02:34<24:06,  1.09it/s]  9%|▉         | 159/1740 [02:35<24:05,  1.09it/s]  9%|▉         | 160/1740 [02:36<24:04,  1.09it/s]  9%|▉         | 161/1740 [02:37<25:13,  1.04it/s]  9%|▉         | 162/1740 [02:38<24:51,  1.06it/s]  9%|▉         | 163/1740 [02:39<24:36,  1.07it/s]  9%|▉         | 164/1740 [02:40<24:21,  1.08it/s]  9%|▉         | 165/1740 [02:41<24:08,  1.09it/s] 10%|▉         | 166/1740 [02:42<24:05,  1.09it/s] 10%|▉         | 167/1740 [02:43<24:02,  1.09it/s] 10%|▉         | 168/1740 [02:43<24:01,  1.09it/s] 10%|▉         | 169/1740 [02:44<23:59,  1.09it/s] 10%|▉         | 170/1740 [02:45<23:56,  1.09it/s] 10%|▉         | 171/1740 [02:46<23:56,  1.09it/s] 10%|▉         | 172/1740 [02:47<23:55,  1.09it/s] 10%|▉         | 173/1740 [02:48<23:53,  1.09it/s] 10%|█         | 174/1740 [02:49<23:52,  1.09it/s] 10%|█         | 175/1740 [02:50<23:52,  1.09it/s] 10%|█         | 176/1740 [02:51<23:50,  1.09it/s] 10%|█         | 177/1740 [02:52<23:50,  1.09it/s] 10%|█         | 178/1740 [02:53<23:49,  1.09it/s] 10%|█         | 179/1740 [02:54<23:47,  1.09it/s] 10%|█         | 180/1740 [02:54<23:47,  1.09it/s] 10%|█         | 181/1740 [02:55<23:46,  1.09it/s] 10%|█         | 182/1740 [02:56<23:44,  1.09it/s] 11%|█         | 183/1740 [02:57<23:43,  1.09it/s] 11%|█         | 184/1740 [02:58<23:41,  1.09it/s] 11%|█         | 185/1740 [02:59<23:38,  1.10it/s] 11%|█         | 186/1740 [03:00<24:41,  1.05it/s] 11%|█         | 187/1740 [03:01<24:22,  1.06it/s] 11%|█         | 188/1740 [03:02<24:08,  1.07it/s] 11%|█         | 189/1740 [03:03<23:58,  1.08it/s] 11%|█         | 190/1740 [03:04<23:52,  1.08it/s] 11%|█         | 191/1740 [03:05<23:47,  1.09it/s] 11%|█         | 192/1740 [03:06<23:42,  1.09it/s] 11%|█         | 193/1740 [03:06<23:39,  1.09it/s] 11%|█         | 194/1740 [03:07<23:37,  1.09it/s] 11%|█         | 195/1740 [03:08<23:34,  1.09it/s] 11%|█▏        | 196/1740 [03:09<23:33,  1.09it/s] 11%|█▏        | 197/1740 [03:10<23:31,  1.09it/s] 11%|█▏        | 198/1740 [03:11<23:32,  1.09it/s] 11%|█▏        | 199/1740 [03:12<23:31,  1.09it/s] 11%|█▏        | 200/1740 [03:13<23:29,  1.09it/s] 12%|█▏        | 201/1740 [03:14<23:29,  1.09it/s] 12%|█▏        | 202/1740 [03:15<23:28,  1.09it/s] 12%|█▏        | 203/1740 [03:16<23:26,  1.09it/s] 12%|█▏        | 204/1740 [03:17<23:25,  1.09it/s] 12%|█▏        | 205/1740 [03:17<23:25,  1.09it/s] 12%|█▏        | 206/1740 [03:18<23:23,  1.09it/s] 12%|█▏        | 207/1740 [03:19<23:16,  1.10it/s] 12%|█▏        | 208/1740 [03:20<23:13,  1.10it/s] 12%|█▏        | 209/1740 [03:21<23:15,  1.10it/s] 12%|█▏        | 210/1740 [03:22<23:15,  1.10it/s] 12%|█▏        | 211/1740 [03:23<23:15,  1.10it/s] 12%|█▏        | 212/1740 [03:24<23:15,  1.09it/s] 12%|█▏        | 213/1740 [03:25<23:15,  1.09it/s] 12%|█▏        | 214/1740 [03:26<23:15,  1.09it/s] 12%|█▏        | 215/1740 [03:27<23:15,  1.09it/s] 12%|█▏        | 216/1740 [03:27<23:14,  1.09it/s] 12%|█▏        | 217/1740 [03:28<23:13,  1.09it/s] 13%|█▎        | 218/1740 [03:29<23:07,  1.10it/s] 13%|█▎        | 219/1740 [03:30<23:03,  1.10it/s] 13%|█▎        | 220/1740 [03:31<23:05,  1.10it/s] 13%|█▎        | 221/1740 [03:32<23:05,  1.10it/s] 13%|█▎        | 222/1740 [03:33<23:05,  1.10it/s] 13%|█▎        | 223/1740 [03:34<23:05,  1.09it/s] 13%|█▎        | 224/1740 [03:35<23:04,  1.09it/s] 13%|█▎        | 225/1740 [03:36<23:04,  1.09it/s] 13%|█▎        | 226/1740 [03:37<23:03,  1.09it/s] 13%|█▎        | 227/1740 [03:38<23:02,  1.09it/s] 13%|█▎        | 228/1740 [03:38<23:02,  1.09it/s] 13%|█▎        | 229/1740 [03:39<22:56,  1.10it/s] 13%|█▎        | 230/1740 [03:40<22:53,  1.10it/s] 13%|█▎        | 231/1740 [03:41<22:54,  1.10it/s] 13%|█▎        | 232/1740 [03:42<19:32,  1.29it/s]{'eval_loss': 14.518677711486816, 'eval_precision': 0.38271604938271603, 'eval_recall': 0.12015503875968993, 'eval_f1': 0.18289085545722714, 'eval_accuracy': 0.9442266571632216, 'eval_runtime': 2.1074, 'eval_samples_per_second': 48.874, 'eval_steps_per_second': 1.898, 'epoch': 1.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.66it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.63it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.59it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                  
                                             [A 13%|█▎        | 232/1740 [03:44<19:32,  1.29it/s]
100%|██████████| 4/4 [00:01<00:00,  2.59it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 13%|█▎        | 233/1740 [03:51<1:20:30,  3.21s/it] 13%|█▎        | 234/1740 [03:51<1:03:11,  2.52s/it] 14%|█▎        | 235/1740 [03:52<52:11,  2.08s/it]   14%|█▎        | 236/1740 [03:53<43:24,  1.73s/it] 14%|█▎        | 237/1740 [03:54<37:13,  1.49s/it] 14%|█▎        | 238/1740 [03:55<32:54,  1.31s/it] 14%|█▎        | 239/1740 [03:56<29:53,  1.19s/it] 14%|█▍        | 240/1740 [03:57<27:46,  1.11s/it] 14%|█▍        | 241/1740 [03:58<26:16,  1.05s/it] 14%|█▍        | 242/1740 [03:59<25:12,  1.01s/it] 14%|█▍        | 243/1740 [04:00<24:21,  1.02it/s] 14%|█▍        | 244/1740 [04:01<23:53,  1.04it/s] 14%|█▍        | 245/1740 [04:02<23:32,  1.06it/s] 14%|█▍        | 246/1740 [04:03<23:16,  1.07it/s] 14%|█▍        | 247/1740 [04:03<23:08,  1.08it/s] 14%|█▍        | 248/1740 [04:04<23:00,  1.08it/s] 14%|█▍        | 249/1740 [04:05<22:54,  1.08it/s] 14%|█▍        | 250/1740 [04:06<22:51,  1.09it/s] 14%|█▍        | 251/1740 [04:07<22:46,  1.09it/s] 14%|█▍        | 252/1740 [04:08<22:44,  1.09it/s] 15%|█▍        | 253/1740 [04:09<22:41,  1.09it/s] 15%|█▍        | 254/1740 [04:10<22:40,  1.09it/s] 15%|█▍        | 255/1740 [04:11<22:38,  1.09it/s] 15%|█▍        | 256/1740 [04:12<22:37,  1.09it/s] 15%|█▍        | 257/1740 [04:13<22:35,  1.09it/s] 15%|█▍        | 258/1740 [04:13<22:36,  1.09it/s] 15%|█▍        | 259/1740 [04:14<22:35,  1.09it/s] 15%|█▍        | 260/1740 [04:15<22:33,  1.09it/s] 15%|█▌        | 261/1740 [04:16<22:32,  1.09it/s] 15%|█▌        | 262/1740 [04:17<22:31,  1.09it/s] 15%|█▌        | 263/1740 [04:18<22:30,  1.09it/s] 15%|█▌        | 264/1740 [04:19<22:28,  1.09it/s] 15%|█▌        | 265/1740 [04:20<22:24,  1.10it/s] 15%|█▌        | 266/1740 [04:21<22:25,  1.10it/s] 15%|█▌        | 267/1740 [04:22<22:25,  1.09it/s] 15%|█▌        | 268/1740 [04:23<22:24,  1.09it/s] 15%|█▌        | 269/1740 [04:24<22:24,  1.09it/s] 16%|█▌        | 270/1740 [04:24<22:23,  1.09it/s] 16%|█▌        | 271/1740 [04:25<22:24,  1.09it/s] 16%|█▌        | 272/1740 [04:26<22:23,  1.09it/s] 16%|█▌        | 273/1740 [04:27<22:22,  1.09it/s] 16%|█▌        | 274/1740 [04:28<22:21,  1.09it/s] 16%|█▌        | 275/1740 [04:29<22:17,  1.10it/s] 16%|█▌        | 276/1740 [04:30<22:11,  1.10it/s] 16%|█▌        | 277/1740 [04:31<22:13,  1.10it/s] 16%|█▌        | 278/1740 [04:32<22:13,  1.10it/s] 16%|█▌        | 279/1740 [04:33<22:13,  1.10it/s] 16%|█▌        | 280/1740 [04:34<22:14,  1.09it/s] 16%|█▌        | 281/1740 [04:35<22:13,  1.09it/s] 16%|█▌        | 282/1740 [04:35<22:12,  1.09it/s] 16%|█▋        | 283/1740 [04:36<22:13,  1.09it/s] 16%|█▋        | 284/1740 [04:37<22:11,  1.09it/s] 16%|█▋        | 285/1740 [04:38<22:11,  1.09it/s] 16%|█▋        | 286/1740 [04:39<22:10,  1.09it/s] 16%|█▋        | 287/1740 [04:40<22:05,  1.10it/s] 17%|█▋        | 288/1740 [04:41<23:07,  1.05it/s] 17%|█▋        | 289/1740 [04:42<22:48,  1.06it/s] 17%|█▋        | 290/1740 [04:43<22:35,  1.07it/s] 17%|█▋        | 291/1740 [04:44<22:25,  1.08it/s] 17%|█▋        | 292/1740 [04:45<22:17,  1.08it/s] 17%|█▋        | 293/1740 [04:46<22:13,  1.08it/s] 17%|█▋        | 294/1740 [04:47<22:09,  1.09it/s] 17%|█▋        | 295/1740 [04:47<22:05,  1.09it/s] 17%|█▋        | 296/1740 [04:48<22:01,  1.09it/s] 17%|█▋        | 297/1740 [04:49<22:00,  1.09it/s] 17%|█▋        | 298/1740 [04:50<21:58,  1.09it/s] 17%|█▋        | 299/1740 [04:51<21:58,  1.09it/s] 17%|█▋        | 300/1740 [04:52<21:57,  1.09it/s] 17%|█▋        | 301/1740 [04:53<21:56,  1.09it/s] 17%|█▋        | 302/1740 [04:54<21:54,  1.09it/s] 17%|█▋        | 303/1740 [04:55<21:54,  1.09it/s] 17%|█▋        | 304/1740 [04:56<21:54,  1.09it/s] 18%|█▊        | 305/1740 [04:57<21:53,  1.09it/s] 18%|█▊        | 306/1740 [04:58<21:50,  1.09it/s] 18%|█▊        | 307/1740 [04:58<21:50,  1.09it/s] 18%|█▊        | 308/1740 [04:59<21:43,  1.10it/s] 18%|█▊        | 309/1740 [05:00<21:41,  1.10it/s] 18%|█▊        | 310/1740 [05:01<21:42,  1.10it/s] 18%|█▊        | 311/1740 [05:02<21:42,  1.10it/s] 18%|█▊        | 312/1740 [05:03<21:43,  1.10it/s] 18%|█▊        | 313/1740 [05:04<21:42,  1.10it/s] 18%|█▊        | 314/1740 [05:05<21:42,  1.09it/s] 18%|█▊        | 315/1740 [05:06<21:42,  1.09it/s] 18%|█▊        | 316/1740 [05:07<21:41,  1.09it/s] 18%|█▊        | 317/1740 [05:08<21:40,  1.09it/s] 18%|█▊        | 318/1740 [05:08<21:39,  1.09it/s] 18%|█▊        | 319/1740 [05:09<21:32,  1.10it/s] 18%|█▊        | 320/1740 [05:10<21:31,  1.10it/s] 18%|█▊        | 321/1740 [05:11<21:32,  1.10it/s] 19%|█▊        | 322/1740 [05:12<21:33,  1.10it/s] 19%|█▊        | 323/1740 [05:13<21:32,  1.10it/s] 19%|█▊        | 324/1740 [05:14<21:31,  1.10it/s] 19%|█▊        | 325/1740 [05:15<21:31,  1.10it/s] 19%|█▊        | 326/1740 [05:16<21:31,  1.09it/s] 19%|█▉        | 327/1740 [05:17<21:31,  1.09it/s] 19%|█▉        | 328/1740 [05:18<22:34,  1.04it/s] 19%|█▉        | 329/1740 [05:19<22:14,  1.06it/s] 19%|█▉        | 330/1740 [05:20<22:00,  1.07it/s] 19%|█▉        | 331/1740 [05:20<21:50,  1.08it/s] 19%|█▉        | 332/1740 [05:21<21:43,  1.08it/s] 19%|█▉        | 333/1740 [05:22<21:37,  1.08it/s] 19%|█▉        | 334/1740 [05:23<21:34,  1.09it/s] 19%|█▉        | 335/1740 [05:24<21:31,  1.09it/s] 19%|█▉        | 336/1740 [05:25<21:27,  1.09it/s] 19%|█▉        | 337/1740 [05:26<21:26,  1.09it/s] 19%|█▉        | 338/1740 [05:27<21:23,  1.09it/s] 19%|█▉        | 339/1740 [05:28<21:22,  1.09it/s] 20%|█▉        | 340/1740 [05:29<21:21,  1.09it/s] 20%|█▉        | 341/1740 [05:30<21:18,  1.09it/s] 20%|█▉        | 342/1740 [05:31<21:19,  1.09it/s] 20%|█▉        | 343/1740 [05:31<21:17,  1.09it/s] 20%|█▉        | 344/1740 [05:32<21:15,  1.09it/s] 20%|█▉        | 345/1740 [05:33<21:14,  1.09it/s] 20%|█▉        | 346/1740 [05:34<21:13,  1.09it/s] 20%|█▉        | 347/1740 [05:35<21:12,  1.09it/s] 20%|██        | 348/1740 [05:36<18:04,  1.28it/s]{'eval_loss': 13.907194137573242, 'eval_precision': 0.52, 'eval_recall': 0.3023255813953488, 'eval_f1': 0.38235294117647056, 'eval_accuracy': 0.9517106200997861, 'eval_runtime': 2.1294, 'eval_samples_per_second': 48.37, 'eval_steps_per_second': 1.878, 'epoch': 2.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  4.07it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.80it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                  
                                             [A 20%|██        | 348/1740 [05:38<18:04,  1.28it/s]
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 20%|██        | 349/1740 [05:44<1:09:12,  2.99s/it] 20%|██        | 350/1740 [05:45<54:45,  2.36s/it]   20%|██        | 351/1740 [05:46<44:39,  1.93s/it] 20%|██        | 352/1740 [05:46<37:35,  1.62s/it] 20%|██        | 353/1740 [05:47<32:38,  1.41s/it] 20%|██        | 354/1740 [05:48<29:08,  1.26s/it] 20%|██        | 355/1740 [05:49<26:43,  1.16s/it] 20%|██        | 356/1740 [05:50<25:01,  1.08s/it] 21%|██        | 357/1740 [05:51<23:48,  1.03s/it] 21%|██        | 358/1740 [05:52<22:59,  1.00it/s] 21%|██        | 359/1740 [05:53<22:23,  1.03it/s] 21%|██        | 360/1740 [05:54<21:59,  1.05it/s] 21%|██        | 361/1740 [05:55<21:40,  1.06it/s] 21%|██        | 362/1740 [05:56<21:28,  1.07it/s] 21%|██        | 363/1740 [05:56<21:17,  1.08it/s] 21%|██        | 364/1740 [05:57<21:12,  1.08it/s] 21%|██        | 365/1740 [05:58<21:06,  1.09it/s] 21%|██        | 366/1740 [05:59<21:58,  1.04it/s] 21%|██        | 367/1740 [06:00<21:36,  1.06it/s] 21%|██        | 368/1740 [06:01<21:23,  1.07it/s] 21%|██        | 369/1740 [06:02<21:13,  1.08it/s] 21%|██▏       | 370/1740 [06:03<21:07,  1.08it/s] 21%|██▏       | 371/1740 [06:04<21:02,  1.08it/s] 21%|██▏       | 372/1740 [06:05<20:58,  1.09it/s] 21%|██▏       | 373/1740 [06:06<20:54,  1.09it/s] 21%|██▏       | 374/1740 [06:07<20:51,  1.09it/s] 22%|██▏       | 375/1740 [06:08<20:51,  1.09it/s] 22%|██▏       | 376/1740 [06:09<20:49,  1.09it/s] 22%|██▏       | 377/1740 [06:09<20:43,  1.10it/s] 22%|██▏       | 378/1740 [06:10<20:41,  1.10it/s] 22%|██▏       | 379/1740 [06:11<20:41,  1.10it/s] 22%|██▏       | 380/1740 [06:12<20:41,  1.10it/s] 22%|██▏       | 381/1740 [06:13<20:41,  1.10it/s] 22%|██▏       | 382/1740 [06:14<20:41,  1.09it/s] 22%|██▏       | 383/1740 [06:15<20:41,  1.09it/s] 22%|██▏       | 384/1740 [06:16<20:40,  1.09it/s] 22%|██▏       | 385/1740 [06:17<20:39,  1.09it/s] 22%|██▏       | 386/1740 [06:18<20:39,  1.09it/s] 22%|██▏       | 387/1740 [06:19<20:37,  1.09it/s] 22%|██▏       | 388/1740 [06:19<20:30,  1.10it/s] 22%|██▏       | 389/1740 [06:20<20:29,  1.10it/s] 22%|██▏       | 390/1740 [06:21<20:29,  1.10it/s] 22%|██▏       | 391/1740 [06:22<20:31,  1.10it/s] 23%|██▎       | 392/1740 [06:23<20:30,  1.10it/s] 23%|██▎       | 393/1740 [06:24<20:30,  1.09it/s] 23%|██▎       | 394/1740 [06:25<20:29,  1.10it/s] 23%|██▎       | 395/1740 [06:26<20:28,  1.09it/s] 23%|██▎       | 396/1740 [06:27<21:27,  1.04it/s] 23%|██▎       | 397/1740 [06:28<21:09,  1.06it/s] 23%|██▎       | 398/1740 [06:29<20:55,  1.07it/s] 23%|██▎       | 399/1740 [06:30<20:46,  1.08it/s] 23%|██▎       | 400/1740 [06:31<20:38,  1.08it/s] 23%|██▎       | 401/1740 [06:31<20:33,  1.09it/s] 23%|██▎       | 402/1740 [06:32<20:30,  1.09it/s] 23%|██▎       | 403/1740 [06:33<20:27,  1.09it/s] 23%|██▎       | 404/1740 [06:34<20:24,  1.09it/s] 23%|██▎       | 405/1740 [06:35<20:22,  1.09it/s] 23%|██▎       | 406/1740 [06:36<20:20,  1.09it/s] 23%|██▎       | 407/1740 [06:37<20:19,  1.09it/s] 23%|██▎       | 408/1740 [06:38<20:19,  1.09it/s] 24%|██▎       | 409/1740 [06:39<20:17,  1.09it/s] 24%|██▎       | 410/1740 [06:40<20:14,  1.10it/s] 24%|██▎       | 411/1740 [06:41<20:07,  1.10it/s] 24%|██▎       | 412/1740 [06:42<20:09,  1.10it/s] 24%|██▎       | 413/1740 [06:42<20:10,  1.10it/s] 24%|██▍       | 414/1740 [06:43<20:10,  1.10it/s] 24%|██▍       | 415/1740 [06:44<20:10,  1.09it/s] 24%|██▍       | 416/1740 [06:45<20:09,  1.09it/s] 24%|██▍       | 417/1740 [06:46<20:09,  1.09it/s] 24%|██▍       | 418/1740 [06:47<20:09,  1.09it/s] 24%|██▍       | 419/1740 [06:48<20:08,  1.09it/s] 24%|██▍       | 420/1740 [06:49<20:06,  1.09it/s] 24%|██▍       | 421/1740 [06:50<20:05,  1.09it/s] 24%|██▍       | 422/1740 [06:51<20:05,  1.09it/s] 24%|██▍       | 423/1740 [06:52<20:04,  1.09it/s] 24%|██▍       | 424/1740 [06:53<20:03,  1.09it/s] 24%|██▍       | 425/1740 [06:53<20:02,  1.09it/s] 24%|██▍       | 426/1740 [06:54<20:00,  1.09it/s] 25%|██▍       | 427/1740 [06:55<19:59,  1.09it/s] 25%|██▍       | 428/1740 [06:56<20:57,  1.04it/s] 25%|██▍       | 429/1740 [06:57<20:39,  1.06it/s] 25%|██▍       | 430/1740 [06:58<20:26,  1.07it/s] 25%|██▍       | 431/1740 [06:59<20:17,  1.08it/s] 25%|██▍       | 432/1740 [07:00<20:10,  1.08it/s] 25%|██▍       | 433/1740 [07:01<20:04,  1.08it/s] 25%|██▍       | 434/1740 [07:02<20:01,  1.09it/s] 25%|██▌       | 435/1740 [07:03<19:58,  1.09it/s] 25%|██▌       | 436/1740 [07:04<19:56,  1.09it/s] 25%|██▌       | 437/1740 [07:05<19:54,  1.09it/s] 25%|██▌       | 438/1740 [07:05<19:52,  1.09it/s] 25%|██▌       | 439/1740 [07:06<19:51,  1.09it/s] 25%|██▌       | 440/1740 [07:07<19:49,  1.09it/s] 25%|██▌       | 441/1740 [07:08<19:48,  1.09it/s] 25%|██▌       | 442/1740 [07:09<19:47,  1.09it/s] 25%|██▌       | 443/1740 [07:10<19:46,  1.09it/s] 26%|██▌       | 444/1740 [07:11<19:45,  1.09it/s] 26%|██▌       | 445/1740 [07:12<19:44,  1.09it/s] 26%|██▌       | 446/1740 [07:13<19:43,  1.09it/s] 26%|██▌       | 447/1740 [07:14<19:41,  1.09it/s] 26%|██▌       | 448/1740 [07:15<19:40,  1.09it/s] 26%|██▌       | 449/1740 [07:16<19:39,  1.09it/s] 26%|██▌       | 450/1740 [07:16<19:38,  1.09it/s] 26%|██▌       | 451/1740 [07:17<19:38,  1.09it/s] 26%|██▌       | 452/1740 [07:18<19:37,  1.09it/s] 26%|██▌       | 453/1740 [07:19<19:36,  1.09it/s] 26%|██▌       | 454/1740 [07:20<20:32,  1.04it/s] 26%|██▌       | 455/1740 [07:21<20:14,  1.06it/s] 26%|██▌       | 456/1740 [07:22<20:02,  1.07it/s] 26%|██▋       | 457/1740 [07:23<19:53,  1.08it/s] 26%|██▋       | 458/1740 [07:24<19:46,  1.08it/s] 26%|██▋       | 459/1740 [07:25<19:42,  1.08it/s] 26%|██▋       | 460/1740 [07:26<19:37,  1.09it/s] 26%|██▋       | 461/1740 [07:27<19:33,  1.09it/s] 27%|██▋       | 462/1740 [07:28<19:31,  1.09it/s] 27%|██▋       | 463/1740 [07:28<19:28,  1.09it/s] 27%|██▋       | 464/1740 [07:29<16:34,  1.28it/s]{'eval_loss': 11.701372146606445, 'eval_precision': 0.7852760736196319, 'eval_recall': 0.49612403100775193, 'eval_f1': 0.6080760095011878, 'eval_accuracy': 0.964183891660727, 'eval_runtime': 2.0771, 'eval_samples_per_second': 49.589, 'eval_steps_per_second': 1.926, 'epoch': 3.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.82it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.77it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A                                                  
                                             [A 27%|██▋       | 464/1740 [07:31<16:34,  1.28it/s]
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 27%|██▋       | 465/1740 [07:35<52:11,  2.46s/it] 27%|██▋       | 466/1740 [07:36<42:19,  1.99s/it] 27%|██▋       | 467/1740 [07:37<35:25,  1.67s/it] 27%|██▋       | 468/1740 [07:38<30:35,  1.44s/it] 27%|██▋       | 469/1740 [07:39<27:11,  1.28s/it] 27%|██▋       | 470/1740 [07:40<24:44,  1.17s/it] 27%|██▋       | 471/1740 [07:41<23:06,  1.09s/it] 27%|██▋       | 472/1740 [07:42<21:57,  1.04s/it] 27%|██▋       | 473/1740 [07:43<21:09,  1.00s/it] 27%|██▋       | 474/1740 [07:43<20:35,  1.02it/s] 27%|██▋       | 475/1740 [07:44<20:11,  1.04it/s] 27%|██▋       | 476/1740 [07:45<19:53,  1.06it/s] 27%|██▋       | 477/1740 [07:46<19:41,  1.07it/s] 27%|██▋       | 478/1740 [07:47<20:29,  1.03it/s] 28%|██▊       | 479/1740 [07:48<20:06,  1.05it/s] 28%|██▊       | 480/1740 [07:49<19:49,  1.06it/s] 28%|██▊       | 481/1740 [07:50<19:37,  1.07it/s] 28%|██▊       | 482/1740 [07:51<19:28,  1.08it/s] 28%|██▊       | 483/1740 [07:52<19:22,  1.08it/s] 28%|██▊       | 484/1740 [07:53<19:18,  1.08it/s] 28%|██▊       | 485/1740 [07:54<19:14,  1.09it/s] 28%|██▊       | 486/1740 [07:55<19:12,  1.09it/s] 28%|██▊       | 487/1740 [07:56<19:09,  1.09it/s] 28%|██▊       | 488/1740 [07:56<19:07,  1.09it/s] 28%|██▊       | 489/1740 [07:57<19:05,  1.09it/s] 28%|██▊       | 490/1740 [07:58<19:03,  1.09it/s] 28%|██▊       | 491/1740 [07:59<19:03,  1.09it/s] 28%|██▊       | 492/1740 [08:00<19:02,  1.09it/s] 28%|██▊       | 493/1740 [08:01<19:01,  1.09it/s] 28%|██▊       | 494/1740 [08:02<19:00,  1.09it/s] 28%|██▊       | 495/1740 [08:03<18:59,  1.09it/s] 29%|██▊       | 496/1740 [08:04<18:58,  1.09it/s] 29%|██▊       | 497/1740 [08:05<18:57,  1.09it/s] 29%|██▊       | 498/1740 [08:06<18:56,  1.09it/s] 29%|██▊       | 499/1740 [08:07<18:55,  1.09it/s] 29%|██▊       | 500/1740 [08:07<18:56,  1.09it/s]                                                   29%|██▊       | 500/1740 [08:07<18:56,  1.09it/s] 29%|██▉       | 501/1740 [08:08<18:54,  1.09it/s] 29%|██▉       | 502/1740 [08:09<18:53,  1.09it/s] 29%|██▉       | 503/1740 [08:10<18:52,  1.09it/s] 29%|██▉       | 504/1740 [08:11<18:51,  1.09it/s] 29%|██▉       | 505/1740 [08:12<18:50,  1.09it/s] 29%|██▉       | 506/1740 [08:13<18:49,  1.09it/s] 29%|██▉       | 507/1740 [08:14<18:48,  1.09it/s] 29%|██▉       | 508/1740 [08:15<18:47,  1.09it/s] 29%|██▉       | 509/1740 [08:16<18:45,  1.09it/s] 29%|██▉       | 510/1740 [08:17<18:45,  1.09it/s] 29%|██▉       | 511/1740 [08:18<18:43,  1.09it/s] 29%|██▉       | 512/1740 [08:18<18:43,  1.09it/s] 29%|██▉       | 513/1740 [08:19<18:41,  1.09it/s] 30%|██▉       | 514/1740 [08:20<18:40,  1.09it/s] 30%|██▉       | 515/1740 [08:21<18:40,  1.09it/s] 30%|██▉       | 516/1740 [08:22<18:39,  1.09it/s] 30%|██▉       | 517/1740 [08:23<18:38,  1.09it/s] 30%|██▉       | 518/1740 [08:24<18:37,  1.09it/s] 30%|██▉       | 519/1740 [08:25<18:37,  1.09it/s] 30%|██▉       | 520/1740 [08:26<18:36,  1.09it/s] 30%|██▉       | 521/1740 [08:27<18:35,  1.09it/s] 30%|███       | 522/1740 [08:28<18:34,  1.09it/s] 30%|███       | 523/1740 [08:28<18:33,  1.09it/s] 30%|███       | 524/1740 [08:29<18:28,  1.10it/s] 30%|███       | 525/1740 [08:30<18:26,  1.10it/s] 30%|███       | 526/1740 [08:31<18:26,  1.10it/s] 30%|███       | 527/1740 [08:32<18:26,  1.10it/s] 30%|███       | 528/1740 [08:33<18:27,  1.09it/s] 30%|███       | 529/1740 [08:34<18:27,  1.09it/s] 30%|███       | 530/1740 [08:35<19:21,  1.04it/s] 31%|███       | 531/1740 [08:36<19:04,  1.06it/s] 31%|███       | 532/1740 [08:37<18:52,  1.07it/s] 31%|███       | 533/1740 [08:38<18:42,  1.08it/s] 31%|███       | 534/1740 [08:39<18:36,  1.08it/s] 31%|███       | 535/1740 [08:40<18:31,  1.08it/s] 31%|███       | 536/1740 [08:40<18:22,  1.09it/s] 31%|███       | 537/1740 [08:41<18:20,  1.09it/s] 31%|███       | 538/1740 [08:42<18:19,  1.09it/s] 31%|███       | 539/1740 [08:43<18:18,  1.09it/s] 31%|███       | 540/1740 [08:44<18:18,  1.09it/s] 31%|███       | 541/1740 [08:45<18:17,  1.09it/s] 31%|███       | 542/1740 [08:46<18:16,  1.09it/s] 31%|███       | 543/1740 [08:47<18:15,  1.09it/s] 31%|███▏      | 544/1740 [08:48<18:14,  1.09it/s] 31%|███▏      | 545/1740 [08:49<18:13,  1.09it/s] 31%|███▏      | 546/1740 [08:50<18:13,  1.09it/s] 31%|███▏      | 547/1740 [08:51<18:11,  1.09it/s] 31%|███▏      | 548/1740 [08:51<18:11,  1.09it/s] 32%|███▏      | 549/1740 [08:52<18:10,  1.09it/s] 32%|███▏      | 550/1740 [08:53<18:08,  1.09it/s] 32%|███▏      | 551/1740 [08:54<18:08,  1.09it/s] 32%|███▏      | 552/1740 [08:55<18:06,  1.09it/s] 32%|███▏      | 553/1740 [08:56<18:05,  1.09it/s] 32%|███▏      | 554/1740 [08:57<18:04,  1.09it/s] 32%|███▏      | 555/1740 [08:58<18:03,  1.09it/s] 32%|███▏      | 556/1740 [08:59<18:03,  1.09it/s] 32%|███▏      | 557/1740 [09:00<18:02,  1.09it/s] 32%|███▏      | 558/1740 [09:01<18:01,  1.09it/s] 32%|███▏      | 559/1740 [09:02<18:01,  1.09it/s] 32%|███▏      | 560/1740 [09:02<17:59,  1.09it/s] 32%|███▏      | 561/1740 [09:03<17:59,  1.09it/s] 32%|███▏      | 562/1740 [09:04<17:58,  1.09it/s] 32%|███▏      | 563/1740 [09:05<17:57,  1.09it/s] 32%|███▏      | 564/1740 [09:06<17:56,  1.09it/s] 32%|███▏      | 565/1740 [09:07<17:54,  1.09it/s] 33%|███▎      | 566/1740 [09:08<17:53,  1.09it/s] 33%|███▎      | 567/1740 [09:09<17:53,  1.09it/s] 33%|███▎      | 568/1740 [09:10<17:51,  1.09it/s] 33%|███▎      | 569/1740 [09:11<17:51,  1.09it/s] 33%|███▎      | 570/1740 [09:12<18:43,  1.04it/s] 33%|███▎      | 571/1740 [09:13<18:27,  1.06it/s] 33%|███▎      | 572/1740 [09:14<18:15,  1.07it/s] 33%|███▎      | 573/1740 [09:14<18:05,  1.07it/s] 33%|███▎      | 574/1740 [09:15<17:59,  1.08it/s] 33%|███▎      | 575/1740 [09:16<17:54,  1.08it/s] 33%|███▎      | 576/1740 [09:17<17:50,  1.09it/s] 33%|███▎      | 577/1740 [09:18<17:47,  1.09it/s] 33%|███▎      | 578/1740 [09:19<17:45,  1.09it/s] 33%|███▎      | 579/1740 [09:20<17:43,  1.09it/s] 33%|███▎      | 580/1740 [09:20<15:06,  1.28it/s]{'eval_loss': 7.473618984222412, 'eval_precision': 0.5751633986928104, 'eval_recall': 0.6821705426356589, 'eval_f1': 0.6241134751773049, 'eval_accuracy': 0.964896650035638, 'eval_runtime': 2.089, 'eval_samples_per_second': 49.306, 'eval_steps_per_second': 1.915, 'epoch': 4.0}
{'loss': 40.3986, 'grad_norm': 39432380.0, 'learning_rate': 6.453752255644988e-05, 'epoch': 4.31}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.68it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.73it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.56it/s][A                                                  
                                             [A 33%|███▎      | 580/1740 [09:23<15:06,  1.28it/s]
100%|██████████| 4/4 [00:01<00:00,  2.56it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 33%|███▎      | 581/1740 [09:27<47:38,  2.47s/it] 33%|███▎      | 582/1740 [09:28<38:35,  2.00s/it] 34%|███▎      | 583/1740 [09:29<32:16,  1.67s/it] 34%|███▎      | 584/1740 [09:30<27:50,  1.45s/it] 34%|███▎      | 585/1740 [09:31<24:46,  1.29s/it] 34%|███▎      | 586/1740 [09:31<22:36,  1.18s/it] 34%|███▎      | 587/1740 [09:32<21:04,  1.10s/it] 34%|███▍      | 588/1740 [09:33<20:00,  1.04s/it] 34%|███▍      | 589/1740 [09:34<19:14,  1.00s/it] 34%|███▍      | 590/1740 [09:35<18:42,  1.02it/s] 34%|███▍      | 591/1740 [09:36<18:21,  1.04it/s] 34%|███▍      | 592/1740 [09:37<18:05,  1.06it/s] 34%|███▍      | 593/1740 [09:38<17:53,  1.07it/s] 34%|███▍      | 594/1740 [09:39<17:45,  1.08it/s] 34%|███▍      | 595/1740 [09:40<17:38,  1.08it/s] 34%|███▍      | 596/1740 [09:41<17:29,  1.09it/s] 34%|███▍      | 597/1740 [09:41<17:27,  1.09it/s] 34%|███▍      | 598/1740 [09:42<17:25,  1.09it/s] 34%|███▍      | 599/1740 [09:43<17:24,  1.09it/s] 34%|███▍      | 600/1740 [09:44<17:22,  1.09it/s] 35%|███▍      | 601/1740 [09:45<17:22,  1.09it/s] 35%|███▍      | 602/1740 [09:46<17:21,  1.09it/s] 35%|███▍      | 603/1740 [09:47<17:19,  1.09it/s] 35%|███▍      | 604/1740 [09:48<17:18,  1.09it/s] 35%|███▍      | 605/1740 [09:49<17:17,  1.09it/s] 35%|███▍      | 606/1740 [09:50<17:17,  1.09it/s] 35%|███▍      | 607/1740 [09:51<17:16,  1.09it/s] 35%|███▍      | 608/1740 [09:52<18:06,  1.04it/s] 35%|███▌      | 609/1740 [09:53<17:50,  1.06it/s] 35%|███▌      | 610/1740 [09:53<17:38,  1.07it/s] 35%|███▌      | 611/1740 [09:54<17:30,  1.07it/s] 35%|███▌      | 612/1740 [09:55<17:24,  1.08it/s] 35%|███▌      | 613/1740 [09:56<17:19,  1.08it/s] 35%|███▌      | 614/1740 [09:57<17:15,  1.09it/s] 35%|███▌      | 615/1740 [09:58<17:13,  1.09it/s] 35%|███▌      | 616/1740 [09:59<17:12,  1.09it/s] 35%|███▌      | 617/1740 [10:00<17:05,  1.09it/s] 36%|███▌      | 618/1740 [10:01<17:06,  1.09it/s] 36%|███▌      | 619/1740 [10:02<17:04,  1.09it/s] 36%|███▌      | 620/1740 [10:03<17:04,  1.09it/s] 36%|███▌      | 621/1740 [10:04<17:03,  1.09it/s] 36%|███▌      | 622/1740 [10:04<17:02,  1.09it/s] 36%|███▌      | 623/1740 [10:05<17:02,  1.09it/s] 36%|███▌      | 624/1740 [10:06<16:59,  1.09it/s] 36%|███▌      | 625/1740 [10:07<16:59,  1.09it/s] 36%|███▌      | 626/1740 [10:08<16:58,  1.09it/s] 36%|███▌      | 627/1740 [10:09<16:55,  1.10it/s] 36%|███▌      | 628/1740 [10:10<16:51,  1.10it/s] 36%|███▌      | 629/1740 [10:11<16:52,  1.10it/s] 36%|███▌      | 630/1740 [10:12<16:53,  1.10it/s] 36%|███▋      | 631/1740 [10:13<16:52,  1.10it/s] 36%|███▋      | 632/1740 [10:14<16:51,  1.10it/s] 36%|███▋      | 633/1740 [10:15<16:51,  1.09it/s] 36%|███▋      | 634/1740 [10:15<16:50,  1.09it/s] 36%|███▋      | 635/1740 [10:16<16:49,  1.09it/s] 37%|███▋      | 636/1740 [10:17<16:48,  1.09it/s] 37%|███▋      | 637/1740 [10:18<16:48,  1.09it/s] 37%|███▋      | 638/1740 [10:19<16:46,  1.09it/s] 37%|███▋      | 639/1740 [10:20<16:46,  1.09it/s] 37%|███▋      | 640/1740 [10:21<16:45,  1.09it/s] 37%|███▋      | 641/1740 [10:22<16:44,  1.09it/s] 37%|███▋      | 642/1740 [10:23<16:43,  1.09it/s] 37%|███▋      | 643/1740 [10:24<16:43,  1.09it/s] 37%|███▋      | 644/1740 [10:25<16:42,  1.09it/s] 37%|███▋      | 645/1740 [10:25<16:42,  1.09it/s] 37%|███▋      | 646/1740 [10:26<16:41,  1.09it/s] 37%|███▋      | 647/1740 [10:27<16:40,  1.09it/s] 37%|███▋      | 648/1740 [10:28<16:38,  1.09it/s] 37%|███▋      | 649/1740 [10:29<17:27,  1.04it/s] 37%|███▋      | 650/1740 [10:30<17:11,  1.06it/s] 37%|███▋      | 651/1740 [10:31<17:00,  1.07it/s] 37%|███▋      | 652/1740 [10:32<16:51,  1.08it/s] 38%|███▊      | 653/1740 [10:33<16:46,  1.08it/s] 38%|███▊      | 654/1740 [10:34<16:41,  1.08it/s] 38%|███▊      | 655/1740 [10:35<16:37,  1.09it/s] 38%|███▊      | 656/1740 [10:36<16:35,  1.09it/s] 38%|███▊      | 657/1740 [10:37<16:33,  1.09it/s] 38%|███▊      | 658/1740 [10:38<16:32,  1.09it/s] 38%|███▊      | 659/1740 [10:38<16:30,  1.09it/s] 38%|███▊      | 660/1740 [10:39<16:28,  1.09it/s] 38%|███▊      | 661/1740 [10:40<16:22,  1.10it/s] 38%|███▊      | 662/1740 [10:41<16:21,  1.10it/s] 38%|███▊      | 663/1740 [10:42<16:22,  1.10it/s] 38%|███▊      | 664/1740 [10:43<16:22,  1.09it/s] 38%|███▊      | 665/1740 [10:44<16:22,  1.09it/s] 38%|███▊      | 666/1740 [10:45<16:22,  1.09it/s] 38%|███▊      | 667/1740 [10:46<16:21,  1.09it/s] 38%|███▊      | 668/1740 [10:47<16:19,  1.09it/s] 38%|███▊      | 669/1740 [10:48<16:19,  1.09it/s] 39%|███▊      | 670/1740 [10:48<16:18,  1.09it/s] 39%|███▊      | 671/1740 [10:49<16:16,  1.09it/s] 39%|███▊      | 672/1740 [10:50<16:16,  1.09it/s] 39%|███▊      | 673/1740 [10:51<16:15,  1.09it/s] 39%|███▊      | 674/1740 [10:52<16:14,  1.09it/s] 39%|███▉      | 675/1740 [10:53<16:14,  1.09it/s] 39%|███▉      | 676/1740 [10:54<16:12,  1.09it/s] 39%|███▉      | 677/1740 [10:55<16:12,  1.09it/s] 39%|███▉      | 678/1740 [10:56<16:11,  1.09it/s] 39%|███▉      | 679/1740 [10:57<16:10,  1.09it/s] 39%|███▉      | 680/1740 [10:58<16:56,  1.04it/s] 39%|███▉      | 681/1740 [10:59<16:42,  1.06it/s] 39%|███▉      | 682/1740 [11:00<16:26,  1.07it/s] 39%|███▉      | 683/1740 [11:01<16:19,  1.08it/s] 39%|███▉      | 684/1740 [11:01<16:14,  1.08it/s] 39%|███▉      | 685/1740 [11:02<16:11,  1.09it/s] 39%|███▉      | 686/1740 [11:03<16:09,  1.09it/s] 39%|███▉      | 687/1740 [11:04<16:06,  1.09it/s] 40%|███▉      | 688/1740 [11:05<16:05,  1.09it/s] 40%|███▉      | 689/1740 [11:06<16:03,  1.09it/s] 40%|███▉      | 690/1740 [11:07<16:01,  1.09it/s] 40%|███▉      | 691/1740 [11:08<16:00,  1.09it/s] 40%|███▉      | 692/1740 [11:09<15:59,  1.09it/s] 40%|███▉      | 693/1740 [11:10<15:58,  1.09it/s] 40%|███▉      | 694/1740 [11:11<15:57,  1.09it/s] 40%|███▉      | 695/1740 [11:11<15:56,  1.09it/s] 40%|████      | 696/1740 [11:12<13:34,  1.28it/s]{'eval_loss': 9.072532653808594, 'eval_precision': 0.5625, 'eval_recall': 0.7325581395348837, 'eval_f1': 0.6363636363636364, 'eval_accuracy': 0.960263720598717, 'eval_runtime': 2.0837, 'eval_samples_per_second': 49.431, 'eval_steps_per_second': 1.92, 'epoch': 5.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.80it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.78it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.65it/s][A                                                  
                                             [A 40%|████      | 696/1740 [11:14<13:34,  1.28it/s]
100%|██████████| 4/4 [00:01<00:00,  2.65it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 40%|████      | 697/1740 [11:18<43:01,  2.47s/it] 40%|████      | 698/1740 [11:19<34:50,  2.01s/it] 40%|████      | 699/1740 [11:20<29:06,  1.68s/it] 40%|████      | 700/1740 [11:21<25:06,  1.45s/it] 40%|████      | 701/1740 [11:22<22:18,  1.29s/it] 40%|████      | 702/1740 [11:23<20:21,  1.18s/it] 40%|████      | 703/1740 [11:24<18:58,  1.10s/it] 40%|████      | 704/1740 [11:25<18:01,  1.04s/it] 41%|████      | 705/1740 [11:26<17:20,  1.00s/it] 41%|████      | 706/1740 [11:27<16:50,  1.02it/s] 41%|████      | 707/1740 [11:28<16:30,  1.04it/s] 41%|████      | 708/1740 [11:28<16:15,  1.06it/s] 41%|████      | 709/1740 [11:29<16:48,  1.02it/s] 41%|████      | 710/1740 [11:30<16:27,  1.04it/s] 41%|████      | 711/1740 [11:31<16:11,  1.06it/s] 41%|████      | 712/1740 [11:32<16:02,  1.07it/s] 41%|████      | 713/1740 [11:33<15:54,  1.08it/s] 41%|████      | 714/1740 [11:34<15:48,  1.08it/s] 41%|████      | 715/1740 [11:35<15:44,  1.09it/s] 41%|████      | 716/1740 [11:36<15:41,  1.09it/s] 41%|████      | 717/1740 [11:37<15:39,  1.09it/s] 41%|████▏     | 718/1740 [11:38<15:37,  1.09it/s] 41%|████▏     | 719/1740 [11:39<15:36,  1.09it/s] 41%|████▏     | 720/1740 [11:40<15:35,  1.09it/s] 41%|████▏     | 721/1740 [11:40<15:28,  1.10it/s] 41%|████▏     | 722/1740 [11:41<15:28,  1.10it/s] 42%|████▏     | 723/1740 [11:42<15:28,  1.10it/s] 42%|████▏     | 724/1740 [11:43<15:27,  1.10it/s] 42%|████▏     | 725/1740 [11:44<15:27,  1.09it/s] 42%|████▏     | 726/1740 [11:45<15:26,  1.09it/s] 42%|████▏     | 727/1740 [11:46<15:26,  1.09it/s] 42%|████▏     | 728/1740 [11:47<15:26,  1.09it/s] 42%|████▏     | 729/1740 [11:48<15:25,  1.09it/s] 42%|████▏     | 730/1740 [11:49<15:23,  1.09it/s] 42%|████▏     | 731/1740 [11:50<15:24,  1.09it/s] 42%|████▏     | 732/1740 [11:51<15:24,  1.09it/s] 42%|████▏     | 733/1740 [11:51<15:23,  1.09it/s] 42%|████▏     | 734/1740 [11:52<15:21,  1.09it/s] 42%|████▏     | 735/1740 [11:53<15:20,  1.09it/s] 42%|████▏     | 736/1740 [11:54<15:18,  1.09it/s] 42%|████▏     | 737/1740 [11:55<15:18,  1.09it/s] 42%|████▏     | 738/1740 [11:56<15:17,  1.09it/s] 42%|████▏     | 739/1740 [11:57<15:16,  1.09it/s] 43%|████▎     | 740/1740 [11:58<15:15,  1.09it/s] 43%|████▎     | 741/1740 [11:59<15:58,  1.04it/s] 43%|████▎     | 742/1740 [12:00<15:45,  1.06it/s] 43%|████▎     | 743/1740 [12:01<15:34,  1.07it/s] 43%|████▎     | 744/1740 [12:02<15:27,  1.07it/s] 43%|████▎     | 745/1740 [12:03<15:21,  1.08it/s] 43%|████▎     | 746/1740 [12:03<15:17,  1.08it/s] 43%|████▎     | 747/1740 [12:04<15:14,  1.09it/s] 43%|████▎     | 748/1740 [12:05<15:13,  1.09it/s] 43%|████▎     | 749/1740 [12:06<15:10,  1.09it/s] 43%|████▎     | 750/1740 [12:07<15:09,  1.09it/s] 43%|████▎     | 751/1740 [12:08<15:08,  1.09it/s] 43%|████▎     | 752/1740 [12:09<15:04,  1.09it/s] 43%|████▎     | 753/1740 [12:10<15:00,  1.10it/s] 43%|████▎     | 754/1740 [12:11<15:00,  1.10it/s] 43%|████▎     | 755/1740 [12:12<14:59,  1.09it/s] 43%|████▎     | 756/1740 [12:13<14:59,  1.09it/s] 44%|████▎     | 757/1740 [12:14<14:58,  1.09it/s] 44%|████▎     | 758/1740 [12:14<14:57,  1.09it/s] 44%|████▎     | 759/1740 [12:15<14:57,  1.09it/s] 44%|████▎     | 760/1740 [12:16<14:56,  1.09it/s] 44%|████▎     | 761/1740 [12:17<14:55,  1.09it/s] 44%|████▍     | 762/1740 [12:18<14:54,  1.09it/s] 44%|████▍     | 763/1740 [12:19<14:51,  1.10it/s] 44%|████▍     | 764/1740 [12:20<14:48,  1.10it/s] 44%|████▍     | 765/1740 [12:21<14:48,  1.10it/s] 44%|████▍     | 766/1740 [12:22<14:49,  1.10it/s] 44%|████▍     | 767/1740 [12:23<15:32,  1.04it/s] 44%|████▍     | 768/1740 [12:24<15:18,  1.06it/s] 44%|████▍     | 769/1740 [12:25<15:09,  1.07it/s] 44%|████▍     | 770/1740 [12:26<15:02,  1.08it/s] 44%|████▍     | 771/1740 [12:26<14:57,  1.08it/s] 44%|████▍     | 772/1740 [12:27<14:54,  1.08it/s] 44%|████▍     | 773/1740 [12:28<14:50,  1.09it/s] 44%|████▍     | 774/1740 [12:29<14:48,  1.09it/s] 45%|████▍     | 775/1740 [12:30<14:45,  1.09it/s] 45%|████▍     | 776/1740 [12:31<14:43,  1.09it/s] 45%|████▍     | 777/1740 [12:32<14:41,  1.09it/s] 45%|████▍     | 778/1740 [12:33<14:40,  1.09it/s] 45%|████▍     | 779/1740 [12:34<14:39,  1.09it/s] 45%|████▍     | 780/1740 [12:35<14:39,  1.09it/s] 45%|████▍     | 781/1740 [12:36<14:38,  1.09it/s] 45%|████▍     | 782/1740 [12:37<14:37,  1.09it/s] 45%|████▌     | 783/1740 [12:37<14:36,  1.09it/s] 45%|████▌     | 784/1740 [12:38<14:35,  1.09it/s] 45%|████▌     | 785/1740 [12:39<14:35,  1.09it/s] 45%|████▌     | 786/1740 [12:40<14:30,  1.10it/s] 45%|████▌     | 787/1740 [12:41<14:29,  1.10it/s] 45%|████▌     | 788/1740 [12:42<14:28,  1.10it/s] 45%|████▌     | 789/1740 [12:43<14:28,  1.10it/s] 45%|████▌     | 790/1740 [12:44<14:28,  1.09it/s] 45%|████▌     | 791/1740 [12:45<14:27,  1.09it/s] 46%|████▌     | 792/1740 [12:46<15:09,  1.04it/s] 46%|████▌     | 793/1740 [12:47<14:56,  1.06it/s] 46%|████▌     | 794/1740 [12:48<14:46,  1.07it/s] 46%|████▌     | 795/1740 [12:49<14:39,  1.07it/s] 46%|████▌     | 796/1740 [12:50<14:34,  1.08it/s] 46%|████▌     | 797/1740 [12:50<14:30,  1.08it/s] 46%|████▌     | 798/1740 [12:51<14:27,  1.09it/s] 46%|████▌     | 799/1740 [12:52<14:25,  1.09it/s] 46%|████▌     | 800/1740 [12:53<14:22,  1.09it/s] 46%|████▌     | 801/1740 [12:54<14:21,  1.09it/s] 46%|████▌     | 802/1740 [12:55<14:20,  1.09it/s] 46%|████▌     | 803/1740 [12:56<14:18,  1.09it/s] 46%|████▌     | 804/1740 [12:57<14:17,  1.09it/s] 46%|████▋     | 805/1740 [12:58<14:16,  1.09it/s] 46%|████▋     | 806/1740 [12:59<14:15,  1.09it/s] 46%|████▋     | 807/1740 [13:00<14:14,  1.09it/s] 46%|████▋     | 808/1740 [13:01<14:13,  1.09it/s] 46%|████▋     | 809/1740 [13:01<14:12,  1.09it/s] 47%|████▋     | 810/1740 [13:02<14:11,  1.09it/s] 47%|████▋     | 811/1740 [13:03<14:09,  1.09it/s] 47%|████▋     | 812/1740 [13:04<12:04,  1.28it/s]{'eval_loss': 9.382637023925781, 'eval_precision': 0.8674033149171271, 'eval_recall': 0.6085271317829457, 'eval_f1': 0.715261958997722, 'eval_accuracy': 0.9734497505345688, 'eval_runtime': 2.0761, 'eval_samples_per_second': 49.612, 'eval_steps_per_second': 1.927, 'epoch': 6.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.85it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.77it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A                                                  
                                             [A 47%|████▋     | 812/1740 [13:06<12:04,  1.28it/s]
100%|██████████| 4/4 [00:01<00:00,  2.62it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 47%|████▋     | 813/1740 [13:10<37:17,  2.41s/it] 47%|████▋     | 814/1740 [13:11<30:18,  1.96s/it] 47%|████▋     | 815/1740 [13:12<25:26,  1.65s/it] 47%|████▋     | 816/1740 [13:13<21:59,  1.43s/it] 47%|████▋     | 817/1740 [13:14<19:36,  1.27s/it] 47%|████▋     | 818/1740 [13:15<17:56,  1.17s/it] 47%|████▋     | 819/1740 [13:15<16:44,  1.09s/it] 47%|████▋     | 820/1740 [13:16<15:55,  1.04s/it] 47%|████▋     | 821/1740 [13:17<15:19,  1.00s/it] 47%|████▋     | 822/1740 [13:18<14:54,  1.03it/s] 47%|████▋     | 823/1740 [13:19<14:37,  1.05it/s] 47%|████▋     | 824/1740 [13:20<14:24,  1.06it/s] 47%|████▋     | 825/1740 [13:21<14:15,  1.07it/s] 47%|████▋     | 826/1740 [13:22<14:10,  1.07it/s] 48%|████▊     | 827/1740 [13:23<14:05,  1.08it/s] 48%|████▊     | 828/1740 [13:24<14:01,  1.08it/s] 48%|████▊     | 829/1740 [13:25<13:59,  1.09it/s] 48%|████▊     | 830/1740 [13:25<13:56,  1.09it/s] 48%|████▊     | 831/1740 [13:26<13:54,  1.09it/s] 48%|████▊     | 832/1740 [13:27<13:52,  1.09it/s] 48%|████▊     | 833/1740 [13:28<13:51,  1.09it/s] 48%|████▊     | 834/1740 [13:29<13:49,  1.09it/s] 48%|████▊     | 835/1740 [13:30<13:48,  1.09it/s] 48%|████▊     | 836/1740 [13:31<13:47,  1.09it/s] 48%|████▊     | 837/1740 [13:32<13:46,  1.09it/s] 48%|████▊     | 838/1740 [13:33<13:45,  1.09it/s] 48%|████▊     | 839/1740 [13:34<13:44,  1.09it/s] 48%|████▊     | 840/1740 [13:35<14:24,  1.04it/s] 48%|████▊     | 841/1740 [13:36<14:10,  1.06it/s] 48%|████▊     | 842/1740 [13:37<14:01,  1.07it/s] 48%|████▊     | 843/1740 [13:38<13:54,  1.07it/s] 49%|████▊     | 844/1740 [13:38<13:50,  1.08it/s] 49%|████▊     | 845/1740 [13:39<13:46,  1.08it/s] 49%|████▊     | 846/1740 [13:40<13:38,  1.09it/s] 49%|████▊     | 847/1740 [13:41<13:37,  1.09it/s] 49%|████▊     | 848/1740 [13:42<13:37,  1.09it/s] 49%|████▉     | 849/1740 [13:43<13:36,  1.09it/s] 49%|████▉     | 850/1740 [13:44<13:35,  1.09it/s] 49%|████▉     | 851/1740 [13:45<13:34,  1.09it/s] 49%|████▉     | 852/1740 [13:46<13:32,  1.09it/s] 49%|████▉     | 853/1740 [13:47<13:32,  1.09it/s] 49%|████▉     | 854/1740 [13:48<13:30,  1.09it/s] 49%|████▉     | 855/1740 [13:49<13:29,  1.09it/s] 49%|████▉     | 856/1740 [13:49<13:25,  1.10it/s] 49%|████▉     | 857/1740 [13:50<13:24,  1.10it/s] 49%|████▉     | 858/1740 [13:51<13:25,  1.10it/s] 49%|████▉     | 859/1740 [13:52<13:24,  1.09it/s] 49%|████▉     | 860/1740 [13:53<13:24,  1.09it/s] 49%|████▉     | 861/1740 [13:54<13:23,  1.09it/s] 50%|████▉     | 862/1740 [13:55<13:23,  1.09it/s] 50%|████▉     | 863/1740 [13:56<13:22,  1.09it/s] 50%|████▉     | 864/1740 [13:57<13:23,  1.09it/s] 50%|████▉     | 865/1740 [13:58<13:21,  1.09it/s] 50%|████▉     | 866/1740 [13:59<13:20,  1.09it/s] 50%|████▉     | 867/1740 [13:59<13:20,  1.09it/s] 50%|████▉     | 868/1740 [14:00<13:18,  1.09it/s] 50%|████▉     | 869/1740 [14:01<13:18,  1.09it/s] 50%|█████     | 870/1740 [14:02<13:17,  1.09it/s] 50%|█████     | 871/1740 [14:03<13:15,  1.09it/s] 50%|█████     | 872/1740 [14:04<13:14,  1.09it/s] 50%|█████     | 873/1740 [14:05<13:13,  1.09it/s] 50%|█████     | 874/1740 [14:06<13:12,  1.09it/s] 50%|█████     | 875/1740 [14:07<13:11,  1.09it/s] 50%|█████     | 876/1740 [14:08<13:10,  1.09it/s] 50%|█████     | 877/1740 [14:09<13:09,  1.09it/s] 50%|█████     | 878/1740 [14:10<13:08,  1.09it/s] 51%|█████     | 879/1740 [14:10<13:08,  1.09it/s] 51%|█████     | 880/1740 [14:12<13:45,  1.04it/s] 51%|█████     | 881/1740 [14:12<13:33,  1.06it/s] 51%|█████     | 882/1740 [14:13<13:24,  1.07it/s] 51%|█████     | 883/1740 [14:14<13:17,  1.07it/s] 51%|█████     | 884/1740 [14:15<13:12,  1.08it/s] 51%|█████     | 885/1740 [14:16<13:08,  1.08it/s] 51%|█████     | 886/1740 [14:17<13:05,  1.09it/s] 51%|█████     | 887/1740 [14:18<13:03,  1.09it/s] 51%|█████     | 888/1740 [14:19<13:02,  1.09it/s] 51%|█████     | 889/1740 [14:20<13:00,  1.09it/s] 51%|█████     | 890/1740 [14:21<12:59,  1.09it/s] 51%|█████     | 891/1740 [14:22<12:57,  1.09it/s] 51%|█████▏    | 892/1740 [14:23<12:56,  1.09it/s] 51%|█████▏    | 893/1740 [14:23<12:55,  1.09it/s] 51%|█████▏    | 894/1740 [14:24<12:54,  1.09it/s] 51%|█████▏    | 895/1740 [14:25<12:53,  1.09it/s] 51%|█████▏    | 896/1740 [14:26<12:53,  1.09it/s] 52%|█████▏    | 897/1740 [14:27<12:51,  1.09it/s] 52%|█████▏    | 898/1740 [14:28<12:50,  1.09it/s] 52%|█████▏    | 899/1740 [14:29<12:49,  1.09it/s] 52%|█████▏    | 900/1740 [14:30<12:48,  1.09it/s] 52%|█████▏    | 901/1740 [14:31<12:47,  1.09it/s] 52%|█████▏    | 902/1740 [14:32<12:47,  1.09it/s] 52%|█████▏    | 903/1740 [14:33<12:46,  1.09it/s] 52%|█████▏    | 904/1740 [14:34<12:45,  1.09it/s] 52%|█████▏    | 905/1740 [14:34<12:44,  1.09it/s] 52%|█████▏    | 906/1740 [14:35<12:43,  1.09it/s] 52%|█████▏    | 907/1740 [14:36<12:43,  1.09it/s] 52%|█████▏    | 908/1740 [14:37<12:42,  1.09it/s] 52%|█████▏    | 909/1740 [14:38<12:41,  1.09it/s] 52%|█████▏    | 910/1740 [14:39<12:39,  1.09it/s] 52%|█████▏    | 911/1740 [14:40<12:35,  1.10it/s] 52%|█████▏    | 912/1740 [14:41<12:35,  1.10it/s] 52%|█████▏    | 913/1740 [14:42<12:35,  1.09it/s] 53%|█████▎    | 914/1740 [14:43<12:34,  1.09it/s] 53%|█████▎    | 915/1740 [14:44<12:34,  1.09it/s] 53%|█████▎    | 916/1740 [14:44<12:33,  1.09it/s] 53%|█████▎    | 917/1740 [14:45<12:32,  1.09it/s] 53%|█████▎    | 918/1740 [14:46<12:31,  1.09it/s] 53%|█████▎    | 919/1740 [14:47<12:31,  1.09it/s] 53%|█████▎    | 920/1740 [14:48<12:30,  1.09it/s] 53%|█████▎    | 921/1740 [14:49<13:04,  1.04it/s] 53%|█████▎    | 922/1740 [14:50<12:50,  1.06it/s] 53%|█████▎    | 923/1740 [14:51<12:43,  1.07it/s] 53%|█████▎    | 924/1740 [14:52<12:38,  1.08it/s] 53%|█████▎    | 925/1740 [14:53<12:33,  1.08it/s] 53%|█████▎    | 926/1740 [14:54<12:30,  1.08it/s] 53%|█████▎    | 927/1740 [14:55<12:27,  1.09it/s] 53%|█████▎    | 928/1740 [14:55<10:35,  1.28it/s]{'eval_loss': 5.938269138336182, 'eval_precision': 0.6934306569343066, 'eval_recall': 0.7364341085271318, 'eval_f1': 0.7142857142857142, 'eval_accuracy': 0.9775481111903065, 'eval_runtime': 2.1064, 'eval_samples_per_second': 48.9, 'eval_steps_per_second': 1.899, 'epoch': 7.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.69it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.74it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.65it/s][A                                                  
                                             [A 53%|█████▎    | 928/1740 [14:57<10:35,  1.28it/s]
100%|██████████| 4/4 [00:01<00:00,  2.65it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 53%|█████▎    | 929/1740 [15:02<33:53,  2.51s/it] 53%|█████▎    | 930/1740 [15:03<27:24,  2.03s/it] 54%|█████▎    | 931/1740 [15:04<22:51,  1.70s/it] 54%|█████▎    | 932/1740 [15:04<19:40,  1.46s/it] 54%|█████▎    | 933/1740 [15:05<17:26,  1.30s/it] 54%|█████▎    | 934/1740 [15:06<15:53,  1.18s/it] 54%|█████▎    | 935/1740 [15:07<14:47,  1.10s/it] 54%|█████▍    | 936/1740 [15:08<14:01,  1.05s/it] 54%|█████▍    | 937/1740 [15:09<13:27,  1.01s/it] 54%|█████▍    | 938/1740 [15:10<13:02,  1.03it/s] 54%|█████▍    | 939/1740 [15:11<12:47,  1.04it/s] 54%|█████▍    | 940/1740 [15:12<12:35,  1.06it/s] 54%|█████▍    | 941/1740 [15:13<12:27,  1.07it/s] 54%|█████▍    | 942/1740 [15:14<12:22,  1.07it/s] 54%|█████▍    | 943/1740 [15:14<12:18,  1.08it/s] 54%|█████▍    | 944/1740 [15:15<12:14,  1.08it/s] 54%|█████▍    | 945/1740 [15:16<12:11,  1.09it/s] 54%|█████▍    | 946/1740 [15:17<12:08,  1.09it/s] 54%|█████▍    | 947/1740 [15:18<12:07,  1.09it/s] 54%|█████▍    | 948/1740 [15:19<12:06,  1.09it/s] 55%|█████▍    | 949/1740 [15:20<12:04,  1.09it/s] 55%|█████▍    | 950/1740 [15:21<12:04,  1.09it/s] 55%|█████▍    | 951/1740 [15:22<12:39,  1.04it/s] 55%|█████▍    | 952/1740 [15:23<12:27,  1.05it/s] 55%|█████▍    | 953/1740 [15:24<12:18,  1.07it/s] 55%|█████▍    | 954/1740 [15:25<12:12,  1.07it/s] 55%|█████▍    | 955/1740 [15:26<12:07,  1.08it/s] 55%|█████▍    | 956/1740 [15:27<12:04,  1.08it/s] 55%|█████▌    | 957/1740 [15:27<12:00,  1.09it/s] 55%|█████▌    | 958/1740 [15:28<11:58,  1.09it/s] 55%|█████▌    | 959/1740 [15:29<11:57,  1.09it/s] 55%|█████▌    | 960/1740 [15:30<11:55,  1.09it/s] 55%|█████▌    | 961/1740 [15:31<11:54,  1.09it/s] 55%|█████▌    | 962/1740 [15:32<11:53,  1.09it/s] 55%|█████▌    | 963/1740 [15:33<11:52,  1.09it/s] 55%|█████▌    | 964/1740 [15:34<11:52,  1.09it/s] 55%|█████▌    | 965/1740 [15:35<11:51,  1.09it/s] 56%|█████▌    | 966/1740 [15:36<11:49,  1.09it/s] 56%|█████▌    | 967/1740 [15:37<11:48,  1.09it/s] 56%|█████▌    | 968/1740 [15:38<11:47,  1.09it/s] 56%|█████▌    | 969/1740 [15:38<11:46,  1.09it/s] 56%|█████▌    | 970/1740 [15:39<11:42,  1.10it/s] 56%|█████▌    | 971/1740 [15:40<11:40,  1.10it/s] 56%|█████▌    | 972/1740 [15:41<11:40,  1.10it/s] 56%|█████▌    | 973/1740 [15:42<11:40,  1.10it/s] 56%|█████▌    | 974/1740 [15:43<11:40,  1.09it/s] 56%|█████▌    | 975/1740 [15:44<11:39,  1.09it/s] 56%|█████▌    | 976/1740 [15:45<12:12,  1.04it/s] 56%|█████▌    | 977/1740 [15:46<12:02,  1.06it/s] 56%|█████▌    | 978/1740 [15:47<11:53,  1.07it/s] 56%|█████▋    | 979/1740 [15:48<11:48,  1.07it/s] 56%|█████▋    | 980/1740 [15:49<11:44,  1.08it/s] 56%|█████▋    | 981/1740 [15:50<11:40,  1.08it/s] 56%|█████▋    | 982/1740 [15:50<11:38,  1.09it/s] 56%|█████▋    | 983/1740 [15:51<11:36,  1.09it/s] 57%|█████▋    | 984/1740 [15:52<11:34,  1.09it/s] 57%|█████▋    | 985/1740 [15:53<11:32,  1.09it/s] 57%|█████▋    | 986/1740 [15:54<11:31,  1.09it/s] 57%|█████▋    | 987/1740 [15:55<11:30,  1.09it/s] 57%|█████▋    | 988/1740 [15:56<11:29,  1.09it/s] 57%|█████▋    | 989/1740 [15:57<11:27,  1.09it/s] 57%|█████▋    | 990/1740 [15:58<11:27,  1.09it/s] 57%|█████▋    | 991/1740 [15:59<11:26,  1.09it/s] 57%|█████▋    | 992/1740 [16:00<11:24,  1.09it/s] 57%|█████▋    | 993/1740 [16:01<11:24,  1.09it/s] 57%|█████▋    | 994/1740 [16:01<11:23,  1.09it/s] 57%|█████▋    | 995/1740 [16:02<11:22,  1.09it/s] 57%|█████▋    | 996/1740 [16:03<11:21,  1.09it/s] 57%|█████▋    | 997/1740 [16:04<11:20,  1.09it/s] 57%|█████▋    | 998/1740 [16:05<11:19,  1.09it/s] 57%|█████▋    | 999/1740 [16:06<11:18,  1.09it/s] 57%|█████▋    | 1000/1740 [16:07<11:16,  1.09it/s]                                                    57%|█████▋    | 1000/1740 [16:07<11:16,  1.09it/s] 58%|█████▊    | 1001/1740 [16:08<11:49,  1.04it/s] 58%|█████▊    | 1002/1740 [16:09<11:38,  1.06it/s] 58%|█████▊    | 1003/1740 [16:10<11:31,  1.07it/s] 58%|█████▊    | 1004/1740 [16:11<11:25,  1.07it/s] 58%|█████▊    | 1005/1740 [16:12<11:20,  1.08it/s] 58%|█████▊    | 1006/1740 [16:13<11:17,  1.08it/s] 58%|█████▊    | 1007/1740 [16:14<11:15,  1.09it/s] 58%|█████▊    | 1008/1740 [16:14<11:12,  1.09it/s] 58%|█████▊    | 1009/1740 [16:15<11:11,  1.09it/s] 58%|█████▊    | 1010/1740 [16:16<11:09,  1.09it/s] 58%|█████▊    | 1011/1740 [16:17<11:07,  1.09it/s] 58%|█████▊    | 1012/1740 [16:18<11:07,  1.09it/s] 58%|█████▊    | 1013/1740 [16:19<11:04,  1.09it/s] 58%|█████▊    | 1014/1740 [16:20<11:00,  1.10it/s] 58%|█████▊    | 1015/1740 [16:21<11:01,  1.10it/s] 58%|█████▊    | 1016/1740 [16:22<11:00,  1.10it/s] 58%|█████▊    | 1017/1740 [16:23<11:00,  1.09it/s] 59%|█████▊    | 1018/1740 [16:24<11:00,  1.09it/s] 59%|█████▊    | 1019/1740 [16:24<10:59,  1.09it/s] 59%|█████▊    | 1020/1740 [16:25<10:58,  1.09it/s] 59%|█████▊    | 1021/1740 [16:26<10:57,  1.09it/s] 59%|█████▊    | 1022/1740 [16:27<10:56,  1.09it/s] 59%|█████▉    | 1023/1740 [16:28<10:56,  1.09it/s] 59%|█████▉    | 1024/1740 [16:29<10:55,  1.09it/s] 59%|█████▉    | 1025/1740 [16:30<10:54,  1.09it/s] 59%|█████▉    | 1026/1740 [16:31<10:53,  1.09it/s] 59%|█████▉    | 1027/1740 [16:32<10:52,  1.09it/s] 59%|█████▉    | 1028/1740 [16:33<10:52,  1.09it/s] 59%|█████▉    | 1029/1740 [16:34<10:50,  1.09it/s] 59%|█████▉    | 1030/1740 [16:35<10:49,  1.09it/s] 59%|█████▉    | 1031/1740 [16:35<10:49,  1.09it/s] 59%|█████▉    | 1032/1740 [16:36<10:47,  1.09it/s] 59%|█████▉    | 1033/1740 [16:37<10:46,  1.09it/s] 59%|█████▉    | 1034/1740 [16:38<10:46,  1.09it/s] 59%|█████▉    | 1035/1740 [16:39<10:45,  1.09it/s] 60%|█████▉    | 1036/1740 [16:40<10:42,  1.10it/s] 60%|█████▉    | 1037/1740 [16:41<10:40,  1.10it/s] 60%|█████▉    | 1038/1740 [16:42<10:40,  1.10it/s] 60%|█████▉    | 1039/1740 [16:43<10:40,  1.09it/s] 60%|█████▉    | 1040/1740 [16:44<10:40,  1.09it/s] 60%|█████▉    | 1041/1740 [16:45<10:39,  1.09it/s] 60%|█████▉    | 1042/1740 [16:46<10:38,  1.09it/s] 60%|█████▉    | 1043/1740 [16:46<10:37,  1.09it/s] 60%|██████    | 1044/1740 [16:47<09:03,  1.28it/s]{'eval_loss': 7.351552963256836, 'eval_precision': 0.7490494296577946, 'eval_recall': 0.7635658914728682, 'eval_f1': 0.7562380038387716, 'eval_accuracy': 0.9768353528153956, 'eval_runtime': 2.1062, 'eval_samples_per_second': 48.904, 'eval_steps_per_second': 1.899, 'epoch': 8.0}
{'loss': 11.5168, 'grad_norm': 20542.794921875, 'learning_rate': 3.8535297513561126e-05, 'epoch': 8.62}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.68it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.75it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A                                                   
                                             [A 60%|██████    | 1044/1740 [16:49<09:03,  1.28it/s]
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 60%|██████    | 1045/1740 [16:53<28:29,  2.46s/it] 60%|██████    | 1046/1740 [16:54<23:04,  2.00s/it] 60%|██████    | 1047/1740 [16:55<19:18,  1.67s/it] 60%|██████    | 1048/1740 [16:56<16:39,  1.44s/it] 60%|██████    | 1049/1740 [16:57<14:48,  1.29s/it] 60%|██████    | 1050/1740 [16:58<14:02,  1.22s/it] 60%|██████    | 1051/1740 [16:59<12:56,  1.13s/it] 60%|██████    | 1052/1740 [17:00<12:09,  1.06s/it] 61%|██████    | 1053/1740 [17:01<11:38,  1.02s/it] 61%|██████    | 1054/1740 [17:02<11:16,  1.01it/s] 61%|██████    | 1055/1740 [17:03<11:02,  1.03it/s] 61%|██████    | 1056/1740 [17:03<10:50,  1.05it/s] 61%|██████    | 1057/1740 [17:04<10:42,  1.06it/s] 61%|██████    | 1058/1740 [17:05<10:36,  1.07it/s] 61%|██████    | 1059/1740 [17:06<10:31,  1.08it/s] 61%|██████    | 1060/1740 [17:07<10:28,  1.08it/s] 61%|██████    | 1061/1740 [17:08<10:25,  1.09it/s] 61%|██████    | 1062/1740 [17:09<10:22,  1.09it/s] 61%|██████    | 1063/1740 [17:10<10:18,  1.09it/s] 61%|██████    | 1064/1740 [17:11<10:18,  1.09it/s] 61%|██████    | 1065/1740 [17:12<10:17,  1.09it/s] 61%|██████▏   | 1066/1740 [17:13<10:16,  1.09it/s] 61%|██████▏   | 1067/1740 [17:14<10:16,  1.09it/s] 61%|██████▏   | 1068/1740 [17:14<10:15,  1.09it/s] 61%|██████▏   | 1069/1740 [17:15<10:15,  1.09it/s] 61%|██████▏   | 1070/1740 [17:16<10:13,  1.09it/s] 62%|██████▏   | 1071/1740 [17:17<10:13,  1.09it/s] 62%|██████▏   | 1072/1740 [17:18<10:12,  1.09it/s] 62%|██████▏   | 1073/1740 [17:19<10:11,  1.09it/s] 62%|██████▏   | 1074/1740 [17:20<10:10,  1.09it/s] 62%|██████▏   | 1075/1740 [17:21<10:09,  1.09it/s] 62%|██████▏   | 1076/1740 [17:22<10:08,  1.09it/s] 62%|██████▏   | 1077/1740 [17:23<10:07,  1.09it/s] 62%|██████▏   | 1078/1740 [17:24<10:06,  1.09it/s] 62%|██████▏   | 1079/1740 [17:25<10:05,  1.09it/s] 62%|██████▏   | 1080/1740 [17:25<10:06,  1.09it/s] 62%|██████▏   | 1081/1740 [17:26<10:04,  1.09it/s] 62%|██████▏   | 1082/1740 [17:27<10:04,  1.09it/s] 62%|██████▏   | 1083/1740 [17:28<10:02,  1.09it/s] 62%|██████▏   | 1084/1740 [17:29<09:59,  1.09it/s] 62%|██████▏   | 1085/1740 [17:30<09:57,  1.10it/s] 62%|██████▏   | 1086/1740 [17:31<09:57,  1.09it/s] 62%|██████▏   | 1087/1740 [17:32<09:57,  1.09it/s] 63%|██████▎   | 1088/1740 [17:33<09:56,  1.09it/s] 63%|██████▎   | 1089/1740 [17:34<09:55,  1.09it/s] 63%|██████▎   | 1090/1740 [17:35<09:55,  1.09it/s] 63%|██████▎   | 1091/1740 [17:36<09:54,  1.09it/s] 63%|██████▎   | 1092/1740 [17:36<09:53,  1.09it/s] 63%|██████▎   | 1093/1740 [17:37<09:52,  1.09it/s] 63%|██████▎   | 1094/1740 [17:38<09:51,  1.09it/s] 63%|██████▎   | 1095/1740 [17:39<09:50,  1.09it/s] 63%|██████▎   | 1096/1740 [17:40<09:47,  1.10it/s] 63%|██████▎   | 1097/1740 [17:41<09:44,  1.10it/s] 63%|██████▎   | 1098/1740 [17:42<09:45,  1.10it/s] 63%|██████▎   | 1099/1740 [17:43<09:44,  1.10it/s] 63%|██████▎   | 1100/1740 [17:44<09:44,  1.09it/s] 63%|██████▎   | 1101/1740 [17:45<09:44,  1.09it/s] 63%|██████▎   | 1102/1740 [17:46<09:43,  1.09it/s] 63%|██████▎   | 1103/1740 [17:47<10:11,  1.04it/s] 63%|██████▎   | 1104/1740 [17:48<10:02,  1.06it/s] 64%|██████▎   | 1105/1740 [17:48<09:55,  1.07it/s] 64%|██████▎   | 1106/1740 [17:49<09:50,  1.07it/s] 64%|██████▎   | 1107/1740 [17:50<09:46,  1.08it/s] 64%|██████▎   | 1108/1740 [17:51<09:43,  1.08it/s] 64%|██████▎   | 1109/1740 [17:52<09:41,  1.09it/s] 64%|██████▍   | 1110/1740 [17:53<09:39,  1.09it/s] 64%|██████▍   | 1111/1740 [17:54<09:37,  1.09it/s] 64%|██████▍   | 1112/1740 [17:55<09:36,  1.09it/s] 64%|██████▍   | 1113/1740 [17:56<09:35,  1.09it/s] 64%|██████▍   | 1114/1740 [17:57<09:34,  1.09it/s] 64%|██████▍   | 1115/1740 [17:58<09:33,  1.09it/s] 64%|██████▍   | 1116/1740 [17:59<09:31,  1.09it/s] 64%|██████▍   | 1117/1740 [17:59<09:31,  1.09it/s] 64%|██████▍   | 1118/1740 [18:00<09:29,  1.09it/s] 64%|██████▍   | 1119/1740 [18:01<09:29,  1.09it/s] 64%|██████▍   | 1120/1740 [18:02<09:28,  1.09it/s] 64%|██████▍   | 1121/1740 [18:03<09:27,  1.09it/s] 64%|██████▍   | 1122/1740 [18:04<09:26,  1.09it/s] 65%|██████▍   | 1123/1740 [18:05<09:25,  1.09it/s] 65%|██████▍   | 1124/1740 [18:06<09:24,  1.09it/s] 65%|██████▍   | 1125/1740 [18:07<09:23,  1.09it/s] 65%|██████▍   | 1126/1740 [18:08<09:22,  1.09it/s] 65%|██████▍   | 1127/1740 [18:09<09:21,  1.09it/s] 65%|██████▍   | 1128/1740 [18:10<09:20,  1.09it/s] 65%|██████▍   | 1129/1740 [18:10<09:20,  1.09it/s] 65%|██████▍   | 1130/1740 [18:11<09:19,  1.09it/s] 65%|██████▌   | 1131/1740 [18:12<09:18,  1.09it/s] 65%|██████▌   | 1132/1740 [18:13<09:17,  1.09it/s] 65%|██████▌   | 1133/1740 [18:14<09:16,  1.09it/s] 65%|██████▌   | 1134/1740 [18:15<09:16,  1.09it/s] 65%|██████▌   | 1135/1740 [18:16<09:14,  1.09it/s] 65%|██████▌   | 1136/1740 [18:17<09:13,  1.09it/s] 65%|██████▌   | 1137/1740 [18:18<09:12,  1.09it/s] 65%|██████▌   | 1138/1740 [18:19<09:11,  1.09it/s] 65%|██████▌   | 1139/1740 [18:20<09:11,  1.09it/s] 66%|██████▌   | 1140/1740 [18:21<09:10,  1.09it/s] 66%|██████▌   | 1141/1740 [18:21<09:09,  1.09it/s] 66%|██████▌   | 1142/1740 [18:22<09:08,  1.09it/s] 66%|██████▌   | 1143/1740 [18:23<09:33,  1.04it/s] 66%|██████▌   | 1144/1740 [18:24<09:25,  1.05it/s] 66%|██████▌   | 1145/1740 [18:25<09:18,  1.07it/s] 66%|██████▌   | 1146/1740 [18:26<09:13,  1.07it/s] 66%|██████▌   | 1147/1740 [18:27<09:09,  1.08it/s] 66%|██████▌   | 1148/1740 [18:28<09:06,  1.08it/s] 66%|██████▌   | 1149/1740 [18:29<09:03,  1.09it/s] 66%|██████▌   | 1150/1740 [18:30<08:59,  1.09it/s] 66%|██████▌   | 1151/1740 [18:31<08:58,  1.09it/s] 66%|██████▌   | 1152/1740 [18:32<08:58,  1.09it/s] 66%|██████▋   | 1153/1740 [18:33<08:57,  1.09it/s] 66%|██████▋   | 1154/1740 [18:34<08:56,  1.09it/s] 66%|██████▋   | 1155/1740 [18:34<08:56,  1.09it/s] 66%|██████▋   | 1156/1740 [18:35<08:55,  1.09it/s] 66%|██████▋   | 1157/1740 [18:36<08:54,  1.09it/s] 67%|██████▋   | 1158/1740 [18:37<08:54,  1.09it/s] 67%|██████▋   | 1159/1740 [18:38<08:52,  1.09it/s] 67%|██████▋   | 1160/1740 [18:39<07:33,  1.28it/s]{'eval_loss': 5.738529682159424, 'eval_precision': 0.8037735849056604, 'eval_recall': 0.8255813953488372, 'eval_f1': 0.81453154875717, 'eval_accuracy': 0.9832501781895937, 'eval_runtime': 2.1172, 'eval_samples_per_second': 48.648, 'eval_steps_per_second': 1.889, 'epoch': 9.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.92it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.82it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A                                                   
                                             [A 67%|██████▋   | 1160/1740 [18:41<07:33,  1.28it/s]
100%|██████████| 4/4 [00:01<00:00,  2.60it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 67%|██████▋   | 1161/1740 [18:46<25:41,  2.66s/it] 67%|██████▋   | 1162/1740 [18:47<20:35,  2.14s/it] 67%|██████▋   | 1163/1740 [18:47<17:01,  1.77s/it] 67%|██████▋   | 1164/1740 [18:48<14:32,  1.51s/it] 67%|██████▋   | 1165/1740 [18:49<12:47,  1.34s/it] 67%|██████▋   | 1166/1740 [18:50<11:34,  1.21s/it] 67%|██████▋   | 1167/1740 [18:51<10:42,  1.12s/it] 67%|██████▋   | 1168/1740 [18:52<10:06,  1.06s/it] 67%|██████▋   | 1169/1740 [18:53<09:40,  1.02s/it] 67%|██████▋   | 1170/1740 [18:54<09:22,  1.01it/s] 67%|██████▋   | 1171/1740 [18:55<09:09,  1.04it/s] 67%|██████▋   | 1172/1740 [18:56<08:59,  1.05it/s] 67%|██████▋   | 1173/1740 [18:57<08:53,  1.06it/s] 67%|██████▋   | 1174/1740 [18:58<08:48,  1.07it/s] 68%|██████▊   | 1175/1740 [18:58<08:44,  1.08it/s] 68%|██████▊   | 1176/1740 [18:59<08:41,  1.08it/s] 68%|██████▊   | 1177/1740 [19:00<08:39,  1.08it/s] 68%|██████▊   | 1178/1740 [19:01<08:37,  1.09it/s] 68%|██████▊   | 1179/1740 [19:02<08:35,  1.09it/s] 68%|██████▊   | 1180/1740 [19:03<08:34,  1.09it/s] 68%|██████▊   | 1181/1740 [19:04<08:58,  1.04it/s] 68%|██████▊   | 1182/1740 [19:05<08:49,  1.05it/s] 68%|██████▊   | 1183/1740 [19:06<08:43,  1.06it/s] 68%|██████▊   | 1184/1740 [19:07<08:38,  1.07it/s] 68%|██████▊   | 1185/1740 [19:08<08:34,  1.08it/s] 68%|██████▊   | 1186/1740 [19:09<08:31,  1.08it/s] 68%|██████▊   | 1187/1740 [19:10<08:29,  1.09it/s] 68%|██████▊   | 1188/1740 [19:11<08:27,  1.09it/s] 68%|██████▊   | 1189/1740 [19:11<08:26,  1.09it/s] 68%|██████▊   | 1190/1740 [19:12<08:25,  1.09it/s] 68%|██████▊   | 1191/1740 [19:13<08:23,  1.09it/s] 69%|██████▊   | 1192/1740 [19:14<08:22,  1.09it/s] 69%|██████▊   | 1193/1740 [19:15<08:21,  1.09it/s] 69%|██████▊   | 1194/1740 [19:16<08:20,  1.09it/s] 69%|██████▊   | 1195/1740 [19:17<08:20,  1.09it/s] 69%|██████▊   | 1196/1740 [19:18<08:19,  1.09it/s] 69%|██████▉   | 1197/1740 [19:19<08:18,  1.09it/s] 69%|██████▉   | 1198/1740 [19:20<08:17,  1.09it/s] 69%|██████▉   | 1199/1740 [19:21<08:16,  1.09it/s] 69%|██████▉   | 1200/1740 [19:22<08:14,  1.09it/s] 69%|██████▉   | 1201/1740 [19:22<08:13,  1.09it/s] 69%|██████▉   | 1202/1740 [19:23<08:12,  1.09it/s] 69%|██████▉   | 1203/1740 [19:24<08:11,  1.09it/s] 69%|██████▉   | 1204/1740 [19:25<08:10,  1.09it/s] 69%|██████▉   | 1205/1740 [19:26<08:10,  1.09it/s] 69%|██████▉   | 1206/1740 [19:27<08:08,  1.09it/s] 69%|██████▉   | 1207/1740 [19:28<08:08,  1.09it/s] 69%|██████▉   | 1208/1740 [19:29<08:07,  1.09it/s] 69%|██████▉   | 1209/1740 [19:30<08:06,  1.09it/s] 70%|██████▉   | 1210/1740 [19:31<08:05,  1.09it/s] 70%|██████▉   | 1211/1740 [19:32<08:04,  1.09it/s] 70%|██████▉   | 1212/1740 [19:33<08:03,  1.09it/s] 70%|██████▉   | 1213/1740 [19:33<08:02,  1.09it/s] 70%|██████▉   | 1214/1740 [19:34<08:01,  1.09it/s] 70%|██████▉   | 1215/1740 [19:35<08:00,  1.09it/s] 70%|██████▉   | 1216/1740 [19:36<07:59,  1.09it/s] 70%|██████▉   | 1217/1740 [19:37<07:58,  1.09it/s] 70%|███████   | 1218/1740 [19:38<07:57,  1.09it/s] 70%|███████   | 1219/1740 [19:39<07:56,  1.09it/s] 70%|███████   | 1220/1740 [19:40<07:54,  1.10it/s] 70%|███████   | 1221/1740 [19:41<07:52,  1.10it/s] 70%|███████   | 1222/1740 [19:42<08:15,  1.05it/s] 70%|███████   | 1223/1740 [19:43<08:08,  1.06it/s] 70%|███████   | 1224/1740 [19:44<08:02,  1.07it/s] 70%|███████   | 1225/1740 [19:45<07:58,  1.08it/s] 70%|███████   | 1226/1740 [19:45<07:55,  1.08it/s] 71%|███████   | 1227/1740 [19:46<07:53,  1.08it/s] 71%|███████   | 1228/1740 [19:47<07:51,  1.09it/s] 71%|███████   | 1229/1740 [19:48<07:49,  1.09it/s] 71%|███████   | 1230/1740 [19:49<07:48,  1.09it/s] 71%|███████   | 1231/1740 [19:50<07:47,  1.09it/s] 71%|███████   | 1232/1740 [19:51<07:46,  1.09it/s] 71%|███████   | 1233/1740 [19:52<07:44,  1.09it/s] 71%|███████   | 1234/1740 [19:53<07:43,  1.09it/s] 71%|███████   | 1235/1740 [19:54<07:43,  1.09it/s] 71%|███████   | 1236/1740 [19:55<07:42,  1.09it/s] 71%|███████   | 1237/1740 [19:56<07:41,  1.09it/s] 71%|███████   | 1238/1740 [19:56<07:40,  1.09it/s] 71%|███████   | 1239/1740 [19:57<07:38,  1.09it/s] 71%|███████▏  | 1240/1740 [19:58<07:37,  1.09it/s] 71%|███████▏  | 1241/1740 [19:59<07:37,  1.09it/s] 71%|███████▏  | 1242/1740 [20:00<07:36,  1.09it/s] 71%|███████▏  | 1243/1740 [20:01<07:35,  1.09it/s] 71%|███████▏  | 1244/1740 [20:02<07:34,  1.09it/s] 72%|███████▏  | 1245/1740 [20:03<07:33,  1.09it/s] 72%|███████▏  | 1246/1740 [20:04<07:32,  1.09it/s] 72%|███████▏  | 1247/1740 [20:05<07:31,  1.09it/s] 72%|███████▏  | 1248/1740 [20:06<07:30,  1.09it/s] 72%|███████▏  | 1249/1740 [20:07<07:29,  1.09it/s] 72%|███████▏  | 1250/1740 [20:07<07:28,  1.09it/s] 72%|███████▏  | 1251/1740 [20:08<07:27,  1.09it/s] 72%|███████▏  | 1252/1740 [20:09<07:26,  1.09it/s] 72%|███████▏  | 1253/1740 [20:10<07:47,  1.04it/s] 72%|███████▏  | 1254/1740 [20:11<07:40,  1.06it/s] 72%|███████▏  | 1255/1740 [20:12<07:34,  1.07it/s] 72%|███████▏  | 1256/1740 [20:13<07:30,  1.07it/s] 72%|███████▏  | 1257/1740 [20:14<07:27,  1.08it/s] 72%|███████▏  | 1258/1740 [20:15<07:25,  1.08it/s] 72%|███████▏  | 1259/1740 [20:16<07:23,  1.08it/s] 72%|███████▏  | 1260/1740 [20:17<07:21,  1.09it/s] 72%|███████▏  | 1261/1740 [20:18<07:19,  1.09it/s] 73%|███████▎  | 1262/1740 [20:19<07:18,  1.09it/s] 73%|███████▎  | 1263/1740 [20:20<07:17,  1.09it/s] 73%|███████▎  | 1264/1740 [20:20<07:16,  1.09it/s] 73%|███████▎  | 1265/1740 [20:21<07:15,  1.09it/s] 73%|███████▎  | 1266/1740 [20:22<07:14,  1.09it/s] 73%|███████▎  | 1267/1740 [20:23<07:13,  1.09it/s] 73%|███████▎  | 1268/1740 [20:24<07:12,  1.09it/s] 73%|███████▎  | 1269/1740 [20:25<07:11,  1.09it/s] 73%|███████▎  | 1270/1740 [20:26<07:10,  1.09it/s] 73%|███████▎  | 1271/1740 [20:27<07:09,  1.09it/s] 73%|███████▎  | 1272/1740 [20:28<07:08,  1.09it/s] 73%|███████▎  | 1273/1740 [20:29<07:08,  1.09it/s] 73%|███████▎  | 1274/1740 [20:30<07:07,  1.09it/s] 73%|███████▎  | 1275/1740 [20:31<07:06,  1.09it/s] 73%|███████▎  | 1276/1740 [20:31<06:02,  1.28it/s]{'eval_loss': 6.412716865539551, 'eval_precision': 0.8223938223938224, 'eval_recall': 0.8255813953488372, 'eval_f1': 0.8239845261121858, 'eval_accuracy': 0.9827156094084105, 'eval_runtime': 2.0884, 'eval_samples_per_second': 49.32, 'eval_steps_per_second': 1.915, 'epoch': 10.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.85it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.72it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.66it/s][A                                                   
                                             [A 73%|███████▎  | 1276/1740 [20:33<06:02,  1.28it/s]
100%|██████████| 4/4 [00:01<00:00,  2.66it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 73%|███████▎  | 1277/1740 [20:37<19:06,  2.48s/it] 73%|███████▎  | 1278/1740 [20:38<15:27,  2.01s/it] 74%|███████▎  | 1279/1740 [20:39<12:54,  1.68s/it] 74%|███████▎  | 1280/1740 [20:40<11:05,  1.45s/it] 74%|███████▎  | 1281/1740 [20:41<09:50,  1.29s/it] 74%|███████▎  | 1282/1740 [20:42<08:57,  1.17s/it] 74%|███████▎  | 1283/1740 [20:43<08:21,  1.10s/it] 74%|███████▍  | 1284/1740 [20:44<08:15,  1.09s/it] 74%|███████▍  | 1285/1740 [20:45<07:51,  1.04s/it] 74%|███████▍  | 1286/1740 [20:46<07:33,  1.00it/s] 74%|███████▍  | 1287/1740 [20:47<07:21,  1.03it/s] 74%|███████▍  | 1288/1740 [20:48<07:12,  1.04it/s] 74%|███████▍  | 1289/1740 [20:49<07:05,  1.06it/s] 74%|███████▍  | 1290/1740 [20:49<06:59,  1.07it/s] 74%|███████▍  | 1291/1740 [20:50<06:55,  1.08it/s] 74%|███████▍  | 1292/1740 [20:51<06:53,  1.08it/s] 74%|███████▍  | 1293/1740 [20:52<06:51,  1.09it/s] 74%|███████▍  | 1294/1740 [20:53<06:49,  1.09it/s] 74%|███████▍  | 1295/1740 [20:54<06:48,  1.09it/s] 74%|███████▍  | 1296/1740 [20:55<06:47,  1.09it/s] 75%|███████▍  | 1297/1740 [20:56<06:46,  1.09it/s] 75%|███████▍  | 1298/1740 [20:57<06:45,  1.09it/s] 75%|███████▍  | 1299/1740 [20:58<06:43,  1.09it/s] 75%|███████▍  | 1300/1740 [20:59<06:43,  1.09it/s] 75%|███████▍  | 1301/1740 [20:59<06:41,  1.09it/s] 75%|███████▍  | 1302/1740 [21:00<06:41,  1.09it/s] 75%|███████▍  | 1303/1740 [21:01<06:40,  1.09it/s] 75%|███████▍  | 1304/1740 [21:02<06:39,  1.09it/s] 75%|███████▌  | 1305/1740 [21:03<06:38,  1.09it/s] 75%|███████▌  | 1306/1740 [21:04<06:37,  1.09it/s] 75%|███████▌  | 1307/1740 [21:05<06:37,  1.09it/s] 75%|███████▌  | 1308/1740 [21:06<06:36,  1.09it/s] 75%|███████▌  | 1309/1740 [21:07<06:35,  1.09it/s] 75%|███████▌  | 1310/1740 [21:08<06:53,  1.04it/s] 75%|███████▌  | 1311/1740 [21:09<06:46,  1.05it/s] 75%|███████▌  | 1312/1740 [21:10<06:42,  1.06it/s] 75%|███████▌  | 1313/1740 [21:11<06:38,  1.07it/s] 76%|███████▌  | 1314/1740 [21:12<06:35,  1.08it/s] 76%|███████▌  | 1315/1740 [21:12<06:33,  1.08it/s] 76%|███████▌  | 1316/1740 [21:13<06:31,  1.08it/s] 76%|███████▌  | 1317/1740 [21:14<06:29,  1.09it/s] 76%|███████▌  | 1318/1740 [21:15<06:28,  1.09it/s] 76%|███████▌  | 1319/1740 [21:16<06:26,  1.09it/s] 76%|███████▌  | 1320/1740 [21:17<06:25,  1.09it/s] 76%|███████▌  | 1321/1740 [21:18<06:24,  1.09it/s] 76%|███████▌  | 1322/1740 [21:19<06:22,  1.09it/s] 76%|███████▌  | 1323/1740 [21:20<06:20,  1.10it/s] 76%|███████▌  | 1324/1740 [21:21<06:20,  1.09it/s] 76%|███████▌  | 1325/1740 [21:22<06:19,  1.09it/s] 76%|███████▌  | 1326/1740 [21:23<06:18,  1.09it/s] 76%|███████▋  | 1327/1740 [21:23<06:18,  1.09it/s] 76%|███████▋  | 1328/1740 [21:24<06:17,  1.09it/s] 76%|███████▋  | 1329/1740 [21:25<06:16,  1.09it/s] 76%|███████▋  | 1330/1740 [21:26<06:15,  1.09it/s] 76%|███████▋  | 1331/1740 [21:27<06:14,  1.09it/s] 77%|███████▋  | 1332/1740 [21:28<06:13,  1.09it/s] 77%|███████▋  | 1333/1740 [21:29<06:12,  1.09it/s] 77%|███████▋  | 1334/1740 [21:30<06:09,  1.10it/s] 77%|███████▋  | 1335/1740 [21:31<06:27,  1.04it/s] 77%|███████▋  | 1336/1740 [21:32<06:21,  1.06it/s] 77%|███████▋  | 1337/1740 [21:33<06:17,  1.07it/s] 77%|███████▋  | 1338/1740 [21:34<06:14,  1.07it/s] 77%|███████▋  | 1339/1740 [21:35<06:11,  1.08it/s] 77%|███████▋  | 1340/1740 [21:36<06:09,  1.08it/s] 77%|███████▋  | 1341/1740 [21:36<06:07,  1.09it/s] 77%|███████▋  | 1342/1740 [21:37<06:06,  1.09it/s] 77%|███████▋  | 1343/1740 [21:38<06:04,  1.09it/s] 77%|███████▋  | 1344/1740 [21:39<06:03,  1.09it/s] 77%|███████▋  | 1345/1740 [21:40<06:01,  1.09it/s] 77%|███████▋  | 1346/1740 [21:41<05:59,  1.10it/s] 77%|███████▋  | 1347/1740 [21:42<05:58,  1.09it/s] 77%|███████▋  | 1348/1740 [21:43<05:58,  1.09it/s] 78%|███████▊  | 1349/1740 [21:44<05:57,  1.09it/s] 78%|███████▊  | 1350/1740 [21:45<05:56,  1.09it/s] 78%|███████▊  | 1351/1740 [21:46<05:56,  1.09it/s] 78%|███████▊  | 1352/1740 [21:46<05:55,  1.09it/s] 78%|███████▊  | 1353/1740 [21:47<05:54,  1.09it/s] 78%|███████▊  | 1354/1740 [21:48<05:53,  1.09it/s] 78%|███████▊  | 1355/1740 [21:49<05:52,  1.09it/s] 78%|███████▊  | 1356/1740 [21:50<05:51,  1.09it/s] 78%|███████▊  | 1357/1740 [21:51<05:50,  1.09it/s] 78%|███████▊  | 1358/1740 [21:52<05:49,  1.09it/s] 78%|███████▊  | 1359/1740 [21:53<05:48,  1.09it/s] 78%|███████▊  | 1360/1740 [21:54<05:48,  1.09it/s] 78%|███████▊  | 1361/1740 [21:55<05:47,  1.09it/s] 78%|███████▊  | 1362/1740 [21:56<05:46,  1.09it/s] 78%|███████▊  | 1363/1740 [21:57<05:45,  1.09it/s] 78%|███████▊  | 1364/1740 [21:57<05:44,  1.09it/s] 78%|███████▊  | 1365/1740 [21:58<05:43,  1.09it/s] 79%|███████▊  | 1366/1740 [21:59<05:42,  1.09it/s] 79%|███████▊  | 1367/1740 [22:00<05:41,  1.09it/s] 79%|███████▊  | 1368/1740 [22:01<05:40,  1.09it/s] 79%|███████▊  | 1369/1740 [22:02<05:39,  1.09it/s] 79%|███████▊  | 1370/1740 [22:03<05:38,  1.09it/s] 79%|███████▉  | 1371/1740 [22:04<05:37,  1.09it/s] 79%|███████▉  | 1372/1740 [22:05<05:37,  1.09it/s] 79%|███████▉  | 1373/1740 [22:06<05:36,  1.09it/s] 79%|███████▉  | 1374/1740 [22:07<05:35,  1.09it/s] 79%|███████▉  | 1375/1740 [22:08<05:34,  1.09it/s] 79%|███████▉  | 1376/1740 [22:08<05:33,  1.09it/s] 79%|███████▉  | 1377/1740 [22:09<05:32,  1.09it/s] 79%|███████▉  | 1378/1740 [22:10<05:31,  1.09it/s] 79%|███████▉  | 1379/1740 [22:11<05:30,  1.09it/s] 79%|███████▉  | 1380/1740 [22:12<05:29,  1.09it/s] 79%|███████▉  | 1381/1740 [22:13<05:28,  1.09it/s] 79%|███████▉  | 1382/1740 [22:14<05:27,  1.09it/s] 79%|███████▉  | 1383/1740 [22:15<05:26,  1.09it/s] 80%|███████▉  | 1384/1740 [22:16<05:25,  1.09it/s] 80%|███████▉  | 1385/1740 [22:17<05:24,  1.09it/s] 80%|███████▉  | 1386/1740 [22:18<05:23,  1.09it/s] 80%|███████▉  | 1387/1740 [22:19<05:39,  1.04it/s] 80%|███████▉  | 1388/1740 [22:20<05:33,  1.06it/s] 80%|███████▉  | 1389/1740 [22:21<05:29,  1.07it/s] 80%|███████▉  | 1390/1740 [22:21<05:25,  1.07it/s] 80%|███████▉  | 1391/1740 [22:22<05:23,  1.08it/s] 80%|████████  | 1392/1740 [22:23<04:34,  1.27it/s]{'eval_loss': 5.464890956878662, 'eval_precision': 0.8196078431372549, 'eval_recall': 0.810077519379845, 'eval_f1': 0.8148148148148148, 'eval_accuracy': 0.9827156094084105, 'eval_runtime': 2.0926, 'eval_samples_per_second': 49.22, 'eval_steps_per_second': 1.911, 'epoch': 11.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  4.09it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.78it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.66it/s][A                                                   
                                             [A 80%|████████  | 1392/1740 [22:25<04:34,  1.27it/s]
100%|██████████| 4/4 [00:01<00:00,  2.66it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 80%|████████  | 1393/1740 [22:29<14:13,  2.46s/it] 80%|████████  | 1394/1740 [22:30<11:30,  2.00s/it] 80%|████████  | 1395/1740 [22:31<09:36,  1.67s/it] 80%|████████  | 1396/1740 [22:32<08:16,  1.44s/it] 80%|████████  | 1397/1740 [22:33<07:21,  1.29s/it] 80%|████████  | 1398/1740 [22:34<06:41,  1.17s/it] 80%|████████  | 1399/1740 [22:35<06:14,  1.10s/it] 80%|████████  | 1400/1740 [22:36<05:54,  1.04s/it] 81%|████████  | 1401/1740 [22:37<05:40,  1.01s/it] 81%|████████  | 1402/1740 [22:37<05:30,  1.02it/s] 81%|████████  | 1403/1740 [22:38<05:23,  1.04it/s] 81%|████████  | 1404/1740 [22:39<05:18,  1.06it/s] 81%|████████  | 1405/1740 [22:40<05:13,  1.07it/s] 81%|████████  | 1406/1740 [22:41<05:09,  1.08it/s] 81%|████████  | 1407/1740 [22:42<05:07,  1.08it/s] 81%|████████  | 1408/1740 [22:43<05:06,  1.08it/s] 81%|████████  | 1409/1740 [22:44<05:04,  1.09it/s] 81%|████████  | 1410/1740 [22:45<05:03,  1.09it/s] 81%|████████  | 1411/1740 [22:46<05:02,  1.09it/s] 81%|████████  | 1412/1740 [22:47<05:00,  1.09it/s] 81%|████████  | 1413/1740 [22:47<04:59,  1.09it/s] 81%|████████▏ | 1414/1740 [22:48<04:58,  1.09it/s] 81%|████████▏ | 1415/1740 [22:49<04:57,  1.09it/s] 81%|████████▏ | 1416/1740 [22:50<04:56,  1.09it/s] 81%|████████▏ | 1417/1740 [22:51<04:55,  1.09it/s] 81%|████████▏ | 1418/1740 [22:52<04:55,  1.09it/s] 82%|████████▏ | 1419/1740 [22:53<04:54,  1.09it/s] 82%|████████▏ | 1420/1740 [22:54<04:53,  1.09it/s] 82%|████████▏ | 1421/1740 [22:55<04:52,  1.09it/s] 82%|████████▏ | 1422/1740 [22:56<04:51,  1.09it/s] 82%|████████▏ | 1423/1740 [22:57<04:50,  1.09it/s] 82%|████████▏ | 1424/1740 [22:58<04:49,  1.09it/s] 82%|████████▏ | 1425/1740 [22:59<05:02,  1.04it/s] 82%|████████▏ | 1426/1740 [23:00<04:57,  1.05it/s] 82%|████████▏ | 1427/1740 [23:00<04:53,  1.07it/s] 82%|████████▏ | 1428/1740 [23:01<04:51,  1.07it/s] 82%|████████▏ | 1429/1740 [23:02<04:49,  1.08it/s] 82%|████████▏ | 1430/1740 [23:03<04:46,  1.08it/s] 82%|████████▏ | 1431/1740 [23:04<04:45,  1.08it/s] 82%|████████▏ | 1432/1740 [23:05<04:43,  1.09it/s] 82%|████████▏ | 1433/1740 [23:06<04:42,  1.09it/s] 82%|████████▏ | 1434/1740 [23:07<04:41,  1.09it/s] 82%|████████▏ | 1435/1740 [23:08<04:40,  1.09it/s] 83%|████████▎ | 1436/1740 [23:09<04:38,  1.09it/s] 83%|████████▎ | 1437/1740 [23:10<04:37,  1.09it/s] 83%|████████▎ | 1438/1740 [23:11<04:36,  1.09it/s] 83%|████████▎ | 1439/1740 [23:11<04:35,  1.09it/s] 83%|████████▎ | 1440/1740 [23:12<04:35,  1.09it/s] 83%|████████▎ | 1441/1740 [23:13<04:34,  1.09it/s] 83%|████████▎ | 1442/1740 [23:14<04:33,  1.09it/s] 83%|████████▎ | 1443/1740 [23:15<04:32,  1.09it/s] 83%|████████▎ | 1444/1740 [23:16<04:31,  1.09it/s] 83%|████████▎ | 1445/1740 [23:17<04:30,  1.09it/s] 83%|████████▎ | 1446/1740 [23:18<04:29,  1.09it/s] 83%|████████▎ | 1447/1740 [23:19<04:28,  1.09it/s] 83%|████████▎ | 1448/1740 [23:20<04:27,  1.09it/s] 83%|████████▎ | 1449/1740 [23:21<04:26,  1.09it/s] 83%|████████▎ | 1450/1740 [23:22<04:25,  1.09it/s] 83%|████████▎ | 1451/1740 [23:22<04:24,  1.09it/s] 83%|████████▎ | 1452/1740 [23:23<04:23,  1.09it/s] 84%|████████▎ | 1453/1740 [23:24<04:22,  1.09it/s] 84%|████████▎ | 1454/1740 [23:25<04:22,  1.09it/s] 84%|████████▎ | 1455/1740 [23:26<04:21,  1.09it/s] 84%|████████▎ | 1456/1740 [23:27<04:33,  1.04it/s] 84%|████████▎ | 1457/1740 [23:28<04:28,  1.05it/s] 84%|████████▍ | 1458/1740 [23:29<04:24,  1.07it/s] 84%|████████▍ | 1459/1740 [23:30<04:20,  1.08it/s] 84%|████████▍ | 1460/1740 [23:31<04:18,  1.08it/s] 84%|████████▍ | 1461/1740 [23:32<04:17,  1.08it/s] 84%|████████▍ | 1462/1740 [23:33<04:15,  1.09it/s] 84%|████████▍ | 1463/1740 [23:34<04:14,  1.09it/s] 84%|████████▍ | 1464/1740 [23:35<04:13,  1.09it/s] 84%|████████▍ | 1465/1740 [23:35<04:12,  1.09it/s] 84%|████████▍ | 1466/1740 [23:36<04:11,  1.09it/s] 84%|████████▍ | 1467/1740 [23:37<04:09,  1.09it/s] 84%|████████▍ | 1468/1740 [23:38<04:08,  1.09it/s] 84%|████████▍ | 1469/1740 [23:39<04:08,  1.09it/s] 84%|████████▍ | 1470/1740 [23:40<04:06,  1.10it/s] 85%|████████▍ | 1471/1740 [23:41<04:05,  1.10it/s] 85%|████████▍ | 1472/1740 [23:42<04:04,  1.10it/s] 85%|████████▍ | 1473/1740 [23:43<04:04,  1.09it/s] 85%|████████▍ | 1474/1740 [23:44<04:03,  1.09it/s] 85%|████████▍ | 1475/1740 [23:45<04:02,  1.09it/s] 85%|████████▍ | 1476/1740 [23:45<04:01,  1.09it/s] 85%|████████▍ | 1477/1740 [23:46<04:00,  1.09it/s] 85%|████████▍ | 1478/1740 [23:47<04:00,  1.09it/s] 85%|████████▌ | 1479/1740 [23:48<03:59,  1.09it/s] 85%|████████▌ | 1480/1740 [23:49<03:58,  1.09it/s] 85%|████████▌ | 1481/1740 [23:50<03:57,  1.09it/s] 85%|████████▌ | 1482/1740 [23:51<03:56,  1.09it/s] 85%|████████▌ | 1483/1740 [23:52<03:55,  1.09it/s] 85%|████████▌ | 1484/1740 [23:53<03:54,  1.09it/s] 85%|████████▌ | 1485/1740 [23:54<03:53,  1.09it/s] 85%|████████▌ | 1486/1740 [23:55<03:52,  1.09it/s] 85%|████████▌ | 1487/1740 [23:56<03:51,  1.09it/s] 86%|████████▌ | 1488/1740 [23:57<04:02,  1.04it/s] 86%|████████▌ | 1489/1740 [23:58<03:58,  1.05it/s] 86%|████████▌ | 1490/1740 [23:58<03:54,  1.07it/s] 86%|████████▌ | 1491/1740 [23:59<03:51,  1.08it/s] 86%|████████▌ | 1492/1740 [24:00<03:49,  1.08it/s] 86%|████████▌ | 1493/1740 [24:01<03:47,  1.09it/s] 86%|████████▌ | 1494/1740 [24:02<03:46,  1.09it/s] 86%|████████▌ | 1495/1740 [24:03<03:45,  1.09it/s] 86%|████████▌ | 1496/1740 [24:04<03:44,  1.09it/s] 86%|████████▌ | 1497/1740 [24:05<03:43,  1.09it/s] 86%|████████▌ | 1498/1740 [24:06<03:41,  1.09it/s] 86%|████████▌ | 1499/1740 [24:07<03:41,  1.09it/s] 86%|████████▌ | 1500/1740 [24:08<03:40,  1.09it/s]                                                    86%|████████▌ | 1500/1740 [24:08<03:40,  1.09it/s] 86%|████████▋ | 1501/1740 [24:09<03:39,  1.09it/s] 86%|████████▋ | 1502/1740 [24:09<03:37,  1.10it/s] 86%|████████▋ | 1503/1740 [24:10<03:36,  1.10it/s] 86%|████████▋ | 1504/1740 [24:11<03:35,  1.09it/s] 86%|████████▋ | 1505/1740 [24:12<03:35,  1.09it/s] 87%|████████▋ | 1506/1740 [24:13<03:34,  1.09it/s] 87%|████████▋ | 1507/1740 [24:14<03:33,  1.09it/s] 87%|████████▋ | 1508/1740 [24:14<03:01,  1.28it/s]{'eval_loss': 5.506173610687256, 'eval_precision': 0.8416988416988417, 'eval_recall': 0.8449612403100775, 'eval_f1': 0.8433268858800773, 'eval_accuracy': 0.985032074126871, 'eval_runtime': 2.0596, 'eval_samples_per_second': 50.01, 'eval_steps_per_second': 1.942, 'epoch': 12.0}
{'loss': 10.024, 'grad_norm': 1638151.125, 'learning_rate': 1.2533072470672377e-05, 'epoch': 12.94}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.87it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.80it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.63it/s][A                                                   
                                             [A 87%|████████▋ | 1508/1740 [24:17<03:01,  1.28it/s]
100%|██████████| 4/4 [00:01<00:00,  2.63it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 87%|████████▋ | 1509/1740 [24:21<09:40,  2.51s/it] 87%|████████▋ | 1510/1740 [24:22<07:47,  2.03s/it] 87%|████████▋ | 1511/1740 [24:23<06:38,  1.74s/it] 87%|████████▋ | 1512/1740 [24:24<05:40,  1.49s/it] 87%|████████▋ | 1513/1740 [24:25<04:59,  1.32s/it] 87%|████████▋ | 1514/1740 [24:26<04:31,  1.20s/it] 87%|████████▋ | 1515/1740 [24:27<04:10,  1.11s/it] 87%|████████▋ | 1516/1740 [24:28<03:56,  1.05s/it] 87%|████████▋ | 1517/1740 [24:29<03:45,  1.01s/it] 87%|████████▋ | 1518/1740 [24:29<03:37,  1.02it/s] 87%|████████▋ | 1519/1740 [24:30<03:32,  1.04it/s] 87%|████████▋ | 1520/1740 [24:31<03:28,  1.06it/s] 87%|████████▋ | 1521/1740 [24:32<03:25,  1.07it/s] 87%|████████▋ | 1522/1740 [24:33<03:22,  1.07it/s] 88%|████████▊ | 1523/1740 [24:34<03:20,  1.08it/s] 88%|████████▊ | 1524/1740 [24:35<03:19,  1.08it/s] 88%|████████▊ | 1525/1740 [24:36<03:18,  1.09it/s] 88%|████████▊ | 1526/1740 [24:37<03:16,  1.09it/s] 88%|████████▊ | 1527/1740 [24:38<03:15,  1.09it/s] 88%|████████▊ | 1528/1740 [24:39<03:14,  1.09it/s] 88%|████████▊ | 1529/1740 [24:39<03:13,  1.09it/s] 88%|████████▊ | 1530/1740 [24:40<03:11,  1.09it/s] 88%|████████▊ | 1531/1740 [24:41<03:11,  1.09it/s] 88%|████████▊ | 1532/1740 [24:42<03:10,  1.09it/s] 88%|████████▊ | 1533/1740 [24:43<03:09,  1.09it/s] 88%|████████▊ | 1534/1740 [24:44<03:08,  1.09it/s] 88%|████████▊ | 1535/1740 [24:45<03:07,  1.09it/s] 88%|████████▊ | 1536/1740 [24:46<03:06,  1.09it/s] 88%|████████▊ | 1537/1740 [24:47<03:05,  1.09it/s] 88%|████████▊ | 1538/1740 [24:48<03:04,  1.09it/s] 88%|████████▊ | 1539/1740 [24:49<03:04,  1.09it/s] 89%|████████▊ | 1540/1740 [24:50<03:03,  1.09it/s] 89%|████████▊ | 1541/1740 [24:50<03:02,  1.09it/s] 89%|████████▊ | 1542/1740 [24:51<03:01,  1.09it/s] 89%|████████▊ | 1543/1740 [24:52<03:00,  1.09it/s] 89%|████████▊ | 1544/1740 [24:53<02:59,  1.09it/s] 89%|████████▉ | 1545/1740 [24:54<02:58,  1.09it/s] 89%|████████▉ | 1546/1740 [24:55<02:57,  1.09it/s] 89%|████████▉ | 1547/1740 [24:56<02:56,  1.09it/s] 89%|████████▉ | 1548/1740 [24:57<02:56,  1.09it/s] 89%|████████▉ | 1549/1740 [24:58<02:55,  1.09it/s] 89%|████████▉ | 1550/1740 [24:59<02:54,  1.09it/s] 89%|████████▉ | 1551/1740 [25:00<02:53,  1.09it/s] 89%|████████▉ | 1552/1740 [25:01<02:52,  1.09it/s] 89%|████████▉ | 1553/1740 [25:01<02:51,  1.09it/s] 89%|████████▉ | 1554/1740 [25:02<02:50,  1.09it/s] 89%|████████▉ | 1555/1740 [25:03<02:49,  1.09it/s] 89%|████████▉ | 1556/1740 [25:04<02:48,  1.09it/s] 89%|████████▉ | 1557/1740 [25:05<02:47,  1.09it/s] 90%|████████▉ | 1558/1740 [25:06<02:46,  1.09it/s] 90%|████████▉ | 1559/1740 [25:07<02:45,  1.09it/s] 90%|████████▉ | 1560/1740 [25:08<02:44,  1.09it/s] 90%|████████▉ | 1561/1740 [25:09<02:43,  1.09it/s] 90%|████████▉ | 1562/1740 [25:10<02:43,  1.09it/s] 90%|████████▉ | 1563/1740 [25:11<02:50,  1.04it/s] 90%|████████▉ | 1564/1740 [25:12<02:46,  1.05it/s] 90%|████████▉ | 1565/1740 [25:13<02:44,  1.07it/s] 90%|█████████ | 1566/1740 [25:14<02:42,  1.07it/s] 90%|█████████ | 1567/1740 [25:14<02:40,  1.08it/s] 90%|█████████ | 1568/1740 [25:15<02:38,  1.08it/s] 90%|█████████ | 1569/1740 [25:16<02:37,  1.09it/s] 90%|█████████ | 1570/1740 [25:17<02:36,  1.09it/s] 90%|█████████ | 1571/1740 [25:18<02:35,  1.09it/s] 90%|█████████ | 1572/1740 [25:19<02:33,  1.09it/s] 90%|█████████ | 1573/1740 [25:20<02:32,  1.10it/s] 90%|█████████ | 1574/1740 [25:21<02:31,  1.09it/s] 91%|█████████ | 1575/1740 [25:22<02:30,  1.09it/s] 91%|█████████ | 1576/1740 [25:23<02:30,  1.09it/s] 91%|█████████ | 1577/1740 [25:24<02:29,  1.09it/s] 91%|█████████ | 1578/1740 [25:25<02:28,  1.09it/s] 91%|█████████ | 1579/1740 [25:25<02:27,  1.09it/s] 91%|█████████ | 1580/1740 [25:26<02:26,  1.09it/s] 91%|█████████ | 1581/1740 [25:27<02:25,  1.09it/s] 91%|█████████ | 1582/1740 [25:28<02:24,  1.09it/s] 91%|█████████ | 1583/1740 [25:29<02:23,  1.09it/s] 91%|█████████ | 1584/1740 [25:30<02:22,  1.09it/s] 91%|█████████ | 1585/1740 [25:31<02:21,  1.09it/s] 91%|█████████ | 1586/1740 [25:32<02:21,  1.09it/s] 91%|█████████ | 1587/1740 [25:33<02:20,  1.09it/s] 91%|█████████▏| 1588/1740 [25:34<02:19,  1.09it/s] 91%|█████████▏| 1589/1740 [25:35<02:18,  1.09it/s] 91%|█████████▏| 1590/1740 [25:36<02:17,  1.09it/s] 91%|█████████▏| 1591/1740 [25:36<02:16,  1.09it/s] 91%|█████████▏| 1592/1740 [25:37<02:15,  1.09it/s] 92%|█████████▏| 1593/1740 [25:38<02:14,  1.09it/s] 92%|█████████▏| 1594/1740 [25:39<02:13,  1.09it/s] 92%|█████████▏| 1595/1740 [25:40<02:12,  1.10it/s] 92%|█████████▏| 1596/1740 [25:41<02:11,  1.10it/s] 92%|█████████▏| 1597/1740 [25:42<02:10,  1.10it/s] 92%|█████████▏| 1598/1740 [25:43<02:09,  1.09it/s] 92%|█████████▏| 1599/1740 [25:44<02:08,  1.09it/s] 92%|█████████▏| 1600/1740 [25:45<02:08,  1.09it/s] 92%|█████████▏| 1601/1740 [25:46<02:07,  1.09it/s] 92%|█████████▏| 1602/1740 [25:46<02:06,  1.09it/s] 92%|█████████▏| 1603/1740 [25:48<02:11,  1.04it/s] 92%|█████████▏| 1604/1740 [25:48<02:08,  1.06it/s] 92%|█████████▏| 1605/1740 [25:49<02:06,  1.07it/s] 92%|█████████▏| 1606/1740 [25:50<02:04,  1.07it/s] 92%|█████████▏| 1607/1740 [25:51<02:03,  1.08it/s] 92%|█████████▏| 1608/1740 [25:52<02:01,  1.08it/s] 92%|█████████▏| 1609/1740 [25:53<02:00,  1.08it/s] 93%|█████████▎| 1610/1740 [25:54<01:59,  1.09it/s] 93%|█████████▎| 1611/1740 [25:55<01:58,  1.09it/s] 93%|█████████▎| 1612/1740 [25:56<01:57,  1.09it/s] 93%|█████████▎| 1613/1740 [25:57<01:56,  1.09it/s] 93%|█████████▎| 1614/1740 [25:58<01:55,  1.09it/s] 93%|█████████▎| 1615/1740 [25:59<01:54,  1.09it/s] 93%|█████████▎| 1616/1740 [25:59<01:53,  1.10it/s] 93%|█████████▎| 1617/1740 [26:00<01:52,  1.10it/s] 93%|█████████▎| 1618/1740 [26:01<01:51,  1.09it/s] 93%|█████████▎| 1619/1740 [26:02<01:50,  1.09it/s] 93%|█████████▎| 1620/1740 [26:03<01:49,  1.09it/s] 93%|█████████▎| 1621/1740 [26:04<01:48,  1.09it/s] 93%|█████████▎| 1622/1740 [26:05<01:48,  1.09it/s] 93%|█████████▎| 1623/1740 [26:06<01:47,  1.09it/s] 93%|█████████▎| 1624/1740 [26:06<01:30,  1.28it/s]{'eval_loss': 4.685653209686279, 'eval_precision': 0.856, 'eval_recall': 0.8294573643410853, 'eval_f1': 0.8425196850393701, 'eval_accuracy': 0.9848538845331433, 'eval_runtime': 2.0769, 'eval_samples_per_second': 49.592, 'eval_steps_per_second': 1.926, 'epoch': 13.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.92it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.78it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.64it/s][A                                                   
                                             [A 93%|█████████▎| 1624/1740 [26:08<01:30,  1.28it/s]
100%|██████████| 4/4 [00:01<00:00,  2.64it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 93%|█████████▎| 1625/1740 [26:13<04:43,  2.46s/it] 93%|█████████▎| 1626/1740 [26:14<03:47,  2.00s/it] 94%|█████████▎| 1627/1740 [26:15<03:09,  1.67s/it] 94%|█████████▎| 1628/1740 [26:15<02:41,  1.45s/it] 94%|█████████▎| 1629/1740 [26:16<02:22,  1.29s/it] 94%|█████████▎| 1630/1740 [26:17<02:09,  1.18s/it] 94%|█████████▎| 1631/1740 [26:18<01:59,  1.10s/it] 94%|█████████▍| 1632/1740 [26:19<01:52,  1.04s/it] 94%|█████████▍| 1633/1740 [26:20<01:47,  1.00s/it] 94%|█████████▍| 1634/1740 [26:21<01:43,  1.02it/s] 94%|█████████▍| 1635/1740 [26:22<01:40,  1.04it/s] 94%|█████████▍| 1636/1740 [26:23<01:38,  1.06it/s] 94%|█████████▍| 1637/1740 [26:24<01:36,  1.07it/s] 94%|█████████▍| 1638/1740 [26:25<01:35,  1.07it/s] 94%|█████████▍| 1639/1740 [26:26<01:33,  1.08it/s] 94%|█████████▍| 1640/1740 [26:27<01:36,  1.03it/s] 94%|█████████▍| 1641/1740 [26:28<01:34,  1.05it/s] 94%|█████████▍| 1642/1740 [26:28<01:32,  1.06it/s] 94%|█████████▍| 1643/1740 [26:29<01:30,  1.07it/s] 94%|█████████▍| 1644/1740 [26:30<01:28,  1.08it/s] 95%|█████████▍| 1645/1740 [26:31<01:27,  1.08it/s] 95%|█████████▍| 1646/1740 [26:32<01:26,  1.09it/s] 95%|█████████▍| 1647/1740 [26:33<01:25,  1.09it/s] 95%|█████████▍| 1648/1740 [26:34<01:24,  1.09it/s] 95%|█████████▍| 1649/1740 [26:35<01:23,  1.09it/s] 95%|█████████▍| 1650/1740 [26:36<01:22,  1.09it/s] 95%|█████████▍| 1651/1740 [26:37<01:21,  1.09it/s] 95%|█████████▍| 1652/1740 [26:38<01:20,  1.09it/s] 95%|█████████▌| 1653/1740 [26:39<01:19,  1.09it/s] 95%|█████████▌| 1654/1740 [26:39<01:18,  1.10it/s] 95%|█████████▌| 1655/1740 [26:40<01:17,  1.09it/s] 95%|█████████▌| 1656/1740 [26:41<01:16,  1.09it/s] 95%|█████████▌| 1657/1740 [26:42<01:15,  1.09it/s] 95%|█████████▌| 1658/1740 [26:43<01:15,  1.09it/s] 95%|█████████▌| 1659/1740 [26:44<01:14,  1.09it/s] 95%|█████████▌| 1660/1740 [26:45<01:13,  1.09it/s] 95%|█████████▌| 1661/1740 [26:46<01:12,  1.09it/s] 96%|█████████▌| 1662/1740 [26:47<01:11,  1.09it/s] 96%|█████████▌| 1663/1740 [26:48<01:10,  1.09it/s] 96%|█████████▌| 1664/1740 [26:49<01:09,  1.09it/s] 96%|█████████▌| 1665/1740 [26:49<01:08,  1.09it/s] 96%|█████████▌| 1666/1740 [26:50<01:07,  1.09it/s] 96%|█████████▌| 1667/1740 [26:51<01:06,  1.09it/s] 96%|█████████▌| 1668/1740 [26:52<01:05,  1.09it/s] 96%|█████████▌| 1669/1740 [26:53<01:05,  1.09it/s] 96%|█████████▌| 1670/1740 [26:54<01:04,  1.09it/s] 96%|█████████▌| 1671/1740 [26:55<01:06,  1.04it/s] 96%|█████████▌| 1672/1740 [26:56<01:04,  1.06it/s] 96%|█████████▌| 1673/1740 [26:57<01:02,  1.07it/s] 96%|█████████▌| 1674/1740 [26:58<01:01,  1.07it/s] 96%|█████████▋| 1675/1740 [26:59<01:00,  1.08it/s] 96%|█████████▋| 1676/1740 [27:00<00:59,  1.08it/s] 96%|█████████▋| 1677/1740 [27:01<00:58,  1.09it/s] 96%|█████████▋| 1678/1740 [27:02<00:57,  1.09it/s] 96%|█████████▋| 1679/1740 [27:02<00:56,  1.09it/s] 97%|█████████▋| 1680/1740 [27:03<00:55,  1.09it/s] 97%|█████████▋| 1681/1740 [27:04<00:54,  1.09it/s] 97%|█████████▋| 1682/1740 [27:05<00:53,  1.09it/s] 97%|█████████▋| 1683/1740 [27:06<00:52,  1.09it/s] 97%|█████████▋| 1684/1740 [27:07<00:51,  1.09it/s] 97%|█████████▋| 1685/1740 [27:08<00:50,  1.09it/s] 97%|█████████▋| 1686/1740 [27:09<00:49,  1.09it/s] 97%|█████████▋| 1687/1740 [27:10<00:48,  1.09it/s] 97%|█████████▋| 1688/1740 [27:11<00:47,  1.09it/s] 97%|█████████▋| 1689/1740 [27:12<00:46,  1.09it/s] 97%|█████████▋| 1690/1740 [27:13<00:45,  1.09it/s] 97%|█████████▋| 1691/1740 [27:13<00:44,  1.09it/s] 97%|█████████▋| 1692/1740 [27:14<00:43,  1.09it/s] 97%|█████████▋| 1693/1740 [27:15<00:43,  1.09it/s] 97%|█████████▋| 1694/1740 [27:16<00:42,  1.09it/s] 97%|█████████▋| 1695/1740 [27:17<00:41,  1.09it/s] 97%|█████████▋| 1696/1740 [27:18<00:40,  1.09it/s] 98%|█████████▊| 1697/1740 [27:19<00:39,  1.09it/s] 98%|█████████▊| 1698/1740 [27:20<00:38,  1.10it/s] 98%|█████████▊| 1699/1740 [27:21<00:37,  1.10it/s] 98%|█████████▊| 1700/1740 [27:22<00:36,  1.09it/s] 98%|█████████▊| 1701/1740 [27:23<00:35,  1.09it/s] 98%|█████████▊| 1702/1740 [27:24<00:34,  1.09it/s] 98%|█████████▊| 1703/1740 [27:25<00:35,  1.04it/s] 98%|█████████▊| 1704/1740 [27:26<00:34,  1.06it/s] 98%|█████████▊| 1705/1740 [27:26<00:32,  1.07it/s] 98%|█████████▊| 1706/1740 [27:27<00:31,  1.07it/s] 98%|█████████▊| 1707/1740 [27:28<00:30,  1.08it/s] 98%|█████████▊| 1708/1740 [27:29<00:29,  1.08it/s] 98%|█████████▊| 1709/1740 [27:30<00:28,  1.08it/s] 98%|█████████▊| 1710/1740 [27:31<00:27,  1.09it/s] 98%|█████████▊| 1711/1740 [27:32<00:26,  1.09it/s] 98%|█████████▊| 1712/1740 [27:33<00:25,  1.09it/s] 98%|█████████▊| 1713/1740 [27:34<00:24,  1.09it/s] 99%|█████████▊| 1714/1740 [27:35<00:23,  1.09it/s] 99%|█████████▊| 1715/1740 [27:36<00:22,  1.09it/s] 99%|█████████▊| 1716/1740 [27:37<00:22,  1.09it/s] 99%|█████████▊| 1717/1740 [27:37<00:21,  1.09it/s] 99%|█████████▊| 1718/1740 [27:38<00:20,  1.09it/s] 99%|█████████▉| 1719/1740 [27:39<00:19,  1.09it/s] 99%|█████████▉| 1720/1740 [27:40<00:18,  1.09it/s] 99%|█████████▉| 1721/1740 [27:41<00:17,  1.10it/s] 99%|█████████▉| 1722/1740 [27:42<00:16,  1.09it/s] 99%|█████████▉| 1723/1740 [27:43<00:15,  1.09it/s] 99%|█████████▉| 1724/1740 [27:44<00:14,  1.09it/s] 99%|█████████▉| 1725/1740 [27:45<00:13,  1.09it/s] 99%|█████████▉| 1726/1740 [27:46<00:12,  1.09it/s] 99%|█████████▉| 1727/1740 [27:47<00:11,  1.09it/s] 99%|█████████▉| 1728/1740 [27:47<00:10,  1.09it/s] 99%|█████████▉| 1729/1740 [27:49<00:10,  1.04it/s] 99%|█████████▉| 1730/1740 [27:49<00:09,  1.06it/s] 99%|█████████▉| 1731/1740 [27:50<00:08,  1.07it/s]100%|█████████▉| 1732/1740 [27:51<00:07,  1.08it/s]100%|█████████▉| 1733/1740 [27:52<00:06,  1.08it/s]100%|█████████▉| 1734/1740 [27:53<00:05,  1.08it/s]100%|█████████▉| 1735/1740 [27:54<00:04,  1.09it/s]100%|█████████▉| 1736/1740 [27:55<00:03,  1.09it/s]100%|█████████▉| 1737/1740 [27:56<00:02,  1.09it/s]100%|█████████▉| 1738/1740 [27:57<00:01,  1.09it/s]100%|█████████▉| 1739/1740 [27:58<00:00,  1.09it/s]100%|██████████| 1740/1740 [27:58<00:00,  1.28it/s]{'eval_loss': 5.105825901031494, 'eval_precision': 0.848, 'eval_recall': 0.8217054263565892, 'eval_f1': 0.8346456692913387, 'eval_accuracy': 0.9843193157519601, 'eval_runtime': 2.0916, 'eval_samples_per_second': 49.244, 'eval_steps_per_second': 1.912, 'epoch': 14.0}

  0%|          | 0/4 [00:00<?, ?it/s][A
 50%|█████     | 2/4 [00:00<00:00,  3.69it/s][A
 75%|███████▌  | 3/4 [00:01<00:00,  2.73it/s][A
100%|██████████| 4/4 [00:01<00:00,  2.57it/s][A                                                   
                                             [A100%|██████████| 1740/1740 [28:00<00:00,  1.28it/s]
100%|██████████| 4/4 [00:01<00:00,  2.57it/s][A
                                             [A                                                   100%|██████████| 1740/1740 [28:04<00:00,  1.28it/s]100%|██████████| 1740/1740 [28:04<00:00,  1.03it/s]
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
{'eval_loss': 4.868744850158691, 'eval_precision': 0.8482490272373541, 'eval_recall': 0.8449612403100775, 'eval_f1': 0.8466019417475729, 'eval_accuracy': 0.9853884533143265, 'eval_runtime': 2.1108, 'eval_samples_per_second': 48.796, 'eval_steps_per_second': 1.895, 'epoch': 15.0}
{'train_runtime': 1684.7278, 'train_samples_per_second': 8.227, 'train_steps_per_second': 1.033, 'train_loss': 18.648738536615483, 'epoch': 15.0}

Evaluating on validation data...
  0%|          | 0/4 [00:00<?, ?it/s] 50%|█████     | 2/4 [00:00<00:00,  3.91it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.74it/s]100%|██████████| 4/4 [00:01<00:00,  2.62it/s]100%|██████████| 4/4 [00:01<00:00,  2.61it/s]
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
Pred: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-duration', 'B-duration', 'I-duration', 'I-duration', 'I-duration', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-country', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']
Gold: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-duration', 'B-duration', 'I-duration', 'I-duration', 'I-duration', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']

Pred: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-city', 'B-city', 'B-city', 'B-city', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-startTime', 'O', 'O', 'B-endTime', 'O', 'O', 'O', 'O']
Gold: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-city', 'B-city', 'B-city', 'B-city', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-startTime', 'O', 'O', 'B-endTime', 'O', 'O', 'O', 'O']

Pred: ['O', 'B-region', 'B-region', 'I-region', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-region', 'B-region', 'I-region', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']
Gold: ['O', 'B-region', 'B-region', 'I-region', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-region', 'B-region', 'I-region', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']


============================================================
VALIDATION CLASSIFICATION REPORTS
============================================================

Validation - Token-level Classification Report:
--------------------------------------------------
               precision    recall  f1-score   support

       B-Soil       0.66      0.62      0.64        34
       B-city       0.83      0.92      0.87        26
    B-country       0.86      1.00      0.92        18
B-cropSpecies       0.96      0.97      0.96        68
   B-duration       0.62      0.53      0.57        15
    B-endTime       0.92      0.92      0.92        13
     B-region       0.97      0.79      0.87        38
  B-startTime       0.94      0.98      0.96        46
       I-Soil       0.48      0.71      0.57        14
I-cropSpecies       0.91      0.97      0.94        33
   I-duration       0.92      0.92      0.92        13
    I-endTime       0.00      0.00      0.00         1
     I-region       1.00      0.75      0.86        16
  I-startTime       0.67      0.67      0.67         3
            O       0.99      0.99      0.99      5274

     accuracy                           0.99      5612
    macro avg       0.78      0.78      0.78      5612
 weighted avg       0.99      0.99      0.99      5612


Validation - Entity-level Classification Report:
--------------------------------------------------
              precision    recall  f1-score   support

        Soil       0.58      0.56      0.57        34
        city       0.83      0.92      0.87        26
     country       0.86      1.00      0.92        18
 cropSpecies       0.94      0.96      0.95        68
    duration       0.62      0.53      0.57        15
     endTime       0.85      0.85      0.85        13
      region       0.94      0.76      0.84        38
   startTime       0.92      0.96      0.94        46

   micro avg       0.85      0.84      0.85       258
   macro avg       0.81      0.82      0.81       258
weighted avg       0.85      0.84      0.84       258


Validation - Additional Statistics:
------------------------------
Total sequences: 103
Total tokens: 5612
Unique labels in predictions: 14
Unique labels in ground truth: 15

Evaluating on test data...
  0%|          | 0/10 [00:00<?, ?it/s] 20%|██        | 2/10 [00:00<00:02,  3.92it/s] 30%|███       | 3/10 [00:01<00:02,  2.71it/s] 40%|████      | 4/10 [00:01<00:02,  2.31it/s] 50%|█████     | 5/10 [00:02<00:02,  2.16it/s] 60%|██████    | 6/10 [00:02<00:01,  2.05it/s] 70%|███████   | 7/10 [00:03<00:01,  1.95it/s] 80%|████████  | 8/10 [00:03<00:01,  1.94it/s] 90%|█████████ | 9/10 [00:04<00:00,  1.95it/s]100%|██████████| 10/10 [00:04<00:00,  1.97it/s]100%|██████████| 10/10 [00:04<00:00,  2.02it/s]

Test Metrics:
{'test_loss': 8.25351619720459, 'test_precision': 0.6796296296296296, 'test_recall': 0.7310756972111554, 'test_f1': 0.7044145873320538, 'test_accuracy': 0.9770422535211267, 'test_runtime': 5.6132, 'test_samples_per_second': 56.83, 'test_steps_per_second': 1.782}

============================================================
TEST CLASSIFICATION REPORTS
============================================================

Test - Token-level Classification Report:
--------------------------------------------------
               precision    recall  f1-score   support

       B-Soil       0.62      0.42      0.50        69
       B-city       0.55      0.79      0.65        39
    B-country       0.68      0.92      0.78        25
B-cropSpecies       0.85      0.87      0.86       193
   B-duration       0.85      0.53      0.65        32
    B-endTime       0.78      0.64      0.70        39
     B-region       0.65      0.57      0.61        35
  B-startTime       0.60      0.97      0.74        70
       I-Soil       0.68      0.53      0.60        43
I-cropSpecies       0.83      0.64      0.72        81
   I-duration       0.85      0.88      0.86        32
    I-endTime       0.00      0.00      0.00         5
     I-region       0.29      0.71      0.42         7
  I-startTime       0.27      0.50      0.35         6
            O       0.99      0.99      0.99     13524

     accuracy                           0.98     14200
    macro avg       0.63      0.66      0.63     14200
 weighted avg       0.98      0.98      0.98     14200


Test - Entity-level Classification Report:
--------------------------------------------------
              precision    recall  f1-score   support

        Soil       0.49      0.35      0.41        69
        city       0.55      0.79      0.65        39
     country       0.68      0.92      0.78        25
 cropSpecies       0.83      0.85      0.84       193
    duration       0.67      0.44      0.53        32
     endTime       0.69      0.56      0.62        39
      region       0.64      0.60      0.62        35
   startTime       0.58      0.96      0.72        70

   micro avg       0.68      0.73      0.70       502
   macro avg       0.64      0.68      0.65       502
weighted avg       0.68      0.73      0.69       502


Test - Additional Statistics:
------------------------------
Total sequences: 319
Total tokens: 14200
Unique labels in predictions: 14
Unique labels in ground truth: 15

============================================================
TRAINING COMPLETED SUCCESSFULLY!
Classification reports saved to:
- validation_classification_report.txt
- test_classification_report.txt
============================================================
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33msandy-bush-724[0m at: [34mhttps://wandb.ai/murtuzanh-university-bonn/huggingface/runs/xuinhbyw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250909_133614-xuinhbyw/logs[0m
Stopping resource monitoring...
job-finetune-generic-bash.bash: line 57: kill: (1006749) - No such process
Total GPU execution time: 7191 seconds
Fetching SLURM job summary...
JobID           Elapsed     MaxRSS    CPUTime ExitCode 
------------ ---------- ---------- ---------- -------- 
23200897       03:32:29            9-10:38:56      0:0 
23200897.ex+   03:32:29            9-10:38:56      0:0 
23200897.0     03:32:16            9-10:25:04      0:0 
All logs are saved in: /home/s27mhusa_hpc/Master-Thesis/OutputNewDatasets6thSeptemberFineTune/job_monitor_logs_mdeberta-crf-reg_23200897_20250909_120602
