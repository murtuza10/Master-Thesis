no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/condabin/conda
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/bin/conda
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/bin/conda-env
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/bin/activate
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/bin/deactivate
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/etc/profile.d/conda.sh
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/etc/fish/conf.d/conda.fish
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/shell/condabin/Conda.psm1
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/shell/condabin/conda-hook.ps1
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/lib/python3.10/site-packages/xontrib/conda.xsh
no change     /opt/software/easybuild-INTEL/software/Miniforge3/24.1.2-0/etc/profile.d/conda.csh
no change     /home/s27mhusa_hpc/.bashrc
No action taken.
Starting resource monitoring every 30 seconds...
Logs will be stored in: /home/s27mhusa_hpc/Master-Thesis/OutputNewDatasets15thSeptemberFineTune/job_monitor_logs_scibert-specific_23235181_20250917_180246
job-finetune-generic-bash-scibert.bash: line 42: iostat: command not found
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json
Retrying in 1s [Retry 1/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json
Retrying in 2s [Retry 2/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json
Retrying in 4s [Retry 3/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json
Retrying in 8s [Retry 4/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json
Retrying in 8s [Retry 5/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Retrying in 1s [Retry 1/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Retrying in 2s [Retry 2/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Retrying in 4s [Retry 3/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Retrying in 8s [Retry 4/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Retrying in 8s [Retry 5/5].
Applying data augmentation...
Original train size: 854, Augmented size: 1110
Map:   0%|          | 0/1213 [00:00<?, ? examples/s]Map:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1000/1213 [00:00<00:00, 6346.66 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1213/1213 [00:00<00:00, 6076.31 examples/s]
[I 2025-09-17 18:03:40,067] A new study created in memory with name: no-name-48f7ede0-5820-4aec-b4f9-d0203babba5b
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Currently logged in as: murtuzanh (murtuzanh-university-bonn) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /home/s27mhusa_hpc/Master-Thesis/Fine-tune/wandb/run-20250917_180343-ckb0nld0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-cosmos-755
wandb: â­ï¸ View project at https://wandb.ai/murtuzanh-university-bonn/huggingface
wandb: ðŸš€ View run at https://wandb.ai/murtuzanh-university-bonn/huggingface/runs/ckb0nld0

================================================================================
PART A: STARTING IMPROVED HYPERPARAMETER SEARCH
================================================================================

  0%|          | 0/18 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  6%|â–Œ         | 1/18 [00:02<00:44,  2.61s/it] 11%|â–ˆ         | 2/18 [00:02<00:19,  1.21s/it] 17%|â–ˆâ–‹        | 3/18 [00:03<00:11,  1.33it/s] 22%|â–ˆâ–ˆâ–       | 4/18 [00:03<00:07,  1.86it/s] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:03<00:05,  2.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:03<00:04,  3.00it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.09it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.40it/s][A                                              
                                             [A 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:04<00:04,  3.00it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.40it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:05<00:10,  1.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:05<00:06,  1.45it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:06<00:04,  1.84it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:06<00:03,  2.27it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:06<00:03,  2.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:06<00:02,  2.84it/s]{'eval_loss': 2.442575216293335, 'eval_precision': 0.0054456103068136535, 'eval_recall': 0.06146926536731634, 'eval_f1': 0.010004880429477794, 'eval_accuracy': 0.2954909590295262, 'eval_runtime': 0.8038, 'eval_samples_per_second': 503.869, 'eval_steps_per_second': 8.709, 'epoch': 1.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.19it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.89it/s][A                                               
                                             [A 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:07<00:02,  2.84it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.89it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:09<00:04,  1.14it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:09<00:02,  1.48it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:09<00:01,  1.88it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:09<00:00,  2.29it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:09<00:00,  2.74it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:10<00:00,  3.27it/s]{'eval_loss': 2.1274125576019287, 'eval_precision': 0.007427581084426839, 'eval_recall': 0.044977511244377814, 'eval_f1': 0.012749681257968553, 'eval_accuracy': 0.6105134660868239, 'eval_runtime': 0.7658, 'eval_samples_per_second': 528.846, 'eval_steps_per_second': 9.141, 'epoch': 2.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.45it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.41it/s][A                                               
                                             [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:11<00:00,  3.27it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.41it/s][A
                                             [A                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:12<00:00,  3.27it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:12<00:00,  1.46it/s]
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
{'eval_loss': 2.014594793319702, 'eval_precision': 0.009184033910279053, 'eval_recall': 0.038980509745127435, 'eval_f1': 0.014865637507146942, 'eval_accuracy': 0.7115281910429542, 'eval_runtime': 0.9873, 'eval_samples_per_second': 410.226, 'eval_steps_per_second': 7.09, 'epoch': 3.0}
{'train_runtime': 13.5207, 'train_samples_per_second': 179.28, 'train_steps_per_second': 1.331, 'train_loss': 2.2539450327555337, 'epoch': 3.0}
  0%|          | 0/6 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.54it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 13.15it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.42it/s]
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/18 [00:00<?, ?it/s]  6%|â–Œ         | 1/18 [00:00<00:06,  2.56it/s] 11%|â–ˆ         | 2/18 [00:00<00:04,  3.46it/s] 17%|â–ˆâ–‹        | 3/18 [00:00<00:03,  4.04it/s] 22%|â–ˆâ–ˆâ–       | 4/18 [00:01<00:03,  4.23it/s] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:01<00:02,  4.44it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:01<00:02,  4.75it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.05it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.26it/s][A                                              
                                             [A 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:02<00:02,  4.75it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.26it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:03<00:09,  1.19it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:03<00:06,  1.56it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:03<00:04,  1.97it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:04<00:03,  2.42it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:04<00:02,  2.87it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:04<00:02,  2.80it/s]{'eval_loss': 2.4527313709259033, 'eval_precision': 0.006551059730250481, 'eval_recall': 0.07369942196531792, 'eval_f1': 0.01203255868821517, 'eval_accuracy': 0.28421918217836584, 'eval_runtime': 0.812, 'eval_samples_per_second': 497.56, 'eval_steps_per_second': 8.621, 'epoch': 1.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.52it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.46it/s][A                                               
                                             [A 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:05<00:02,  2.80it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.46it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:06<00:04,  1.10it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:07<00:02,  1.44it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:07<00:01,  1.82it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:07<00:00,  2.22it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:07<00:00,  2.65it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:07<00:00,  3.14it/s]{'eval_loss': 2.138545274734497, 'eval_precision': 0.008062603746739389, 'eval_recall': 0.049132947976878616, 'eval_f1': 0.013852108372377268, 'eval_accuracy': 0.5992374971966808, 'eval_runtime': 0.8003, 'eval_samples_per_second': 504.837, 'eval_steps_per_second': 8.747, 'epoch': 2.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.82it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.90it/s][A                                               
                                             [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:08<00:00,  3.14it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.90it/s][A
                                             [A                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:10<00:00,  3.14it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:10<00:00,  1.79it/s]
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
{'eval_loss': 2.0270884037017822, 'eval_precision': 0.008712487899322363, 'eval_recall': 0.03901734104046243, 'eval_f1': 0.01424426272751253, 'eval_accuracy': 0.6906630784181804, 'eval_runtime': 0.7927, 'eval_samples_per_second': 509.643, 'eval_steps_per_second': 8.83, 'epoch': 3.0}
{'train_runtime': 10.044, 'train_samples_per_second': 241.637, 'train_steps_per_second': 1.792, 'train_loss': 2.253414577907986, 'epoch': 3.0}
  0%|          | 0/6 [00:00<?, ?it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00,  7.72it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  8.50it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00,  9.58it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.77it/s]
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/18 [00:00<?, ?it/s]  6%|â–Œ         | 1/18 [00:00<00:06,  2.58it/s] 11%|â–ˆ         | 2/18 [00:00<00:04,  3.40it/s] 17%|â–ˆâ–‹        | 3/18 [00:00<00:03,  3.97it/s] 22%|â–ˆâ–ˆâ–       | 4/18 [00:01<00:03,  4.32it/s] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:01<00:02,  4.53it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:01<00:02,  4.87it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.13it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.60it/s][A                                              
                                             [A 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:02<00:02,  4.87it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.60it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:03<00:09,  1.20it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:03<00:06,  1.58it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:03<00:04,  2.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:04<00:03,  2.47it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:04<00:02,  2.89it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:04<00:01,  3.39it/s]{'eval_loss': 2.445789098739624, 'eval_precision': 0.005719866071428571, 'eval_recall': 0.06721311475409836, 'eval_f1': 0.010542555926973514, 'eval_accuracy': 0.28585247883917775, 'eval_runtime': 0.8049, 'eval_samples_per_second': 501.922, 'eval_steps_per_second': 8.697, 'epoch': 1.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.16it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.46it/s][A                                               
                                             [A 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:05<00:01,  3.39it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.46it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:06<00:04,  1.11it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:07<00:02,  1.45it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:07<00:01,  1.84it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:07<00:00,  2.28it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:07<00:00,  2.73it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:07<00:00,  3.25it/s]{'eval_loss': 2.1319808959960938, 'eval_precision': 0.006329113924050633, 'eval_recall': 0.03934426229508197, 'eval_f1': 0.010904134484325308, 'eval_accuracy': 0.6099959693671907, 'eval_runtime': 0.9541, 'eval_samples_per_second': 423.457, 'eval_steps_per_second': 7.337, 'epoch': 2.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.42it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.93it/s][A                                               
                                             [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:08<00:00,  3.25it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.93it/s][A
                                             [A                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:09<00:00,  3.25it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:09<00:00,  1.83it/s]
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
{'eval_loss': 2.0214364528656006, 'eval_precision': 0.007339449541284404, 'eval_recall': 0.03278688524590164, 'eval_f1': 0.01199400299850075, 'eval_accuracy': 0.7058444175735591, 'eval_runtime': 0.7741, 'eval_samples_per_second': 521.87, 'eval_steps_per_second': 9.042, 'epoch': 3.0}
{'train_runtime': 9.8371, 'train_samples_per_second': 246.719, 'train_steps_per_second': 1.83, 'train_loss': 2.2481522030300565, 'epoch': 3.0}
  0%|          | 0/6 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  8.48it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00,  9.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.92it/s]
[I 2025-09-17 18:04:24,880] Trial 0 finished with value: 0.013701301077720074 and parameters: {'dropout': 0.37499520288023525, 'weight_decay': 0.23275740943693987, 'learning_rate': 3.650996743085083e-06, 'warmup_ratio': 0.15534484458330788, 'num_train_epochs': 3, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.013701301077720074.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/42 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  2%|â–         | 1/42 [00:00<00:15,  2.58it/s]  5%|â–         | 2/42 [00:00<00:11,  3.46it/s]  7%|â–‹         | 3/42 [00:00<00:09,  3.98it/s] 10%|â–‰         | 4/42 [00:01<00:08,  4.33it/s] 12%|â–ˆâ–        | 5/42 [00:01<00:08,  4.44it/s] 14%|â–ˆâ–        | 6/42 [00:01<00:07,  4.84it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.71it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 13.03it/s][A                                              
                                             [A 14%|â–ˆâ–        | 6/42 [00:02<00:07,  4.84it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 13.03it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 17%|â–ˆâ–‹        | 7/42 [00:03<00:29,  1.18it/s] 19%|â–ˆâ–‰        | 8/42 [00:03<00:21,  1.56it/s] 21%|â–ˆâ–ˆâ–       | 9/42 [00:03<00:16,  1.99it/s] 24%|â–ˆâ–ˆâ–       | 10/42 [00:04<00:13,  2.41it/s] 26%|â–ˆâ–ˆâ–Œ       | 11/42 [00:04<00:10,  2.85it/s] 29%|â–ˆâ–ˆâ–Š       | 12/42 [00:04<00:10,  2.87it/s]{'eval_loss': 2.55720591545105, 'eval_precision': 0.005253327107167873, 'eval_recall': 0.06746626686656672, 'eval_f1': 0.009747644319289506, 'eval_accuracy': 0.2008850232700084, 'eval_runtime': 0.7885, 'eval_samples_per_second': 513.659, 'eval_steps_per_second': 8.878, 'epoch': 1.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.35it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.67it/s][A                                               
                                             [A 29%|â–ˆâ–ˆâ–Š       | 12/42 [00:05<00:10,  2.87it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.67it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 31%|â–ˆâ–ˆâ–ˆ       | 13/42 [00:06<00:25,  1.12it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 14/42 [00:07<00:19,  1.47it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 15/42 [00:07<00:14,  1.85it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 16/42 [00:07<00:11,  2.27it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 17/42 [00:07<00:09,  2.72it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 18/42 [00:07<00:07,  3.24it/s]{'eval_loss': 1.8864526748657227, 'eval_precision': 0.012684989429175475, 'eval_recall': 0.035982008995502246, 'eval_f1': 0.01875732708089097, 'eval_accuracy': 0.7901121538109407, 'eval_runtime': 0.7672, 'eval_samples_per_second': 527.891, 'eval_steps_per_second': 9.124, 'epoch': 2.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.91it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.73it/s][A                                               
                                             [A 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 18/42 [00:08<00:07,  3.24it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.73it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 19/42 [00:10<00:19,  1.15it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 20/42 [00:10<00:16,  1.37it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 21/42 [00:10<00:12,  1.75it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 22/42 [00:10<00:09,  2.15it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 23/42 [00:11<00:07,  2.59it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 24/42 [00:11<00:05,  3.09it/s]{'eval_loss': 1.260654091835022, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9245441367208362, 'eval_runtime': 0.7621, 'eval_samples_per_second': 531.435, 'eval_steps_per_second': 9.185, 'epoch': 3.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00, 19.95it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00, 13.04it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.25it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 24/42 [00:12<00:05,  3.09it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.25it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 25/42 [00:13<00:14,  1.16it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 26/42 [00:13<00:10,  1.50it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 27/42 [00:13<00:07,  1.90it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 28/42 [00:13<00:05,  2.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 29/42 [00:14<00:04,  2.78it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 30/42 [00:14<00:03,  3.29it/s]{'eval_loss': 0.8778784275054932, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9284351873044938, 'eval_runtime': 0.7653, 'eval_samples_per_second': 529.222, 'eval_steps_per_second': 9.147, 'epoch': 4.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  8.05it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00,  8.43it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  9.47it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 30/42 [00:15<00:03,  3.29it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  9.47it/s][A
                                             [A                                                71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 30/42 [00:16<00:03,  3.29it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 30/42 [00:16<00:06,  1.79it/s]
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
{'eval_loss': 0.6814363598823547, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9286640726329443, 'eval_runtime': 1.12, 'eval_samples_per_second': 361.594, 'eval_steps_per_second': 6.25, 'epoch': 5.0}
{'train_runtime': 16.7647, 'train_samples_per_second': 337.376, 'train_steps_per_second': 2.505, 'train_loss': 1.4519259134928386, 'epoch': 5.0}
  0%|          | 0/6 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.88it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.92it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.06it/s]
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/42 [00:00<?, ?it/s]  2%|â–         | 1/42 [00:00<00:15,  2.62it/s]  5%|â–         | 2/42 [00:00<00:11,  3.45it/s]  7%|â–‹         | 3/42 [00:00<00:09,  3.98it/s] 10%|â–‰         | 4/42 [00:01<00:08,  4.34it/s] 12%|â–ˆâ–        | 5/42 [00:01<00:08,  4.50it/s] 14%|â–ˆâ–        | 6/42 [00:01<00:07,  4.89it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.11it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.97it/s][A                                              
                                             [A 14%|â–ˆâ–        | 6/42 [00:02<00:07,  4.89it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.97it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 17%|â–ˆâ–‹        | 7/42 [00:03<00:31,  1.11it/s] 19%|â–ˆâ–‰        | 8/42 [00:03<00:23,  1.47it/s] 21%|â–ˆâ–ˆâ–       | 9/42 [00:04<00:17,  1.88it/s] 24%|â–ˆâ–ˆâ–       | 10/42 [00:04<00:13,  2.33it/s] 26%|â–ˆâ–ˆâ–Œ       | 11/42 [00:04<00:11,  2.74it/s] 29%|â–ˆâ–ˆâ–Š       | 12/42 [00:04<00:11,  2.70it/s]{'eval_loss': 2.5676965713500977, 'eval_precision': 0.006373776462554063, 'eval_recall': 0.08092485549132948, 'eval_f1': 0.011816838995568684, 'eval_accuracy': 0.19309262166405022, 'eval_runtime': 0.7892, 'eval_samples_per_second': 511.933, 'eval_steps_per_second': 8.87, 'epoch': 1.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.15it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.89it/s][A                                               
                                             [A 29%|â–ˆâ–ˆâ–Š       | 12/42 [00:05<00:11,  2.70it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.89it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 31%|â–ˆâ–ˆâ–ˆ       | 13/42 [00:07<00:26,  1.11it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 14/42 [00:07<00:19,  1.45it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 15/42 [00:07<00:14,  1.84it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 16/42 [00:07<00:11,  2.26it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 17/42 [00:07<00:09,  2.67it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 18/42 [00:08<00:07,  3.18it/s]{'eval_loss': 1.9019346237182617, 'eval_precision': 0.010848126232741617, 'eval_recall': 0.031791907514450865, 'eval_f1': 0.016176470588235292, 'eval_accuracy': 0.7773790835015325, 'eval_runtime': 0.7747, 'eval_samples_per_second': 521.461, 'eval_steps_per_second': 9.035, 'epoch': 2.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.71it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.44it/s][A                                               
                                             [A 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 18/42 [00:09<00:07,  3.18it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.44it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 19/42 [00:10<00:21,  1.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 20/42 [00:10<00:15,  1.41it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 21/42 [00:10<00:11,  1.79it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 22/42 [00:11<00:09,  2.22it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 23/42 [00:11<00:07,  2.65it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 24/42 [00:11<00:05,  3.16it/s]{'eval_loss': 1.277185082435608, 'eval_precision': 0.029411764705882353, 'eval_recall': 0.002890173410404624, 'eval_f1': 0.005263157894736842, 'eval_accuracy': 0.9259176197951708, 'eval_runtime': 0.9513, 'eval_samples_per_second': 424.671, 'eval_steps_per_second': 7.358, 'epoch': 3.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.25it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.86it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 24/42 [00:12<00:05,  3.16it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.86it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 25/42 [00:13<00:14,  1.18it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 26/42 [00:13<00:10,  1.53it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 27/42 [00:13<00:07,  1.91it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 28/42 [00:14<00:05,  2.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 29/42 [00:14<00:04,  2.76it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 30/42 [00:14<00:04,  2.79it/s]{'eval_loss': 0.8853325843811035, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9303281752261344, 'eval_runtime': 0.7709, 'eval_samples_per_second': 524.035, 'eval_steps_per_second': 9.08, 'epoch': 4.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.74it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.69it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 30/42 [00:15<00:04,  2.79it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.69it/s][A
                                             [A                                                71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 30/42 [00:16<00:04,  2.79it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 30/42 [00:16<00:06,  1.79it/s]
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
{'eval_loss': 0.690656840801239, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9304776855797264, 'eval_runtime': 0.7685, 'eval_samples_per_second': 525.725, 'eval_steps_per_second': 9.109, 'epoch': 5.0}
{'train_runtime': 16.7332, 'train_samples_per_second': 338.43, 'train_steps_per_second': 2.51, 'train_loss': 1.4549559275309245, 'epoch': 5.0}
  0%|          | 0/6 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.10it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.82it/s]
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/42 [00:00<?, ?it/s]  2%|â–         | 1/42 [00:00<00:15,  2.61it/s]  5%|â–         | 2/42 [00:00<00:11,  3.52it/s]  7%|â–‹         | 3/42 [00:00<00:09,  4.09it/s] 10%|â–‰         | 4/42 [00:00<00:08,  4.41it/s] 12%|â–ˆâ–        | 5/42 [00:01<00:08,  4.61it/s] 14%|â–ˆâ–        | 6/42 [00:01<00:07,  4.94it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.84it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.93it/s][A                                              
                                             [A 14%|â–ˆâ–        | 6/42 [00:02<00:07,  4.94it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.93it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 17%|â–ˆâ–‹        | 7/42 [00:03<00:30,  1.13it/s] 19%|â–ˆâ–‰        | 8/42 [00:03<00:22,  1.50it/s] 21%|â–ˆâ–ˆâ–       | 9/42 [00:04<00:17,  1.93it/s] 24%|â–ˆâ–ˆâ–       | 10/42 [00:04<00:13,  2.37it/s] 26%|â–ˆâ–ˆâ–Œ       | 11/42 [00:04<00:10,  2.83it/s] 29%|â–ˆâ–ˆâ–Š       | 12/42 [00:04<00:08,  3.36it/s]{'eval_loss': 2.5618808269500732, 'eval_precision': 0.005116335729077841, 'eval_recall': 0.06885245901639345, 'eval_f1': 0.009524889443247532, 'eval_accuracy': 0.1841999193873438, 'eval_runtime': 0.7873, 'eval_samples_per_second': 513.162, 'eval_steps_per_second': 8.891, 'epoch': 1.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.80it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 13.08it/s][A                                               
                                             [A 29%|â–ˆâ–ˆâ–Š       | 12/42 [00:05<00:08,  3.36it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 13.08it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 31%|â–ˆâ–ˆâ–ˆ       | 13/42 [00:06<00:26,  1.10it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 14/42 [00:07<00:19,  1.44it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 15/42 [00:07<00:14,  1.84it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 16/42 [00:07<00:11,  2.27it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 17/42 [00:07<00:09,  2.71it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 18/42 [00:07<00:07,  3.20it/s]{'eval_loss': 1.8996142148971558, 'eval_precision': 0.008743169398907104, 'eval_recall': 0.02622950819672131, 'eval_f1': 0.013114754098360656, 'eval_accuracy': 0.7850060459492141, 'eval_runtime': 0.9402, 'eval_samples_per_second': 429.694, 'eval_steps_per_second': 7.445, 'epoch': 2.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.79it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 13.04it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 18/42 [00:08<00:07,  3.20it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 13.04it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 19/42 [00:09<00:19,  1.19it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 20/42 [00:10<00:15,  1.42it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 21/42 [00:10<00:11,  1.81it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 22/42 [00:10<00:08,  2.24it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 23/42 [00:10<00:07,  2.67it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 24/42 [00:11<00:05,  3.19it/s]{'eval_loss': 1.2825264930725098, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9273679967754938, 'eval_runtime': 0.7461, 'eval_samples_per_second': 541.48, 'eval_steps_per_second': 9.382, 'epoch': 3.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.21it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 13.04it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 24/42 [00:11<00:05,  3.19it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 13.04it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 25/42 [00:13<00:14,  1.19it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 26/42 [00:13<00:10,  1.54it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 27/42 [00:13<00:07,  1.94it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 28/42 [00:13<00:05,  2.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 29/42 [00:14<00:04,  2.81it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 30/42 [00:14<00:03,  3.31it/s]{'eval_loss': 0.8937851786613464, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9329302700523983, 'eval_runtime': 0.7463, 'eval_samples_per_second': 541.315, 'eval_steps_per_second': 9.379, 'epoch': 4.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  8.46it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00,  8.80it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  9.80it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 30/42 [00:15<00:03,  3.31it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  9.80it/s][A
                                             [A                                                71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 30/42 [00:16<00:03,  3.31it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 30/42 [00:16<00:06,  1.82it/s]
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
{'eval_loss': 0.7008727192878723, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9330108827085852, 'eval_runtime': 0.9327, 'eval_samples_per_second': 433.165, 'eval_steps_per_second': 7.505, 'epoch': 5.0}
{'train_runtime': 16.4504, 'train_samples_per_second': 344.248, 'train_steps_per_second': 2.553, 'train_loss': 1.4557791392008463, 'epoch': 5.0}
  0%|          | 0/6 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.64it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.18it/s]
[I 2025-09-17 18:05:25,182] Trial 1 finished with value: 0.01601618392249564 and parameters: {'dropout': 0.37473658375065055, 'weight_decay': 0.05169513548747687, 'learning_rate': 5.9467209312755804e-06, 'warmup_ratio': 0.23448057359693986, 'num_train_epochs': 7, 'per_device_train_batch_size': 16}. Best is trial 1 with value: 0.01601618392249564.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Retrying in 1s [Retry 1/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Retrying in 2s [Retry 2/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Retrying in 4s [Retry 3/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Retrying in 8s [Retry 4/5].
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/100 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  1%|          | 1/100 [00:00<00:26,  3.80it/s]  2%|â–         | 2/100 [00:00<00:20,  4.71it/s]  3%|â–Ž         | 3/100 [00:00<00:18,  5.24it/s]  4%|â–         | 4/100 [00:00<00:17,  5.37it/s]  5%|â–Œ         | 5/100 [00:00<00:17,  5.51it/s]  6%|â–Œ         | 6/100 [00:01<00:16,  5.62it/s]  7%|â–‹         | 7/100 [00:01<00:16,  5.68it/s]  8%|â–Š         | 8/100 [00:01<00:16,  5.73it/s]  9%|â–‰         | 9/100 [00:01<00:16,  5.65it/s] 10%|â–ˆ         | 10/100 [00:01<00:15,  5.69it/s] 11%|â–ˆ         | 11/100 [00:02<00:15,  5.63it/s] 12%|â–ˆâ–        | 12/100 [00:02<00:15,  5.63it/s] 13%|â–ˆâ–Ž        | 13/100 [00:02<00:15,  5.68it/s] 14%|â–ˆâ–        | 14/100 [00:02<00:15,  5.65it/s] 15%|â–ˆâ–Œ        | 15/100 [00:02<00:14,  5.70it/s] 16%|â–ˆâ–Œ        | 16/100 [00:02<00:14,  5.73it/s] 17%|â–ˆâ–‹        | 17/100 [00:03<00:14,  5.75it/s] 18%|â–ˆâ–Š        | 18/100 [00:03<00:14,  5.76it/s] 19%|â–ˆâ–‰        | 19/100 [00:03<00:17,  4.51it/s] 20%|â–ˆâ–ˆ        | 20/100 [00:03<00:16,  4.83it/s] 21%|â–ˆâ–ˆ        | 21/100 [00:03<00:15,  5.04it/s] 22%|â–ˆâ–ˆâ–       | 22/100 [00:04<00:14,  5.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 23/100 [00:04<00:14,  5.31it/s] 24%|â–ˆâ–ˆâ–       | 24/100 [00:04<00:14,  5.38it/s] 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:04<00:13,  5.62it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.38it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.53it/s][A                                                
                                             [A 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:05<00:13,  5.62it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.53it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [00:06<00:55,  1.34it/s] 27%|â–ˆâ–ˆâ–‹       | 27/100 [00:06<00:41,  1.74it/s] 28%|â–ˆâ–ˆâ–Š       | 28/100 [00:07<00:32,  2.21it/s] 29%|â–ˆâ–ˆâ–‰       | 29/100 [00:07<00:26,  2.69it/s] 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:07<00:21,  3.21it/s] 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:07<00:18,  3.69it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:07<00:20,  3.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [00:08<00:17,  3.88it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:08<00:15,  4.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [00:08<00:13,  4.68it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:08<00:12,  4.97it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [00:08<00:12,  5.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [00:08<00:11,  5.31it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [00:09<00:11,  5.42it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:09<00:10,  5.51it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [00:09<00:10,  5.59it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [00:09<00:10,  5.61it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [00:09<00:10,  5.67it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [00:09<00:09,  5.64it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [00:10<00:09,  5.66it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [00:10<00:09,  5.59it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [00:10<00:09,  5.64it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [00:10<00:09,  5.68it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [00:10<00:08,  5.72it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:11<00:10,  4.62it/s]                                                 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:11<00:10,  4.62it/s]{'eval_loss': 1.8192020654678345, 'eval_precision': 0.015602836879432624, 'eval_recall': 0.03298350824587706, 'eval_f1': 0.02118440057775638, 'eval_accuracy': 0.827038986800946, 'eval_runtime': 0.7693, 'eval_samples_per_second': 526.442, 'eval_steps_per_second': 9.099, 'epoch': 1.0}
{'loss': 1.9013, 'grad_norm': 599123.3125, 'learning_rate': 1.4219597940665886e-06, 'epoch': 2.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.08it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.70it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:11<00:10,  4.62it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.70it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [00:13<00:37,  1.29it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [00:13<00:28,  1.69it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [00:13<00:21,  2.15it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [00:13<00:17,  2.64it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [00:13<00:14,  3.13it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [00:14<00:12,  3.64it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [00:14<00:10,  4.10it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [00:14<00:09,  4.47it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [00:14<00:08,  4.79it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [00:14<00:07,  5.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [00:14<00:07,  5.25it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [00:15<00:07,  5.39it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [00:15<00:08,  4.42it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [00:15<00:07,  4.72it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [00:15<00:07,  4.91it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [00:16<00:06,  5.15it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [00:16<00:06,  5.38it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [00:16<00:05,  5.51it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [00:16<00:05,  5.59it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [00:16<00:05,  5.72it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [00:16<00:05,  5.74it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [00:17<00:04,  5.77it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [00:17<00:04,  5.72it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [00:17<00:04,  5.74it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [00:17<00:04,  5.77it/s]{'eval_loss': 0.7758448719978333, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9285877775234608, 'eval_runtime': 0.761, 'eval_samples_per_second': 532.174, 'eval_steps_per_second': 9.198, 'epoch': 2.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.04it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.58it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [00:18<00:04,  5.77it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.58it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [00:19<00:19,  1.25it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [00:19<00:14,  1.64it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [00:20<00:10,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [00:20<00:08,  2.57it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [00:20<00:06,  3.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [00:20<00:05,  3.57it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [00:20<00:04,  4.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [00:21<00:03,  4.42it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [00:21<00:03,  4.76it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [00:21<00:02,  5.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [00:21<00:02,  5.23it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [00:21<00:02,  5.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [00:21<00:02,  5.42it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [00:22<00:01,  5.53it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [00:22<00:01,  5.60it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [00:22<00:01,  5.70it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [00:22<00:01,  5.79it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [00:22<00:01,  5.75it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [00:22<00:01,  5.76it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [00:23<00:01,  4.59it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [00:23<00:00,  4.89it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [00:23<00:00,  5.13it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [00:23<00:00,  5.21it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [00:23<00:00,  5.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:24<00:00,  5.61it/s]                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:24<00:00,  5.61it/s]{'eval_loss': 0.48258137702941895, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9287403677424277, 'eval_runtime': 0.7782, 'eval_samples_per_second': 520.411, 'eval_steps_per_second': 8.995, 'epoch': 3.0}
{'loss': 0.5414, 'grad_norm': 74618.5234375, 'learning_rate': 2.788156458954095e-08, 'epoch': 4.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00, 19.51it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00, 12.90it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.01it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                 
                                             [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:24<00:00,  5.61it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.01it/s][A
                                             [A                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:26<00:00,  5.61it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:26<00:00,  3.80it/s]
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
{'eval_loss': 0.45618247985839844, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9287403677424277, 'eval_runtime': 0.772, 'eval_samples_per_second': 524.615, 'eval_steps_per_second': 9.067, 'epoch': 4.0}
{'train_runtime': 26.2857, 'train_samples_per_second': 122.957, 'train_steps_per_second': 3.804, 'train_loss': 1.2213698196411134, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.70it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.66it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.61it/s]
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:26,  3.74it/s]  2%|â–         | 2/100 [00:00<00:21,  4.62it/s]  3%|â–Ž         | 3/100 [00:00<00:18,  5.14it/s]  4%|â–         | 4/100 [00:00<00:19,  5.04it/s]  5%|â–Œ         | 5/100 [00:01<00:18,  5.16it/s]  6%|â–Œ         | 6/100 [00:01<00:17,  5.33it/s]  7%|â–‹         | 7/100 [00:01<00:17,  5.47it/s]  8%|â–Š         | 8/100 [00:01<00:16,  5.56it/s]  9%|â–‰         | 9/100 [00:01<00:16,  5.56it/s] 10%|â–ˆ         | 10/100 [00:01<00:15,  5.68it/s] 11%|â–ˆ         | 11/100 [00:02<00:15,  5.72it/s] 12%|â–ˆâ–        | 12/100 [00:02<00:15,  5.74it/s] 13%|â–ˆâ–Ž        | 13/100 [00:02<00:15,  5.76it/s] 14%|â–ˆâ–        | 14/100 [00:02<00:14,  5.77it/s] 15%|â–ˆâ–Œ        | 15/100 [00:02<00:14,  5.79it/s] 16%|â–ˆâ–Œ        | 16/100 [00:02<00:14,  5.68it/s] 17%|â–ˆâ–‹        | 17/100 [00:03<00:14,  5.66it/s] 18%|â–ˆâ–Š        | 18/100 [00:03<00:18,  4.45it/s] 19%|â–ˆâ–‰        | 19/100 [00:03<00:16,  4.77it/s] 20%|â–ˆâ–ˆ        | 20/100 [00:03<00:16,  4.98it/s] 21%|â–ˆâ–ˆ        | 21/100 [00:03<00:15,  5.20it/s] 22%|â–ˆâ–ˆâ–       | 22/100 [00:04<00:14,  5.37it/s] 23%|â–ˆâ–ˆâ–Ž       | 23/100 [00:04<00:14,  5.46it/s] 24%|â–ˆâ–ˆâ–       | 24/100 [00:04<00:13,  5.55it/s] 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:04<00:13,  5.71it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.45it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.71it/s][A                                                
                                             [A 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:05<00:13,  5.71it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.71it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [00:06<00:56,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 27/100 [00:06<00:42,  1.70it/s] 28%|â–ˆâ–ˆâ–Š       | 28/100 [00:07<00:33,  2.17it/s] 29%|â–ˆâ–ˆâ–‰       | 29/100 [00:07<00:29,  2.38it/s] 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:07<00:24,  2.89it/s] 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:07<00:20,  3.37it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:07<00:17,  3.84it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [00:08<00:15,  4.29it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:08<00:14,  4.66it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [00:08<00:13,  4.87it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:08<00:12,  5.08it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [00:08<00:12,  5.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [00:09<00:11,  5.35it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [00:09<00:11,  5.46it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:09<00:10,  5.56it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [00:09<00:10,  5.58it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [00:09<00:10,  5.65it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [00:09<00:10,  5.56it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [00:10<00:10,  5.58it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [00:10<00:09,  5.53it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [00:10<00:09,  5.51it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [00:10<00:09,  5.55it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [00:10<00:11,  4.38it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [00:11<00:10,  4.72it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:11<00:09,  5.05it/s]                                                 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:11<00:09,  5.05it/s]{'eval_loss': 1.8290516138076782, 'eval_precision': 0.012064343163538873, 'eval_recall': 0.02601156069364162, 'eval_f1': 0.01648351648351648, 'eval_accuracy': 0.8187934514465127, 'eval_runtime': 0.7762, 'eval_samples_per_second': 520.453, 'eval_steps_per_second': 9.018, 'epoch': 1.0}
{'loss': 1.9, 'grad_norm': 643630.25, 'learning_rate': 1.4219597940665886e-06, 'epoch': 2.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.19it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 13.13it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:12<00:09,  5.05it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 13.13it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [00:13<00:36,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [00:13<00:27,  1.73it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [00:13<00:21,  2.20it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [00:13<00:17,  2.65it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [00:14<00:14,  3.17it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [00:14<00:11,  3.67it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [00:14<00:10,  4.13it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [00:14<00:09,  4.52it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [00:14<00:08,  4.84it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [00:14<00:07,  5.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [00:15<00:09,  4.22it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [00:15<00:08,  4.49it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [00:15<00:07,  4.81it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [00:15<00:07,  5.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [00:15<00:06,  5.31it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [00:16<00:06,  5.45it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [00:16<00:05,  5.55it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [00:16<00:05,  5.58it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [00:16<00:05,  5.61it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [00:16<00:05,  5.67it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [00:17<00:05,  5.60it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [00:17<00:04,  5.66it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [00:17<00:04,  5.70it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [00:17<00:04,  5.74it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [00:17<00:04,  5.85it/s]{'eval_loss': 0.7751855850219727, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9304029304029304, 'eval_runtime': 0.7606, 'eval_samples_per_second': 531.193, 'eval_steps_per_second': 9.204, 'epoch': 2.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.07it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.45it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [00:18<00:04,  5.85it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.45it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [00:19<00:18,  1.29it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [00:20<00:13,  1.69it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [00:20<00:10,  2.14it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [00:20<00:07,  2.65it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [00:20<00:06,  3.17it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [00:20<00:05,  3.63it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [00:20<00:04,  4.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [00:21<00:03,  4.45it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [00:21<00:03,  4.80it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [00:21<00:02,  5.07it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [00:21<00:02,  5.24it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [00:21<00:02,  5.40it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [00:21<00:02,  5.51it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [00:22<00:01,  5.60it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [00:22<00:01,  5.66it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [00:22<00:01,  5.66it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [00:22<00:01,  5.59it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [00:22<00:01,  5.64it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [00:23<00:01,  4.52it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [00:23<00:01,  4.84it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [00:23<00:00,  5.06it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [00:23<00:00,  5.27it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [00:23<00:00,  5.46it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [00:24<00:00,  5.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:24<00:00,  5.52it/s]                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:24<00:00,  5.52it/s]{'eval_loss': 0.4834398925304413, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9304776855797264, 'eval_runtime': 0.9309, 'eval_samples_per_second': 434.011, 'eval_steps_per_second': 7.52, 'epoch': 3.0}
{'loss': 0.5357, 'grad_norm': 134166.03125, 'learning_rate': 2.788156458954095e-08, 'epoch': 4.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.83it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.59it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                 
                                             [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:25<00:00,  5.52it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.59it/s][A
                                             [A                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:26<00:00,  5.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:26<00:00,  3.80it/s]
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
{'eval_loss': 0.45788145065307617, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9304776855797264, 'eval_runtime': 0.7866, 'eval_samples_per_second': 513.581, 'eval_steps_per_second': 8.899, 'epoch': 4.0}
{'train_runtime': 26.3046, 'train_samples_per_second': 123.02, 'train_steps_per_second': 3.802, 'train_loss': 1.2178112602233886, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.71it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.84it/s]
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:26,  3.68it/s]  2%|â–         | 2/100 [00:00<00:21,  4.65it/s]  3%|â–Ž         | 3/100 [00:00<00:18,  5.18it/s]  4%|â–         | 4/100 [00:00<00:17,  5.41it/s]  5%|â–Œ         | 5/100 [00:00<00:17,  5.51it/s]  6%|â–Œ         | 6/100 [00:01<00:16,  5.60it/s]  7%|â–‹         | 7/100 [00:01<00:16,  5.60it/s]  8%|â–Š         | 8/100 [00:01<00:16,  5.67it/s]  9%|â–‰         | 9/100 [00:01<00:15,  5.71it/s] 10%|â–ˆ         | 10/100 [00:01<00:15,  5.73it/s] 11%|â–ˆ         | 11/100 [00:02<00:15,  5.76it/s] 12%|â–ˆâ–        | 12/100 [00:02<00:15,  5.71it/s] 13%|â–ˆâ–Ž        | 13/100 [00:02<00:15,  5.73it/s] 14%|â–ˆâ–        | 14/100 [00:02<00:14,  5.75it/s] 15%|â–ˆâ–Œ        | 15/100 [00:02<00:14,  5.78it/s] 16%|â–ˆâ–Œ        | 16/100 [00:02<00:14,  5.79it/s] 17%|â–ˆâ–‹        | 17/100 [00:03<00:14,  5.69it/s] 18%|â–ˆâ–Š        | 18/100 [00:03<00:18,  4.44it/s] 19%|â–ˆâ–‰        | 19/100 [00:03<00:16,  4.79it/s] 20%|â–ˆâ–ˆ        | 20/100 [00:03<00:15,  5.05it/s] 21%|â–ˆâ–ˆ        | 21/100 [00:03<00:15,  5.11it/s] 22%|â–ˆâ–ˆâ–       | 22/100 [00:04<00:14,  5.34it/s] 23%|â–ˆâ–ˆâ–Ž       | 23/100 [00:04<00:14,  5.42it/s] 24%|â–ˆâ–ˆâ–       | 24/100 [00:04<00:13,  5.53it/s] 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:04<00:13,  5.64it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00, 20.00it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00, 13.10it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.24it/s][A                                                
                                             [A 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:05<00:13,  5.64it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.24it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [00:06<00:56,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 27/100 [00:06<00:42,  1.70it/s] 28%|â–ˆâ–ˆâ–Š       | 28/100 [00:07<00:33,  2.16it/s] 29%|â–ˆâ–ˆâ–‰       | 29/100 [00:07<00:26,  2.66it/s] 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:07<00:25,  2.79it/s] 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:07<00:20,  3.31it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:07<00:17,  3.80it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [00:08<00:15,  4.24it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:08<00:14,  4.56it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [00:08<00:13,  4.83it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:08<00:12,  5.07it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [00:08<00:12,  5.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [00:08<00:11,  5.37it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [00:09<00:11,  5.43it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:09<00:10,  5.59it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [00:09<00:10,  5.64it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [00:09<00:10,  5.67it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [00:09<00:09,  5.76it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [00:10<00:09,  5.77it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [00:10<00:09,  5.78it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [00:10<00:09,  5.78it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [00:10<00:11,  4.55it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [00:10<00:10,  4.75it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [00:11<00:10,  5.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:11<00:09,  5.28it/s]                                                 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:11<00:09,  5.28it/s]{'eval_loss': 1.8238922357559204, 'eval_precision': 0.007633587786259542, 'eval_recall': 0.01639344262295082, 'eval_f1': 0.010416666666666666, 'eval_accuracy': 0.8278113663845224, 'eval_runtime': 0.7635, 'eval_samples_per_second': 529.137, 'eval_steps_per_second': 9.168, 'epoch': 1.0}
{'loss': 1.8987, 'grad_norm': 587026.3125, 'learning_rate': 1.4219597940665886e-06, 'epoch': 2.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.22it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.27it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:12<00:09,  5.28it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.27it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [00:13<00:36,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [00:13<00:27,  1.72it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [00:13<00:21,  2.19it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [00:13<00:17,  2.69it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [00:13<00:14,  3.21it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [00:14<00:11,  3.70it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [00:14<00:10,  4.13it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [00:14<00:09,  4.53it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [00:14<00:08,  4.88it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [00:14<00:09,  4.16it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [00:15<00:08,  4.48it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [00:15<00:07,  4.85it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [00:15<00:07,  5.09it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [00:15<00:06,  5.19it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [00:15<00:06,  5.36it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [00:16<00:06,  5.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [00:16<00:05,  5.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [00:16<00:05,  5.60it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [00:16<00:05,  5.66it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [00:16<00:05,  5.70it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [00:16<00:05,  5.74it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [00:17<00:04,  5.75it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [00:17<00:04,  5.77it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [00:17<00:04,  5.83it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [00:17<00:04,  5.80it/s]{'eval_loss': 0.765486478805542, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9330914953647723, 'eval_runtime': 0.7672, 'eval_samples_per_second': 526.57, 'eval_steps_per_second': 9.124, 'epoch': 2.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.15it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00,  8.66it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                
                                             [A 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [00:18<00:04,  5.80it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.66it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [00:19<00:18,  1.28it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [00:19<00:13,  1.67it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [00:20<00:10,  2.12it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [00:20<00:08,  2.62it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [00:20<00:06,  3.13it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [00:20<00:05,  3.66it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [00:20<00:04,  4.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [00:21<00:03,  4.52it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [00:21<00:03,  4.84it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [00:21<00:02,  5.09it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [00:21<00:02,  5.18it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [00:21<00:02,  5.35it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [00:21<00:02,  5.41it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [00:22<00:02,  5.48it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [00:22<00:01,  5.62it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [00:22<00:01,  4.50it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [00:22<00:01,  4.79it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [00:22<00:01,  5.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [00:23<00:01,  5.19it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [00:23<00:00,  5.25it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [00:23<00:00,  5.36it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [00:23<00:00,  5.44it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [00:23<00:00,  5.53it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [00:23<00:00,  5.59it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:24<00:00,  5.72it/s]                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:24<00:00,  5.72it/s]{'eval_loss': 0.4683212339878082, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9330914953647723, 'eval_runtime': 0.9167, 'eval_samples_per_second': 440.718, 'eval_steps_per_second': 7.636, 'epoch': 3.0}
{'loss': 0.5458, 'grad_norm': 83437.171875, 'learning_rate': 2.788156458954095e-08, 'epoch': 4.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.15it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.45it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                                 
                                             [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:24<00:00,  5.72it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.45it/s][A
                                             [A                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:26<00:00,  5.72it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:26<00:00,  3.81it/s]
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
{'eval_loss': 0.4405629634857178, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9330914953647723, 'eval_runtime': 0.7647, 'eval_samples_per_second': 528.309, 'eval_steps_per_second': 9.154, 'epoch': 4.0}
{'train_runtime': 26.2475, 'train_samples_per_second': 123.288, 'train_steps_per_second': 3.81, 'train_loss': 1.222275733947754, 'epoch': 4.0}
  0%|          | 0/6 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  8.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00,  8.75it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  9.88it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.21it/s]
[I 2025-09-17 18:07:08,812] Trial 2 finished with value: 0.01602819457597984 and parameters: {'dropout': 0.1142589727861862, 'weight_decay': 0.024725823543497664, 'learning_rate': 2.2584067317528173e-06, 'warmup_ratio': 0.18817319556161027, 'num_train_epochs': 4, 'per_device_train_batch_size': 4}. Best is trial 2 with value: 0.01602819457597984.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/90 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  1%|          | 1/90 [00:00<00:35,  2.53it/s]  2%|â–         | 2/90 [00:00<00:25,  3.46it/s]  3%|â–Ž         | 3/90 [00:00<00:21,  4.03it/s]  4%|â–         | 4/90 [00:01<00:19,  4.32it/s]  6%|â–Œ         | 5/90 [00:01<00:18,  4.49it/s]  7%|â–‹         | 6/90 [00:01<00:17,  4.74it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00, 19.77it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00, 12.94it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.24it/s][A                                              
                                             [A  7%|â–‹         | 6/90 [00:02<00:17,  4.74it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.24it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  8%|â–Š         | 7/90 [00:03<01:10,  1.18it/s]  9%|â–‰         | 8/90 [00:03<00:52,  1.55it/s] 10%|â–ˆ         | 9/90 [00:03<00:41,  1.97it/s] 11%|â–ˆ         | 10/90 [00:04<00:33,  2.40it/s] 12%|â–ˆâ–        | 11/90 [00:04<00:28,  2.81it/s] 13%|â–ˆâ–Ž        | 12/90 [00:04<00:23,  3.34it/s]{'eval_loss': 2.730656385421753, 'eval_precision': 0.0049382716049382715, 'eval_recall': 0.07196401799100449, 'eval_f1': 0.009242322133436025, 'eval_accuracy': 0.09514000152590218, 'eval_runtime': 0.805, 'eval_samples_per_second': 503.126, 'eval_steps_per_second': 8.696, 'epoch': 1.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.44it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.69it/s][A                                               
                                             [A 13%|â–ˆâ–Ž        | 12/90 [00:05<00:23,  3.34it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.69it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 14%|â–ˆâ–        | 13/90 [00:06<01:10,  1.09it/s] 16%|â–ˆâ–Œ        | 14/90 [00:07<00:53,  1.43it/s] 17%|â–ˆâ–‹        | 15/90 [00:07<00:41,  1.82it/s] 18%|â–ˆâ–Š        | 16/90 [00:07<00:33,  2.22it/s] 19%|â–ˆâ–‰        | 17/90 [00:07<00:27,  2.67it/s] 20%|â–ˆâ–ˆ        | 18/90 [00:07<00:22,  3.16it/s]{'eval_loss': 2.6060445308685303, 'eval_precision': 0.004912359048788657, 'eval_recall': 0.06596701649175413, 'eval_f1': 0.00914380714879468, 'eval_accuracy': 0.16571297779812313, 'eval_runtime': 0.9634, 'eval_samples_per_second': 420.389, 'eval_steps_per_second': 7.266, 'epoch': 2.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.91it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.65it/s][A                                               
                                             [A 20%|â–ˆâ–ˆ        | 18/90 [00:08<00:22,  3.16it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.65it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 21%|â–ˆâ–ˆ        | 19/90 [00:10<01:05,  1.08it/s] 22%|â–ˆâ–ˆâ–       | 20/90 [00:10<00:49,  1.40it/s] 23%|â–ˆâ–ˆâ–Ž       | 21/90 [00:10<00:38,  1.79it/s] 24%|â–ˆâ–ˆâ–       | 22/90 [00:10<00:30,  2.22it/s] 26%|â–ˆâ–ˆâ–Œ       | 23/90 [00:11<00:25,  2.65it/s] 27%|â–ˆâ–ˆâ–‹       | 24/90 [00:11<00:21,  3.12it/s]{'eval_loss': 2.3991785049438477, 'eval_precision': 0.005352112676056338, 'eval_recall': 0.05697151424287856, 'eval_f1': 0.009784987768765288, 'eval_accuracy': 0.3365377279316396, 'eval_runtime': 0.7877, 'eval_samples_per_second': 514.18, 'eval_steps_per_second': 8.887, 'epoch': 3.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.35it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 13.22it/s][A                                               
                                             [A 27%|â–ˆâ–ˆâ–‹       | 24/90 [00:12<00:21,  3.12it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 13.22it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 28%|â–ˆâ–ˆâ–Š       | 25/90 [00:13<00:57,  1.14it/s] 29%|â–ˆâ–ˆâ–‰       | 26/90 [00:13<00:43,  1.48it/s] 30%|â–ˆâ–ˆâ–ˆ       | 27/90 [00:13<00:33,  1.87it/s] 31%|â–ˆâ–ˆâ–ˆ       | 28/90 [00:14<00:26,  2.31it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 29/90 [00:14<00:22,  2.73it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 30/90 [00:14<00:18,  3.21it/s]{'eval_loss': 2.110846757888794, 'eval_precision': 0.00751684810782789, 'eval_recall': 0.043478260869565216, 'eval_f1': 0.012817679558011049, 'eval_accuracy': 0.6273746852826734, 'eval_runtime': 0.7835, 'eval_samples_per_second': 516.891, 'eval_steps_per_second': 8.934, 'epoch': 4.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  8.86it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00,  9.53it/s][A                                               
                                             [A 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 30/90 [00:15<00:18,  3.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  9.53it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 34%|â–ˆâ–ˆâ–ˆâ–      | 31/90 [00:16<00:53,  1.10it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 32/90 [00:16<00:40,  1.43it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 33/90 [00:17<00:31,  1.80it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 34/90 [00:17<00:25,  2.22it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 35/90 [00:17<00:20,  2.65it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 36/90 [00:17<00:17,  3.18it/s]{'eval_loss': 1.783521056175232, 'eval_precision': 0.013942680092951201, 'eval_recall': 0.026986506746626688, 'eval_f1': 0.018386108273748723, 'eval_accuracy': 0.8366521705958648, 'eval_runtime': 0.9438, 'eval_samples_per_second': 429.134, 'eval_steps_per_second': 7.417, 'epoch': 5.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.02it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.79it/s][A                                               
                                             [A 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 36/90 [00:18<00:17,  3.18it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.79it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 37/90 [00:19<00:45,  1.16it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 38/90 [00:20<00:34,  1.51it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 39/90 [00:20<00:29,  1.76it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/90 [00:20<00:23,  2.16it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 41/90 [00:20<00:18,  2.60it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 42/90 [00:21<00:15,  3.10it/s]{'eval_loss': 1.5063401460647583, 'eval_precision': 0.01644736842105263, 'eval_recall': 0.0074962518740629685, 'eval_f1': 0.010298661174047374, 'eval_accuracy': 0.9073777370870527, 'eval_runtime': 0.7598, 'eval_samples_per_second': 533.045, 'eval_steps_per_second': 9.213, 'epoch': 6.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.58it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 13.33it/s][A                                               
                                             [A 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 42/90 [00:21<00:15,  3.10it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 13.33it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 43/90 [00:23<00:39,  1.19it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 44/90 [00:23<00:30,  1.52it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 45/90 [00:23<00:23,  1.92it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 46/90 [00:23<00:18,  2.36it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 47/90 [00:23<00:15,  2.79it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 48/90 [00:24<00:12,  3.29it/s]{'eval_loss': 1.2761636972427368, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.923552300297551, 'eval_runtime': 0.7393, 'eval_samples_per_second': 547.802, 'eval_steps_per_second': 9.468, 'epoch': 7.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.21it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00,  8.70it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 48/90 [00:25<00:12,  3.29it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.70it/s][A
                                             [A                                                53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 48/90 [00:26<00:12,  3.29it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 48/90 [00:26<00:23,  1.82it/s]
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
{'eval_loss': 1.0947613716125488, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9275959411001755, 'eval_runtime': 0.9024, 'eval_samples_per_second': 448.799, 'eval_steps_per_second': 7.757, 'epoch': 8.0}
{'train_runtime': 26.3576, 'train_samples_per_second': 459.829, 'train_steps_per_second': 3.415, 'train_loss': 1.7045292854309082, 'epoch': 8.0}
  0%|          | 0/6 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.39it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.29it/s]
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/90 [00:00<?, ?it/s]  1%|          | 1/90 [00:00<00:34,  2.57it/s]  2%|â–         | 2/90 [00:00<00:25,  3.43it/s]  3%|â–Ž         | 3/90 [00:00<00:21,  4.01it/s]  4%|â–         | 4/90 [00:01<00:19,  4.35it/s]  6%|â–Œ         | 5/90 [00:01<00:18,  4.50it/s]  7%|â–‹         | 6/90 [00:01<00:17,  4.87it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.47it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 13.29it/s][A                                              
                                             [A  7%|â–‹         | 6/90 [00:02<00:17,  4.87it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 13.29it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  8%|â–Š         | 7/90 [00:03<01:13,  1.13it/s]  9%|â–‰         | 8/90 [00:03<00:54,  1.50it/s] 10%|â–ˆ         | 9/90 [00:04<00:42,  1.93it/s] 11%|â–ˆ         | 10/90 [00:04<00:33,  2.37it/s] 12%|â–ˆâ–        | 11/90 [00:04<00:28,  2.82it/s] 13%|â–ˆâ–Ž        | 12/90 [00:04<00:27,  2.89it/s]{'eval_loss': 2.7413809299468994, 'eval_precision': 0.006176589712434184, 'eval_recall': 0.08815028901734104, 'eval_f1': 0.0115442846328539, 'eval_accuracy': 0.09299543993421544, 'eval_runtime': 0.7908, 'eval_samples_per_second': 510.879, 'eval_steps_per_second': 8.852, 'epoch': 1.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00, 18.82it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00, 12.83it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.16it/s][A                                               
                                             [A 13%|â–ˆâ–Ž        | 12/90 [00:05<00:27,  2.89it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.16it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 14%|â–ˆâ–        | 13/90 [00:06<01:09,  1.10it/s] 16%|â–ˆâ–Œ        | 14/90 [00:07<00:52,  1.44it/s] 17%|â–ˆâ–‹        | 15/90 [00:07<00:40,  1.83it/s] 18%|â–ˆâ–Š        | 16/90 [00:07<00:32,  2.26it/s] 19%|â–ˆâ–‰        | 17/90 [00:07<00:27,  2.67it/s] 20%|â–ˆâ–ˆ        | 18/90 [00:08<00:22,  3.15it/s]{'eval_loss': 2.6168265342712402, 'eval_precision': 0.006005022382356152, 'eval_recall': 0.07947976878612717, 'eval_f1': 0.011166379047812406, 'eval_accuracy': 0.1597518128130373, 'eval_runtime': 0.8161, 'eval_samples_per_second': 495.032, 'eval_steps_per_second': 8.577, 'epoch': 2.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.10it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.89it/s][A                                               
                                             [A 20%|â–ˆâ–ˆ        | 18/90 [00:08<00:22,  3.15it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.89it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 21%|â–ˆâ–ˆ        | 19/90 [00:10<01:05,  1.08it/s] 22%|â–ˆâ–ˆâ–       | 20/90 [00:10<00:49,  1.42it/s] 23%|â–ˆâ–ˆâ–Ž       | 21/90 [00:10<00:38,  1.80it/s] 24%|â–ˆâ–ˆâ–       | 22/90 [00:10<00:30,  2.20it/s] 26%|â–ˆâ–ˆâ–Œ       | 23/90 [00:11<00:25,  2.63it/s] 27%|â–ˆâ–ˆâ–‹       | 24/90 [00:11<00:21,  3.14it/s]{'eval_loss': 2.4068892002105713, 'eval_precision': 0.006727996704654675, 'eval_recall': 0.0708092485549133, 'eval_f1': 0.012288401253918493, 'eval_accuracy': 0.33325857815653737, 'eval_runtime': 0.7957, 'eval_samples_per_second': 507.703, 'eval_steps_per_second': 8.797, 'epoch': 3.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.90it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.59it/s][A                                               
                                             [A 27%|â–ˆâ–ˆâ–‹       | 24/90 [00:12<00:21,  3.14it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.59it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 28%|â–ˆâ–ˆâ–Š       | 25/90 [00:13<00:58,  1.11it/s] 29%|â–ˆâ–ˆâ–‰       | 26/90 [00:13<00:44,  1.45it/s] 30%|â–ˆâ–ˆâ–ˆ       | 27/90 [00:14<00:34,  1.83it/s] 31%|â–ˆâ–ˆâ–ˆ       | 28/90 [00:14<00:27,  2.26it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 29/90 [00:14<00:22,  2.67it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 30/90 [00:14<00:18,  3.16it/s]{'eval_loss': 2.1188061237335205, 'eval_precision': 0.008223274358335409, 'eval_recall': 0.0476878612716763, 'eval_f1': 0.01402763018065887, 'eval_accuracy': 0.6165059430365553, 'eval_runtime': 0.792, 'eval_samples_per_second': 510.104, 'eval_steps_per_second': 8.838, 'epoch': 4.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00,  7.48it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00,  9.07it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 10.19it/s][A                                               
                                             [A 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 30/90 [00:15<00:18,  3.16it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 10.19it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 34%|â–ˆâ–ˆâ–ˆâ–      | 31/90 [00:16<00:54,  1.09it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 32/90 [00:17<00:40,  1.42it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 33/90 [00:17<00:31,  1.81it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 34/90 [00:17<00:25,  2.22it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 35/90 [00:17<00:20,  2.67it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 36/90 [00:17<00:17,  3.18it/s]{'eval_loss': 1.7931400537490845, 'eval_precision': 0.012408759124087591, 'eval_recall': 0.024566473988439308, 'eval_f1': 0.016488845780795344, 'eval_accuracy': 0.8293339313747476, 'eval_runtime': 0.9378, 'eval_samples_per_second': 430.818, 'eval_steps_per_second': 7.465, 'epoch': 5.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.81it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 13.12it/s][A                                               
                                             [A 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 36/90 [00:18<00:17,  3.18it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 13.12it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 37/90 [00:20<00:45,  1.16it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 38/90 [00:20<00:36,  1.41it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 39/90 [00:20<00:28,  1.80it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/90 [00:20<00:22,  2.22it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 41/90 [00:21<00:18,  2.65it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 42/90 [00:21<00:15,  3.15it/s]{'eval_loss': 1.5152610540390015, 'eval_precision': 0.01764705882352941, 'eval_recall': 0.008670520231213872, 'eval_f1': 0.011627906976744186, 'eval_accuracy': 0.9058832324138446, 'eval_runtime': 0.7532, 'eval_samples_per_second': 536.351, 'eval_steps_per_second': 9.293, 'epoch': 6.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.81it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.96it/s][A                                               
                                             [A 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 42/90 [00:21<00:15,  3.15it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.96it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 43/90 [00:23<00:40,  1.16it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 44/90 [00:23<00:30,  1.50it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 45/90 [00:23<00:23,  1.88it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 46/90 [00:23<00:19,  2.30it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 47/90 [00:24<00:15,  2.71it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 48/90 [00:24<00:13,  3.20it/s]{'eval_loss': 1.2857162952423096, 'eval_precision': 0.03125, 'eval_recall': 0.004335260115606936, 'eval_f1': 0.0076142131979695426, 'eval_accuracy': 0.924198250728863, 'eval_runtime': 0.7615, 'eval_samples_per_second': 530.508, 'eval_steps_per_second': 9.192, 'epoch': 7.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  8.69it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00,  9.34it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 48/90 [00:25<00:13,  3.20it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  9.34it/s][A
                                             [A                                                53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 48/90 [00:26<00:13,  3.20it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 48/90 [00:26<00:23,  1.80it/s]
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
{'eval_loss': 1.1042035818099976, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9286088061598265, 'eval_runtime': 0.9433, 'eval_samples_per_second': 428.281, 'eval_steps_per_second': 7.421, 'epoch': 8.0}
{'train_runtime': 26.6569, 'train_samples_per_second': 455.23, 'train_steps_per_second': 3.376, 'train_loss': 1.703969955444336, 'epoch': 8.0}
  0%|          | 0/6 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.13it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.95it/s]
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/90 [00:00<?, ?it/s]  1%|          | 1/90 [00:00<00:34,  2.55it/s]  2%|â–         | 2/90 [00:00<00:26,  3.37it/s]  3%|â–Ž         | 3/90 [00:00<00:21,  3.96it/s]  4%|â–         | 4/90 [00:01<00:19,  4.32it/s]  6%|â–Œ         | 5/90 [00:01<00:18,  4.50it/s]  7%|â–‹         | 6/90 [00:01<00:17,  4.84it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.96it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 13.09it/s][A                                              
                                             [A  7%|â–‹         | 6/90 [00:02<00:17,  4.84it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 13.09it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  8%|â–Š         | 7/90 [00:03<01:12,  1.15it/s]  9%|â–‰         | 8/90 [00:03<00:54,  1.51it/s] 10%|â–ˆ         | 9/90 [00:04<00:42,  1.92it/s] 11%|â–ˆ         | 10/90 [00:04<00:33,  2.36it/s] 12%|â–ˆâ–        | 11/90 [00:04<00:28,  2.80it/s] 13%|â–ˆâ–Ž        | 12/90 [00:04<00:27,  2.87it/s]{'eval_loss': 2.734332323074341, 'eval_precision': 0.005215123859191656, 'eval_recall': 0.07868852459016394, 'eval_f1': 0.00978194416140208, 'eval_accuracy': 0.0860137041515518, 'eval_runtime': 0.7808, 'eval_samples_per_second': 517.401, 'eval_steps_per_second': 8.965, 'epoch': 1.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.58it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.87it/s][A                                               
                                             [A 13%|â–ˆâ–Ž        | 12/90 [00:05<00:27,  2.87it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.87it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 14%|â–ˆâ–        | 13/90 [00:06<01:09,  1.12it/s] 16%|â–ˆâ–Œ        | 14/90 [00:07<00:52,  1.46it/s] 17%|â–ˆâ–‹        | 15/90 [00:07<00:40,  1.85it/s] 18%|â–ˆâ–Š        | 16/90 [00:07<00:32,  2.26it/s] 19%|â–ˆâ–‰        | 17/90 [00:07<00:27,  2.66it/s] 20%|â–ˆâ–ˆ        | 18/90 [00:07<00:22,  3.19it/s]{'eval_loss': 2.611729145050049, 'eval_precision': 0.005143792377834931, 'eval_recall': 0.07213114754098361, 'eval_f1': 0.009602793539938894, 'eval_accuracy': 0.15114873035066506, 'eval_runtime': 0.7831, 'eval_samples_per_second': 515.892, 'eval_steps_per_second': 8.939, 'epoch': 2.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.15it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.98it/s][A                                               
                                             [A 20%|â–ˆâ–ˆ        | 18/90 [00:08<00:22,  3.19it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.98it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 21%|â–ˆâ–ˆ        | 19/90 [00:10<01:04,  1.11it/s] 22%|â–ˆâ–ˆâ–       | 20/90 [00:10<00:48,  1.43it/s] 23%|â–ˆâ–ˆâ–Ž       | 21/90 [00:10<00:38,  1.81it/s] 24%|â–ˆâ–ˆâ–       | 22/90 [00:10<00:30,  2.23it/s] 26%|â–ˆâ–ˆâ–Œ       | 23/90 [00:11<00:25,  2.67it/s] 27%|â–ˆâ–ˆâ–‹       | 24/90 [00:11<00:20,  3.16it/s]{'eval_loss': 2.405742645263672, 'eval_precision': 0.005885815185403178, 'eval_recall': 0.06557377049180328, 'eval_f1': 0.01080205238995409, 'eval_accuracy': 0.324385328496574, 'eval_runtime': 0.7773, 'eval_samples_per_second': 519.75, 'eval_steps_per_second': 9.006, 'epoch': 3.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.76it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.75it/s][A                                               
                                             [A 27%|â–ˆâ–ˆâ–‹       | 24/90 [00:12<00:20,  3.16it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.75it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 28%|â–ˆâ–ˆâ–Š       | 25/90 [00:13<00:56,  1.15it/s] 29%|â–ˆâ–ˆâ–‰       | 26/90 [00:13<00:42,  1.49it/s] 30%|â–ˆâ–ˆâ–ˆ       | 27/90 [00:13<00:33,  1.87it/s] 31%|â–ˆâ–ˆâ–ˆ       | 28/90 [00:14<00:26,  2.30it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 29/90 [00:14<00:22,  2.73it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 30/90 [00:14<00:18,  3.24it/s]{'eval_loss': 2.122593641281128, 'eval_precision': 0.006498781478472786, 'eval_recall': 0.03934426229508197, 'eval_f1': 0.011155008133860096, 'eval_accuracy': 0.6199919387343813, 'eval_runtime': 0.768, 'eval_samples_per_second': 526.075, 'eval_steps_per_second': 9.115, 'epoch': 4.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00, 19.29it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00, 12.66it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 11.91it/s][A                                               
                                             [A 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 30/90 [00:15<00:18,  3.24it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 11.91it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 34%|â–ˆâ–ˆâ–ˆâ–      | 31/90 [00:16<00:53,  1.10it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 32/90 [00:16<00:40,  1.43it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 33/90 [00:17<00:31,  1.82it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 34/90 [00:17<00:25,  2.24it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 35/90 [00:17<00:20,  2.67it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 36/90 [00:17<00:17,  3.15it/s]{'eval_loss': 1.800925612449646, 'eval_precision': 0.009316770186335404, 'eval_recall': 0.019672131147540985, 'eval_f1': 0.012644889357218126, 'eval_accuracy': 0.8310358726320032, 'eval_runtime': 0.9369, 'eval_samples_per_second': 431.229, 'eval_steps_per_second': 7.472, 'epoch': 5.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.75it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.77it/s][A                                               
                                             [A 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 36/90 [00:18<00:17,  3.15it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.77it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 37/90 [00:20<00:48,  1.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 38/90 [00:20<00:36,  1.43it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 39/90 [00:20<00:30,  1.67it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/90 [00:20<00:24,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 41/90 [00:21<00:19,  2.51it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 42/90 [00:21<00:15,  3.02it/s]{'eval_loss': 1.5260419845581055, 'eval_precision': 0.017804154302670624, 'eval_recall': 0.009836065573770493, 'eval_f1': 0.012671594508975714, 'eval_accuracy': 0.9079403466344216, 'eval_runtime': 0.9084, 'eval_samples_per_second': 444.734, 'eval_steps_per_second': 7.706, 'epoch': 6.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 15.73it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.84it/s][A                                               
                                             [A 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 42/90 [00:21<00:15,  3.02it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.84it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 43/90 [00:23<00:40,  1.16it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 44/90 [00:23<00:30,  1.51it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 45/90 [00:23<00:23,  1.90it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 46/90 [00:23<00:18,  2.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 47/90 [00:24<00:15,  2.73it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 48/90 [00:24<00:13,  3.22it/s]{'eval_loss': 1.2988282442092896, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9264006449012495, 'eval_runtime': 0.7528, 'eval_samples_per_second': 536.69, 'eval_steps_per_second': 9.299, 'epoch': 7.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  8.29it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00,  9.27it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 48/90 [00:25<00:13,  3.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  9.27it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 49/90 [00:26<00:37,  1.11it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 50/90 [00:26<00:27,  1.44it/s]                                                56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 50/90 [00:26<00:27,  1.44it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 51/90 [00:27<00:21,  1.83it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 52/90 [00:27<00:16,  2.25it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 53/90 [00:27<00:13,  2.66it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 54/90 [00:27<00:11,  3.17it/s]{'eval_loss': 1.1182891130447388, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9309149536477227, 'eval_runtime': 0.9202, 'eval_samples_per_second': 439.013, 'eval_steps_per_second': 7.607, 'epoch': 8.0}
{'loss': 1.6583, 'grad_norm': 101658.6328125, 'learning_rate': 1.7941088717181734e-06, 'epoch': 8.33}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00, 16.01it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00, 12.78it/s][A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                                               
                                             [A 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 54/90 [00:28<00:11,  3.17it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.78it/s][A
                                             [A                                                60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 54/90 [00:29<00:11,  3.17it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 54/90 [00:29<00:19,  1.82it/s]
/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
{'eval_loss': 0.9929837584495544, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.932285368802902, 'eval_runtime': 0.7549, 'eval_samples_per_second': 535.196, 'eval_steps_per_second': 9.273, 'epoch': 9.0}
{'train_runtime': 29.7129, 'train_samples_per_second': 408.408, 'train_steps_per_second': 3.029, 'train_loss': 1.5720667309231229, 'epoch': 9.0}
  0%|          | 0/6 [00:00<?, ?it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00, 18.18it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00,  8.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  9.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.28it/s]
[I 2025-09-17 18:08:41,557] Trial 3 finished with value: 0.01584884952117326 and parameters: {'dropout': 0.4053534124125632, 'weight_decay': 0.12160529727071716, 'learning_rate': 2.844318942967836e-06, 'warmup_ratio': 0.2719244107115406, 'num_train_epochs': 15, 'per_device_train_batch_size': 16}. Best is trial 2 with value: 0.01602819457597984.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Retrying in 1s [Retry 1/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Retrying in 2s [Retry 2/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Retrying in 4s [Retry 3/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Retrying in 8s [Retry 4/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Retrying in 8s [Retry 5/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Retrying in 1s [Retry 1/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Retrying in 2s [Retry 2/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Retrying in 4s [Retry 3/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Retrying in 8s [Retry 4/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Retrying in 8s [Retry 5/5].
HTTP Error 429 thrown while requesting HEAD https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json
Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/600 [00:00<?, ?it/s]/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  0%|          | 1/600 [00:00<03:03,  3.26it/s]  0%|          | 2/600 [00:00<02:17,  4.35it/s]  0%|          | 3/600 [00:00<02:00,  4.96it/s]  1%|          | 4/600 [00:00<01:52,  5.30it/s]  1%|          | 5/600 [00:00<01:46,  5.57it/s]  1%|          | 6/600 [00:01<01:44,  5.70it/s]  1%|          | 7/600 [00:01<01:41,  5.82it/s]  1%|â–         | 8/600 [00:01<01:40,  5.86it/s]  2%|â–         | 9/600 [00:01<01:39,  5.94it/s]  2%|â–         | 10/600 [00:01<01:38,  6.00it/s]  2%|â–         | 11/600 [00:01<01:37,  6.05it/s]  2%|â–         | 12/600 [00:02<01:37,  6.03it/s]  2%|â–         | 13/600 [00:02<01:38,  5.98it/s]  2%|â–         | 14/600 [00:02<01:39,  5.91it/s]  2%|â–Ž         | 15/600 [00:02<01:37,  5.98it/s]  3%|â–Ž         | 16/600 [00:02<01:36,  6.02it/s]  3%|â–Ž         | 17/600 [00:02<01:36,  6.05it/s]  3%|â–Ž         | 18/600 [00:03<02:02,  4.74it/s]  3%|â–Ž         | 19/600 [00:03<01:54,  5.07it/s]  3%|â–Ž         | 20/600 [00:03<01:48,  5.35it/s]  4%|â–Ž         | 21/600 [00:03<01:43,  5.61it/s]  4%|â–Ž         | 22/600 [00:03<01:40,  5.76it/s]  4%|â–         | 23/600 [00:04<01:37,  5.94it/s]  4%|â–         | 24/600 [00:04<01:36,  6.00it/s]  4%|â–         | 25/600 [00:04<01:34,  6.10it/s]  4%|â–         | 26/600 [00:04<01:33,  6.16it/s]  4%|â–         | 27/600 [00:04<01:32,  6.18it/s]  5%|â–         | 28/600 [00:04<01:32,  6.20it/s]  5%|â–         | 29/600 [00:05<01:33,  6.14it/s]  5%|â–Œ         | 30/600 [00:05<01:31,  6.21it/s]  5%|â–Œ         | 31/600 [00:05<01:30,  6.26it/s]  5%|â–Œ         | 32/600 [00:05<01:32,  6.14it/s]  6%|â–Œ         | 33/600 [00:05<01:31,  6.23it/s]  6%|â–Œ         | 34/600 [00:05<01:29,  6.30it/s]  6%|â–Œ         | 35/600 [00:06<01:55,  4.91it/s]  6%|â–Œ         | 36/600 [00:06<01:47,  5.27it/s]  6%|â–Œ         | 37/600 [00:06<01:42,  5.47it/s]  6%|â–‹         | 38/600 [00:06<01:37,  5.78it/s]  6%|â–‹         | 39/600 [00:06<01:34,  5.97it/s]  7%|â–‹         | 40/600 [00:06<01:31,  6.10it/s]  7%|â–‹         | 41/600 [00:07<01:31,  6.13it/s]  7%|â–‹         | 42/600 [00:07<01:31,  6.08it/s]  7%|â–‹         | 43/600 [00:07<01:29,  6.22it/s]  7%|â–‹         | 44/600 [00:07<01:29,  6.22it/s]  8%|â–Š         | 45/600 [00:07<01:28,  6.28it/s]  8%|â–Š         | 46/600 [00:07<01:28,  6.28it/s]  8%|â–Š         | 47/600 [00:08<01:27,  6.32it/s]  8%|â–Š         | 48/600 [00:08<01:27,  6.34it/s]  8%|â–Š         | 49/600 [00:08<01:26,  6.37it/s]  8%|â–Š         | 50/600 [00:08<01:24,  6.51it/s]                                                  8%|â–Š         | 50/600 [00:08<01:24,  6.51it/s]{'loss': 2.7399, 'grad_norm': 1110495.5, 'learning_rate': 7.292898648178149e-07, 'epoch': 1.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  8.59it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00,  9.60it/s][A                                                
                                             [A  8%|â–Š         | 50/600 [00:09<01:24,  6.51it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  9.60it/s][A
                                             [A/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  8%|â–Š         | 51/600 [00:10<07:03,  1.30it/s]  9%|â–Š         | 52/600 [00:10<05:23,  1.69it/s]  9%|â–‰         | 53/600 [00:11<04:12,  2.17it/s]  9%|â–‰         | 54/600 [00:11<03:20,  2.72it/s]  9%|â–‰         | 55/600 [00:11<02:48,  3.24it/s]  9%|â–‰         | 56/600 [00:11<02:24,  3.76it/s] 10%|â–‰         | 57/600 [00:11<02:08,  4.22it/s] 10%|â–‰         | 58/600 [00:11<01:55,  4.70it/s] 10%|â–‰         | 59/600 [00:12<01:46,  5.07it/s] 10%|â–ˆ         | 60/600 [00:12<01:39,  5.41it/s] 10%|â–ˆ         | 61/600 [00:12<01:35,  5.67it/s] 10%|â–ˆ         | 62/600 [00:12<01:31,  5.86it/s] 10%|â–ˆ         | 63/600 [00:12<01:29,  6.01it/s] 11%|â–ˆ         | 64/600 [00:12<01:27,  6.11it/s] 11%|â–ˆ         | 65/600 [00:12<01:26,  6.20it/s] 11%|â–ˆ         | 66/600 [00:13<01:49,  4.86it/s] 11%|â–ˆ         | 67/600 [00:13<01:42,  5.21it/s] 11%|â–ˆâ–        | 68/600 [00:13<01:38,  5.38it/s] 12%|â–ˆâ–        | 69/600 [00:13<01:35,  5.54it/s] 12%|â–ˆâ–        | 70/600 [00:13<01:31,  5.81it/s] 12%|â–ˆâ–        | 71/600 [00:14<01:30,  5.84it/s] 12%|â–ˆâ–        | 72/600 [00:14<01:28,  5.99it/s] 12%|â–ˆâ–        | 73/600 [00:14<01:28,  5.97it/s] 12%|â–ˆâ–        | 74/600 [00:14<01:27,  6.01it/s] 12%|â–ˆâ–Ž        | 75/600 [00:14<01:26,  6.07it/s] 13%|â–ˆâ–Ž        | 76/600 [00:14<01:24,  6.17it/s] 13%|â–ˆâ–Ž        | 77/600 [00:15<01:23,  6.25it/s] 13%|â–ˆâ–Ž        | 78/600 [00:15<01:22,  6.31it/s] 13%|â–ˆâ–Ž        | 79/600 [00:15<01:22,  6.33it/s] 13%|â–ˆâ–Ž        | 80/600 [00:15<01:23,  6.19it/s] 14%|â–ˆâ–Ž        | 81/600 [00:15<01:22,  6.32it/s] 14%|â–ˆâ–Ž        | 82/600 [00:15<01:23,  6.22it/s] 14%|â–ˆâ–        | 83/600 [00:16<01:22,  6.26it/s] 14%|â–ˆâ–        | 84/600 [00:16<01:46,  4.86it/s] 14%|â–ˆâ–        | 85/600 [00:16<01:39,  5.15it/s] 14%|â–ˆâ–        | 86/600 [00:16<01:36,  5.35it/s] 14%|â–ˆâ–        | 87/600 [00:16<01:31,  5.62it/s] 15%|â–ˆâ–        | 88/600 [00:16<01:27,  5.83it/s] 15%|â–ˆâ–        | 89/600 [00:17<01:25,  5.95it/s] 15%|â–ˆâ–Œ        | 90/600 [00:17<01:24,  6.07it/s] 15%|â–ˆâ–Œ        | 91/600 [00:17<01:23,  6.11it/s] 15%|â–ˆâ–Œ        | 92/600 [00:17<01:23,  6.10it/s] 16%|â–ˆâ–Œ        | 93/600 [00:17<01:24,  6.03it/s] 16%|â–ˆâ–Œ        | 94/600 [00:17<01:22,  6.14it/s] 16%|â–ˆâ–Œ        | 95/600 [00:18<01:21,  6.20it/s] 16%|â–ˆâ–Œ        | 96/600 [00:18<01:21,  6.18it/s] 16%|â–ˆâ–Œ        | 97/600 [00:18<01:22,  6.10it/s] 16%|â–ˆâ–‹        | 98/600 [00:18<01:21,  6.18it/s] 16%|â–ˆâ–‹        | 99/600 [00:18<01:20,  6.23it/s] 17%|â–ˆâ–‹        | 100/600 [00:18<01:18,  6.33it/s]                                                  17%|â–ˆâ–‹        | 100/600 [00:18<01:18,  6.33it/s]{'eval_loss': 2.3716113567352295, 'eval_precision': 0.005473372781065089, 'eval_recall': 0.05547226386806597, 'eval_f1': 0.0099636461559176, 'eval_accuracy': 0.3672083619439994, 'eval_runtime': 0.9381, 'eval_samples_per_second': 431.734, 'eval_steps_per_second': 7.462, 'epoch': 1.0}
{'loss': 1.7236, 'grad_norm': 1248261.875, 'learning_rate': 1.18039107345542e-06, 'epoch': 2.0}

  0%|          | 0/6 [00:00<?, ?it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00, 18.89it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00, 12.56it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 11.84it/s][A                                                 
                                             [A 17%|â–ˆâ–‹        | 100/600 [00:19<01:18,  6.33it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 11.84it/s][A
                                             [A[W 2025-09-17 18:09:49,815] Trial 4 failed with parameters: {'dropout': 0.3431762997131764, 'weight_decay': 0.05267282263947079, 'learning_rate': 1.2204442635726698e-06, 'warmup_ratio': 0.13583389628579892, 'num_train_epochs': 12, 'per_device_train_batch_size': 2} because of the following error: RuntimeError('Parent directory /lustre/scratch/data/s27mhusa_hpc-murtuza_master_thesis/Scibert-results-broad_focal_loss/hyperparameter_search_regularized/trial_4/checkpoint-100 does not exist.').
Traceback (most recent call last):
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "/home/s27mhusa_hpc/Master-Thesis/Fine-tune/fine-tune-scibert-specific-reg_broad-17sept.py", line 448, in objective
    trainer.train()
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/transformers/trainer.py", line 2238, in train
    return inner_training_loop(
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/transformers/trainer.py", line 2698, in _inner_training_loop
    self._maybe_log_save_evaluate(
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/transformers/trainer.py", line 3144, in _maybe_log_save_evaluate
    self._save_checkpoint(model, trial)
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/transformers/trainer.py", line 3252, in _save_checkpoint
    self._save_optimizer_and_scheduler(output_dir)
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/transformers/trainer.py", line 3391, in _save_optimizer_and_scheduler
    torch.save(self.lr_scheduler.state_dict(), os.path.join(output_dir, SCHEDULER_NAME))
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/serialization.py", line 966, in save
    with _open_zipfile_writer(f) as opened_zipfile:
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/serialization.py", line 828, in _open_zipfile_writer
    return container(name_or_buffer)  # type: ignore[arg-type]
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/serialization.py", line 792, in __init__
    torch._C.PyTorchFileWriter(
RuntimeError: Parent directory /lustre/scratch/data/s27mhusa_hpc-murtuza_master_thesis/Scibert-results-broad_focal_loss/hyperparameter_search_regularized/trial_4/checkpoint-100 does not exist.
[W 2025-09-17 18:09:49,819] Trial 4 failed with value None.
{'eval_loss': 1.2989107370376587, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9234760051880675, 'eval_runtime': 0.9364, 'eval_samples_per_second': 432.487, 'eval_steps_per_second': 7.475, 'epoch': 2.0}
Traceback (most recent call last):
  File "/home/s27mhusa_hpc/Master-Thesis/Fine-tune/fine-tune-scibert-specific-reg_broad-17sept.py", line 463, in <module>
    study.optimize(objective, n_trials=10)  # Reduced trials for faster testing
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/optuna/study/study.py", line 475, in optimize
    _optimize(
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/optuna/study/_optimize.py", line 63, in _optimize
    _optimize_sequential(
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/optuna/study/_optimize.py", line 160, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/optuna/study/_optimize.py", line 248, in _run_trial
    raise func_err
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "/home/s27mhusa_hpc/Master-Thesis/Fine-tune/fine-tune-scibert-specific-reg_broad-17sept.py", line 448, in objective
    trainer.train()
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/transformers/trainer.py", line 2238, in train
    return inner_training_loop(
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/transformers/trainer.py", line 2698, in _inner_training_loop
    self._maybe_log_save_evaluate(
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/transformers/trainer.py", line 3144, in _maybe_log_save_evaluate
    self._save_checkpoint(model, trial)
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/transformers/trainer.py", line 3252, in _save_checkpoint
    self._save_optimizer_and_scheduler(output_dir)
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/transformers/trainer.py", line 3391, in _save_optimizer_and_scheduler
    torch.save(self.lr_scheduler.state_dict(), os.path.join(output_dir, SCHEDULER_NAME))
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/serialization.py", line 966, in save
    with _open_zipfile_writer(f) as opened_zipfile:
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/serialization.py", line 828, in _open_zipfile_writer
    return container(name_or_buffer)  # type: ignore[arg-type]
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/serialization.py", line 792, in __init__
    torch._C.PyTorchFileWriter(
RuntimeError: Parent directory /lustre/scratch/data/s27mhusa_hpc-murtuza_master_thesis/Scibert-results-broad_focal_loss/hyperparameter_search_regularized/trial_4/checkpoint-100 does not exist.
Traceback (most recent call last):
  File "/home/s27mhusa_hpc/Master-Thesis/Fine-tune/fine-tune-scibert-specific-reg_broad-17sept.py", line 463, in <module>
    study.optimize(objective, n_trials=10)  # Reduced trials for faster testing
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/optuna/study/study.py", line 475, in optimize
    _optimize(
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/optuna/study/_optimize.py", line 63, in _optimize
    _optimize_sequential(
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/optuna/study/_optimize.py", line 160, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/optuna/study/_optimize.py", line 248, in _run_trial
    raise func_err
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "/home/s27mhusa_hpc/Master-Thesis/Fine-tune/fine-tune-scibert-specific-reg_broad-17sept.py", line 448, in objective
    trainer.train()
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/transformers/trainer.py", line 2238, in train
    return inner_training_loop(
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/transformers/trainer.py", line 2698, in _inner_training_loop
    self._maybe_log_save_evaluate(
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/transformers/trainer.py", line 3144, in _maybe_log_save_evaluate
    self._save_checkpoint(model, trial)
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/transformers/trainer.py", line 3252, in _save_checkpoint
    self._save_optimizer_and_scheduler(output_dir)
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/transformers/trainer.py", line 3391, in _save_optimizer_and_scheduler
    torch.save(self.lr_scheduler.state_dict(), os.path.join(output_dir, SCHEDULER_NAME))
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/serialization.py", line 966, in save
    with _open_zipfile_writer(f) as opened_zipfile:
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/serialization.py", line 828, in _open_zipfile_writer
    return container(name_or_buffer)  # type: ignore[arg-type]
  File "/home/s27mhusa_hpc/.conda/envs/Llama/lib/python3.9/site-packages/torch/serialization.py", line 792, in __init__
    torch._C.PyTorchFileWriter(
RuntimeError: Parent directory /lustre/scratch/data/s27mhusa_hpc-murtuza_master_thesis/Scibert-results-broad_focal_loss/hyperparameter_search_regularized/trial_4/checkpoint-100 does not exist.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mmisty-cosmos-755[0m at: [34mhttps://wandb.ai/murtuzanh-university-bonn/huggingface/runs/ckb0nld0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250917_180343-ckb0nld0/logs[0m
Stopping resource monitoring...
job-finetune-generic-bash-scibert.bash: line 58: kill: (2255919) - No such process
Total GPU execution time: 426 seconds
Fetching SLURM job summary...
JobID           Elapsed     MaxRSS    CPUTime ExitCode 
------------ ---------- ---------- ---------- -------- 
23235181     6-00:29:54            1541-07:34:24      0:0 
23235181.ex+ 6-00:29:54            1541-07:34:24      0:0 
23235181.0   6-00:29:41            1541-06:38:56      0:0 
All logs are saved in: /home/s27mhusa_hpc/Master-Thesis/OutputNewDatasets15thSeptemberFineTune/job_monitor_logs_scibert-specific_23235181_20250917_180246
